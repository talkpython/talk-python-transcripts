1
00:00:00,020 --> 00:00:02,440
Michael Kennedy: So, hey Hugo, welcome to Talk Python.

2
00:00:04,140 --> 00:00:08,040
Hugo Bowne-Anderson: Michael, it's such a pleasure to be here and to be back.

3
00:00:08,040 --> 00:00:11,380
Hugo Bowne-Anderson: I think this is my third time over the years on Talk Python.

4
00:00:11,940 --> 00:00:13,480
Michael Kennedy: I do think it is your third time.

5
00:00:15,300 --> 00:00:17,600
Michael Kennedy: It's been a lot of fun data science things

6
00:00:17,940 --> 00:00:21,360
Michael Kennedy: and I think people will see that our conversation,

7
00:00:21,620 --> 00:00:23,680
Michael Kennedy: the thing that we're going to really focus on this time,

8
00:00:24,800 --> 00:00:27,420
Michael Kennedy: will have evolved a little bit as the times have changed.

9
00:00:28,360 --> 00:00:34,040
Michael Kennedy: I'd say since the last couple of years, the data science and the entirety of programming has gotten a little different.

10
00:00:34,840 --> 00:00:53,740
Hugo Bowne-Anderson: Well, yeah, actually, just our conversations over the years, like, kind of are, can be a symbol of the trajectory from, like, early days of data science, PyDataStack, all of these amazing things as it went from academia to industry, then to, you know, large-scale distributed compute when I came and talked about Dask and Coiled.

11
00:00:53,860 --> 00:01:04,300
Hugo Bowne-Anderson: And now, a couple of years after our quote-unquote GPT moment and our ChatGPT moment and our stable diffusion moment here to talk about LLM's foundation models meet data science.

12
00:01:05,000 --> 00:01:05,300
Michael Kennedy: That's right.

13
00:01:05,420 --> 00:01:09,360
Michael Kennedy: We've gone from local machine to cloud to AI.

14
00:01:10,640 --> 00:01:10,900
Hugo Bowne-Anderson: Wow.

15
00:01:11,320 --> 00:01:13,440
Michael Kennedy: I do see that we'll actually maybe be back.

16
00:01:14,320 --> 00:01:27,020
Michael Kennedy: I see a world where we build together smaller models that maybe run locally, doing other things, maybe some servers, connecting MCP servers, connecting all these things, like little special agents.

17
00:01:27,760 --> 00:01:30,120
Michael Kennedy: That's going to be something we can potentially dive into.

18
00:01:30,310 --> 00:01:30,680
Michael Kennedy: We'll see.

19
00:01:30,860 --> 00:01:32,800
Michael Kennedy: But I think the arc is not done.

20
00:01:33,760 --> 00:01:43,460
Hugo Bowne-Anderson: The other thing that comes to mind is I do, and we'll get into this with AI-assisted programming, which I think superpowers people who know what they're doing, but may not be great for beginners.

21
00:01:44,440 --> 00:01:56,400
Hugo Bowne-Anderson: I do imagine we might have boot camps or classes where you're in a cave and no access to AI or the internet and you actually learn to code on a laptop without any of this stuff.

22
00:01:57,320 --> 00:01:59,200
Michael Kennedy: Yeah, there's going to be a local PyPI.

23
00:02:00,700 --> 00:02:02,880
Michael Kennedy: It's going to be a local set of docs.

24
00:02:02,950 --> 00:02:04,160
Michael Kennedy: You know, there was this really cool app.

25
00:02:04,520 --> 00:02:08,060
Michael Kennedy: Gosh, I've covered it on Python Bytes, the news podcast I do.

26
00:02:08,860 --> 00:02:19,020
Michael Kennedy: And I wish I could remember, but what it would do is it had like hundreds, maybe thousands of different projects like Flask or Tailwind or whatever, span technologies.

27
00:02:19,230 --> 00:02:25,140
Michael Kennedy: And you could click it and say, I want to have Flask 3.1 offline.

28
00:02:25,820 --> 00:02:26,340
Michael Kennedy: Get me the docs.

29
00:02:27,060 --> 00:02:32,900
Michael Kennedy: And you could create like a catalog of all these different projects you're using all offline searchable docs across.

30
00:02:33,080 --> 00:02:33,280
Hugo Bowne-Anderson: Amazing.

31
00:02:33,900 --> 00:02:35,760
Michael Kennedy: I feel like something like that might come back.

32
00:02:35,880 --> 00:02:36,280
Michael Kennedy: You know what I mean?

33
00:02:36,460 --> 00:02:42,440
Hugo Bowne-Anderson: Well, it's funny you mention that because I was chatting with Innes Montani of spaCy and Prodigy fame the other night.

34
00:02:42,540 --> 00:02:43,120
Hugo Bowne-Anderson: She's here in Sydney.

35
00:02:43,690 --> 00:02:56,680
Hugo Bowne-Anderson: And she reminded me that Sebastian Ramirez of FastAPI, when he was building FastAPI originally, I think what she reminded me was they didn't have great Internet access where they were.

36
00:02:56,830 --> 00:03:02,260
Hugo Bowne-Anderson: So they did download a lot of things at very slow speeds, then build everything locally.

37
00:03:03,260 --> 00:03:03,420
Michael Kennedy: Yeah.

38
00:03:03,980 --> 00:03:06,480
Michael Kennedy: I'm reliving that, by the way, in a very weird way.

39
00:03:06,820 --> 00:03:07,940
Michael Kennedy: My fiber motor died.

40
00:03:08,030 --> 00:03:09,560
Michael Kennedy: And if anybody watches the video,

41
00:03:10,080 --> 00:03:12,300
Michael Kennedy: they'll see that I'm actually in the library here, which is great.

42
00:03:12,420 --> 00:03:13,440
Michael Kennedy: I've preserved a little private room.

43
00:03:13,450 --> 00:03:14,460
Michael Kennedy: I got high-speed internet here.

44
00:03:14,940 --> 00:03:17,580
Michael Kennedy: But at home, I'm tethered with one bar of LTE.

45
00:03:17,710 --> 00:03:20,020
Michael Kennedy: So anything I do, it's at like 30 kilobits.

46
00:03:20,640 --> 00:03:21,820
Michael Kennedy: And it brings me back to my youth.

47
00:03:22,200 --> 00:03:24,320
Michael Kennedy: But boy, you got to decide what you want to do next.

48
00:03:24,720 --> 00:03:25,160
Michael Kennedy: No rush.

49
00:03:27,320 --> 00:03:27,400
Michael Kennedy: Yeah.

50
00:03:27,690 --> 00:03:30,360
Michael Kennedy: So I do, circling back and closing this up,

51
00:03:30,390 --> 00:03:33,880
Michael Kennedy: I do think this...

52
00:03:34,000 --> 00:03:35,940
Michael Kennedy: true learning the code thing is both,

53
00:03:36,460 --> 00:03:38,040
Michael Kennedy: it's going to be something that comes back around.

54
00:03:38,130 --> 00:03:40,620
Michael Kennedy: I think it's actually a challenge

55
00:03:41,460 --> 00:03:44,080
Michael Kennedy: with all the tools and the cheats.

56
00:03:44,280 --> 00:03:45,620
Michael Kennedy: I don't consider them bad cheats,

57
00:03:45,760 --> 00:03:47,700
Michael Kennedy: but the things that can do the work for you,

58
00:03:47,760 --> 00:03:50,100
Michael Kennedy: it requires a lot of willpower to stay focused.

59
00:03:50,210 --> 00:03:53,720
Michael Kennedy: And I do think it's going to be kind of a kobold moment as well,

60
00:03:54,000 --> 00:03:55,680
Michael Kennedy: where somewhere down the line,

61
00:03:55,840 --> 00:03:56,340
Michael Kennedy: people are going to be like,

62
00:03:56,460 --> 00:03:57,580
Michael Kennedy: we need to just get some people

63
00:03:57,630 --> 00:03:59,460
Michael Kennedy: that used to type this stuff in by hand.

64
00:03:59,690 --> 00:04:00,760
Michael Kennedy: And we need them to look at it

65
00:04:00,760 --> 00:04:02,020
Michael Kennedy: and figure out why this doesn't work.

66
00:04:03,060 --> 00:04:03,560
Hugo Bowne-Anderson: Without a doubt.

67
00:04:03,760 --> 00:04:05,440
Hugo Bowne-Anderson: Learn Python the hard way.

68
00:04:05,570 --> 00:04:06,460
Hugo Bowne-Anderson: Learn X the hard way.

69
00:04:06,590 --> 00:04:10,980
Hugo Bowne-Anderson: Like sometimes, most things, you got to do the work, right?

70
00:04:11,640 --> 00:04:12,400
Michael Kennedy: You definitely do.

71
00:04:13,120 --> 00:04:16,579
Michael Kennedy: Well, Hugo, before we get into the topic too much,

72
00:04:17,480 --> 00:04:18,519
Michael Kennedy: quick introduction on yourself.

73
00:04:19,120 --> 00:04:19,579
Michael Kennedy: Who are you?

74
00:04:19,630 --> 00:04:20,720
Michael Kennedy: I know you've been on the show a few times,

75
00:04:20,829 --> 00:04:21,900
Michael Kennedy: but it's spanned many years.

76
00:04:22,800 --> 00:04:25,200
Michael Kennedy: And I say it often, but it's always worth repeating.

77
00:04:25,460 --> 00:04:27,860
Michael Kennedy: Like 50% of the people in the Python community

78
00:04:29,040 --> 00:04:30,340
Michael Kennedy: are new over the last two years.

79
00:04:30,480 --> 00:04:31,980
Michael Kennedy: Like they've only been here two years or less,

80
00:04:32,030 --> 00:04:33,120
Michael Kennedy: which blows my mind.

81
00:04:33,360 --> 00:04:36,020
Michael Kennedy: So those people probably want to listen to the podcast before they got into Python.

82
00:04:36,220 --> 00:04:36,560
Michael Kennedy: Who are you?

83
00:04:37,780 --> 00:04:39,600
Hugo Bowne-Anderson: So firstly, what is up, Python community?

84
00:04:41,440 --> 00:04:42,820
Hugo Bowne-Anderson: Clearly, I'm a huge fan of Python.

85
00:04:42,980 --> 00:04:43,660
Hugo Bowne-Anderson: Used it for many years.

86
00:04:43,800 --> 00:04:44,140
Hugo Bowne-Anderson: Love it.

87
00:04:45,340 --> 00:04:48,660
Hugo Bowne-Anderson: Background many moons ago in scientific research, biology, math, physics.

88
00:04:50,280 --> 00:04:54,580
Hugo Bowne-Anderson: Was working in academic research at Yale University, New Haven, Connecticut.

89
00:04:54,880 --> 00:04:57,140
Hugo Bowne-Anderson: Living in New York City just over a decade ago.

90
00:04:58,260 --> 00:05:02,060
Hugo Bowne-Anderson: The data science, ML meetups, hackathons there blew my mind so much.

91
00:05:02,560 --> 00:05:07,140
Hugo Bowne-Anderson: moved to industry, small startup at the time,

92
00:05:07,400 --> 00:05:10,200
Hugo Bowne-Anderson: DataCamp, worked on curriculum, education,

93
00:05:10,620 --> 00:05:14,000
Hugo Bowne-Anderson: internal data science, product, wore many hats, as you do,

94
00:05:14,640 --> 00:05:17,700
Hugo Bowne-Anderson: and worked a lot on Pythonic education there.

95
00:05:18,200 --> 00:05:20,200
Hugo Bowne-Anderson: Since then, I've been working a mixture of DevRel,

96
00:05:20,630 --> 00:05:22,520
Hugo Bowne-Anderson: marketing, product, a year and a half ago,

97
00:05:23,500 --> 00:05:27,460
Hugo Bowne-Anderson: and on wonderful projects, such as Dask at Coiled with Matt Rocklin,

98
00:05:27,680 --> 00:05:31,900
Hugo Bowne-Anderson: then Metaflow out of Netflix with the wonderful team at Out of Bounds.

99
00:05:32,340 --> 00:05:35,900
Hugo Bowne-Anderson: A year and a half ago or so, space was so exciting, man.

100
00:05:36,200 --> 00:05:37,300
Hugo Bowne-Anderson: I decided to go freelance.

101
00:05:38,740 --> 00:05:50,440
Hugo Bowne-Anderson: And so I mixed my time, essentially helping people build, ship, and maintain AI, LLM, ML, data-powered products more generally.

102
00:05:50,580 --> 00:05:51,860
Hugo Bowne-Anderson: I do this through consulting.

103
00:05:52,240 --> 00:05:53,720
Hugo Bowne-Anderson: I do it through advising.

104
00:05:54,460 --> 00:05:58,720
Hugo Bowne-Anderson: I do it through education and developer relations.

105
00:05:58,840 --> 00:06:05,120
Hugo Bowne-Anderson: So helping open source frameworks and products reach developers and getting material that helps them.

106
00:06:05,340 --> 00:06:15,360
Hugo Bowne-Anderson: My former colleague and boss at Outer Bounds, Vilay, who really gets developer relations, refers to DevRel as the wisdom layer.

107
00:06:15,480 --> 00:06:18,400
Hugo Bowne-Anderson: And he puts it firmly beside product as a pillar.

108
00:06:18,900 --> 00:06:30,800
Hugo Bowne-Anderson: And I love that because I think a lot of the time we consider education or DevRel as a necessary thing you have to do as opposed to being at a foundational pillar.

109
00:06:31,140 --> 00:06:37,840
Hugo Bowne-Anderson: And once again, that's why I'm in such admiration of the work you do in bringing so many resources to the community at large.

110
00:06:38,920 --> 00:06:39,240
Michael Kennedy: Thank you.

111
00:06:40,540 --> 00:06:46,480
Michael Kennedy: And foreshadowing a little bit, I would like to kind of reinforce that quote you just said.

112
00:06:46,540 --> 00:06:49,920
Michael Kennedy: And, you know, it's the wisdom layer.

113
00:06:50,390 --> 00:06:57,220
Michael Kennedy: Like, as data scientists, your job is to provide insight and knowledge and trends and forecasting.

114
00:06:57,840 --> 00:07:05,560
Michael Kennedy: As developers, our job is to provide solutions and things that we can use, apps and tools and whatnot.

115
00:07:06,220 --> 00:07:14,860
Michael Kennedy: And I think a lot of us, myself included, get tied down in like, oh, I'm really good at coding and I'm good at this library.

116
00:07:15,840 --> 00:07:21,080
Michael Kennedy: And we can kind of forget that the real first tier job of ours

117
00:07:21,320 --> 00:07:24,960
Michael Kennedy: is to provide answers and solutions and apps.

118
00:07:26,380 --> 00:07:28,360
Michael Kennedy: And I think a lot of the pushback on AI is like,

119
00:07:28,500 --> 00:07:30,880
Michael Kennedy: it's taken my coding somewhat.

120
00:07:31,580 --> 00:07:31,980
Michael Kennedy: Absolutely.

121
00:07:32,240 --> 00:07:32,480
Hugo Bowne-Anderson: Right?

122
00:07:33,160 --> 00:07:33,300
Hugo Bowne-Anderson: Yeah.

123
00:07:33,720 --> 00:07:34,660
Hugo Bowne-Anderson: One way I...

124
00:07:35,460 --> 00:07:35,860
Hugo Bowne-Anderson: Go ahead.

125
00:07:35,920 --> 00:07:37,000
Hugo Bowne-Anderson: I was just going to add to that.

126
00:07:37,140 --> 00:07:42,880
Hugo Bowne-Anderson: One way I think about it is it has taken my coding in some ways,

127
00:07:43,120 --> 00:07:47,160
Hugo Bowne-Anderson: But as we'll get to, I never particularly enjoyed writing,

128
00:07:48,100 --> 00:07:50,880
Hugo Bowne-Anderson: love Pandas, never particularly enjoyed writing Pandas code,

129
00:07:51,210 --> 00:07:53,720
Hugo Bowne-Anderson: for example, incredible tool.

130
00:07:54,100 --> 00:07:57,680
Hugo Bowne-Anderson: But if I can help me write my Pandas code, I read it,

131
00:07:57,800 --> 00:07:59,300
Hugo Bowne-Anderson: make sure it's all good in the hood,

132
00:07:59,650 --> 00:08:01,300
Hugo Bowne-Anderson: and then I get to focus on building systems,

133
00:08:02,050 --> 00:08:03,140
Hugo Bowne-Anderson: I think that's a huge win.

134
00:08:04,760 --> 00:08:05,640
Michael Kennedy: Yeah, 100%.

135
00:08:06,010 --> 00:08:08,100
Michael Kennedy: I would be remiss to not give a little shout out

136
00:08:08,260 --> 00:08:11,160
Michael Kennedy: to a couple of things that you have done or are doing.

137
00:08:11,780 --> 00:08:13,120
Michael Kennedy: Let's take it chronologically.

138
00:08:14,480 --> 00:08:17,520
Michael Kennedy: A while ago, you worked on the Fundamentals of Dask,

139
00:08:17,640 --> 00:08:20,060
Michael Kennedy: high-performance data science course over at Talk Python.

140
00:08:20,280 --> 00:08:21,380
Michael Kennedy: This course is 100% free.

141
00:08:22,120 --> 00:08:23,760
Michael Kennedy: People want to dive into it and learn from you,

142
00:08:23,880 --> 00:08:25,080
Michael Kennedy: they can absolutely take it.

143
00:08:26,020 --> 00:08:27,140
Hugo Bowne-Anderson: I might even take it now.

144
00:08:29,260 --> 00:08:30,440
Michael Kennedy: It's just over an hour.

145
00:08:31,140 --> 00:08:32,260
Michael Kennedy: Yeah, people can drop in,

146
00:08:32,400 --> 00:08:34,520
Michael Kennedy: and I'll be sure to put a link in the show notes for that.

147
00:08:34,719 --> 00:08:37,460
Hugo Bowne-Anderson: That was really fun to build with you as well, Michael.

148
00:08:37,659 --> 00:08:39,479
Michael Kennedy: That was during the early days of COVID,

149
00:08:39,599 --> 00:08:40,380
Hugo Bowne-Anderson: we were working on that.

150
00:08:40,479 --> 00:08:45,860
Michael Kennedy: so you know what else do we have to do no it was really great working on it with and working on

151
00:08:45,860 --> 00:08:52,780
Michael Kennedy: with you as well i appreciate that tons and then you uh since then have started a data podcast

152
00:08:53,360 --> 00:08:59,680
Michael Kennedy: called vanishing ingredients exactly about that so this is a podcast and i still call it a data

153
00:08:59,840 --> 00:09:05,500
Hugo Bowne-Anderson: podcast although a lot of people like you have to call it ai hugo and i'm ai is data and a lot as

154
00:09:05,500 --> 00:09:08,499
Hugo Bowne-Anderson: we'll get to a lot of the principles in in building ai powered products are the same

155
00:09:09,240 --> 00:09:12,960
Hugo Bowne-Anderson: modulo implementation details of building data powered products.

156
00:09:13,080 --> 00:09:18,220
Hugo Bowne-Anderson: But it's a podcast where I talk with industry practitioners and builders

157
00:09:19,240 --> 00:09:22,400
Hugo Bowne-Anderson: about what they're doing in the space, how they're building,

158
00:09:23,100 --> 00:09:27,840
Hugo Bowne-Anderson: and essentially trying to help propagate knowledge from the bleeding edge

159
00:09:28,440 --> 00:09:32,800
Hugo Bowne-Anderson: back to builders and leaders in the space.

160
00:09:33,020 --> 00:09:36,440
Hugo Bowne-Anderson: So recently had a conversation with Hamil Hussain there,

161
00:09:36,980 --> 00:09:39,260
Hugo Bowne-Anderson: who he's the evals guy among other things.

162
00:09:40,140 --> 00:09:47,060
Hugo Bowne-Anderson: But all about the eval space and how you can use evaluation in the LLM powered software

163
00:09:47,580 --> 00:09:50,620
Hugo Bowne-Anderson: development lifecycle to improve your product.

164
00:09:51,080 --> 00:09:57,620
Hugo Bowne-Anderson: I've spoken with Shell Gentleman at NASA, conversations with Jeremy Howard.

165
00:09:59,240 --> 00:10:04,219
Hugo Bowne-Anderson: So one of the things, as I'm sure you do, I love about podcasting is I get to invite people

166
00:10:04,280 --> 00:10:09,220
Hugo Bowne-Anderson: I admire and who I think are awesome to chat about stuff and then share it, share it with

167
00:10:09,420 --> 00:10:09,760
Hugo Bowne-Anderson: the public.

168
00:10:09,820 --> 00:10:15,920
Hugo Bowne-Anderson: So that's the rationale there, but it's really to help people propagate knowledge, wisdom

169
00:10:16,160 --> 00:10:19,040
Hugo Bowne-Anderson: and skills back, back the adoption curve along the way.

170
00:10:19,060 --> 00:10:19,240
Michael Kennedy: Yeah.

171
00:10:19,300 --> 00:10:19,580
Michael Kennedy: Amazing.

172
00:10:20,120 --> 00:10:20,260
Michael Kennedy: Yeah.

173
00:10:20,340 --> 00:10:21,120
Michael Kennedy: That's, that's good work.

174
00:10:21,760 --> 00:10:22,500
Michael Kennedy: Who should listen to it?

175
00:10:23,060 --> 00:10:25,320
Michael Kennedy: Beginners, experts, data people, programmers.

176
00:10:26,520 --> 00:10:27,620
Hugo Bowne-Anderson: It's a, it's a, it's a great question.

177
00:10:28,060 --> 00:10:31,440
Hugo Bowne-Anderson: The way I think every, everyone should listen to it.

178
00:10:31,520 --> 00:10:35,620
Hugo Bowne-Anderson: everyone who's interested in building and shipping data-powered stuff.

179
00:10:36,390 --> 00:10:41,580
Hugo Bowne-Anderson: And the way I actually chat about it with guests is the first third of any conversation,

180
00:10:42,010 --> 00:10:45,660
Hugo Bowne-Anderson: I want everyone to understand, everyone who's somewhat technical.

181
00:10:46,500 --> 00:10:48,260
Hugo Bowne-Anderson: The middle, we can go a bit deeper.

182
00:10:48,410 --> 00:10:49,840
Hugo Bowne-Anderson: And the third is a free-for-all.

183
00:10:50,070 --> 00:10:54,020
Hugo Bowne-Anderson: So I definitely encourage everyone to jump in.

184
00:10:54,960 --> 00:10:59,520
Hugo Bowne-Anderson: And we've got specific episodes on evals, of course, and that type of stuff.

185
00:11:00,240 --> 00:11:03,400
Hugo Bowne-Anderson: But we also have industry-specific episodes,

186
00:11:03,660 --> 00:11:05,280
Hugo Bowne-Anderson: such as chatting about what was happening

187
00:11:05,350 --> 00:11:08,000
Hugo Bowne-Anderson: in the early days of shipping LLM-powered software

188
00:11:08,160 --> 00:11:11,260
Hugo Bowne-Anderson: at Honeycomb or NASA and these types of places.

189
00:11:11,660 --> 00:11:14,539
Michael Kennedy: Yeah, that is one of the little secrets

190
00:11:15,730 --> 00:11:16,720
Michael Kennedy: of being podcast hosts,

191
00:11:16,810 --> 00:11:19,320
Michael Kennedy: is you get to talk to people about amazing stuff.

192
00:11:19,500 --> 00:11:20,760
Michael Kennedy: You're like, huh, it'd be really cool

193
00:11:20,840 --> 00:11:23,300
Michael Kennedy: to talk to the people that made that Fusion breakthrough.

194
00:11:24,320 --> 00:11:24,900
Michael Kennedy: They did Python.

195
00:11:25,120 --> 00:11:26,660
Michael Kennedy: Why don't we invite them and they'll draw by?

196
00:11:26,730 --> 00:11:27,300
Michael Kennedy: You know, it's amazing.

197
00:11:28,160 --> 00:11:28,320
Hugo Bowne-Anderson: Yeah, yeah.

198
00:11:29,040 --> 00:11:31,980
Hugo Bowne-Anderson: And I get like a lot of my friends who work in the space connect me with other people.

199
00:11:31,990 --> 00:11:38,300
Hugo Bowne-Anderson: So I'm actually chatting with a data leader at Mozilla and then the VP of learning at Duolingo soon.

200
00:11:38,390 --> 00:11:41,380
Hugo Bowne-Anderson: So we're going to have a lot of really fun episodes coming up.

201
00:11:42,220 --> 00:11:43,740
Michael Kennedy: What's up with the name Vanishing Gradients?

202
00:11:43,830 --> 00:11:44,300
Michael Kennedy: Where did I come from?

203
00:11:44,980 --> 00:11:46,160
Hugo Bowne-Anderson: Yeah, it's a good question.

204
00:11:46,570 --> 00:11:50,840
Hugo Bowne-Anderson: So there's the vanishing gradient problem in deep learning.

205
00:11:51,020 --> 00:11:53,560
Hugo Bowne-Anderson: So when you do stochastic gradient descent,

206
00:11:54,390 --> 00:11:56,420
Hugo Bowne-Anderson: you compute gradients and climb down

207
00:11:56,530 --> 00:11:59,500
Hugo Bowne-Anderson: in order to optimize your neural networks.

208
00:12:00,110 --> 00:12:03,880
Hugo Bowne-Anderson: And there's a challenge that sometimes gradients vanish

209
00:12:04,340 --> 00:12:05,640
Hugo Bowne-Anderson: and you stop learning.

210
00:12:05,830 --> 00:12:09,560
Hugo Bowne-Anderson: So the rationale was, what happens when you stop learning?

211
00:12:09,670 --> 00:12:13,240
Hugo Bowne-Anderson: And let's bring back the idea of learning in this space.

212
00:12:13,470 --> 00:12:15,620
Hugo Bowne-Anderson: The opposite, of course, is the exploding gradients problem,

213
00:12:15,720 --> 00:12:18,120
Hugo Bowne-Anderson: which I also considered calling it,

214
00:12:18,240 --> 00:12:20,000
Hugo Bowne-Anderson: where the gradients just explode, of course.

215
00:12:20,420 --> 00:12:22,280
Hugo Bowne-Anderson: But we went with Vanishing for that reason.

216
00:12:22,500 --> 00:12:23,360
Michael Kennedy: I like that.

217
00:12:23,460 --> 00:12:26,440
Michael Kennedy: That's a very clever, very subtle name.

218
00:12:27,220 --> 00:12:27,360
Michael Kennedy: Nice.

219
00:12:28,620 --> 00:12:32,480
Michael Kennedy: So let's talk data science in 2025.

220
00:12:33,120 --> 00:12:35,500
Michael Kennedy: And to be clear, I didn't ask,

221
00:12:35,580 --> 00:12:39,060
Michael Kennedy: let's talk using AI for data science.

222
00:12:40,420 --> 00:12:42,280
Michael Kennedy: Let's talk data science in 2025.

223
00:12:42,680 --> 00:12:47,100
Michael Kennedy: And surely, many of, I think there's two things here.

224
00:12:47,100 --> 00:12:48,360
Michael Kennedy: I think there's some really interesting,

225
00:12:49,160 --> 00:12:55,220
Michael Kennedy: what I don't know how we want to think about, like pure programming libraries and tools that are super powerful.

226
00:12:55,800 --> 00:12:57,940
Michael Kennedy: And we could give a quick shout out to some of them.

227
00:12:58,890 --> 00:13:04,140
Michael Kennedy: But then also, anytime you're exploring data, using some of these LLMs,

228
00:13:04,430 --> 00:13:08,020
Michael Kennedy: and especially the agentic tooling, it's a game changer.

229
00:13:09,200 --> 00:13:10,400
Michael Kennedy: So let's start with the first one.

230
00:13:11,340 --> 00:13:18,920
Michael Kennedy: What tools, you know, things like pollers maybe or whatever is like jumping out at you over the last year or so that's like, wow.

231
00:13:19,580 --> 00:13:32,200
Hugo Bowne-Anderson: Such a wonderful question. And I'll actually, I chatted about this on Vanishing Gradients with Akshay Agrawal, who built Marimo and develops Marimo, which I encourage everyone to check out.

232
00:13:32,280 --> 00:13:39,460
Hugo Bowne-Anderson: So let's actually rewind slightly and think about what we've been using over the past decade plus plus.

233
00:13:39,640 --> 00:13:51,800
Hugo Bowne-Anderson: And it's, you know, the PyData stack, Jupyter Notebooks, Pandas, you know, SQL, SQLite databases,

234
00:13:52,300 --> 00:13:55,940
Hugo Bowne-Anderson: and in production, maybe Postgres and these types of things.

235
00:13:56,240 --> 00:13:58,700
Hugo Bowne-Anderson: And how has this evolved now?

236
00:13:58,760 --> 00:14:04,940
Hugo Bowne-Anderson: What are like modern, really cutting edge tools that we use in similar ways?

237
00:14:04,990 --> 00:14:06,160
Hugo Bowne-Anderson: You mentioned polars.

238
00:14:06,490 --> 00:14:12,220
Hugo Bowne-Anderson: And I totally agree that this is something we're seeing a lot of activity on and a lot of use on.

239
00:14:12,270 --> 00:14:15,200
Hugo Bowne-Anderson: On the database side, we've got DuckDB, right?

240
00:14:16,320 --> 00:14:17,480
Michael Kennedy: DuckDB is huge.

241
00:14:17,780 --> 00:14:17,880
Hugo Bowne-Anderson: Yeah.

242
00:14:18,380 --> 00:14:19,520
Michael Kennedy: DuckDB is making a huge impact.

243
00:14:21,040 --> 00:14:27,020
Hugo Bowne-Anderson: And man, seriously, it's just, you know, beautiful to use, but it's so fast as well, right?

244
00:14:27,660 --> 00:14:29,800
Hugo Bowne-Anderson: And I mean, and that's what you want there.

245
00:14:30,270 --> 00:14:32,000
Hugo Bowne-Anderson: And then on the literate programming side,

246
00:14:32,220 --> 00:14:35,680
Hugo Bowne-Anderson: you've got Marimo, which I'm a huge fan of.

247
00:14:36,310 --> 00:14:38,080
Hugo Bowne-Anderson: I still use Jupyter Notebooks a lot,

248
00:14:38,080 --> 00:14:41,060
Hugo Bowne-Anderson: but one thing Marimo affords me,

249
00:14:41,440 --> 00:14:45,440
Hugo Bowne-Anderson: because it's actually a.py file as well,

250
00:14:45,670 --> 00:14:46,520
Hugo Bowne-Anderson: you can convert them.

251
00:14:46,550 --> 00:14:48,240
Hugo Bowne-Anderson: Well, they're essentially scripts as well.

252
00:14:48,330 --> 00:14:50,080
Hugo Bowne-Anderson: So the notebook to production story

253
00:14:50,860 --> 00:14:52,060
Hugo Bowne-Anderson: is really interesting there.

254
00:14:54,000 --> 00:14:57,080
Michael Kennedy: I think Marimo is super interesting.

255
00:14:57,760 --> 00:15:02,100
Michael Kennedy: I think when I look at it, when I see people working with it,

256
00:15:02,100 --> 00:15:04,660
Michael Kennedy: or when I work with it, the limited extent to which I have,

257
00:15:06,720 --> 00:15:11,600
Michael Kennedy: it just looks smooth and polished and modern.

258
00:15:12,560 --> 00:15:16,540
Michael Kennedy: And I don't know, when I use it, I feel like it's something great.

259
00:15:16,880 --> 00:15:20,340
Michael Kennedy: It also solves the problem that while Jupyter Notebooks,

260
00:15:21,600 --> 00:15:22,860
Michael Kennedy: Jupyter Notebooks, JupyterLab, whatever,

261
00:15:23,190 --> 00:15:26,540
Michael Kennedy: in general is an incredible tool for data exploration,

262
00:15:27,480 --> 00:15:29,420
Michael Kennedy: and presenting data,

263
00:15:29,980 --> 00:15:34,840
Michael Kennedy: it has this crazy implicit go-to sort of sequence, right?

264
00:15:34,960 --> 00:15:36,960
Michael Kennedy: Like if you don't just go run all cells

265
00:15:37,400 --> 00:15:38,420
Michael Kennedy: and you start bouncing around,

266
00:15:39,860 --> 00:15:42,400
Michael Kennedy: you end up potentially running stuff out of order

267
00:15:42,540 --> 00:15:44,520
Michael Kennedy: or skipping a step that would have made a different answer

268
00:15:45,120 --> 00:15:45,700
Hugo Bowne-Anderson: a step below.

269
00:15:45,820 --> 00:15:47,040
Michael Kennedy: And that's real dangerous.

270
00:15:47,240 --> 00:15:50,900
Michael Kennedy: And so Marimo uses the abstract syntax tree

271
00:15:50,940 --> 00:15:53,940
Michael Kennedy: to look at dependencies across cells

272
00:15:53,980 --> 00:15:54,900
Michael Kennedy: and make sure they run in order,

273
00:15:55,080 --> 00:15:59,360
Michael Kennedy: which I think is an underappreciated benefit.

274
00:16:00,020 --> 00:16:00,920
Hugo Bowne-Anderson: It's like, oh, that's kind of nice.

275
00:16:01,640 --> 00:16:03,840
Michael Kennedy: No, do you want the wrong answer or the right answer?

276
00:16:04,020 --> 00:16:06,300
Michael Kennedy: This is really important in data science and science in general.

277
00:16:06,880 --> 00:16:07,760
Hugo Bowne-Anderson: Yeah, you're right.

278
00:16:07,920 --> 00:16:12,380
Hugo Bowne-Anderson: My understanding is it uses the AST to build a DAG of cells and executes them.

279
00:16:12,780 --> 00:16:17,840
Hugo Bowne-Anderson: And what that means is, yeah, and it means you can't redefine something in a cell below,

280
00:16:18,040 --> 00:16:21,320
Hugo Bowne-Anderson: but it'll give you a scratch pad to do so if you want to.

281
00:16:21,460 --> 00:16:25,120
Hugo Bowne-Anderson: Now, I just want to say that's fantastic for a lot of cases.

282
00:16:25,500 --> 00:16:31,920
Hugo Bowne-Anderson: There are cases when you just want to explore an experiment where Jupyter Notebooks absolutely excel.

283
00:16:32,180 --> 00:16:34,720
Hugo Bowne-Anderson: So it's not an either or here as well.

284
00:16:34,960 --> 00:16:42,220
Hugo Bowne-Anderson: And I do want to say Jupyter Notebooks, in all honesty, get a bunch of hate for that.

285
00:16:42,360 --> 00:16:44,060
Hugo Bowne-Anderson: And neither you nor I feel that way.

286
00:16:44,100 --> 00:16:48,800
Hugo Bowne-Anderson: But I just want to be very explicit that that's not what we're saying here at all.

287
00:16:49,020 --> 00:16:50,760
Michael Kennedy: Yeah, I have a lot of reverence for notebooks.

288
00:16:51,180 --> 00:17:00,660
Michael Kennedy: They really, not only did they change the game for data science in general, but they changed it for Python full stop.

289
00:17:01,420 --> 00:17:14,680
Michael Kennedy: Like, so if you look at the popularity and the people participating in Python, like one of its really powerful aspects is people are coming from all these different angles with different ideas and perspectives and different tools they want to build and so on.

290
00:17:14,720 --> 00:17:15,640
Michael Kennedy: And that's made it so rich.

291
00:17:15,810 --> 00:17:21,980
Michael Kennedy: And that started basically in 2012 with the PyData stack with notebooks and all of that.

292
00:17:23,180 --> 00:17:29,160
Hugo Bowne-Anderson: Yeah, I remember the first notebook I opened was called an IPython notebook, not even a Jupyter notebook.

293
00:17:29,270 --> 00:17:33,800
Hugo Bowne-Anderson: And of course, it's all based around IPython also.

294
00:17:34,070 --> 00:17:35,200
Hugo Bowne-Anderson: So we've got to give a shout out to that.

295
00:17:35,230 --> 00:17:38,800
Hugo Bowne-Anderson: And as I said, I was actually working in biology, in research at the time.

296
00:17:39,260 --> 00:17:43,200
Hugo Bowne-Anderson: And in biology, we have notebooks, right?

297
00:17:43,380 --> 00:17:46,860
Hugo Bowne-Anderson: Like you write, you put your PCR gel, you put your figures there, you write things.

298
00:17:47,150 --> 00:17:49,940
Hugo Bowne-Anderson: This idea of literate programming is exactly that.

299
00:17:50,070 --> 00:17:52,260
Hugo Bowne-Anderson: And what it does is it brings experimentation.

300
00:17:53,030 --> 00:17:57,040
Hugo Bowne-Anderson: It brings scientific rigor and scientific research into computation.

301
00:17:57,650 --> 00:18:06,620
Hugo Bowne-Anderson: And very important for this space where we are, really what we're talking about in data science, ML, AI, is the convergence of software meeting data and experimentation.

302
00:18:06,890 --> 00:18:08,140
Hugo Bowne-Anderson: So we need new tools for this.

303
00:18:08,860 --> 00:18:12,880
Hugo Bowne-Anderson: And notebooks are one of the most awesome examples of that.

304
00:18:13,620 --> 00:18:19,700
Michael Kennedy: okay i took us down a bit of a hole with the marimo stuff because it is cool yeah anything

305
00:18:19,850 --> 00:18:23,940
Michael Kennedy: else that jumps out to you i have one at the end that i want to riff on before we get off this

306
00:18:24,050 --> 00:18:28,900
Michael Kennedy: topic but what else jumps out to you tools 2024 2025 that's kind of like oh that's different

307
00:18:29,780 --> 00:18:35,220
Hugo Bowne-Anderson: so to step to step back a bit i we are talking about like data science with ai and that type of

308
00:18:35,220 --> 00:18:41,079
Hugo Bowne-Anderson: stuff and this works both ways right like data science plays into ai and and building with

309
00:18:41,160 --> 00:18:47,100
Hugo Bowne-Anderson: foundation models but i'd have to fire myself if i didn't talk about the other way which is ai

310
00:18:47,260 --> 00:18:55,180
Hugo Bowne-Anderson: helping us do data science and um the tools are ai assisted the biggest tool is ai assisted

311
00:18:56,080 --> 00:19:02,400
Hugo Bowne-Anderson: programming for data science which is revolutionary i i think maybe isn't even

312
00:19:02,540 --> 00:19:05,040
Hugo Bowne-Anderson: as big a term as we need for this.

313
00:19:05,860 --> 00:19:06,420
Hugo Bowne-Anderson: Absolutely groundbreaking.

314
00:19:07,780 --> 00:19:07,960
Michael Kennedy: Yeah.

315
00:19:10,360 --> 00:19:15,580
Michael Kennedy: It's easy to get frustrated saying it's bad for the environment.

316
00:19:16,460 --> 00:19:18,380
Michael Kennedy: I'm a good data scientist, good developer.

317
00:19:18,390 --> 00:19:19,160
Michael Kennedy: I don't need this stuff.

318
00:19:21,520 --> 00:19:24,760
Michael Kennedy: But for the most part, I feel like the cat is out of the bag,

319
00:19:24,920 --> 00:19:27,980
Michael Kennedy: the Pandora's box is open, whatever analogy you want to use here.

320
00:19:30,280 --> 00:19:31,480
Michael Kennedy: It's made such a difference.

321
00:19:32,600 --> 00:19:36,020
Hugo Bowne-Anderson: without a doubt and I definitely agree on climate concerns we should be having larger

322
00:19:36,380 --> 00:19:41,900
Hugo Bowne-Anderson: conversations around this um you can start using smaller models and and and local models for AI

323
00:19:42,040 --> 00:19:48,600
Hugo Bowne-Anderson: assisted programming they won't superpower you as as much um but there are you know I I think

324
00:19:49,030 --> 00:19:56,339
Hugo Bowne-Anderson: to say all and this is to say all of AI is very bad for the climate is I suppose like saying both

325
00:19:56,480 --> 00:20:02,900
Hugo Bowne-Anderson: hummers and electric cars uh in the same bucket right so but i totally agree that that's a concern

326
00:20:03,180 --> 00:20:09,360
Hugo Bowne-Anderson: we need and but and the other thing though man if we're talking about like

327
00:20:10,230 --> 00:20:13,940
Hugo Bowne-Anderson: you know software's writing the software ai's writing the software vibe coding i don't necessarily

328
00:20:14,220 --> 00:20:18,980
Hugo Bowne-Anderson: understand it guess what we were all copy and pasting from stack overflow we've been doing that

329
00:20:19,120 --> 00:20:24,899
Hugo Bowne-Anderson: for a long time right um and i don't necessarily understand all that code so this is in some ways

330
00:20:24,920 --> 00:20:28,240
Hugo Bowne-Anderson: scaling and superpowering that behavior.

331
00:20:29,580 --> 00:20:30,180
Michael Kennedy: And it's on us.

332
00:20:30,880 --> 00:20:34,280
Michael Kennedy: It's on you, it's on me, it's on everyone who uses it to either,

333
00:20:34,950 --> 00:20:36,660
Michael Kennedy: and we're going to get into this more in detail later,

334
00:20:37,140 --> 00:20:40,700
Michael Kennedy: use that as a learning experience or as a,

335
00:20:41,380 --> 00:20:44,480
Michael Kennedy: well, I don't need to know that, whatever it says, right?

336
00:20:44,760 --> 00:20:46,520
Michael Kennedy: That was true with Stack Overflow as well.

337
00:20:46,760 --> 00:20:50,500
Michael Kennedy: Like you would go to Stack Overflow and you would just copy something.

338
00:20:50,740 --> 00:20:53,399
Michael Kennedy: And the knock on people who would take stuff from Stack Overflow

339
00:20:53,420 --> 00:20:56,100
Michael Kennedy: and paste it was they had no idea what it meant.

340
00:20:56,700 --> 00:20:57,960
Michael Kennedy: They just saw that it solved the problem.

341
00:20:58,050 --> 00:21:00,800
Michael Kennedy: There was even that joke keyboard that Stack Overflow created.

342
00:21:01,400 --> 00:21:04,700
Michael Kennedy: All it had was like a control and a C and a V,

343
00:21:05,050 --> 00:21:06,320
Michael Kennedy: and they had a Stack Overflow logo.

344
00:21:06,370 --> 00:21:07,220
Michael Kennedy: It's like, this is all you need, right?

345
00:21:07,680 --> 00:21:09,120
Michael Kennedy: It was hilarious, right?

346
00:21:10,220 --> 00:21:13,260
Hugo Bowne-Anderson: I'd like to system prompt ChatGBT to not be so sycophantic

347
00:21:13,760 --> 00:21:15,340
Hugo Bowne-Anderson: and treat me like people on Stack Overflow

348
00:21:15,410 --> 00:21:16,000
Hugo Bowne-Anderson: used to treat people.

349
00:21:16,440 --> 00:21:16,980
Michael Kennedy: That's right.

350
00:21:17,760 --> 00:21:19,560
Michael Kennedy: My ego is doing way too well today.

351
00:21:19,630 --> 00:21:20,500
Michael Kennedy: I need to be beat down.

352
00:21:20,920 --> 00:21:23,380
Michael Kennedy: The thing is, you could go to Stack Overflow

353
00:21:23,400 --> 00:21:24,640
Michael Kennedy: wow, okay, I didn't know that.

354
00:21:26,180 --> 00:21:27,180
Michael Kennedy: And then you learn it.

355
00:21:27,200 --> 00:21:28,640
Michael Kennedy: And you don't need to go back to Stack Overflow

356
00:21:28,680 --> 00:21:29,600
Michael Kennedy: and copy that thing

357
00:21:29,740 --> 00:21:31,440
Michael Kennedy: because now you've understood something deep.

358
00:21:32,020 --> 00:21:32,800
Michael Kennedy: And that's different.

359
00:21:33,680 --> 00:21:35,700
Michael Kennedy: That's on you when you're copying from Stack Overflow.

360
00:21:35,840 --> 00:21:38,580
Michael Kennedy: And it's on you 100 times over

361
00:21:39,060 --> 00:21:40,720
Michael Kennedy: if you use these tools, right?

362
00:21:40,860 --> 00:21:41,740
Michael Kennedy: Because a lot of times,

363
00:21:42,080 --> 00:21:42,980
Michael Kennedy: especially the agentic stuff,

364
00:21:43,140 --> 00:21:44,260
Michael Kennedy: it explains what it does.

365
00:21:44,440 --> 00:21:45,180
Michael Kennedy: Like, here's what it was.

366
00:21:45,380 --> 00:21:46,260
Michael Kennedy: Here's why I changed it.

367
00:21:46,640 --> 00:21:47,800
Michael Kennedy: If you let that scroll by

368
00:21:47,960 --> 00:21:49,600
Michael Kennedy: or you can go slow and study it

369
00:21:50,000 --> 00:21:50,720
Michael Kennedy: and become smarter,

370
00:21:51,400 --> 00:21:52,300
Michael Kennedy: not more brain dead.

371
00:21:52,360 --> 00:21:52,780
Michael Kennedy: You know what I mean?

372
00:21:52,880 --> 00:21:53,000
Michael Kennedy: Absolutely.

373
00:21:53,160 --> 00:21:56,660
Hugo Bowne-Anderson: And for me, like, if I was getting, like,

374
00:21:56,840 --> 00:21:58,720
Hugo Bowne-Anderson: Pandas or scikit-learn code from Stack Overflow,

375
00:21:58,900 --> 00:22:01,540
Hugo Bowne-Anderson: I'd really, like, want to understand it

376
00:22:01,660 --> 00:22:02,720
Hugo Bowne-Anderson: because that was my bread and butter.

377
00:22:02,860 --> 00:22:04,540
Hugo Bowne-Anderson: Whereas if it was front-end stuff,

378
00:22:05,860 --> 00:22:09,240
Hugo Bowne-Anderson: like, I'd probably go and find the same issue,

379
00:22:10,059 --> 00:22:11,400
Hugo Bowne-Anderson: question time and time again.

380
00:22:11,900 --> 00:22:14,480
Hugo Bowne-Anderson: Same with, like, environment stuff,

381
00:22:14,860 --> 00:22:17,180
Hugo Bowne-Anderson: like getting environments working in Jupyter Notebooks

382
00:22:17,180 --> 00:22:19,340
Hugo Bowne-Anderson: or something, I just, I still can't drop that stuff.

383
00:22:19,540 --> 00:22:19,960
Michael Kennedy: I know.

384
00:22:20,000 --> 00:22:22,580
Michael Kennedy: I was just thinking of Bash scripts, like Shell.

385
00:22:22,660 --> 00:22:26,560
Michael Kennedy: shell scripts. I'm like, you know what, this is just, I don't need to remember this. I just

386
00:22:26,740 --> 00:22:31,620
Michael Kennedy: bookmark that puppy. And long as it doesn't have RMRF or something destructive in it,

387
00:22:32,360 --> 00:22:37,800
Michael Kennedy: I'm just writing. Incredible. Okay. One more thing before we move on to like the AI

388
00:22:38,600 --> 00:22:45,480
Michael Kennedy: depths that I think is, we got to talk about it because today is October 7th, 2025 as we record

389
00:22:45,600 --> 00:22:50,040
Michael Kennedy: this, not as I release it. So, you know, I'll have to be a bit nostalgic for a few weeks.

390
00:22:51,160 --> 00:22:53,480
Michael Kennedy: But today is Python Pi Day.

391
00:22:54,240 --> 00:22:56,700
Michael Kennedy: Python 3.14 came out today, right?

392
00:22:57,240 --> 00:22:59,580
Michael Kennedy: And one of the main features of Python 3.14

393
00:23:00,410 --> 00:23:04,820
Michael Kennedy: is the free-threaded aspect being sort of officially taken in.

394
00:23:05,760 --> 00:23:08,780
Michael Kennedy: And I know one of the big challenges that's been solved

395
00:23:09,040 --> 00:23:11,280
Michael Kennedy: with C extensions and Rust and other stuff,

396
00:23:11,560 --> 00:23:12,860
Michael Kennedy: but it's still a bit of a challenge.

397
00:23:13,030 --> 00:23:14,180
Michael Kennedy: It's like, I've got a ton of data.

398
00:23:14,350 --> 00:23:16,000
Michael Kennedy: I want to process it in my codes in Python.

399
00:23:16,350 --> 00:23:19,220
Michael Kennedy: How do I take advantage of the 32 cores I got?

400
00:23:19,420 --> 00:23:21,360
Michael Kennedy: Or do I get one 30 second of a computer?

401
00:23:22,370 --> 00:23:22,480
Michael Kennedy: Right?

402
00:23:22,700 --> 00:23:27,760
Michael Kennedy: And so I think starting to think about parallel programming a little bit,

403
00:23:28,660 --> 00:23:30,940
Michael Kennedy: it's going to take on whatever significance it takes,

404
00:23:31,050 --> 00:23:32,840
Michael Kennedy: it's going to take on more than it has traditionally.

405
00:23:36,000 --> 00:23:36,460
Hugo Bowne-Anderson: Totally agree.

406
00:23:36,500 --> 00:23:39,740
Michael Kennedy: And I think it's the data scientists who are going to need it more than anyone.

407
00:23:40,960 --> 00:23:41,140
Hugo Bowne-Anderson: Right?

408
00:23:41,370 --> 00:23:44,300
Michael Kennedy: Because our web frameworks handle that kind of stuff for us.

409
00:23:44,340 --> 00:23:47,820
Michael Kennedy: They fan that out into processes and other things.

410
00:23:48,060 --> 00:23:54,360
Michael Kennedy: But when you got real computational stuff, there's no IO blocking that you can work around, right?

411
00:23:54,520 --> 00:23:55,860
Michael Kennedy: To leverage async, right?

412
00:23:55,960 --> 00:23:57,140
Michael Kennedy: You've got to do the CPU stuff.

413
00:23:58,000 --> 00:23:58,160
Hugo Bowne-Anderson: Exactly.

414
00:23:58,490 --> 00:24:05,660
Hugo Bowne-Anderson: And it's a really good question because I would have a trillion percent agreed with you.

415
00:24:06,940 --> 00:24:17,400
Hugo Bowne-Anderson: And I 100%, but I would have a trillion percent agreed with you pre our chat GBT moment when data scientists, ML engineers, all of these types of people.

416
00:24:18,920 --> 00:24:22,000
Hugo Bowne-Anderson: weren't only building products, serving models,

417
00:24:22,660 --> 00:24:23,260
Hugo Bowne-Anderson: that type of stuff,

418
00:24:23,620 --> 00:24:25,440
Hugo Bowne-Anderson: but they were responsible for training as well.

419
00:24:27,540 --> 00:24:29,740
Hugo Bowne-Anderson: And also, I think you're totally right

420
00:24:29,740 --> 00:24:31,280
Hugo Bowne-Anderson: with large-scale analytics.

421
00:24:31,560 --> 00:24:33,900
Hugo Bowne-Anderson: Think about Dask and geospatial,

422
00:24:34,540 --> 00:24:37,040
Hugo Bowne-Anderson: large-scale, multidimensional, geospatial,

423
00:24:37,300 --> 00:24:39,340
Hugo Bowne-Anderson: atmospheric data, these types of things,

424
00:24:39,880 --> 00:24:40,720
Hugo Bowne-Anderson: and basic analytics.

425
00:24:40,780 --> 00:24:42,040
Hugo Bowne-Anderson: I'm not even talking about machine learning there.

426
00:24:42,440 --> 00:24:45,540
Hugo Bowne-Anderson: But we have entered a regime now

427
00:24:45,540 --> 00:24:50,520
Hugo Bowne-Anderson: where you can build ML and AI-powered products

428
00:24:51,040 --> 00:24:54,820
Hugo Bowne-Anderson: by pinging APIs or hosting your own models

429
00:24:54,860 --> 00:24:55,520
Hugo Bowne-Anderson: and that type of stuff,

430
00:24:55,540 --> 00:24:58,300
Hugo Bowne-Anderson: whether it's from Hugging Face or wherever it may be,

431
00:24:58,880 --> 00:25:00,960
Hugo Bowne-Anderson: or using Olama locally.

432
00:25:01,500 --> 00:25:03,140
Hugo Bowne-Anderson: And in that case,

433
00:25:05,440 --> 00:25:07,360
Hugo Bowne-Anderson: I think because you're not doing the training yourself,

434
00:25:07,440 --> 00:25:08,740
Hugo Bowne-Anderson: you're able to do a lot of things

435
00:25:09,020 --> 00:25:12,000
Hugo Bowne-Anderson: without requiring massive, massive compute.

436
00:25:12,820 --> 00:25:12,980
Michael Kennedy: Yeah.

437
00:25:14,460 --> 00:25:15,700
Michael Kennedy: Yeah, there is a bit of a...

438
00:25:16,940 --> 00:25:19,440
Michael Kennedy: It seems like a big area, but it's a bit of a thin area

439
00:25:19,700 --> 00:25:22,640
Michael Kennedy: because you've got the regular programming you can do.

440
00:25:22,760 --> 00:25:26,000
Michael Kennedy: Then you need that async, you need that parallelism for higher compute,

441
00:25:26,360 --> 00:25:30,140
Michael Kennedy: but you don't go very far until someone says, "Fine, I'm doing it in Rust.

442
00:25:30,420 --> 00:25:33,200
Michael Kennedy: I'm doing it in C++," or it's an API, and then you don't need it again.

443
00:25:33,340 --> 00:25:37,640
Michael Kennedy: You know what I mean? There's like a little stratosphere sort of bit of it.

444
00:25:38,100 --> 00:25:38,380
Hugo Bowne-Anderson: Exactly.

445
00:25:39,480 --> 00:25:39,560
Michael Kennedy: Yeah.

446
00:25:39,980 --> 00:25:41,000
Hugo Bowne-Anderson: And happy Python Pi Day.

447
00:25:42,280 --> 00:25:43,620
Michael Kennedy: Yes, happy Python Pi Day.

448
00:25:44,500 --> 00:25:45,040
Michael Kennedy: That's very cool.

449
00:25:45,040 --> 00:25:51,560
Michael Kennedy: I have not even installed it yet today because uv has not shipped their support for it yet.

450
00:25:52,500 --> 00:26:02,800
Hugo Bowne-Anderson: I'm so â€“ when I mention new modern tools like Marimo and Polars and DuckDB, uv has to be in there as well.

451
00:26:04,200 --> 00:26:12,640
Hugo Bowne-Anderson: Also very excited about other package management, but plus plus, for lack of a better term, tools like Pixie, that Wolf Volprecht.

452
00:26:13,040 --> 00:26:19,180
Hugo Bowne-Anderson: his his team who i know have been on the show and um you know who uh people may know from mamba

453
00:26:19,380 --> 00:26:25,040
Hugo Bowne-Anderson: which helped us with conda so much um so uv is not the only only story out there solving these

454
00:26:25,840 --> 00:26:30,140
Michael Kennedy: i i agree i do think i do think it's really interesting especially for the data science

455
00:26:30,620 --> 00:26:37,700
Michael Kennedy: crowd because things have gotten better for those of us that use pip exclusively it's like faster

456
00:26:38,600 --> 00:26:43,000
Michael Kennedy: a little bit better resolution a little bit better workflow like some of the tools are brought

457
00:26:43,020 --> 00:26:49,140
Michael Kennedy: like pip-tools plus just regular pip but i think it's a bigger consideration for your side of the

458
00:26:49,260 --> 00:26:55,200
Michael Kennedy: fence in that there's conda and now do you stick with conda or do you use uv like that's

459
00:26:56,420 --> 00:27:03,320
Michael Kennedy: they they kind of compete more than pip did with uv i think actually i use uv i can i can i can

460
00:27:03,360 --> 00:27:08,640
Michael Kennedy: say that yeah i i agree i think i think uv is pushing over the edge and then the pyx stuff

461
00:27:08,620 --> 00:27:13,960
Michael Kennedy: that charlie's released if you're like an org where they help with building like the layers of

462
00:27:13,960 --> 00:27:18,740
Michael Kennedy: machine models and pytorch and stuff is it's pretty interesting yeah okay i also just want to say on

463
00:27:18,880 --> 00:27:25,040
Hugo Bowne-Anderson: python pi day that is so geeky and i i i would want to i do want to say show my geeky t-shirt to

464
00:27:25,220 --> 00:27:31,180
Hugo Bowne-Anderson: everyone which says schrodinger's cat wanted dead and alive it's a wanted poster so speaking of

465
00:27:32,700 --> 00:27:36,980
Michael Kennedy: that's perfect that's for me i i just have a sweater i'm sorry i didn't i didn't

466
00:27:36,860 --> 00:27:37,480
Hugo Bowne-Anderson: You're in a library, though.

467
00:27:37,900 --> 00:27:38,000
Hugo Bowne-Anderson: Yeah.

468
00:27:38,820 --> 00:27:38,980
Michael Kennedy: That's true.

469
00:27:39,040 --> 00:27:39,560
Michael Kennedy: I'm in a library.

470
00:27:39,660 --> 00:27:42,040
Michael Kennedy: It's full of books, so I'm sure something geeky is behind me.

471
00:27:43,240 --> 00:27:43,420
Michael Kennedy: All right.

472
00:27:43,580 --> 00:27:52,740
Michael Kennedy: So we've talked about maybe some of the other not so necessarily AI-focused tools is like what people should focus on.

473
00:27:53,380 --> 00:27:56,920
Michael Kennedy: But like we both said, it's so transformative.

474
00:27:58,000 --> 00:28:02,800
Michael Kennedy: And if people haven't actually tried it and seen it in action, you've got to see it to believe it.

475
00:28:02,800 --> 00:28:05,740
Michael Kennedy: Because I was a skeptic until my friend's like, no, let's sit down and let me show you.

476
00:28:05,860 --> 00:28:09,500
Michael Kennedy: I'm like, oh, okay, I get it.

477
00:28:10,340 --> 00:28:11,980
Michael Kennedy: And so let's talk about some of the AI tools.

478
00:28:12,680 --> 00:28:14,520
Hugo Bowne-Anderson: Yeah, and I'd like to kind of,

479
00:28:14,980 --> 00:28:17,360
Hugo Bowne-Anderson: I've done an initial slicing into different levels,

480
00:28:17,760 --> 00:28:21,740
Hugo Bowne-Anderson: which may be useful thinking through the evolution of these tools.

481
00:28:22,000 --> 00:28:26,660
Hugo Bowne-Anderson: And so how do we use AI to help us code?

482
00:28:26,800 --> 00:28:31,220
Hugo Bowne-Anderson: And jokingly, level zero, because we zero index here,

483
00:28:32,520 --> 00:28:34,760
Hugo Bowne-Anderson: is copy and pasting from Stack Overflow, right?

484
00:28:34,920 --> 00:28:42,500
Hugo Bowne-Anderson: Now, that's not quite using AI, but it is AI is using collective wisdom as opposed to stuff in yourself, right?

485
00:28:42,540 --> 00:28:44,780
Hugo Bowne-Anderson: So we've got that, okay?

486
00:28:45,160 --> 00:29:00,980
Hugo Bowne-Anderson: But then after our ChatGPT moment, people started copy, instead of copying and pasting between Stack Overflow and their IDE, VS Code, Jupyter Notebooks, whatever it may be, people started copying and pasting between ChatGPT and the IDE.

487
00:29:01,620 --> 00:29:06,220
Hugo Bowne-Anderson: So you would, you know, let's say you get an error message from your IDE, copy it into

488
00:29:06,340 --> 00:29:09,180
Hugo Bowne-Anderson: ChatGBT, give it a bit more context, whatever it may be.

489
00:29:09,950 --> 00:29:14,660
Hugo Bowne-Anderson: And then such as, you know, give it the code you wrote plus the error message, plus your

490
00:29:14,840 --> 00:29:15,080
Hugo Bowne-Anderson: environment.

491
00:29:16,030 --> 00:29:21,940
Hugo Bowne-Anderson: And it will be pretty good at helping you depending on what packages you're using, what

492
00:29:22,060 --> 00:29:22,200
Hugo Bowne-Anderson: framework.

493
00:29:22,310 --> 00:29:26,620
Hugo Bowne-Anderson: If you're working in PyData, absolutely fantastic, right?

494
00:29:27,280 --> 00:29:29,420
Hugo Bowne-Anderson: Because, of course, it's trained on scikit-learn.

495
00:29:29,540 --> 00:29:30,860
Hugo Bowne-Anderson: It's trained on mapplotlib.

496
00:29:31,020 --> 00:29:31,980
Hugo Bowne-Anderson: It's trained on Seaborn.

497
00:29:32,120 --> 00:29:33,760
Hugo Bowne-Anderson: It's trained on spaCy, right?

498
00:29:34,680 --> 00:29:40,000
Hugo Bowne-Anderson: One of the biggest frustrations at that point was it wasn't trained on ChatGPT's current API.

499
00:29:40,400 --> 00:29:48,600
Hugo Bowne-Anderson: So it would always give you, even if you corrected it, it would always revert to a previous OpenAI API.

500
00:29:48,870 --> 00:29:49,000
Hugo Bowne-Anderson: Okay.

501
00:29:49,420 --> 00:29:50,900
Hugo Bowne-Anderson: So level one, copy and pasting.

502
00:29:51,340 --> 00:29:53,380
Hugo Bowne-Anderson: Level two, code completion in IDE.

503
00:29:53,490 --> 00:29:55,220
Hugo Bowne-Anderson: So you can think copilot or whatever.

504
00:29:55,620 --> 00:29:58,060
Hugo Bowne-Anderson: You're writing code and it will start suggesting things, right?

505
00:29:58,320 --> 00:30:00,000
Hugo Bowne-Anderson: So that's just working your IDE.

506
00:30:00,640 --> 00:30:03,840
Hugo Bowne-Anderson: Now, I think these things people probably know about.

507
00:30:05,220 --> 00:30:08,380
Hugo Bowne-Anderson: But then level three is where things get really wild for me,

508
00:30:08,600 --> 00:30:12,520
Hugo Bowne-Anderson: where you actually, you have an agent in your IDE or your terminal.

509
00:30:12,800 --> 00:30:18,440
Hugo Bowne-Anderson: So Cursor, which is a VS CodeFork, has an agent and a chat in it

510
00:30:18,580 --> 00:30:22,060
Hugo Bowne-Anderson: where you can have an empty repository and say,

511
00:30:22,180 --> 00:30:28,160
Hugo Bowne-Anderson: hey, I want you to write a program that, you know,

512
00:30:28,420 --> 00:30:34,200
Hugo Bowne-Anderson: creates a rag pipeline over the documents in this subdirectory

513
00:30:34,200 --> 00:30:35,060
Hugo Bowne-Anderson: or something like that.

514
00:30:35,290 --> 00:30:37,140
Hugo Bowne-Anderson: And it will go and do that immediately.

515
00:30:37,410 --> 00:30:40,620
Hugo Bowne-Anderson: It will be, when you do that, it won't be great.

516
00:30:40,720 --> 00:30:41,940
Hugo Bowne-Anderson: It'll do all types of nonsense.

517
00:30:42,090 --> 00:30:44,420
Hugo Bowne-Anderson: It might write lots of directories and subdirectories.

518
00:30:45,090 --> 00:30:47,160
Hugo Bowne-Anderson: So we can talk about some of the gotchas,

519
00:30:47,770 --> 00:30:50,920
Hugo Bowne-Anderson: but this is agentic coding where you're chatting

520
00:30:51,280 --> 00:30:53,180
Hugo Bowne-Anderson: and it just throws stuff in.

521
00:30:54,540 --> 00:30:55,500
Hugo Bowne-Anderson: I will also add,

522
00:30:55,530 --> 00:30:57,140
Hugo Bowne-Anderson: and this is something we mentioned briefly beforehand.

523
00:30:57,680 --> 00:31:00,360
Hugo Bowne-Anderson: I don't like typing that much, to be honest.

524
00:31:00,420 --> 00:31:01,860
Hugo Bowne-Anderson: So I use Super Whisper.

525
00:31:02,020 --> 00:31:05,240
Hugo Bowne-Anderson: There are other tools to do this where I dictate to it.

526
00:31:05,820 --> 00:31:07,680
Hugo Bowne-Anderson: And I also have a stream deck,

527
00:31:08,120 --> 00:31:09,640
Hugo Bowne-Anderson: which is what we mentioned beforehand,

528
00:31:11,100 --> 00:31:13,100
Hugo Bowne-Anderson: which a lot of content creators use this.

529
00:31:13,260 --> 00:31:17,700
Hugo Bowne-Anderson: It's like buttons and knobs that you can assign to macros.

530
00:31:18,200 --> 00:31:20,160
Hugo Bowne-Anderson: And so when I have a button that opens cursor,

531
00:31:20,440 --> 00:31:21,480
Hugo Bowne-Anderson: puts it in agent mode,

532
00:31:21,980 --> 00:31:25,880
Hugo Bowne-Anderson: attaches Claude, Sonnet 4.5 or Gemma 2.5,

533
00:31:26,200 --> 00:31:27,340
Hugo Bowne-Anderson: whatever it may be, exactly.

534
00:31:27,560 --> 00:31:29,240
Hugo Bowne-Anderson: that's a stream deck.

535
00:31:29,660 --> 00:31:33,040
Hugo Bowne-Anderson: And then I have accept code buttons and reject code

536
00:31:33,050 --> 00:31:33,820
Hugo Bowne-Anderson: and that type of stuff.

537
00:31:34,030 --> 00:31:37,460
Hugo Bowne-Anderson: So I can actually build a not insignificant amount of software

538
00:31:37,660 --> 00:31:39,120
Hugo Bowne-Anderson: with my voice and three buttons.

539
00:31:40,180 --> 00:31:40,760
Michael Kennedy: That's awesome.

540
00:31:41,360 --> 00:31:42,620
Hugo Bowne-Anderson: Which is so powerful.

541
00:31:44,160 --> 00:31:46,140
Michael Kennedy: I also, I want to just say,

542
00:31:46,210 --> 00:31:49,240
Michael Kennedy: I also find that if I do dictation,

543
00:31:50,020 --> 00:31:54,140
Michael Kennedy: I can be a lot more patient and thorough in a lot of ways, right?

544
00:31:54,320 --> 00:31:55,720
Michael Kennedy: Like, I don't know about you,

545
00:31:55,860 --> 00:31:57,480
Michael Kennedy: but I've had like RSI issues.

546
00:31:57,500 --> 00:32:00,800
Michael Kennedy: So I've got to be real cognizant of like how much typing I do.

547
00:32:01,020 --> 00:32:04,100
Michael Kennedy: I've got my Microsoft Sculpt ergonomic keyboard

548
00:32:04,300 --> 00:32:05,240
Michael Kennedy: that I drag with me everywhere

549
00:32:05,380 --> 00:32:07,920
Michael Kennedy: because square keyboards will destroy me in like a week.

550
00:32:08,660 --> 00:32:12,900
Michael Kennedy: And so it lets me go on without worrying about those kinds of things.

551
00:32:13,000 --> 00:32:16,780
Michael Kennedy: I use Mac Whisper, but it's super similar, I believe, right?

552
00:32:16,900 --> 00:32:18,320
Hugo Bowne-Anderson: It just uses the same underlying engine.

553
00:32:20,019 --> 00:32:21,920
Michael Kennedy: And that's really nice that you can...

554
00:32:22,480 --> 00:32:24,120
Michael Kennedy: I do it for email. I do it for lots of things.

555
00:32:26,340 --> 00:32:30,080
Hugo Bowne-Anderson: I love how you mentioned it does help one be more patient because yeah,

556
00:32:30,300 --> 00:32:32,539
Hugo Bowne-Anderson: when typing, well, when chatting with an AI,

557
00:32:33,680 --> 00:32:37,340
Hugo Bowne-Anderson: you can get frustrated and the friction in typing and correcting yourself and

558
00:32:37,340 --> 00:32:38,860
Hugo Bowne-Anderson: that type of stuff you just don't have when, when,

559
00:32:38,980 --> 00:32:40,560
Hugo Bowne-Anderson: when speaking natural language.

560
00:32:41,120 --> 00:32:44,980
Michael Kennedy: Yeah. And I find that people, I don't, I don't, I mean,

561
00:32:45,040 --> 00:32:47,740
Michael Kennedy: this is not scientific, but my experience has been that people say like,

562
00:32:47,840 --> 00:32:48,820
Michael Kennedy: oh, this stuff is not good.

563
00:32:48,960 --> 00:32:54,359
Michael Kennedy: It always just gives me junk results and so on is so often there's not enough

564
00:32:54,420 --> 00:33:01,320
Michael Kennedy: information given. It'd be like, create me a graph, not use Plotly to create this type of graph

565
00:33:01,700 --> 00:33:06,800
Michael Kennedy: with this type of focus from this data like I did before. You know what I mean? Those are really

566
00:33:06,960 --> 00:33:12,620
Michael Kennedy: different things. And the more specificity you can give these tools, the better. I use a lot of AI

567
00:33:12,880 --> 00:33:20,600
Michael Kennedy: stuff. And I would say I have plenty of prompts that are pages long. And I was like, here's a file.

568
00:33:20,920 --> 00:33:23,220
Michael Kennedy: Here's four pages of what I want you to do with it.

569
00:33:23,920 --> 00:33:24,420
Michael Kennedy: Let's go.

570
00:33:24,440 --> 00:33:26,380
Michael Kennedy: And it gives not always the right answer,

571
00:33:26,420 --> 00:33:28,760
Michael Kennedy: but incredible results compared to what if you just say,

572
00:33:28,860 --> 00:33:30,000
Michael Kennedy: you know, analyze this or whatever.

573
00:33:30,640 --> 00:33:31,120
Hugo Bowne-Anderson: Absolutely.

574
00:33:31,280 --> 00:33:33,320
Hugo Bowne-Anderson: And we'll get to this when we talk about gotchas,

575
00:33:33,420 --> 00:33:36,740
Hugo Bowne-Anderson: but having a conversation with your system

576
00:33:37,280 --> 00:33:38,880
Hugo Bowne-Anderson: before getting it to write anything

577
00:33:39,940 --> 00:33:42,100
Hugo Bowne-Anderson: is incredibly important and productive.

578
00:33:42,980 --> 00:33:45,800
Hugo Bowne-Anderson: Isaac Flath, who he has a wonderful course on Maven

579
00:33:46,020 --> 00:33:47,900
Hugo Bowne-Anderson: called Elite AI Assisted Coding,

580
00:33:48,020 --> 00:33:50,260
Hugo Bowne-Anderson: which I'm actually starting as a student this week.

581
00:33:50,700 --> 00:33:51,860
Hugo Bowne-Anderson: and I may give a guest talk there.

582
00:33:52,840 --> 00:33:54,040
Hugo Bowne-Anderson: I don't know whether he came up with it,

583
00:33:54,040 --> 00:33:57,280
Hugo Bowne-Anderson: but he calls it Socratic and dialogue-driven development,

584
00:33:57,500 --> 00:33:59,320
Hugo Bowne-Anderson: where you essentially pair program with the AI.

585
00:33:59,780 --> 00:34:02,360
Hugo Bowne-Anderson: Don't expect it to do everything, but have conversations.

586
00:34:02,820 --> 00:34:06,360
Hugo Bowne-Anderson: So the other thing is a lot of these agentic systems like Cursor,

587
00:34:06,480 --> 00:34:08,780
Hugo Bowne-Anderson: which I use daily, probably a bit too much,

588
00:34:09,050 --> 00:34:16,440
Hugo Bowne-Anderson: you can plug into any state-of-the-art AI API.

589
00:34:16,800 --> 00:34:19,179
Hugo Bowne-Anderson: So, you know, Sonnet 4.5 came out recently,

590
00:34:19,320 --> 00:34:21,080
Hugo Bowne-Anderson: and the day after you could use that in cursor.

591
00:34:21,399 --> 00:34:22,940
Hugo Bowne-Anderson: Gemini 2.5 came out a while ago.

592
00:34:23,580 --> 00:34:24,780
Hugo Bowne-Anderson: Then you couldn't plug it in.

593
00:34:25,520 --> 00:34:27,040
Hugo Bowne-Anderson: GPT-5 and so on.

594
00:34:28,020 --> 00:34:30,440
Hugo Bowne-Anderson: The other thing I just wanted to give a shout out to is Continue.

595
00:34:31,460 --> 00:34:35,060
Hugo Bowne-Anderson: Tyler Dunn, speaking of modern tools and open source tools,

596
00:34:36,080 --> 00:34:39,399
Hugo Bowne-Anderson: it's like an open source cursor of sorts.

597
00:34:39,440 --> 00:34:41,480
Hugo Bowne-Anderson: And I mean, he wouldn't frame it that way,

598
00:34:41,700 --> 00:34:43,679
Hugo Bowne-Anderson: but you can have all your own local models,

599
00:34:44,560 --> 00:34:46,560
Hugo Bowne-Anderson: data preserving, privacy preserving,

600
00:34:47,440 --> 00:34:48,820
Hugo Bowne-Anderson: and use those in this way.

601
00:34:49,159 --> 00:34:51,520
Hugo Bowne-Anderson: So just going back to this slicing though,

602
00:34:51,850 --> 00:34:53,139
Hugo Bowne-Anderson: level one, copy and paste code,

603
00:34:53,450 --> 00:34:54,639
Hugo Bowne-Anderson: level two, code completion,

604
00:34:55,280 --> 00:34:58,280
Hugo Bowne-Anderson: level three, agents in an IDE or terminal.

605
00:34:58,560 --> 00:34:59,860
Hugo Bowne-Anderson: So Claude code, for example,

606
00:34:59,910 --> 00:35:00,620
Hugo Bowne-Anderson: can be in your terminal,

607
00:35:01,440 --> 00:35:02,980
Hugo Bowne-Anderson: cursor, VS Code, fork.

608
00:35:03,600 --> 00:35:05,860
Hugo Bowne-Anderson: Level four is embedded in other tools

609
00:35:06,320 --> 00:35:08,320
Hugo Bowne-Anderson: like Slack or Discord or email.

610
00:35:08,750 --> 00:35:10,880
Hugo Bowne-Anderson: You can tag cursor in Slack to,

611
00:35:11,500 --> 00:35:15,980
Hugo Bowne-Anderson: you know, if you notice a documentation fault,

612
00:35:16,340 --> 00:35:19,280
Hugo Bowne-Anderson: You can tag it in Slack to fix that.

613
00:35:19,960 --> 00:35:22,580
Hugo Bowne-Anderson: Manus, you can tag in email threads now.

614
00:35:23,740 --> 00:35:25,840
Hugo Bowne-Anderson: Level 5 is more proactive.

615
00:35:26,040 --> 00:35:27,400
Hugo Bowne-Anderson: So all of these are reactive systems.

616
00:35:28,680 --> 00:35:29,800
Hugo Bowne-Anderson: Level 5 is more proactive.

617
00:35:29,900 --> 00:35:31,420
Hugo Bowne-Anderson: So you can have Cursor, for example,

618
00:35:31,640 --> 00:35:32,360
Hugo Bowne-Anderson: and a lot of these systems,

619
00:35:32,380 --> 00:35:33,340
Hugo Bowne-Anderson: I just use Cursor the most,

620
00:35:33,740 --> 00:35:35,720
Hugo Bowne-Anderson: to do code review in CI,

621
00:35:35,900 --> 00:35:36,700
Hugo Bowne-Anderson: in continuous integration.

622
00:35:37,260 --> 00:35:39,160
Hugo Bowne-Anderson: So whenever I submit a PR,

623
00:35:39,500 --> 00:35:42,180
Hugo Bowne-Anderson: Cursor can come in and do a code review there.

624
00:35:43,440 --> 00:35:44,900
Hugo Bowne-Anderson: Now I'm getting a bit to future music.

625
00:35:45,360 --> 00:35:54,840
Hugo Bowne-Anderson: Level six, we've got async or background agents that just, you know, do stuff in the background, essentially, which we're going to see a lot more of.

626
00:35:55,140 --> 00:36:00,080
Hugo Bowne-Anderson: And then level seven, which we haven't seen so much proactive agents.

627
00:36:00,140 --> 00:36:04,120
Hugo Bowne-Anderson: And I think these are going to be huge that will just notice stuff happening in production.

628
00:36:04,260 --> 00:36:05,580
Hugo Bowne-Anderson: Like, hey, we have this outlier here.

629
00:36:05,820 --> 00:36:07,640
Hugo Bowne-Anderson: Oh, this didn't quite work.

630
00:36:07,920 --> 00:36:10,900
Hugo Bowne-Anderson: or agents that come to me on a Monday morning and be like,

631
00:36:11,050 --> 00:36:12,940
Hugo Bowne-Anderson: hey, check this out, check that out, check that,

632
00:36:13,120 --> 00:36:16,020
Hugo Bowne-Anderson: like a good colleague, right?

633
00:36:16,400 --> 00:36:17,260
Michael Kennedy: Yeah, that's awesome.

634
00:36:17,940 --> 00:36:18,040
Hugo Bowne-Anderson: Yeah.

635
00:36:18,740 --> 00:36:24,160
Hugo Bowne-Anderson: But we're already at level five and kind of got background agents as well.

636
00:36:24,230 --> 00:36:28,640
Hugo Bowne-Anderson: So we're getting, yeah, to a lot of really exciting places.

637
00:36:29,380 --> 00:36:29,520
Michael Kennedy: Yeah.

638
00:36:29,610 --> 00:36:34,180
Michael Kennedy: So I'm 100% bought in up to level four, probably.

639
00:36:34,540 --> 00:36:39,280
Michael Kennedy: Like certainly the agent decoding, a little bit of the code review, not so much in CI,

640
00:36:39,560 --> 00:36:43,620
Michael Kennedy: but like looking at the stuff that I might ask you like, hey, what's going on here?

641
00:36:44,440 --> 00:36:45,260
Michael Kennedy: Why is it like this?

642
00:36:46,260 --> 00:36:48,840
Michael Kennedy: Background agents, I just haven't got there.

643
00:36:48,890 --> 00:36:54,360
Michael Kennedy: They seem like they don't have enough to work with, right?

644
00:36:54,440 --> 00:36:57,520
Michael Kennedy: They don't have my whole machine and all the setups and all the things they need.

645
00:36:57,550 --> 00:36:59,140
Michael Kennedy: But I can see how they would be useful.

646
00:36:59,270 --> 00:37:01,380
Michael Kennedy: Certainly the way you're describing like a good colleague.

647
00:37:02,720 --> 00:37:05,520
Michael Kennedy: And so one example is not necessarily in software,

648
00:37:06,100 --> 00:37:08,760
Hugo Bowne-Anderson: but background agents, and I haven't done this,

649
00:37:08,830 --> 00:37:09,680
Hugo Bowne-Anderson: but I've got friends and colleagues

650
00:37:09,780 --> 00:37:11,720
Hugo Bowne-Anderson: who've built background agents that monitor their inbox

651
00:37:12,300 --> 00:37:14,520
Hugo Bowne-Anderson: and will ping them, like their email, sorry,

652
00:37:15,739 --> 00:37:17,800
Hugo Bowne-Anderson: and will cluster emails and be like,

653
00:37:17,830 --> 00:37:19,300
Hugo Bowne-Anderson: hey, you really should reply to this one.

654
00:37:19,540 --> 00:37:21,560
Hugo Bowne-Anderson: This is a prospect or a client

655
00:37:21,680 --> 00:37:23,080
Hugo Bowne-Anderson: that really needs your attention right now.

656
00:37:23,839 --> 00:37:26,120
Michael Kennedy: Yeah, I think that kind of stuff would be really neat.

657
00:37:26,580 --> 00:37:27,700
Michael Kennedy: I will throw out there now,

658
00:37:27,870 --> 00:37:29,640
Michael Kennedy: this comes from Sentry, who is a sponsor of the show,

659
00:37:29,750 --> 00:37:31,260
Michael Kennedy: just to be fair, but I'm not doing this

660
00:37:31,270 --> 00:37:32,100
Michael Kennedy: because they sponsored it.

661
00:37:32,900 --> 00:37:40,280
Michael Kennedy: they added this thing called seer that when your app collects an exception or

662
00:37:40,420 --> 00:37:43,620
Michael Kennedy: something or doesn't collect and it gets dumped up there depending how you send it

663
00:37:43,620 --> 00:37:48,300
Michael Kennedy: up there is it'll apply AI to whatever it receives and it'll look if you bind it

664
00:37:48,360 --> 00:37:53,900
Michael Kennedy: to your github and so on it'll like try to understand the project and maybe by

665
00:37:53,900 --> 00:37:57,760
Michael Kennedy: the time you get to look at the bug report it actually has a solution

666
00:37:58,100 --> 00:38:02,120
Michael Kennedy: suggested as well which and it'll do a PR which that's on the verge of what you

667
00:38:02,700 --> 00:38:05,780
Michael Kennedy: suggesting as this sort of like proactive buddy that's just hanging out there.

668
00:38:06,740 --> 00:38:14,180
Hugo Bowne-Anderson: Absolutely. And as I said, I do want to mention just a few gotchas. Or actually, let me just say

669
00:38:14,620 --> 00:38:19,120
Hugo Bowne-Anderson: some of the really powerful use cases in data science, since we are talking about foundation

670
00:38:19,220 --> 00:38:27,340
Hugo Bowne-Anderson: models for data science. Just writing code. I mean, text to SQL, all these LLMs are trained on now,

671
00:38:27,580 --> 00:38:33,820
Hugo Bowne-Anderson: Right? So writing SQL code based on what you say or what you type in natural language.

672
00:38:34,320 --> 00:38:38,360
Hugo Bowne-Anderson: Now, chat with it beforehand so that you make sure it understands your schema.

673
00:38:38,860 --> 00:38:42,040
Hugo Bowne-Anderson: It may not be great at complex joins, this type of stuff.

674
00:38:43,020 --> 00:38:45,820
Hugo Bowne-Anderson: Understand the system you're working with. Get a feel for how it works.

675
00:38:46,980 --> 00:38:54,380
Hugo Bowne-Anderson: Actually think of it as, you know, like a super excited ADHD-esque, perhaps slightly autistic as well.

676
00:38:54,410 --> 00:38:56,880
Hugo Bowne-Anderson: And I mean that with all the love.

677
00:38:57,740 --> 00:39:00,600
Hugo Bowne-Anderson: in terms of absolute deep memory,

678
00:39:00,670 --> 00:39:02,880
Hugo Bowne-Anderson: be able to recall a lot of information.

679
00:39:04,800 --> 00:39:06,280
Hugo Bowne-Anderson: And on the ADHD spectrum,

680
00:39:06,330 --> 00:39:08,200
Hugo Bowne-Anderson: in terms of just how it will do,

681
00:39:09,460 --> 00:39:10,720
Hugo Bowne-Anderson: it will spread its attention

682
00:39:10,930 --> 00:39:12,120
Hugo Bowne-Anderson: over a lot of different places

683
00:39:12,300 --> 00:39:13,420
Hugo Bowne-Anderson: and create lots of different stuff,

684
00:39:13,500 --> 00:39:14,580
Hugo Bowne-Anderson: some of which may not work,

685
00:39:14,580 --> 00:39:16,660
Hugo Bowne-Anderson: but some of which will be incredible.

686
00:39:17,120 --> 00:39:19,040
Hugo Bowne-Anderson: So have empathy for your system in that sense.

687
00:39:19,160 --> 00:39:20,920
Hugo Bowne-Anderson: But writing SQL code, amazing.

688
00:39:21,720 --> 00:39:22,160
Hugo Bowne-Anderson: PyDataStack.

689
00:39:22,880 --> 00:39:24,820
Michael Kennedy: I want to run an idea by you

690
00:39:24,890 --> 00:39:26,040
Michael Kennedy: and just see what you think here

691
00:39:26,060 --> 00:39:27,340
Michael Kennedy: with what you just said with like,

692
00:39:28,180 --> 00:39:29,580
Michael Kennedy: think of it as this super excited,

693
00:39:30,440 --> 00:39:34,020
Michael Kennedy: somewhat scatterbrained junior helper,

694
00:39:34,900 --> 00:39:35,420
Michael Kennedy: excited friend.

695
00:39:38,160 --> 00:39:39,240
Michael Kennedy: If you had hired somebody,

696
00:39:40,440 --> 00:39:41,340
Michael Kennedy: even if they went to Stanford,

697
00:39:42,320 --> 00:39:43,340
Michael Kennedy: but they hadn't really done work

698
00:39:43,520 --> 00:39:45,040
Michael Kennedy: on any like major data science projects

699
00:39:45,460 --> 00:39:46,340
Michael Kennedy: and they came to your company

700
00:39:46,960 --> 00:39:47,960
Michael Kennedy: and you gave them a job,

701
00:39:48,940 --> 00:39:50,100
Michael Kennedy: would you expect 100%,

702
00:39:50,260 --> 00:39:52,360
Michael Kennedy: like absolutely 100% correctness?

703
00:39:52,700 --> 00:39:53,360
Michael Kennedy: And they're, no.

704
00:39:54,280 --> 00:39:56,020
Michael Kennedy: So I don't know why people expect

705
00:39:56,080 --> 00:39:58,220
Michael Kennedy: the AI to be literally 100%

706
00:39:58,300 --> 00:39:59,740
Michael Kennedy: I think I have an idea why, but

707
00:40:00,240 --> 00:40:02,340
Michael Kennedy: expecting the AI to be 100% right

708
00:40:03,680 --> 00:40:04,040
Michael Kennedy: where

709
00:40:04,540 --> 00:40:05,880
Michael Kennedy: it's kind of doing some of this

710
00:40:06,110 --> 00:40:08,000
Michael Kennedy: human level type of reason. I mean, not thinking

711
00:40:08,120 --> 00:40:09,280
Michael Kennedy: I'm not saying that, but

712
00:40:10,320 --> 00:40:11,700
Michael Kennedy: this kind of problem,

713
00:40:11,930 --> 00:40:13,080
Michael Kennedy: this creative problem solving,

714
00:40:14,299 --> 00:40:15,840
Michael Kennedy: we should have a little bit of patience

715
00:40:16,080 --> 00:40:17,800
Michael Kennedy: for if it gets it wrong, especially if we give it

716
00:40:17,940 --> 00:40:19,400
Michael Kennedy: poor directions. You know what I mean?

717
00:40:20,030 --> 00:40:21,080
Michael Kennedy: Without a doubt. Yeah.

718
00:40:21,720 --> 00:40:23,900
Michael Kennedy: I just feel like people so often go, well, it's a computer

719
00:40:24,060 --> 00:40:25,900
Michael Kennedy: and it's wrong, so it's trash. It's no good.

720
00:40:26,160 --> 00:40:30,760
Michael Kennedy: well was it 95% right because that's really helpful this is so important and there are

721
00:40:31,000 --> 00:40:35,960
Hugo Bowne-Anderson: several things in there firstly I think when after our chat champion moment Jeremy Howard noticed a

722
00:40:36,140 --> 00:40:41,140
Hugo Bowne-Anderson: complaint that people like oh I need to chat with like it doesn't do the thing the first time and I

723
00:40:41,220 --> 00:40:44,960
Hugo Bowne-Anderson: need to correct it and Jeremy was like what type of human don't you need to have a conversation with

724
00:40:45,040 --> 00:40:51,720
Hugo Bowne-Anderson: to learn learn stuff um the other thing is in all of these well nearly all of these systems now

725
00:40:52,240 --> 00:40:57,220
Hugo Bowne-Anderson: you have memory and cursor for example has cursor rules whereas if you notice stuff that it doesn't

726
00:40:57,580 --> 00:41:01,520
Hugo Bowne-Anderson: that it does or doesn't do put it in the rules you can have project specific rules you can have

727
00:41:01,980 --> 00:41:09,540
Hugo Bowne-Anderson: cursor uh general rules um this type of stuff um such as always explain your reasoning and to

728
00:41:09,620 --> 00:41:15,380
Hugo Bowne-Anderson: your point i don't think these things think but they mimic reasoning and thought um in in in pretty

729
00:41:15,800 --> 00:41:24,620
Hugo Bowne-Anderson: sophisticated ways. So I totally agree with that. Also, use these things to not only write code,

730
00:41:24,800 --> 00:41:33,160
Hugo Bowne-Anderson: but to write tests for code producers, right? To debug, to add assertions. Now, also,

731
00:41:33,900 --> 00:41:41,400
Hugo Bowne-Anderson: make sure you're always reading the code on average that it writes. If things are really

732
00:41:41,400 --> 00:41:45,700
Hugo Bowne-Anderson: important, it's about your appetite for risk. Maybe if things are really important, make sure

733
00:41:45,840 --> 00:41:53,680
Hugo Bowne-Anderson: you know what the code does and read it. If things aren't as important, maybe you don't need to. And

734
00:41:53,740 --> 00:42:00,400
Hugo Bowne-Anderson: an example I'll give there is one of the biggest wins here is being able to vibe code your own

735
00:42:00,700 --> 00:42:04,420
Michael Kennedy: data viewers. So let's say I'm building... 100%. I agree with you on this.

736
00:42:04,600 --> 00:42:09,440
Hugo Bowne-Anderson: Incredible, right? So if I'm building an LLM powered app where... Okay, building an LLM powered

737
00:42:09,460 --> 00:42:15,120
Hugo Bowne-Anderson: out and I've got all these conversations, I can build a vibe code, a custom, a bespoke custom

738
00:42:15,560 --> 00:42:23,160
Hugo Bowne-Anderson: viewer to view that. If it's an agent that writes emails, I can even build a viewer that displays

739
00:42:24,660 --> 00:42:30,420
Hugo Bowne-Anderson: the conversations as emails or whatever it may be, right? Now, I need to make sure that it's

740
00:42:30,880 --> 00:42:35,940
Hugo Bowne-Anderson: displaying the correct information. So I need to make sure that my traces are actually looking

741
00:42:35,980 --> 00:42:40,580
Hugo Bowne-Anderson: looking correct so i need to understand that code but the ins and outs of the front end it's building

742
00:42:41,200 --> 00:42:46,920
Hugo Bowne-Anderson: not not the biggest deal for me so figure out what's important and and what isn't um there's

743
00:42:47,060 --> 00:42:53,100
Michael Kennedy: so many tools like this that are like it's not me worth taking a week to write that but wouldn't it

744
00:42:53,100 --> 00:42:57,820
Michael Kennedy: be cool if i had that and nothing depends on it it's kind of like its own side little utility

745
00:42:58,340 --> 00:43:02,980
Michael Kennedy: there's no it's not a building block that's going to become an important foundational thing it just

746
00:43:02,940 --> 00:43:04,860
Michael Kennedy: If it works, you're like, that's awesome, I have that.

747
00:43:05,800 --> 00:43:08,740
Michael Kennedy: There's people who have got to take advantage of just going like,

748
00:43:08,880 --> 00:43:10,840
Michael Kennedy: oh, I need a utility that does X,

749
00:43:11,420 --> 00:43:15,280
Michael Kennedy: or I need a view in our admin section of the web app that does this.

750
00:43:15,480 --> 00:43:16,420
Michael Kennedy: Nothing depends on it.

751
00:43:16,820 --> 00:43:18,140
Michael Kennedy: If it works, amazing.

752
00:43:18,220 --> 00:43:21,360
Michael Kennedy: If it doesn't, well, it didn't exist anyway, so whatever.

753
00:43:22,220 --> 00:43:23,500
Hugo Bowne-Anderson: There's so many opportunities.

754
00:43:23,920 --> 00:43:25,140
Hugo Bowne-Anderson: I love this so much.

755
00:43:26,120 --> 00:43:28,640
Hugo Bowne-Anderson: I want to take a slight detour because it's so important.

756
00:43:28,720 --> 00:43:36,940
Hugo Bowne-Anderson: I actually think the surface area of what software is, is expanding and changing completely.

757
00:43:36,970 --> 00:43:43,120
Hugo Bowne-Anderson: So let's just look at, take a bit of a sociological big picture look at history where software,

758
00:43:45,880 --> 00:43:49,240
Hugo Bowne-Anderson: classically, has been very expensive to build, right?

759
00:43:49,600 --> 00:43:56,760
Hugo Bowne-Anderson: You've needed to pay a lot of not inexpensive engineers to build out a sophisticated product

760
00:43:57,620 --> 00:44:00,700
Hugo Bowne-Anderson: for that reason, you've had to get a lot of demand.

761
00:44:01,120 --> 00:44:03,200
Hugo Bowne-Anderson: You've had to have a lot of service area of the market.

762
00:44:03,480 --> 00:44:05,520
Hugo Bowne-Anderson: What that's meant is that you've needed to cover

763
00:44:06,100 --> 00:44:10,220
Hugo Bowne-Anderson: a lot of edge cases to satisfy a large market

764
00:44:10,700 --> 00:44:13,300
Hugo Bowne-Anderson: so that you can make revenue based on the costs

765
00:44:13,580 --> 00:44:14,960
Hugo Bowne-Anderson: that you're accruing, right?

766
00:44:15,580 --> 00:44:19,400
Hugo Bowne-Anderson: Now, with the ability to even vibe code

767
00:44:19,400 --> 00:44:23,480
Hugo Bowne-Anderson: or use AI-assisted coding to build this type of stuff,

768
00:44:23,600 --> 00:44:26,080
Hugo Bowne-Anderson: it changes what we can build.

769
00:44:26,540 --> 00:44:31,660
Hugo Bowne-Anderson: and what it needs, what type of people it needs to satisfy.

770
00:44:32,020 --> 00:44:34,560
Hugo Bowne-Anderson: So that's why the conversation of like vibe coding

771
00:44:34,560 --> 00:44:37,240
Hugo Bowne-Anderson: is going to bury Salesforce or SaaS

772
00:44:38,420 --> 00:44:40,340
Hugo Bowne-Anderson: versus like old men screaming at clouds,

773
00:44:40,540 --> 00:44:42,900
Hugo Bowne-Anderson: vibe coding sucks or whatever it is,

774
00:44:43,560 --> 00:44:45,760
Hugo Bowne-Anderson: misses the entire middle ground

775
00:44:46,320 --> 00:44:48,580
Hugo Bowne-Anderson: of the types of things that are possible.

776
00:44:48,640 --> 00:44:51,440
Hugo Bowne-Anderson: And I do think internal products such as,

777
00:44:51,880 --> 00:44:53,040
Hugo Bowne-Anderson: we've talked about data viewers,

778
00:44:53,700 --> 00:44:55,080
Hugo Bowne-Anderson: internal products such as, you know,

779
00:44:56,060 --> 00:45:02,060
Hugo Bowne-Anderson: Lots of companies are ripping out their marketing automation stacks and building things internally

780
00:45:02,880 --> 00:45:10,300
Hugo Bowne-Anderson: through to, I mean, I've got a friend who built a chess tutor app, which, I mean, it's

781
00:45:10,400 --> 00:45:14,260
Hugo Bowne-Anderson: not chess.com, but like a hundred of his friends use it, right?

782
00:45:14,660 --> 00:45:20,440
Hugo Bowne-Anderson: So the idea of the different types of software we can build now and thinking about, you know,

783
00:45:21,320 --> 00:45:23,340
Hugo Bowne-Anderson: ephemeral software or just-in-time software,

784
00:45:24,480 --> 00:45:26,340
Hugo Bowne-Anderson: disposable software, fast software

785
00:45:27,160 --> 00:45:28,860
Hugo Bowne-Anderson: that we can build to solve a problem right now

786
00:45:29,090 --> 00:45:30,280
Hugo Bowne-Anderson: and then move on.

787
00:45:30,510 --> 00:45:32,300
Hugo Bowne-Anderson: I think we need to shift our mental model

788
00:45:32,390 --> 00:45:33,660
Hugo Bowne-Anderson: of what software actually is.

789
00:45:35,600 --> 00:45:36,340
Hugo Bowne-Anderson: Oh, you're on mute, Michael.

790
00:45:37,880 --> 00:45:38,120
Michael Kennedy: Thank you.

791
00:45:38,120 --> 00:45:38,780
Michael Kennedy: I 100% agree.

792
00:45:39,030 --> 00:45:41,220
Michael Kennedy: And it's such an exciting time.

793
00:45:44,280 --> 00:45:46,080
Michael Kennedy: I also think this actually has an implication

794
00:45:46,580 --> 00:45:48,440
Michael Kennedy: for PyPI packages

795
00:45:48,650 --> 00:45:50,720
Michael Kennedy: and a lot of these just external packages.

796
00:45:51,440 --> 00:45:52,620
Michael Kennedy: So think about the ones you use.

797
00:45:52,740 --> 00:45:56,800
Michael Kennedy: This is not going to happen for Pandas or Polars or Jupyter or something like that.

798
00:45:57,170 --> 00:46:09,740
Michael Kennedy: But how often have you gone like, "Oh, I need a package that will let me look up both my IPv4 and IPv6 IP address."

799
00:46:10,180 --> 00:46:12,420
Michael Kennedy: And you'd take that as a dependency.

800
00:46:13,540 --> 00:46:17,720
Michael Kennedy: That's like using one function out of whatever thing you grab that might give you that information.

801
00:46:18,380 --> 00:46:21,740
Michael Kennedy: and there's a lot more opportunity to have fewer building blocks

802
00:46:21,880 --> 00:46:24,200
Michael Kennedy: and dependencies that you need in your application.

803
00:46:24,530 --> 00:46:27,360
Michael Kennedy: If you can just say, hey, agent thing,

804
00:46:28,060 --> 00:46:30,480
Michael Kennedy: I need this and put it in its own file and boom.

805
00:46:30,920 --> 00:46:32,380
Michael Kennedy: And now you're not dependent on,

806
00:46:32,560 --> 00:46:34,300
Michael Kennedy: well, did that thing upgrade to Python 3.15?

807
00:46:34,960 --> 00:46:35,780
Michael Kennedy: Sorry, you're stuck.

808
00:46:36,050 --> 00:46:36,580
Michael Kennedy: It didn't.

809
00:46:36,880 --> 00:46:37,220
Michael Kennedy: You know what I mean?

810
00:46:37,440 --> 00:46:41,620
Michael Kennedy: Like it's, you were sort of free from these like little weird,

811
00:46:41,990 --> 00:46:44,760
Michael Kennedy: I depend on this whole tree of dependencies

812
00:46:45,280 --> 00:46:47,080
Michael Kennedy: because I need one little piece of functionality.

813
00:46:47,320 --> 00:46:50,340
Michael Kennedy: You can vendor end stuff a lot easier if it's low stakes.

814
00:46:51,220 --> 00:46:51,700
Hugo Bowne-Anderson: Absolutely.

815
00:46:53,520 --> 00:46:55,920
Hugo Bowne-Anderson: The other thing that I think AI assisted coding

816
00:46:56,560 --> 00:46:57,540
Hugo Bowne-Anderson: I've seen help with is,

817
00:46:58,660 --> 00:47:00,060
Hugo Bowne-Anderson: now this will be a bit controversial,

818
00:47:00,440 --> 00:47:02,640
Hugo Bowne-Anderson: but it's going from prototype to production.

819
00:47:02,940 --> 00:47:03,940
Hugo Bowne-Anderson: And what I really mean by that,

820
00:47:04,080 --> 00:47:06,560
Hugo Bowne-Anderson: let's say your production stack is in like Databricks,

821
00:47:06,760 --> 00:47:07,680
Hugo Bowne-Anderson: Spark, whatever.

822
00:47:08,140 --> 00:47:09,980
Hugo Bowne-Anderson: You can prototype, write your pandas code.

823
00:47:10,620 --> 00:47:12,200
Hugo Bowne-Anderson: And then because once again,

824
00:47:12,940 --> 00:47:15,220
Hugo Bowne-Anderson: Spark, Databricks, all that documentation is in training data,

825
00:47:15,740 --> 00:47:16,620
Hugo Bowne-Anderson: you can then convert it.

826
00:47:16,720 --> 00:47:22,540
Hugo Bowne-Anderson: relatively easily. But of course, read, test your code that you're pushing to prod just as you would

827
00:47:22,660 --> 00:47:29,800
Hugo Bowne-Anderson: with a junior software engineer, right? Yeah. The other thing is some gotchas with this.

828
00:47:31,280 --> 00:47:37,740
Hugo Bowne-Anderson: It'll do lots of things you don't ask it to do, okay? Such as...

829
00:47:40,920 --> 00:47:46,020
Hugo Bowne-Anderson: It will just start downloading packages, for example, if you're trying to write some code,

830
00:47:46,160 --> 00:47:52,900
Hugo Bowne-Anderson: right? And it will, so it'll do lots of things you don't ask it to do. And it will also do things

831
00:47:52,900 --> 00:48:00,520
Hugo Bowne-Anderson: you ask it to not do, right? So you'll say only write in one file and Devon, for example, like

832
00:48:00,680 --> 00:48:05,460
Hugo Bowne-Anderson: will create like nested sub directories, each with 15 notebooks, right? Or something,

833
00:48:06,740 --> 00:48:13,620
Hugo Bowne-Anderson: something like that. It will also forget lots of things in your, in your conversation, right?

834
00:48:14,280 --> 00:48:17,360
Hugo Bowne-Anderson: So make sure to remind it of things.

835
00:48:18,040 --> 00:48:19,720
Hugo Bowne-Anderson: It will do something called dead looping.

836
00:48:20,260 --> 00:48:22,540
Hugo Bowne-Anderson: And this is one of the most frustrating and pernicious things,

837
00:48:22,640 --> 00:48:23,880
Hugo Bowne-Anderson: depending on how long the loop is.

838
00:48:24,040 --> 00:48:30,920
Hugo Bowne-Anderson: But it will try to solve your most recent concern.

839
00:48:31,220 --> 00:48:33,800
Hugo Bowne-Anderson: It will really optimize locally around the conversation.

840
00:48:34,360 --> 00:48:35,520
Hugo Bowne-Anderson: And so it will solve that.

841
00:48:35,880 --> 00:48:38,280
Hugo Bowne-Anderson: Then another error will appear, and it will solve that.

842
00:48:38,440 --> 00:48:40,780
Hugo Bowne-Anderson: And it will, another error appear, it will solve that.

843
00:48:41,260 --> 00:48:43,720
Hugo Bowne-Anderson: And after a while, it might actually go back to the initial state.

844
00:48:43,980 --> 00:48:44,980
Hugo Bowne-Anderson: So that's what deadlocking is.

845
00:48:45,080 --> 00:48:45,220
Hugo Bowne-Anderson: Yeah, yeah.

846
00:48:45,420 --> 00:48:46,380
Hugo Bowne-Anderson: And it just cycles, yeah.

847
00:48:46,580 --> 00:48:48,080
Hugo Bowne-Anderson: Three, five, seven, nine.

848
00:48:48,200 --> 00:48:49,580
Hugo Bowne-Anderson: So be very careful about that.

849
00:48:50,380 --> 00:48:52,140
Hugo Bowne-Anderson: Solutions are get it to zoom out.

850
00:48:52,320 --> 00:48:53,520
Hugo Bowne-Anderson: Say, hey, let's zoom out

851
00:48:53,560 --> 00:48:55,420
Hugo Bowne-Anderson: and have a holistic conversation about this.

852
00:48:55,620 --> 00:48:56,260
Hugo Bowne-Anderson: Now, this is wild.

853
00:48:56,420 --> 00:48:58,500
Hugo Bowne-Anderson: This is how we're interacting with software as well.

854
00:48:58,620 --> 00:48:59,940
Michael Kennedy: It's part of the-

855
00:48:59,940 --> 00:49:01,500
Michael Kennedy: It's science fiction.

856
00:49:01,500 --> 00:49:02,820
Michael Kennedy: It really is.

857
00:49:02,820 --> 00:49:05,940
Hugo Bowne-Anderson: But write product requirement drops with it before any code.

858
00:49:06,040 --> 00:49:07,880
Hugo Bowne-Anderson: Now, it may still just start writing code,

859
00:49:07,880 --> 00:49:10,340
Hugo Bowne-Anderson: even when you tell it to do that, right?

860
00:49:10,340 --> 00:49:11,220
Hugo Bowne-Anderson: Plan with it.

861
00:49:11,700 --> 00:49:17,840
Hugo Bowne-Anderson: Have empathy for your super excited, bright, fast, forgetful intern, right?

862
00:49:18,580 --> 00:49:21,640
Hugo Bowne-Anderson: Also, you know, I've really embraced this plan thing.

863
00:49:21,840 --> 00:49:24,340
Michael Kennedy: All my major projects have a plans folder.

864
00:49:24,660 --> 00:49:27,140
Michael Kennedy: And every time I start, I create a markdown file.

865
00:49:27,220 --> 00:49:29,060
Michael Kennedy: I say, we're going to plan it out.

866
00:49:29,160 --> 00:49:32,180
Michael Kennedy: I want you to write in this markdown file what we're going to do.

867
00:49:33,340 --> 00:49:35,360
Michael Kennedy: And I'll do that with a really expensive model, you know,

868
00:49:35,400 --> 00:49:37,020
Michael Kennedy: like a thinking something or whatever.

869
00:49:38,100 --> 00:49:38,720
Michael Kennedy: And it'll do it.

870
00:49:38,740 --> 00:49:39,200
Michael Kennedy: Then I'll switch.

871
00:49:39,440 --> 00:49:40,780
Michael Kennedy: I'll completely throw away that chat.

872
00:49:40,980 --> 00:49:42,320
Michael Kennedy: get another one, a little lower model,

873
00:49:42,460 --> 00:49:43,880
Michael Kennedy: say, we're going to do phase one of this plan.

874
00:49:44,360 --> 00:49:44,760
Michael Kennedy: Let's go.

875
00:49:45,820 --> 00:49:46,760
Michael Kennedy: And then two, and then three.

876
00:49:47,040 --> 00:49:48,220
Michael Kennedy: And every time I say, when you're done,

877
00:49:48,290 --> 00:49:50,340
Michael Kennedy: you update the plan so you know where we are

878
00:49:50,420 --> 00:49:52,200
Michael Kennedy: and what we've done, what's not.

879
00:49:52,300 --> 00:49:54,100
Michael Kennedy: And it's tremendously successful.

880
00:49:54,799 --> 00:49:55,160
Hugo Bowne-Anderson: Absolutely.

881
00:49:55,350 --> 00:49:58,100
Hugo Bowne-Anderson: And also, there is a concern of

882
00:49:58,840 --> 00:50:00,780
Hugo Bowne-Anderson: sometimes you want memory from one chat.

883
00:50:00,920 --> 00:50:02,460
Hugo Bowne-Anderson: Like sometimes a chat just degrades.

884
00:50:02,550 --> 00:50:03,620
Hugo Bowne-Anderson: So start a new conversation.

885
00:50:03,790 --> 00:50:04,840
Hugo Bowne-Anderson: And there are clever ways,

886
00:50:04,970 --> 00:50:07,760
Hugo Bowne-Anderson: different for different products and models,

887
00:50:08,040 --> 00:50:10,560
Hugo Bowne-Anderson: but to get it to summarize the conversation so far,

888
00:50:10,780 --> 00:50:12,900
Hugo Bowne-Anderson: Like literally say, I'm going to take another instance of you.

889
00:50:13,760 --> 00:50:17,800
Hugo Bowne-Anderson: Let's squash this so I can pass the important memories to it and so on.

890
00:50:18,300 --> 00:50:21,280
Hugo Bowne-Anderson: The other thing is Cursor, a lot of these products have,

891
00:50:21,380 --> 00:50:23,480
Hugo Bowne-Anderson: it used to be called YOLO mode on Cursor.

892
00:50:23,600 --> 00:50:27,140
Hugo Bowne-Anderson: Like Y-O-L-O mode, right?

893
00:50:27,140 --> 00:50:28,880
Hugo Bowne-Anderson: Where it just executes.

894
00:50:29,400 --> 00:50:31,020
Michael Kennedy: I run in YOLO mode, by the way.

895
00:50:31,040 --> 00:50:31,520
Michael Kennedy: I do it.

896
00:50:32,040 --> 00:50:37,460
Hugo Bowne-Anderson: Man, I have too much anxiety around that.

897
00:50:38,140 --> 00:50:51,420
Michael Kennedy: So here's the thing that's really gotten that I've really noticed that's interesting is my Git discipline is significantly better now that I'm â€“ if I do that.

898
00:50:51,570 --> 00:50:56,660
Michael Kennedy: So I'll open it up and I'll go and I'll start having a chat and I'll make sure everything is checked in.

899
00:50:56,670 --> 00:50:59,080
Michael Kennedy: I might do a separate branch if I think it's going to go bonkers.

900
00:50:59,610 --> 00:51:00,820
Michael Kennedy: And then it'll do a little bit of work.

901
00:51:00,940 --> 00:51:02,280
Michael Kennedy: And I'm like, okay, that's successful.

902
00:51:02,370 --> 00:51:04,860
Michael Kennedy: So I'll stage those changes but not even commit them.

903
00:51:05,680 --> 00:51:08,320
Michael Kennedy: and then I'll let it keep going and it'll create more work

904
00:51:08,430 --> 00:51:10,100
Michael Kennedy: and I see if it's successful, I'll just put it

905
00:51:10,100 --> 00:51:12,160
Michael Kennedy: and then eventually I'll commit it at the end.

906
00:51:12,190 --> 00:51:13,440
Michael Kennedy: It won't even push it necessarily.

907
00:51:14,520 --> 00:51:15,980
Michael Kennedy: And then you can also, while it's running,

908
00:51:17,359 --> 00:51:19,200
Michael Kennedy: have the get diff window open

909
00:51:19,230 --> 00:51:20,860
Michael Kennedy: and you can just sort of see what it's doing

910
00:51:21,780 --> 00:51:23,480
Hugo Bowne-Anderson: by looking at the diffs that start to appear.

911
00:51:24,060 --> 00:51:26,220
Michael Kennedy: And so that's why I'm okay with YOLO mode

912
00:51:26,350 --> 00:51:29,840
Michael Kennedy: because I can always just get revert and we're fine again.

913
00:51:30,300 --> 00:51:30,600
Hugo Bowne-Anderson: Totally.

914
00:51:30,860 --> 00:51:33,100
Hugo Bowne-Anderson: And also, I didn't mention this,

915
00:51:33,160 --> 00:51:36,620
Hugo Bowne-Anderson: but these AI assistants are great at looking at diffs with you.

916
00:51:37,450 --> 00:51:40,220
Hugo Bowne-Anderson: And I also, I'm really thinking through what happens

917
00:51:40,620 --> 00:51:43,020
Hugo Bowne-Anderson: when we have so much AI generated code.

918
00:51:43,410 --> 00:51:44,900
Hugo Bowne-Anderson: And I think part of the future of work,

919
00:51:44,900 --> 00:51:46,700
Hugo Bowne-Anderson: I don't want to get too sci-fi-esque,

920
00:51:46,860 --> 00:51:50,500
Hugo Bowne-Anderson: but how many agents can you manage simultaneously?

921
00:51:50,840 --> 00:51:52,440
Hugo Bowne-Anderson: Like maybe the SuperSpa employees

922
00:51:52,640 --> 00:51:54,980
Hugo Bowne-Anderson: will be people who can manage a hundred agents.

923
00:51:55,920 --> 00:51:57,980
Michael Kennedy: It's like the revenge of the program manager.

924
00:51:58,200 --> 00:51:58,740
Michael Kennedy: I'm telling you.

925
00:51:59,360 --> 00:52:00,160
Hugo Bowne-Anderson: It's so true.

926
00:52:01,320 --> 00:52:07,060
Hugo Bowne-Anderson: And in fact, project management, product management are some of the most important skills moving forward.

927
00:52:07,270 --> 00:52:11,200
Hugo Bowne-Anderson: But also, when you have so many agents generating code, what happens to CICD?

928
00:52:11,250 --> 00:52:12,320
Hugo Bowne-Anderson: What happens to Jenkins?

929
00:52:13,440 --> 00:52:20,220
Hugo Bowne-Anderson: There's going to be a whole new space of products and agents that may deal with these types of systems, right?

930
00:52:20,620 --> 00:52:28,040
Hugo Bowne-Anderson: Look during the Industrial Revolution, what sprung up when looms appeared and the satellite industries that happened there.

931
00:52:28,180 --> 00:52:32,860
Hugo Bowne-Anderson: So I think we're talking about job automation and job displacement,

932
00:52:32,970 --> 00:52:36,780
Hugo Bowne-Anderson: but the amount of new jobs that will become available,

933
00:52:37,060 --> 00:52:38,440
Hugo Bowne-Anderson: I'm actually very excited about.

934
00:52:38,530 --> 00:52:39,980
Hugo Bowne-Anderson: And we'll put in the show notes, please,

935
00:52:40,220 --> 00:52:42,720
Hugo Bowne-Anderson: but there's an essay by Tim O'Reilly,

936
00:52:42,730 --> 00:52:44,260
Hugo Bowne-Anderson: and I did a podcast with him about it, actually,

937
00:52:44,400 --> 00:52:45,580
Hugo Bowne-Anderson: that we can link to if you're up for it,

938
00:52:45,850 --> 00:52:48,340
Hugo Bowne-Anderson: called The End of Programming As We Know It.

939
00:52:48,630 --> 00:52:48,740
Hugo Bowne-Anderson: Okay.

940
00:52:50,459 --> 00:52:54,659
Hugo Bowne-Anderson: And he essentially, with his great depth of historical knowledge

941
00:52:54,660 --> 00:52:57,640
Hugo Bowne-Anderson: and his forward thinking through vectors

942
00:52:58,320 --> 00:52:59,580
Hugo Bowne-Anderson: prevents a really wonderful vision

943
00:52:59,980 --> 00:53:02,900
Hugo Bowne-Anderson: and ideas around where software is heading.

944
00:53:03,160 --> 00:53:03,320
Hugo Bowne-Anderson: Exactly.

945
00:53:04,660 --> 00:53:05,520
Michael Kennedy: Yeah, very cool.

946
00:53:06,000 --> 00:53:07,320
Michael Kennedy: What about exploring data?

947
00:53:07,880 --> 00:53:09,940
Michael Kennedy: So we've been talking about mostly writing data,

948
00:53:10,180 --> 00:53:12,060
Michael Kennedy: testing, writing code, testing code

949
00:53:12,520 --> 00:53:13,560
Michael Kennedy: in the context of data science.

950
00:53:14,180 --> 00:53:17,960
Michael Kennedy: But I think it's actually really pretty powerful to say,

951
00:53:18,480 --> 00:53:19,180
Michael Kennedy: here's a CSV.

952
00:53:20,200 --> 00:53:21,600
Michael Kennedy: This is basically what it means.

953
00:53:23,180 --> 00:53:25,560
Michael Kennedy: Let's start looking at, get me some graphs,

954
00:53:25,880 --> 00:53:26,680
Michael Kennedy: pull me out some trends.

955
00:53:27,560 --> 00:53:28,100
Michael Kennedy: What's important?

956
00:53:28,340 --> 00:53:29,520
Michael Kennedy: What do you see that I didn't see?

957
00:53:30,800 --> 00:53:33,940
Michael Kennedy: What do you think about this exploratory analysis side of it?

958
00:53:34,200 --> 00:53:37,560
Michael Kennedy: And that doesn't even worry you about,

959
00:53:37,980 --> 00:53:39,740
Michael Kennedy: is there maybe a bug in the code

960
00:53:41,020 --> 00:53:43,000
Michael Kennedy: because I don't want to put it in production, right?

961
00:53:43,100 --> 00:53:45,940
Michael Kennedy: It's just fooling around to get a jumpstart on understanding.

962
00:53:46,680 --> 00:53:51,179
Hugo Bowne-Anderson: - So firstly, exploratory data analysis is one

963
00:53:51,200 --> 00:53:54,260
Hugo Bowne-Anderson: of a scientist and data scientist's most important jobs, right?

964
00:53:55,500 --> 00:53:59,260
Hugo Bowne-Anderson: So the question then becomes is how can we get AI to, you know,

965
00:53:59,430 --> 00:54:03,720
Hugo Bowne-Anderson: help us, you know, see what's happening that's so integral to what we do.

966
00:54:04,070 --> 00:54:06,580
Hugo Bowne-Anderson: And the truth is they're wonderful.

967
00:54:07,010 --> 00:54:11,100
Hugo Bowne-Anderson: They can be wonderful at pulling out insights that I just haven't noticed

968
00:54:11,230 --> 00:54:14,160
Hugo Bowne-Anderson: or I don't even think about how to visualize.

969
00:54:14,410 --> 00:54:18,979
Hugo Bowne-Anderson: Now, if I ask it to find the mean or median, it may suck at that on average

970
00:54:19,000 --> 00:54:21,580
Hugo Bowne-Anderson: unless it writes the code to do so, right?

971
00:54:21,840 --> 00:54:26,280
Hugo Bowne-Anderson: But when you get it to do EDA or exploratory data analysis,

972
00:54:26,860 --> 00:54:30,400
Hugo Bowne-Anderson: it will provide insights that I haven't thought of.

973
00:54:30,620 --> 00:54:33,420
Hugo Bowne-Anderson: So one example I saw recently from a client

974
00:54:33,880 --> 00:54:39,280
Hugo Bowne-Anderson: was throwing in like thousands of rows of customer data

975
00:54:39,540 --> 00:54:42,240
Hugo Bowne-Anderson: and website data of customers.

976
00:54:42,840 --> 00:54:47,940
Hugo Bowne-Anderson: And it immediately showed clusters of high usage versus low usage.

977
00:54:48,260 --> 00:54:52,480
Hugo Bowne-Anderson: You could see power users. You could see power users who spent a lot on the platform.

978
00:54:52,850 --> 00:54:55,260
Hugo Bowne-Anderson: You could see power users who didn't spend much on the platform.

979
00:54:56,150 --> 00:55:03,860
Hugo Bowne-Anderson: And this is the type of work that takes hours for data scientists to sift through and develop hypotheses around.

980
00:55:04,030 --> 00:55:08,980
Hugo Bowne-Anderson: So when we're talking about, you know, data science is exploration and hypothesis driven, right?

981
00:55:08,980 --> 00:55:15,980
Hugo Bowne-Anderson: So when we're talking about exploration and hypothesis driven data science, it's wonderful there.

982
00:55:16,040 --> 00:55:20,680
Hugo Bowne-Anderson: And once again, this isn't to replace what we do, but it's to help us.

983
00:55:20,780 --> 00:55:24,140
Hugo Bowne-Anderson: It's having a thought partner.

984
00:55:25,140 --> 00:55:25,340
Michael Kennedy: Yeah.

985
00:55:25,960 --> 00:55:26,700
Hugo Bowne-Anderson: Which is fast.

986
00:55:28,840 --> 00:55:32,460
Michael Kennedy: Like beyond the computer, a different bicycle of the mind of a sort.

987
00:55:32,540 --> 00:55:36,160
Michael Kennedy: Yeah, maybe like a little, maybe it's like an e-bike of the mind.

988
00:55:36,320 --> 00:55:36,780
Michael Kennedy: What do you think?

989
00:55:37,660 --> 00:55:38,120
Hugo Bowne-Anderson: I love it.

990
00:55:38,160 --> 00:55:39,380
Michael Kennedy: I love e-bikes.

991
00:55:40,340 --> 00:55:40,740
Hugo Bowne-Anderson: They're awesome.

992
00:55:41,100 --> 00:55:43,240
Hugo Bowne-Anderson: And I especially, because I live in Sydney, right?

993
00:55:43,480 --> 00:55:45,900
Hugo Bowne-Anderson: So getting to the beach, it's actually quite hilly.

994
00:55:46,060 --> 00:55:50,320
Hugo Bowne-Anderson: depending where where you are um and the other thing i

995
00:55:53,560 --> 00:55:58,460
Hugo Bowne-Anderson: yeah when so hopefully we have time to talk about this but something i do a lot of work on

996
00:55:58,640 --> 00:56:08,240
Hugo Bowne-Anderson: is what i call uh evaluation driven development um first lm and ai powered applications um where

997
00:56:08,320 --> 00:56:15,420
Hugo Bowne-Anderson: A really important part of this is error analysis and failure analysis.

998
00:56:15,660 --> 00:56:20,220
Hugo Bowne-Anderson: So seeing where your applications fail.

999
00:56:20,370 --> 00:56:29,160
Hugo Bowne-Anderson: So let's say we're building a chatbot, which is RAG.

1000
00:56:29,160 --> 00:56:32,300
Hugo Bowne-Anderson: So it has some corpus of documents and it retrieves stuff from it.

1001
00:56:32,300 --> 00:56:34,980
Hugo Bowne-Anderson: And we want to interact with it, right?

1002
00:56:37,000 --> 00:56:43,440
Hugo Bowne-Anderson: When we're building that, some of the first steps and ongoing process is seeing what failure modes they are.

1003
00:56:43,560 --> 00:56:47,140
Hugo Bowne-Anderson: Is it hallucinating or is it not retrieving things correctly?

1004
00:56:47,320 --> 00:56:48,920
Hugo Bowne-Anderson: Is it looking at the wrong documents?

1005
00:56:50,100 --> 00:56:51,160
Hugo Bowne-Anderson: These types of things.

1006
00:56:51,880 --> 00:56:59,440
Hugo Bowne-Anderson: And you do that to drive the development and iterative process of AI-powered software.

1007
00:57:00,680 --> 00:57:06,740
Hugo Bowne-Anderson: Now, you can also use AI to look at that and look at the results in the data exploration.

1008
00:57:06,890 --> 00:57:10,140
Hugo Bowne-Anderson: And it can really bring out a lot of different failure modes.

1009
00:57:10,230 --> 00:57:25,080
Hugo Bowne-Anderson: It can say, hey, look at this cluster of conversations where the user finally got the correct response, but they asked to be connected to a representative first, and they didn't get connected to a representative.

1010
00:57:25,380 --> 00:57:29,460
Hugo Bowne-Anderson: So this is actually an example where the conversation looks like it's resolved.

1011
00:57:29,680 --> 00:57:31,880
Hugo Bowne-Anderson: the support ticket was resolved or whatever it is.

1012
00:57:32,920 --> 00:57:34,740
Hugo Bowne-Anderson: But there's a deep failure mode within there.

1013
00:57:34,960 --> 00:57:38,660
Hugo Bowne-Anderson: So AI can be very good in terms of the data exploration

1014
00:57:38,810 --> 00:57:41,280
Hugo Bowne-Anderson: and hypothesis driving process with that.

1015
00:57:43,060 --> 00:57:43,640
Hugo Bowne-Anderson: So that was an example.

1016
00:57:43,790 --> 00:57:48,720
Hugo Bowne-Anderson: But yeah, should we get into building LLM-powered software?

1017
00:57:49,460 --> 00:57:50,100
Michael Kennedy: Yeah, sure.

1018
00:57:52,720 --> 00:57:57,799
Hugo Bowne-Anderson: So I wonder whether you'd like to bring up the figure

1019
00:57:58,340 --> 00:58:03,240
Hugo Bowne-Anderson: that I will talk through because I know there'll be people listening. And I'll share it in the chat

1020
00:58:03,360 --> 00:58:14,540
Hugo Bowne-Anderson: with you. Ah, great. So this is a slightly tongue in cheek figure, but it speaks to real pain we

1021
00:58:14,660 --> 00:58:19,780
Hugo Bowne-Anderson: have. So on the x-axis, we have time. And we're talking about building software. On the y-axis,

1022
00:58:19,900 --> 00:58:24,999
Hugo Bowne-Anderson: we have excitement or dopamine, if you will, if you want to measure it. And for the scientists

1023
00:58:25,020 --> 00:58:31,020
Hugo Bowne-Anderson: out there, I apologize for not having units on my axes, but it's all good. We know with traditional

1024
00:58:31,240 --> 00:58:36,460
Hugo Bowne-Anderson: software, excitement increases over time. Things are pretty boring at the start. You have a hello

1025
00:58:36,700 --> 00:58:40,940
Hugo Bowne-Anderson: world and basic features and add unit tests. Then you scale and optimize and load balance. And

1026
00:58:41,460 --> 00:58:46,460
Hugo Bowne-Anderson: over time, excitement increases and increases and increases. This is absolutely inverted with

1027
00:58:46,680 --> 00:58:50,380
Hugo Bowne-Anderson: generative AI powered software, right? Where you have a flashy demo at the start. You're like,

1028
00:58:50,400 --> 00:58:56,340
Hugo Bowne-Anderson: wow check this out okay then you're like oh wait does it actually work all that like can someone

1029
00:58:56,380 --> 00:59:01,380
Hugo Bowne-Anderson: else use it and so you have issues with basic functionality then so excitement goes down

1030
00:59:01,980 --> 00:59:06,840
Hugo Bowne-Anderson: um then you're like oh no all these hallucinations excitement goes down then you have monitoring

1031
00:59:06,980 --> 00:59:11,620
Hugo Bowne-Anderson: challenges you're like how can i even look at all my conversations and tool calls and actions and

1032
00:59:11,700 --> 00:59:16,660
Hugo Bowne-Anderson: this type of stuff um excitement goes down then you have integration issues how do i integrate into my

1033
00:59:16,640 --> 00:59:22,700
Hugo Bowne-Anderson: enterprise stack uh excitement goes down again and i i don't think it's a coincidence um that you

1034
00:59:22,700 --> 00:59:29,020
Hugo Bowne-Anderson: know this is one of the most exciting technologies of a generation that's um totally addicted to

1035
00:59:29,120 --> 00:59:35,920
Hugo Bowne-Anderson: instagram as well right um but the question is and a lot of work i i do is in helping people

1036
00:59:36,640 --> 00:59:40,780
Hugo Bowne-Anderson: raise the curve not change anything not even change the excitement of the flashy demo but just

1037
00:59:40,800 --> 00:59:44,960
Hugo Bowne-Anderson: Make sure that excitement goes up and up and up as you build.

1038
00:59:46,500 --> 00:59:49,180
Hugo Bowne-Anderson: And once again, there's no free lunch.

1039
00:59:49,300 --> 00:59:51,980
Hugo Bowne-Anderson: You've got to do this the hard way, right?

1040
00:59:53,420 --> 00:59:57,980
Hugo Bowne-Anderson: And so this is something, and a short plug for a course I teach,

1041
00:59:57,980 --> 00:59:59,540
Hugo Bowne-Anderson: but this is something I teach a lot on,

1042
00:59:59,760 --> 01:00:03,460
Hugo Bowne-Anderson: and I teach a Maven course building LM powered applications

1043
01:00:04,180 --> 01:00:05,940
Hugo Bowne-Anderson: for data science and software engineers

1044
01:00:06,240 --> 01:00:07,700
Hugo Bowne-Anderson: with my colleague, Stefan Krauchik,

1045
01:00:07,800 --> 01:00:10,800
Hugo Bowne-Anderson: who he works on agent infrastructure at Salesforce.

1046
01:00:11,340 --> 01:00:12,900
Hugo Bowne-Anderson: I bring a lot of the data and ML stuff.

1047
01:00:12,940 --> 01:00:14,560
Hugo Bowne-Anderson: He brings a lot of the ops stuff.

1048
01:00:14,980 --> 01:00:19,860
Hugo Bowne-Anderson: But yeah, in this course, we teach a lot of these things.

1049
01:00:21,880 --> 01:00:26,060
Hugo Bowne-Anderson: And the way we do that, one way to think about it

1050
01:00:26,260 --> 01:00:28,500
Hugo Bowne-Anderson: is what we call evaluation-driven development.

1051
01:00:28,960 --> 01:00:33,280
Hugo Bowne-Anderson: So that's not necessarily having like very sophisticated evals

1052
01:00:33,760 --> 01:00:36,120
Hugo Bowne-Anderson: and tests and that type of stuff to start,

1053
01:00:36,460 --> 01:00:47,240
Hugo Bowne-Anderson: But it's about having a sense of where you want your product to go and having a sense of evaluation of how to drive it in that direction.

1054
01:00:47,760 --> 01:00:55,700
Hugo Bowne-Anderson: And the skill set that's required for this is so similar to people who've built data science and ML-powered products, right?

1055
01:00:55,850 --> 01:00:58,520
Hugo Bowne-Anderson: So it's a curiosity to explore data.

1056
01:00:58,920 --> 01:00:59,740
Hugo Bowne-Anderson: It's a hacker mindset.

1057
01:01:00,700 --> 01:01:02,460
Hugo Bowne-Anderson: It's experimenting with different tools.

1058
01:01:02,740 --> 01:01:05,000
Hugo Bowne-Anderson: And what have we been doing in the PyDataStack?

1059
01:01:05,280 --> 01:01:08,020
Hugo Bowne-Anderson: I mean, look at the data viz landscape in Python.

1060
01:01:08,220 --> 01:01:12,820
Hugo Bowne-Anderson: I think it was maybe PyCon 2018 that Jake Vanderplus,

1061
01:01:13,060 --> 01:01:14,420
Hugo Bowne-Anderson: I think, first time gave his talk, you know,

1062
01:01:14,820 --> 01:01:16,140
Hugo Bowne-Anderson: data visualization in Python.

1063
01:01:16,500 --> 01:01:19,500
Hugo Bowne-Anderson: And, you know, there were so many tools one could use there.

1064
01:01:19,640 --> 01:01:21,760
Hugo Bowne-Anderson: It's this type of mindset you need.

1065
01:01:21,960 --> 01:01:23,640
Hugo Bowne-Anderson: And then in terms of the product workflow,

1066
01:01:24,120 --> 01:01:28,520
Hugo Bowne-Anderson: how you make sure you don't kind of go down this curve,

1067
01:01:28,900 --> 01:01:31,400
Hugo Bowne-Anderson: lose excitement in what I call proof of concept purgatory.

1068
01:01:31,920 --> 01:01:33,280
Hugo Bowne-Anderson: People call the plateau of productivity.

1069
01:01:33,700 --> 01:01:35,580
Hugo Bowne-Anderson: There are all types of fun names about it.

1070
01:01:36,060 --> 01:01:39,880
Hugo Bowne-Anderson: But what you do is you use the machine learning mindset,

1071
01:01:40,020 --> 01:01:43,700
Hugo Bowne-Anderson: which is get some data in and out of your system.

1072
01:01:44,160 --> 01:01:45,360
Hugo Bowne-Anderson: If you don't have users yet,

1073
01:01:45,500 --> 01:01:47,900
Hugo Bowne-Anderson: you can generate synthetic data to do so, right?

1074
01:01:48,920 --> 01:01:52,640
Hugo Bowne-Anderson: Then you label it, pass or fail initially.

1075
01:01:52,980 --> 01:01:54,920
Hugo Bowne-Anderson: And this is in the spirit of iteration.

1076
01:01:55,720 --> 01:01:57,000
Hugo Bowne-Anderson: You give it a failure mode,

1077
01:01:57,400 --> 01:01:59,760
Hugo Bowne-Anderson: such as it was hallucination, retrieval error,

1078
01:02:00,400 --> 01:02:01,180
Hugo Bowne-Anderson: wrong tool call.

1079
01:02:01,300 --> 01:02:03,540
Hugo Bowne-Anderson: And a tool call essentially is what an agent does.

1080
01:02:04,040 --> 01:02:06,480
Hugo Bowne-Anderson: So an agent is an LLM plus tool calls.

1081
01:02:06,740 --> 01:02:10,020
Hugo Bowne-Anderson: A tool call could be ping an API, send an email, whatever it is.

1082
01:02:10,480 --> 01:02:15,360
Hugo Bowne-Anderson: Agent plus tool call in some while loop or for loop, right?

1083
01:02:16,700 --> 01:02:22,540
Hugo Bowne-Anderson: And so you have, did this particular interaction pass or fail?

1084
01:02:23,660 --> 01:02:24,840
Hugo Bowne-Anderson: What was the failure mode?

1085
01:02:25,420 --> 01:02:28,340
Hugo Bowne-Anderson: And then how do I fix these particular failure modes?

1086
01:02:28,560 --> 01:02:31,520
Hugo Bowne-Anderson: And I mean, one way to do this initially,

1087
01:02:31,560 --> 01:02:32,900
Hugo Bowne-Anderson: depending on the complexity of your system,

1088
01:02:33,160 --> 01:02:34,480
Hugo Bowne-Anderson: is to put all of this in a spreadsheet

1089
01:02:34,820 --> 01:02:36,000
Hugo Bowne-Anderson: and do a pivot table.

1090
01:02:36,380 --> 01:02:37,840
Hugo Bowne-Anderson: I know AI engineers hate it

1091
01:02:37,840 --> 01:02:39,420
Hugo Bowne-Anderson: when I tell them to do pivot tables,

1092
01:02:39,680 --> 01:02:40,800
Hugo Bowne-Anderson: but if you rank order,

1093
01:02:42,040 --> 01:02:43,920
Hugo Bowne-Anderson: use a pivot table to rank order your failure modes

1094
01:02:44,100 --> 01:02:44,880
Hugo Bowne-Anderson: by frequency,

1095
01:02:45,360 --> 01:02:47,240
Hugo Bowne-Anderson: then you can see what to fix first.

1096
01:02:47,520 --> 01:02:48,880
Hugo Bowne-Anderson: And if it's a retrieval error,

1097
01:02:49,260 --> 01:02:51,700
Hugo Bowne-Anderson: maybe you want to fix the rag part of your system

1098
01:02:51,900 --> 01:02:53,120
Hugo Bowne-Anderson: and the retrieval part, right?

1099
01:02:53,940 --> 01:02:55,420
Hugo Bowne-Anderson: As opposed to the generative part.

1100
01:02:55,560 --> 01:02:57,440
Hugo Bowne-Anderson: So focus on your embeddings or chunks.

1101
01:02:57,920 --> 01:02:58,680
Hugo Bowne-Anderson: If it's a tool call,

1102
01:02:59,060 --> 01:03:01,380
Hugo Bowne-Anderson: focus on how that tool call is defined.

1103
01:03:01,480 --> 01:03:04,000
Hugo Bowne-Anderson: and heuristics that the LLM uses there.

1104
01:03:04,440 --> 01:03:05,200
Hugo Bowne-Anderson: A lot of the time--

1105
01:03:05,220 --> 01:03:07,840
Michael Kennedy: - I would like to add, well, this is great.

1106
01:03:07,960 --> 01:03:10,940
Michael Kennedy: I would like to add that you can use

1107
01:03:11,080 --> 01:03:14,740
Michael Kennedy: those agentic coding tools to help build better analytics

1108
01:03:16,260 --> 01:03:17,400
Michael Kennedy: or other support.

1109
01:03:17,720 --> 01:03:19,320
Michael Kennedy: So if you're like, God, we don't really have,

1110
01:03:19,420 --> 01:03:20,440
Michael Kennedy: we can't really track that, right?

1111
01:03:20,560 --> 01:03:23,020
Michael Kennedy: Like, well, give it half an hour and you can,

1112
01:03:23,200 --> 01:03:23,720
Michael Kennedy: you know what I mean?

1113
01:03:24,440 --> 01:03:24,660
Hugo Bowne-Anderson: - Exactly.

1114
01:03:24,720 --> 01:03:27,080
Michael Kennedy: - And so you got to kind of think out of the box

1115
01:03:27,100 --> 01:03:28,540
Michael Kennedy: and be a little creative there.

1116
01:03:29,140 --> 01:03:32,560
Michael Kennedy: Maybe build an MCP server that specializes in solving,

1117
01:03:32,720 --> 01:03:38,080
Michael Kennedy: you know, a specialized LLM that addresses a shortcoming

1118
01:03:38,260 --> 01:03:40,660
Michael Kennedy: that you can then force it to use the MCP server

1119
01:03:40,820 --> 01:03:42,000
Michael Kennedy: and work more constrained or whatever.

1120
01:03:42,860 --> 01:03:43,640
Hugo Bowne-Anderson: Exactly, exactly.

1121
01:03:43,920 --> 01:03:45,300
Hugo Bowne-Anderson: And as we kind of hinted at earlier,

1122
01:03:45,440 --> 01:03:49,100
Hugo Bowne-Anderson: one of the wacky things here is that a lot of this comes down to prompting

1123
01:03:49,140 --> 01:03:51,720
Hugo Bowne-Anderson: and people like, should I fine tune or prompt engineer or rag

1124
01:03:51,820 --> 01:03:52,640
Hugo Bowne-Anderson: or that type of stuff?

1125
01:03:53,660 --> 01:03:56,060
Hugo Bowne-Anderson: Prompt and prompt and prompt initially,

1126
01:03:56,780 --> 01:03:59,800
Hugo Bowne-Anderson: because you can get so much lift by prompting.

1127
01:03:59,900 --> 01:04:01,920
Hugo Bowne-Anderson: Now, if it is actually a retrieval error,

1128
01:04:02,360 --> 01:04:05,140
Hugo Bowne-Anderson: perhaps you want to improve your embeddings

1129
01:04:05,440 --> 01:04:07,520
Hugo Bowne-Anderson: or your chunking strategy or that type of stuff.

1130
01:04:08,680 --> 01:04:12,160
Hugo Bowne-Anderson: The other thing is, of course, data, metadata, data ingestion.

1131
01:04:13,080 --> 01:04:14,780
Hugo Bowne-Anderson: Draw an architectural diagram of your system

1132
01:04:15,080 --> 01:04:17,380
Hugo Bowne-Anderson: where you see, you know, you have your RAG,

1133
01:04:17,400 --> 01:04:19,020
Hugo Bowne-Anderson: you have your output, you have your embeddings,

1134
01:04:19,240 --> 01:04:21,180
Hugo Bowne-Anderson: you have your OCR, or if you've got PDS,

1135
01:04:21,300 --> 01:04:22,420
Hugo Bowne-Anderson: however you're ingesting your data,

1136
01:04:23,140 --> 01:04:24,520
Hugo Bowne-Anderson: a huge amount of the time,

1137
01:04:24,920 --> 01:04:32,200
Hugo Bowne-Anderson: fixing how you do your OCR on your PDFs will be far more significant lift than switching out to

1138
01:04:32,860 --> 01:04:39,400
Hugo Bowne-Anderson: Claude Sonnet 4.5. Okay. And on that point, I totally understand why people want to try

1139
01:04:39,780 --> 01:04:45,120
Hugo Bowne-Anderson: the newest and sexiest model. And I'm not telling people not to. What I'm saying is focus on the

1140
01:04:45,340 --> 01:04:53,780
Hugo Bowne-Anderson: fundamentals. And then when you have, you know, this set of evals of like, of labeled data of what,

1141
01:04:54,000 --> 01:04:55,100
Hugo Bowne-Anderson: what works, what doesn't.

1142
01:04:55,720 --> 01:04:57,500
Hugo Bowne-Anderson: You want a test set, essentially, right?

1143
01:04:57,580 --> 01:04:58,380
Hugo Bowne-Anderson: Like in machine learning.

1144
01:04:58,500 --> 01:04:59,320
Hugo Bowne-Anderson: So it's the same process.

1145
01:04:59,840 --> 01:05:01,940
Hugo Bowne-Anderson: You have this test set, your gold standard,

1146
01:05:02,460 --> 01:05:03,260
Hugo Bowne-Anderson: which ideally covers,

1147
01:05:03,800 --> 01:05:05,420
Hugo Bowne-Anderson: has coverage over all your failure modes.

1148
01:05:05,440 --> 01:05:06,560
Hugo Bowne-Anderson: You want eval coverage.

1149
01:05:07,100 --> 01:05:09,000
Hugo Bowne-Anderson: Then when you switch out to a new model,

1150
01:05:09,340 --> 01:05:11,120
Hugo Bowne-Anderson: you can see how it performed on your test set.

1151
01:05:11,480 --> 01:05:12,120
Hugo Bowne-Anderson: Imagine that.

1152
01:05:12,460 --> 01:05:15,220
Hugo Bowne-Anderson: Imagine being able to switch out a model

1153
01:05:15,460 --> 01:05:17,760
Michael Kennedy: and seeing what's up there, right?

1154
01:05:18,120 --> 01:05:20,880
Michael Kennedy: Be able to say it's better concretely with data,

1155
01:05:20,980 --> 01:05:22,020
Michael Kennedy: not just it feels better.

1156
01:05:22,760 --> 01:05:23,520
Michael Kennedy: Yeah, exactly.

1157
01:05:24,300 --> 01:05:24,780
Michael Kennedy: All right.

1158
01:05:24,840 --> 01:05:26,320
Michael Kennedy: We're pretty much, you go ahead.

1159
01:05:26,480 --> 01:05:27,680
Hugo Bowne-Anderson: I was just going to add one more thing.

1160
01:05:27,900 --> 01:05:30,780
Hugo Bowne-Anderson: There are all these eval conversations about we don't want these evals.

1161
01:05:30,780 --> 01:05:32,460
Hugo Bowne-Anderson: We want online evals.

1162
01:05:32,600 --> 01:05:34,460
Hugo Bowne-Anderson: And then there are people do things only by vibes.

1163
01:05:34,520 --> 01:05:37,680
Hugo Bowne-Anderson: And all of these things are absolutely valid as well.

1164
01:05:37,680 --> 01:05:41,680
Hugo Bowne-Anderson: I think it's a healthy combination for whatever your product needs at any point in time.

1165
01:05:42,560 --> 01:05:42,680
Michael Kennedy: Yeah.

1166
01:05:43,640 --> 01:05:44,480
Michael Kennedy: We're pretty much out of time.

1167
01:05:44,520 --> 01:05:52,120
Michael Kennedy: But I do want to take just a couple minutes, literally, and get your thoughts on people coming into the industry.

1168
01:05:53,000 --> 01:05:55,840
Michael Kennedy: Data scientists who are just graduating now

1169
01:05:56,300 --> 01:05:57,260
Michael Kennedy: or they got their first job

1170
01:05:57,360 --> 01:05:58,440
Michael Kennedy: or they're about to get their first job.

1171
01:05:59,160 --> 01:06:02,300
Michael Kennedy: I imagine this is something of a scary time to think,

1172
01:06:02,300 --> 01:06:04,600
Michael Kennedy: well, now I'm not just competing with all the other people.

1173
01:06:04,760 --> 01:06:09,360
Michael Kennedy: Now these AI things are fighting against me getting a job as well.

1174
01:06:09,540 --> 01:06:12,480
Michael Kennedy: But I think it's both a blessing and a curse.

1175
01:06:14,000 --> 01:06:15,140
Michael Kennedy: But what do you think?

1176
01:06:15,760 --> 01:06:17,120
Hugo Bowne-Anderson: Yeah, I totally agree.

1177
01:06:18,640 --> 01:06:19,560
Hugo Bowne-Anderson: Focus on three things.

1178
01:06:21,700 --> 01:06:23,440
Hugo Bowne-Anderson: What value you can deliver?

1179
01:06:23,660 --> 01:06:25,780
Hugo Bowne-Anderson: What's your skill as a data scientist?

1180
01:06:25,930 --> 01:06:29,640
Hugo Bowne-Anderson: And it is looking at data.

1181
01:06:29,750 --> 01:06:30,480
Hugo Bowne-Anderson: It is building.

1182
01:06:30,910 --> 01:06:33,060
Hugo Bowne-Anderson: And it is tying that to business value.

1183
01:06:33,170 --> 01:06:35,580
Hugo Bowne-Anderson: So if you focus on your skills and you build, build, build,

1184
01:06:35,990 --> 01:06:37,920
Hugo Bowne-Anderson: and consistently tie it to business value,

1185
01:06:38,780 --> 01:06:41,200
Hugo Bowne-Anderson: I think you'll go a long way.

1186
01:06:41,420 --> 01:06:44,440
Hugo Bowne-Anderson: And this actually speaks to how we think about evaluation

1187
01:06:45,660 --> 01:06:46,540
Hugo Bowne-Anderson: more generally.

1188
01:06:46,730 --> 01:06:49,400
Hugo Bowne-Anderson: And I do want to give a shout out to a Sydney-based company

1189
01:06:49,420 --> 01:06:55,720
Hugo Bowne-Anderson: called Lorikeet that they build customer support agents

1190
01:06:56,280 --> 01:06:58,840
Hugo Bowne-Anderson: for all types of industries.

1191
01:07:00,480 --> 01:07:04,380
Hugo Bowne-Anderson: And when they do evaluation, they always evaluate,

1192
01:07:04,660 --> 01:07:07,220
Hugo Bowne-Anderson: was the ticket solved or not?

1193
01:07:07,380 --> 01:07:09,020
Hugo Bowne-Anderson: That's the most important evaluation.

1194
01:07:09,220 --> 01:07:12,540
Hugo Bowne-Anderson: It's not, did this LLM call result in what we wanted it to be

1195
01:07:13,300 --> 01:07:14,360
Hugo Bowne-Anderson: or anything along those lines.

1196
01:07:14,460 --> 01:07:19,120
Hugo Bowne-Anderson: Of course, once they see a failure, they tie it back.

1197
01:07:19,940 --> 01:07:26,740
Hugo Bowne-Anderson: to these more technical LLM-based failure modes.

1198
01:07:28,960 --> 01:07:32,460
Hugo Bowne-Anderson: But I wonder if, yeah,

1199
01:07:33,300 --> 01:07:35,740
Hugo Bowne-Anderson: maybe Google Lorikeet AI or something like that.

1200
01:07:36,640 --> 01:07:38,180
Michael Kennedy: I had it in another tab.

1201
01:07:38,300 --> 01:07:38,580
Michael Kennedy: I don't know.

1202
01:07:38,620 --> 01:07:39,200
Michael Kennedy: I'll get it back.

1203
01:07:39,940 --> 01:07:40,160
Michael Kennedy: Oh, good.

1204
01:07:40,300 --> 01:07:40,560
Hugo Bowne-Anderson: Hold on.

1205
01:07:41,280 --> 01:07:43,980
Hugo Bowne-Anderson: And one thing I love about,

1206
01:07:44,000 --> 01:07:45,240
Hugo Bowne-Anderson: and I'm indexing on them,

1207
01:07:45,780 --> 01:07:49,180
Hugo Bowne-Anderson: There are lots of companies that do this.

1208
01:07:50,830 --> 01:07:59,400
Hugo Bowne-Anderson: But one thing that's very interesting about them is that their pricing model is ticket resolution based, right?

1209
01:07:59,630 --> 01:08:07,700
Hugo Bowne-Anderson: So if they've built a concierge or customer service agent for you, you pay based on how many tickets are resolved.

1210
01:08:08,080 --> 01:08:12,720
Hugo Bowne-Anderson: A lot of their competitors, their pricing is based on tokens, right?

1211
01:08:12,880 --> 01:08:15,900
Hugo Bowne-Anderson: Because that's what they pay for.

1212
01:08:16,440 --> 01:08:25,240
Hugo Bowne-Anderson: And in terms of aligning incentives, having it based around resolution is incredibly important for how you build as well.

1213
01:08:25,339 --> 01:08:30,299
Hugo Bowne-Anderson: And the reason, the question was, what should early stage data scientists focus on?

1214
01:08:30,540 --> 01:08:40,319
Hugo Bowne-Anderson: The reason I detoured on that story is supreme focus on business value, how your skills can be tied to business value via building stuff.

1215
01:08:41,460 --> 01:08:41,580
Michael Kennedy: Yeah.

1216
01:08:42,850 --> 01:08:42,980
Michael Kennedy: Awesome.

1217
01:08:43,660 --> 01:08:44,560
Michael Kennedy: It's great advice.

1218
01:08:44,650 --> 01:08:54,060
Michael Kennedy: And I will just throw one more thing out there for people is don't let these AI tools undercut your desire to actually learn the details.

1219
01:08:55,200 --> 01:08:57,240
Michael Kennedy: If you just go like, all right, I asked it,

1220
01:08:57,359 --> 01:08:59,640
Michael Kennedy: and it gave me the answer, and it just streamed by,

1221
01:08:59,779 --> 01:09:02,100
Michael Kennedy: and you didn't pay attention, you're doing it wrong.

1222
01:09:02,480 --> 01:09:06,180
Michael Kennedy: You've got to stop, read, pay attention, question,

1223
01:09:06,460 --> 01:09:07,060
Michael Kennedy: why did it do that?

1224
01:09:07,109 --> 01:09:08,600
Michael Kennedy: You can even ask it, why did you do this?

1225
01:09:08,890 --> 01:09:11,680
Michael Kennedy: Rather than that way, it might give you a documentation link.

1226
01:09:12,240 --> 01:09:16,180
Michael Kennedy: You've got to stay active, and it's so easy to just go next,

1227
01:09:16,380 --> 01:09:18,420
Michael Kennedy: next, next, because it's exciting that it's building something.

1228
01:09:19,600 --> 01:09:19,960
Michael Kennedy: Absolutely.

1229
01:09:20,370 --> 01:09:25,000
Hugo Bowne-Anderson: And I will add one other thing there, which is we need to carve out

1230
01:09:25,020 --> 01:09:26,720
Hugo Bowne-Anderson: these things won't always work.

1231
01:09:26,960 --> 01:09:28,440
Hugo Bowne-Anderson: You can spend a day working with AI

1232
01:09:28,740 --> 01:09:31,319
Hugo Bowne-Anderson: and make less progress than if you'd done it yourself as well.

1233
01:09:31,400 --> 01:09:33,220
Hugo Bowne-Anderson: I want to be very clear about that.

1234
01:09:34,279 --> 01:09:36,640
Hugo Bowne-Anderson: What we all need to do is figure out organizations

1235
01:09:36,940 --> 01:09:39,339
Hugo Bowne-Anderson: we can work at, work with, and then time ourselves

1236
01:09:40,339 --> 01:09:43,380
Hugo Bowne-Anderson: to experiment with these seriously emerging

1237
01:09:43,759 --> 01:09:47,839
Hugo Bowne-Anderson: and rapidly changing technologies.

1238
01:09:48,120 --> 01:09:50,859
Hugo Bowne-Anderson: So it won't always be wins is my point.

1239
01:09:50,940 --> 01:09:53,120
Hugo Bowne-Anderson: So don't get discouraged when it isn't.

1240
01:09:55,240 --> 01:10:01,860
Michael Kennedy: awesome Hugo thank you for being on the show sharing what you've been up to your yeah absolutely

1241
01:10:02,140 --> 01:10:05,320
Michael Kennedy: I'll put a link to your podcasts your courses stuff like that in the show notes for people

1242
01:10:05,440 --> 01:10:10,300
Hugo Bowne-Anderson: I'd love that oh and I mentioned this to you earlier but um always love talk python of course

1243
01:10:10,460 --> 01:10:15,240
Hugo Bowne-Anderson: and I'm so grateful for having me on three times and I'd love to offer your audience 20% off my

1244
01:10:15,370 --> 01:10:19,640
Michael Kennedy: course as well so we'll include that that link in the show notes beautiful we'll put it put it right

1245
01:10:19,620 --> 01:10:26,340
Michael Kennedy: about the link. All right. Well, thanks for being here. We live in weird and amazing and crazy times.

1246
01:10:26,550 --> 01:10:32,000
Michael Kennedy: And yeah, I'm not leaving with that. On the journey together. Thanks. That's right. See you later.

1247
01:10:32,260 --> 01:10:32,620
Michael Kennedy: Bye, everyone. Ciao.

1248
01:11:02,060 --> 01:11:02,420
Michael Kennedy: out.