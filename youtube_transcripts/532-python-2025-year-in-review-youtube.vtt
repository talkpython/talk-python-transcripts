WEBVTT

00:00:00.760 --> 00:00:03.380
<v Michael Kennedy>Hey, everyone. It's so awesome to be here with you all.

00:00:03.560 --> 00:00:05.840
<v Michael Kennedy>Thanks for taking the time out of your day to be part of

00:00:05.980 --> 00:00:07.980
<v Michael Kennedy>Talk Python for this year in review,

00:00:08.420 --> 00:00:09.780
<v Michael Kennedy>this Python year in review.

00:00:10.840 --> 00:00:13.640
<v Michael Kennedy>Yeah, let's just jump right into it. Gregory.

00:00:15.040 --> 00:00:16.920
<v Michael Kennedy>Hi. Welcome to the show. Welcome back to the show.

00:00:17.660 --> 00:00:19.180
<v Gregory Kapfhammer>Yeah. On a positive note,

00:00:19.250 --> 00:00:20.360
<v Gregory Kapfhammer>the last time I recorded,

00:00:20.530 --> 00:00:23.600
<v Gregory Kapfhammer>I had to record in my home in my closet,

00:00:24.290 --> 00:00:26.140
<v Gregory Kapfhammer>because the power was out throughout my city.

00:00:26.920 --> 00:00:29.980
<v Gregory Kapfhammer>Today, I'm actually back in my recording studio and glad to be

00:00:30.000 --> 00:00:34.760
<v Gregory Kapfhammer>to chat with people. I'm an associate professor of computer and information science, and I do

00:00:35.080 --> 00:00:39.300
<v Gregory Kapfhammer>research in software engineering and software testing. I've built a bunch of Python tools,

00:00:39.620 --> 00:00:43.640
<v Gregory Kapfhammer>and one of the areas we're studying now is flaky test cases in Python projects.

00:00:44.420 --> 00:00:49.500
<v Gregory Kapfhammer>I'm also really excited about teaching in a wide variety of areas. In fact, I use Python for

00:00:49.720 --> 00:00:55.220
<v Gregory Kapfhammer>operating systems classes or theory of computation classes. And one of the things I'm excited about

00:00:55.240 --> 00:00:57.000
<v Gregory Kapfhammer>is being a podcast host.

00:00:57.520 --> 00:01:00.360
<v Gregory Kapfhammer>I'm also a host on the Software Engineering Radio podcast

00:01:00.860 --> 00:01:02.740
<v Gregory Kapfhammer>sponsored by the IEEE Computer Society.

00:01:03.560 --> 00:01:04.940
<v Gregory Kapfhammer>And I've had the cool opportunity

00:01:05.300 --> 00:01:06.700
<v Gregory Kapfhammer>to interview a whole bunch of people

00:01:06.810 --> 00:01:07.780
<v Gregory Kapfhammer>in the Python community.

00:01:08.300 --> 00:01:10.140
<v Michael Kennedy>So Michael, thanks for welcoming me to the show.

00:01:10.640 --> 00:01:11.900
<v Michael Kennedy>Yeah, it's awesome to have you back.

00:01:12.120 --> 00:01:14.020
<v Michael Kennedy>And we talked about FlakyTest last time.

00:01:14.200 --> 00:01:18.020
<v Michael Kennedy>I do have to say your AV setup is quite good.

00:01:18.600 --> 00:01:20.440
<v Michael Kennedy>I love the new mic and all that.

00:01:22.719 --> 00:01:23.600
<v Michael Kennedy>Thomas, welcome.

00:01:24.170 --> 00:01:24.580
<v Michael Kennedy>Awesome to have you.

00:01:25.280 --> 00:01:34.600
<v Speaker 3>Thanks for having me. I'm Tomas Wauters. I'm a longtime Python core developer, although not as long as one of the other guests on this podcast.

00:01:36.900 --> 00:01:46.560
<v Speaker 3>I worked at Google for 17 years. For the last year or so, I've worked at Meta. In both cases, I work on Python itself within the company and just deploying it internally.

00:01:47.500 --> 00:01:51.880
<v Speaker 3>I've also been a board member of the PSF, although I'm not one right now.

00:01:52.570 --> 00:01:59.000
<v Speaker 3>And I've been a steering council member for five years and currently not because of the

00:01:59.160 --> 00:02:01.900
<v Speaker 3>elections are going and I don't know what the result is going to be.

00:02:02.060 --> 00:02:08.800
<v Speaker 3>But I think there's like five, six chance that I'll be on the steering council since

00:02:08.899 --> 00:02:14.320
<v Speaker 3>we only have six candidates for five positions when this episode probably airs.

00:02:14.320 --> 00:02:14.700
<v Speaker 3>I don't know.

00:02:15.720 --> 00:02:15.820
<v Michael Kennedy>Yeah.

00:02:16.440 --> 00:02:16.580
<v Michael Kennedy>Amazing.

00:02:17.200 --> 00:02:23.540
<v Michael Kennedy>that that's quite the contribution to the whole community thank you oh i i i always forget this

00:02:23.540 --> 00:02:28.320
<v Speaker 3>i also got the uh what is it the distinguished service award from the psf this year i should

00:02:28.440 --> 00:02:33.200
<v Speaker 3>probably mention that so yes i've been i have been recognized no need to talk about it further

00:02:34.580 --> 00:02:38.460
<v Michael Kennedy>wonderful wonderful jody welcome back on the show awesome to catch up with you

00:02:39.170 --> 00:02:43.999
<v Jodie Burchell>yeah thanks for having me back um so i am a data scientist and developer advocate

00:02:44.000 --> 00:02:46.380
<v Jodie Burchell>at JetBrains working on PyCharm.

00:02:47.060 --> 00:02:49.480
<v Jodie Burchell>And I've been a data scientist for around 10 years.

00:02:50.180 --> 00:02:53.640
<v Jodie Burchell>And prior to that, I was actually a clinical psychologist.

00:02:53.900 --> 00:02:56.640
<v Jodie Burchell>So that was my training, my PhD,

00:02:57.040 --> 00:02:59.720
<v Jodie Burchell>but abandoned academia for greener pastures.

00:03:00.040 --> 00:03:00.600
<v Jodie Burchell>Let's put it that way.

00:03:01.620 --> 00:03:02.280
<v Jodie Burchell>Noah Franz Gregory.

00:03:06.740 --> 00:03:07.420
<v Michael Kennedy>Brett, hello.

00:03:08.660 --> 00:03:09.100
<v Michael Kennedy>Good to see you.

00:03:09.300 --> 00:03:09.440
<v Michael Kennedy>Hello.

00:03:10.060 --> 00:03:10.200
<v Speaker 5>Yes.

00:03:11.080 --> 00:03:11.780
<v Speaker 5>Okay, let's see here.

00:03:12.040 --> 00:03:13.740
<v Speaker 5>I've been at Microsoft for 10 years.

00:03:15.219 --> 00:03:18.720
<v Speaker 5>Started working on AI R&D for Python developers.

00:03:19.840 --> 00:03:22.140
<v Speaker 5>Also keep Wazzy running for Python here

00:03:22.820 --> 00:03:24.640
<v Speaker 5>and do a lot of internal consulting for teams.

00:03:25.560 --> 00:03:28.820
<v Speaker 5>Outside, I am actually the shortest running

00:03:29.640 --> 00:03:31.000
<v Speaker 5>core developer on this call, amazingly,

00:03:31.130 --> 00:03:32.640
<v Speaker 5>even though I've been doing it for 22 years.

00:03:32.940 --> 00:03:34.920
<v Speaker 5>I've also only gotten the Frank Wilson Award,

00:03:35.140 --> 00:03:35.760
<v Speaker 5>not the DSA.

00:03:36.480 --> 00:03:39.020
<v Speaker 5>So I feel very underaccomplished here as a core developer.

00:03:41.100 --> 00:03:43.140
<v Speaker 5>Yeah, that's me in a nutshell.

00:03:44.240 --> 00:03:45.760
<v Speaker 5>I'm still trying to catch Anthony Shaw.

00:03:46.620 --> 00:03:47.280
<v Speaker 5>Most quoted.

00:03:47.760 --> 00:03:49.020
<v Speaker 6>Yeah, most quoted.

00:03:49.500 --> 00:03:51.640
<v Speaker 5>I will say actually at work, it is in my email footer

00:03:51.700 --> 00:03:53.500
<v Speaker 5>that I'm a famous Python quotationist.

00:03:54.300 --> 00:03:56.220
<v Speaker 5>That was Anthony Shaw's suggestion, by the way.

00:03:56.480 --> 00:03:57.200
<v Speaker 5>That was not mine.

00:03:57.920 --> 00:04:00.660
<v Speaker 5>But it does link to the April Fool's joke from last year.

00:04:01.760 --> 00:04:03.680
<v Speaker 5>And I am still trying to catch Anthony Shaw, I think,

00:04:03.720 --> 00:04:04.800
<v Speaker 5>on appearances on this podcast.

00:04:05.300 --> 00:04:06.300
<v Michael Kennedy>Well, plus one.

00:04:07.020 --> 00:04:08.320
<v Michael Kennedy>Anthony Shaw shouldn't be here, honestly.

00:04:08.700 --> 00:04:09.820
<v Michael Kennedy>I mean, I put it out into Discord.

00:04:11.160 --> 00:04:13.560
<v Michael Kennedy>he could have been here, but probably at an odd time.

00:04:17.900 --> 00:04:21.040
<v Michael Kennedy>You used to work on VS Code a bunch,

00:04:21.040 --> 00:04:22.320
<v Michael Kennedy>on the Python aspect of VS Code.

00:04:22.330 --> 00:04:24.280
<v Michael Kennedy>You recently changed roles, right?

00:04:25.240 --> 00:04:26.080
<v Speaker 5>Not recently.

00:04:26.240 --> 00:04:27.840
<v Speaker 5>That was, I used to be the dev manager.

00:04:27.840 --> 00:04:29.340
<v Michael Kennedy>By the 70 years, years ago?

00:04:31.240 --> 00:04:32.840
<v Speaker 5>Yeah, September of 2024.

00:04:33.770 --> 00:04:34.440
<v Speaker 5>So it's been over a year.

00:04:34.660 --> 00:04:36.220
<v Michael Kennedy>That counts as recent for me.

00:04:37.840 --> 00:04:41.320
<v Speaker 5>Yes, I used to be the dev manager for the Python experience in VS Code.

00:04:41.820 --> 00:04:42.180
<v Michael Kennedy>Okay.

00:04:42.970 --> 00:04:43.220
<v Michael Kennedy>Very cool.

00:04:43.420 --> 00:04:44.200
<v Michael Kennedy>That's quite a shift.

00:04:45.120 --> 00:04:46.480
<v Speaker 5>Yeah, it went back to being an IC, basically.

00:04:49.380 --> 00:04:51.080
<v Michael Kennedy>You're good at your TPS reports again now?

00:04:53.100 --> 00:04:55.020
<v Speaker 5>Actually, I just did do my connect, so I kind of did.

00:04:55.520 --> 00:04:55.840
<v Speaker 5>Awesome.

00:04:56.599 --> 00:05:00.040
<v Michael Kennedy>Reuben, I bet you haven't filed a TPS report in at least a year.

00:05:02.260 --> 00:05:03.120
<v Reuven Lerner>At least, at least.

00:05:04.280 --> 00:05:04.940
<v Reuven Lerner>So yeah, I'm Reuben.

00:05:05.820 --> 00:05:09.080
<v Reuven Lerner>I'm a freelance Python and Pandas trainer.

00:05:09.600 --> 00:05:13.000
<v Reuven Lerner>I just celebrated this past week 30 years since going freelance.

00:05:14.619 --> 00:05:16.480
<v Reuven Lerner>So I guess it's working out okay.

00:05:18.300 --> 00:05:20.180
<v Reuven Lerner>We'll know at some point if I need to get a real job.

00:05:21.120 --> 00:05:25.120
<v Reuven Lerner>So I teach Python Pandas both at companies and on my online platform.

00:05:25.340 --> 00:05:26.060
<v Reuven Lerner>I have newsletters.

00:05:26.200 --> 00:05:30.860
<v Reuven Lerner>I've written books, speak at conferences, and generally try to help people improve their

00:05:31.280 --> 00:05:34.859
<v Reuven Lerner>Python and Pandas fluency and confidence and have a lot of fun with this community

00:05:35.300 --> 00:05:36.080
<v Reuven Lerner>as well as with the language.

00:05:36.760 --> 00:05:37.140
<v Michael Kennedy>Yeah, awesome.

00:05:37.390 --> 00:05:38.120
<v Michael Kennedy>Oh, good to have you here.

00:05:38.980 --> 00:05:41.160
<v Michael Kennedy>Barry, it's great to have a musician on the show.

00:05:42.219 --> 00:05:42.580
<v Speaker 6>Thanks.

00:05:43.880 --> 00:05:45.320
<v Speaker 6>Yeah, I've got my basses over here.

00:05:45.620 --> 00:05:47.760
<v Speaker 6>So, you know, if you need to be serenaded.

00:05:48.340 --> 00:05:50.820
<v Michael Kennedy>Yeah, like a Xenopython may break out at any moment.

00:05:53.040 --> 00:05:53.880
<v Speaker 6>Good, good, good.

00:05:54.719 --> 00:05:57.100
<v Speaker 6>Well, thanks for having me here.

00:05:57.840 --> 00:06:01.820
<v Speaker 6>Yeah, I've been a core developer for a long time, since 1994.

00:06:04.460 --> 00:06:14.500
<v Speaker 6>And I've been, you know, in the early days, I did tons of stuff for Python.org, worked with Guido at CNRI.

00:06:14.990 --> 00:06:27.020
<v Speaker 6>And, you know, we moved everything from the mailing, you know, the Postmaster stuff and version control systems back in the day, websites, all that kind of stuff.

00:06:27.090 --> 00:06:29.260
<v Speaker 6>I try to not do any of those things anymore.

00:06:30.020 --> 00:06:33.200
<v Speaker 6>There's more, way more competent people doing that stuff now.

00:06:35.680 --> 00:06:37.400
<v Speaker 6>I have been a release manager

00:06:39.660 --> 00:06:41.540
<v Speaker 6>I'm currently back

00:06:41.660 --> 00:06:42.720
<v Speaker 6>on the steering council

00:06:44.020 --> 00:06:45.060
<v Speaker 6>and running again

00:06:45.140 --> 00:06:47.200
<v Speaker 6>so between Thomas and I

00:06:47.200 --> 00:06:48.900
<v Speaker 6>we'll see who makes it to

00:06:49.320 --> 00:06:50.420
<v Speaker 6>six years I guess

00:06:52.680 --> 00:06:55.060
<v Speaker 6>and I'm currently working for

00:06:55.300 --> 00:06:57.000
<v Speaker 6>NVIDIA and I do

00:06:57.040 --> 00:06:57.980
<v Speaker 6>all Python stuff

00:06:59.440 --> 00:07:00.160
<v Speaker 6>some

00:07:01.540 --> 00:07:03.280
<v Speaker 6>half and half roughly of

00:07:03.300 --> 00:07:11.340
<v Speaker 6>things and external open source community work, both in packaging and in core Python.

00:07:12.490 --> 00:07:14.520
<v Speaker 6>So that's, I guess, quick.

00:07:15.200 --> 00:07:15.860
<v Michael Kennedy>Yeah, awesome.

00:07:16.110 --> 00:07:16.920
<v Michael Kennedy>I think that's about it.

00:07:17.520 --> 00:07:20.360
<v Michael Kennedy>Yeah, you all are living in exciting tech spaces.

00:07:20.640 --> 00:07:21.220
<v Michael Kennedy>That's for sure.

00:07:21.600 --> 00:07:22.040
<v Michael Kennedy>That's for sure.

00:07:22.650 --> 00:07:23.040
<v Michael Kennedy>For sure.

00:07:23.200 --> 00:07:23.280
<v Michael Kennedy>Yeah.

00:07:23.650 --> 00:07:26.900
<v Michael Kennedy>Well, great to have you all back on the show.

00:07:28.280 --> 00:07:29.320
<v Michael Kennedy>Let's start with our first topic.

00:07:29.480 --> 00:07:37.920
<v Michael Kennedy>So the idea is we've each picked at least a thing that we think stood out in 2025 in the Python space that we can focus on.

00:07:38.100 --> 00:07:41.740
<v Michael Kennedy>And, yeah, well, let's go with Jodi first.

00:07:42.700 --> 00:07:45.340
<v Michael Kennedy>I'm excited to hear what you thought was one of the bigger things.

00:07:46.520 --> 00:07:46.620
<v Jodie Burchell>Yeah.

00:07:46.960 --> 00:07:49.360
<v Jodie Burchell>So I'm going to mention AI.

00:07:49.960 --> 00:07:52.440
<v Jodie Burchell>Like, wow, what a, you know, big surprise.

00:07:53.340 --> 00:07:59.700
<v Jodie Burchell>So to kind of give context of where I'm coming from, I've been working in NLP for a long time.

00:07:59.750 --> 00:08:02.120
<v Jodie Burchell>I like to say I was working on LLMs before they were cool.

00:08:03.620 --> 00:08:10.240
<v Jodie Burchell>So sort of playing around with the very first releases from Google in like 2019, incorporating that into search.

00:08:11.280 --> 00:08:16.960
<v Jodie Burchell>So I've been very interested sort of seeing the unfolding of the GPT models as they've grown.

00:08:17.820 --> 00:08:32.860
<v Jodie Burchell>And let's say I'm slightly disgusted by the discourse around the models as they become more mainstream, more sort of the talk about people's jobs being replaced, a lot of the hysteria, a lot of the doomsday stuff.

00:08:33.080 --> 00:08:43.120
<v Jodie Burchell>So I've been doing talks and other content for around two and a half years now, just trying to cut through the hype a bit, being like, you know, they're just language models, they're good for language tasks.

00:08:43.260 --> 00:08:46.080
<v Jodie Burchell>Let's think about realistically what they're about.

00:08:46.460 --> 00:08:51.940
<v Jodie Burchell>And what was very interesting for me this year, I've been incorrectly predicting the bubble

00:08:52.220 --> 00:08:53.920
<v Jodie Burchell>bursting for about two and a half years.

00:08:54.420 --> 00:09:00.880
<v Jodie Burchell>So I was quite vindicated when in August GPT-5 came out and all of a sudden everyone else

00:09:01.360 --> 00:09:02.800
<v Jodie Burchell>started saying, maybe this is a bubble.

00:09:03.620 --> 00:09:03.740
<v Michael Kennedy>Yeah.

00:09:04.060 --> 00:09:08.840
<v Michael Kennedy>So you think that was the first big release that was kind of a letdown compared to what

00:09:08.840 --> 00:09:09.500
<v Michael Kennedy>the hype was?

00:09:10.180 --> 00:09:10.360
<v Jodie Burchell>Yeah.

00:09:10.500 --> 00:09:11.240
<v Jodie Burchell>And it was really interesting.

00:09:11.560 --> 00:09:15.600
<v Jodie Burchell>So I found this really nice Atlantic article and I didn't save it, unfortunately.

00:09:16.140 --> 00:09:22.520
<v Jodie Burchell>but essentially it told sort of the whole story of what was going on behind the scenes. So GPT-4

00:09:22.840 --> 00:09:29.120
<v Jodie Burchell>came out in March of 2023. And that was the model that came out with this Microsoft research paper

00:09:29.340 --> 00:09:33.980
<v Jodie Burchell>saying, you know, sparks of AGI, artificial general intelligence, blah, blah, blah. And from that

00:09:34.320 --> 00:09:43.019
<v Jodie Burchell>point, there was really this big expectation sort of fueled by open AI that GPT-5 was going to be

00:09:42.980 --> 00:09:49.180
<v Jodie Burchell>AGI model. And it turns out what was happening internally is these scaling laws that were sort of

00:09:49.520 --> 00:09:55.260
<v Jodie Burchell>considered, you know, this exponential growth thing that would sort of push the power of these models

00:09:55.680 --> 00:10:01.940
<v Jodie Burchell>perhaps towards human-like performance. They weren't laws at all. And of course, they started failing.

00:10:02.280 --> 00:10:07.180
<v Jodie Burchell>So the model that they'd originally pitched as GPT-4 just didn't live up to performance. They

00:10:07.340 --> 00:10:11.920
<v Jodie Burchell>started this post-training stuff where they were going more into like specialized reasoning models.

00:10:12.300 --> 00:10:16.100
<v Jodie Burchell>And what we have now are good models that are good for specific tasks.

00:10:16.900 --> 00:10:22.460
<v Jodie Burchell>But I don't know what happened, but eventually they had to put the GPT-5 label on something.

00:10:23.560 --> 00:10:27.920
<v Jodie Burchell>And yeah, let's say it didn't live up to expectations.

00:10:28.340 --> 00:10:39.920
<v Jodie Burchell>So I think the cracks are starting to show because the underlying expectation always was this will be improving to the point where anything's possible.

00:10:40.220 --> 00:10:42.380
<v Jodie Burchell>and you can't put a price on that.

00:10:43.130 --> 00:10:46.340
<v Jodie Burchell>But it turns out that if maybe there's a limit on what's possible,

00:10:47.300 --> 00:10:48.920
<v Jodie Burchell>yeah, you can put a price on it.

00:10:49.620 --> 00:10:52.580
<v Michael Kennedy>And a lot of the valuations are on the first part.

00:10:53.980 --> 00:10:56.180
<v Jodie Burchell>Yes, and it's always been a bit interesting to me

00:10:56.400 --> 00:10:57.960
<v Jodie Burchell>because I come from a scientific background

00:10:58.250 --> 00:11:00.260
<v Jodie Burchell>and you need to know how to measure stuff, right?

00:11:00.900 --> 00:11:03.000
<v Jodie Burchell>And I'm like, what are you trying to achieve?

00:11:03.520 --> 00:11:05.580
<v Jodie Burchell>Like Gregory's nodding, like please jump in.

00:11:06.060 --> 00:11:09.000
<v Jodie Burchell>I'm on my monologue, so please don't interrupt me.

00:11:10.980 --> 00:11:16.080
<v Jodie Burchell>you really need to understand what you're actually trying to get these models to do. What is AGI?

00:11:16.580 --> 00:11:24.160
<v Jodie Burchell>No one knows this. And what's going to be possible with this? And it's more science fiction than fact.

00:11:24.720 --> 00:11:28.980
<v Jodie Burchell>So this for me has been the big news this year. And I'm feeling slightly smug,

00:11:29.180 --> 00:11:32.640
<v Jodie Burchell>I'm going to be honest, even though my predictions were off by about a year and a half.

00:11:34.800 --> 00:11:38.900
<v Michael Kennedy>Yeah, maybe it's not an exponential curve. It's a titration S curve with an asymptote.

00:11:40.080 --> 00:11:40.800
<v Jodie Burchell>Yeah, sigmoid.

00:11:41.280 --> 00:11:41.420
<v Jodie Burchell>Yeah.

00:11:41.660 --> 00:11:42.460
<v Michael Kennedy>Yeah, yeah, yeah.

00:11:42.640 --> 00:11:46.720
<v Reuven Lerner>I mean, I think we have to sort of separate the technology from the business.

00:11:47.370 --> 00:11:58.520
<v Reuven Lerner>And the technology, even if it doesn't get any better, even if we stay with what we have today, I still think this is like one of the most amazing technologies I've ever seen.

00:11:59.120 --> 00:12:00.140
<v Reuven Lerner>It's not a god.

00:12:00.500 --> 00:12:01.760
<v Reuven Lerner>It's not a panacea.

00:12:02.400 --> 00:12:06.380
<v Reuven Lerner>But it's like a chainsaw that if you know how to use it, it's really effective.

00:12:07.160 --> 00:12:11.000
<v Reuven Lerner>But in the hands of amateurs, you can really get hurt.

00:12:11.620 --> 00:12:17.220
<v Reuven Lerner>And so, yes, it's great to see this sort of thing happening and improving, but who knows

00:12:17.320 --> 00:12:17.820
<v Reuven Lerner>where it's going to go.

00:12:17.920 --> 00:12:19.320
<v Reuven Lerner>And I'm a little skeptical of the AGI thing.

00:12:19.440 --> 00:12:23.880
<v Reuven Lerner>What I'm a little more worried about is that these companies seem to have no possible way

00:12:24.220 --> 00:12:27.300
<v Reuven Lerner>of ever making the money that they're promising to their investors.

00:12:28.140 --> 00:12:36.900
<v Reuven Lerner>And I do worry a lot that we're sort of like a year 2000 situation where, yeah, the technology

00:12:36.920 --> 00:12:47.320
<v Reuven Lerner>But the businesses are unsustainable. And out of the ashes of what will happen, we will get some amazing technology and even better than we had before. But there are going to be ashes.

00:12:50.600 --> 00:13:14.880
<v Jodie Burchell>Yeah. For me, that also makes me worry. And I don't know if anyone reads Ed Zitron here. He's a journalist kind of digging into the state of the AI industry. He does get a bit sort of, he has a bit of a reputation as a bit of a crank now. So I think he's leaned into that pretty hard. But he does take the time to also pull out numbers and point out things that don't make sense.

00:13:15.880 --> 00:13:18.320
<v Jodie Burchell>And he was one of the first ones to sound the whistle

00:13:18.520 --> 00:13:20.540
<v Jodie Burchell>on this circular funding we've been seeing.

00:13:20.880 --> 00:13:28.840
<v Jodie Burchell>So the worry, of course, is when a lot of this becomes borrowings

00:13:29.640 --> 00:13:32.620
<v Jodie Burchell>from banks and then that starts dragging in funding

00:13:33.020 --> 00:13:36.380
<v Jodie Burchell>from everyday people and also the effect that this has had

00:13:36.460 --> 00:13:39.040
<v Jodie Burchell>on particularly the US economy, like the stock market.

00:13:39.640 --> 00:13:43.620
<v Jodie Burchell>I think the investment in AI spending now exceeds consumer spending

00:13:43.740 --> 00:13:49.320
<v Jodie Burchell>in the US, which is a really scary prospect.

00:13:50.220 --> 00:13:50.780
<v Michael Kennedy>That is crazy.

00:13:53.580 --> 00:13:56.960
<v Jodie Burchell>But yeah, also as Reven said, like I love LLMs.

00:13:58.140 --> 00:14:00.160
<v Jodie Burchell>They are the most powerful tools we've ever had

00:14:00.170 --> 00:14:01.420
<v Jodie Burchell>for natural language processing.

00:14:02.120 --> 00:14:04.200
<v Jodie Burchell>It's phenomenal the problems we can solve with them now.

00:14:04.400 --> 00:14:06.400
<v Jodie Burchell>Like I didn't think this sort of stuff would be possible

00:14:07.070 --> 00:14:08.260
<v Jodie Burchell>when I started in data science.

00:14:10.100 --> 00:14:12.140
<v Jodie Burchell>I still think there's a use case for agents,

00:14:12.380 --> 00:14:15.260
<v Jodie Burchell>although I do think they've been a bit overstated,

00:14:15.960 --> 00:14:17.440
<v Jodie Burchell>especially now that I'm building them.

00:14:18.760 --> 00:14:21.280
<v Jodie Burchell>Let's say it's not very fun building non-deterministic software.

00:14:21.420 --> 00:14:22.440
<v Jodie Burchell>It's quite frustrating, actually.

00:14:24.420 --> 00:14:27.400
<v Jodie Burchell>But I hope we're going to see improvements in the framework,

00:14:27.760 --> 00:14:30.080
<v Jodie Burchell>particularly I've heard good things about Pydantic AI.

00:14:31.100 --> 00:14:34.220
<v Jodie Burchell>And yeah, hopefully we can control the input outputs

00:14:34.680 --> 00:14:36.200
<v Jodie Burchell>and make them a bit more strict.

00:14:36.460 --> 00:14:38.480
<v Jodie Burchell>This will fix a lot of the problems.

00:14:39.720 --> 00:14:41.940
<v Michael Kennedy>One thing I do want to put out in this conversation,

00:14:41.980 --> 00:14:45.520
<v Michael Kennedy>I think is worth separating.

00:14:45.680 --> 00:14:47.100
<v Michael Kennedy>And Reuben, you touched on this some,

00:14:47.600 --> 00:14:51.120
<v Michael Kennedy>but I want to suggest to you all,

00:14:51.160 --> 00:14:52.400
<v Michael Kennedy>throw this out to you all and see what you think.

00:14:53.260 --> 00:14:56.040
<v Michael Kennedy>I think it's very possible that this AI bubble

00:14:56.920 --> 00:14:59.080
<v Michael Kennedy>crashes the economy and causes bad things

00:14:59.380 --> 00:15:01.020
<v Michael Kennedy>economically to happen and a bunch of companies

00:15:01.040 --> 00:15:05.440
<v Michael Kennedy>that are like wrappers over OpenAI, API, go away.

00:15:07.000 --> 00:15:10.760
<v Michael Kennedy>But I don't think things like the agentic coding tools

00:15:12.120 --> 00:15:12.840
<v Michael Kennedy>will vanish.

00:15:13.180 --> 00:15:14.760
<v Michael Kennedy>They might stop training. They might slow their

00:15:14.960 --> 00:15:15.960
<v Michael Kennedy>advance because that's super expensive.

00:15:17.540 --> 00:15:18.620
<v Michael Kennedy>Even as you said,

00:15:18.780 --> 00:15:20.600
<v Michael Kennedy>even if we just had

00:15:20.740 --> 00:15:22.720
<v Michael Kennedy>Claude Sonnet 4

00:15:23.900 --> 00:15:24.860
<v Michael Kennedy>and the world

00:15:25.100 --> 00:15:26.860
<v Michael Kennedy>never got something else, it would be so much

00:15:27.440 --> 00:15:28.860
<v Michael Kennedy>farther beyond autocomplete

00:15:29.270 --> 00:15:30.800
<v Michael Kennedy>and the other stuff that we had before and

00:15:31.000 --> 00:15:32.080
<v Michael Kennedy>Stack Overflow that it's

00:15:32.740 --> 00:15:34.740
<v Michael Kennedy>I don't think it's going to go. The reason I'm throwing this out there

00:15:34.800 --> 00:15:36.760
<v Michael Kennedy>is I was talking to somebody and they were like, well, I don't think

00:15:36.820 --> 00:15:38.940
<v Michael Kennedy>it's worth learning because I think the bubble is going to

00:15:38.960 --> 00:15:42.600
<v Michael Kennedy>pop and so I don't want to learn this agent at coding because it won't be around very long.

00:15:43.660 --> 00:15:44.020
<v Michael Kennedy>What do you all think?

00:15:46.880 --> 00:15:50.600
<v Speaker 5>Yeah, I think it's here to stay. I think it's just

00:15:51.020 --> 00:15:54.820
<v Speaker 5>where is the limit? Where does it stop potentially? I think that's the

00:15:54.830 --> 00:15:58.860
<v Speaker 5>big open question for everybody, right? Pragmatically, it's a tool.

00:15:59.480 --> 00:16:02.960
<v Speaker 5>It's useful in some scenarios and not in others. And you

00:16:02.990 --> 00:16:06.680
<v Speaker 5>just have to learn how to use the tool appropriately for your use case and to get what you need out of it.

00:16:06.780 --> 00:16:10.860
<v Speaker 5>And sometimes that's not using it because it's just going to take up more time than it will to be productive.

00:16:10.940 --> 00:16:14.940
<v Speaker 5>But other times it's fully juices up your productivity and you can get more done.

00:16:15.100 --> 00:16:16.360
<v Speaker 5>It's give and take.

00:16:17.040 --> 00:16:21.940
<v Speaker 5>But I don't think it's going to go anywhere because as you said, Michael, there's even academics doing research now.

00:16:22.140 --> 00:16:23.880
<v Speaker 5>There's open weight models as well.

00:16:24.540 --> 00:16:35.100
<v Speaker 5>There's a lot of different ways to run this, whether you're at the scale of the frontier models that are doing these huge trainings or you're doing something local and more specialized.

00:16:35.160 --> 00:16:38.540
<v Speaker 5>So I think the general use of AI isn't going anywhere.

00:16:38.610 --> 00:16:49.600
<v Speaker 5>I think it's just a question of how far can this current trend go and where will it, I don't want to say stop, because that plays into the whole, it's going to completely go away.

00:16:49.600 --> 00:16:50.280
<v Speaker 5>I don't think it ever will.

00:16:50.290 --> 00:16:54.320
<v Speaker 5>I think it's just going to be where are we going to start to potentially bump up against limits.

00:16:55.840 --> 00:17:00.080
<v Gregory Kapfhammer>One thing that I'll say is that many of these systems are almost, to me, like a dream come true.

00:17:00.800 --> 00:17:06.860
<v Gregory Kapfhammer>Now, admittedly, it's the case that the systems I'm building are maybe only tens of thousands of lines or hundreds of thousands of lines.

00:17:07.439 --> 00:17:26.500
<v Gregory Kapfhammer>But I can remember thinking to myself, how cool would it be if I had a system that could automatically refactor and then add test cases and increase the code coverage and make sure all my checkers and linters pass and do that automatically and continue the process until it achieved its goal?

00:17:27.360 --> 00:17:45.100
<v Gregory Kapfhammer>And I remember thinking that five to seven years ago, I would never realize that goal in my entire lifetime. And now when I use like anthropics models through open code or cloud code, it's incredible how much you can achieve so quickly, even for systems that are of medium to moderate scale.

00:17:45.700 --> 00:18:06.080
<v Gregory Kapfhammer>So from my vantage point, it is a really exciting tool. It's incredibly powerful. And what I have found is that the LLMs are much better when I teach them how to use tools. And the tools that it's using are actually really quick, fast ones that can give rapid feedback to the LLM and tell it whether it's moving in the right direction or not.

00:18:06.640 --> 00:18:13.400
<v Michael Kennedy>Yeah, there's an engineering angle to this. It's not just Vibe Coding if you take the time to learn it.

00:18:14.840 --> 00:18:40.080
<v Jodie Burchell>There was actually a very interesting study. I don't think the study itself has been released. I haven't found it yet, but I saw a talk on it by some guys at Stanford. So they call it the 10K developer study. And basically what they were doing was studying real code bases, including I think 80% of them were actually private code bases, and seeing the point where the team started adopting AI.

00:18:41.160 --> 00:18:43.720
<v Jodie Burchell>And so their findings are really interesting and nuanced.

00:18:43.720 --> 00:18:48.520
<v Jodie Burchell>And I think they probably intuitively align with what a lot of us have experienced with AI.

00:18:49.520 --> 00:19:00.840
<v Jodie Burchell>So basically, yes, there are productivity boosts, but it produces a lot of code, but the code tends to be worse than the code you would write and also introduces more bugs.

00:19:01.180 --> 00:19:06.900
<v Jodie Burchell>So when you account for the time that you spend refactoring and debugging, you're still more productive.

00:19:07.800 --> 00:19:10.900
<v Jodie Burchell>But then it also depends on the type of project, as Gregory was saying.

00:19:11.180 --> 00:19:12.740
<v Jodie Burchell>So it's better for greenfield projects.

00:19:13.260 --> 00:19:14.640
<v Jodie Burchell>It's better for smaller code bases.

00:19:14.960 --> 00:19:16.020
<v Jodie Burchell>It's better for simpler problems.

00:19:16.220 --> 00:19:21.020
<v Jodie Burchell>And it's better for more popular languages because, obviously, there's more training data.

00:19:21.880 --> 00:19:24.860
<v Jodie Burchell>And so this was actually I like this study so much.

00:19:24.960 --> 00:19:27.660
<v Jodie Burchell>I'll actually share it with you, Michael, if you want to put it in the show notes.

00:19:27.880 --> 00:19:31.820
<v Jodie Burchell>But it shows that, yeah, the picture is not that simple.

00:19:31.900 --> 00:19:37.120
<v Jodie Burchell>And all this conflicting information and conflicting experiences people were having line up completely with this.

00:19:37.240 --> 00:19:42.060
<v Jodie Burchell>So again, like I work at an IDE company, it's tools for the job.

00:19:42.620 --> 00:19:45.260
<v Jodie Burchell>It's not like your IDE will replace you.

00:19:46.280 --> 00:19:47.500
<v Jodie Burchell>AI is not going to replace you.

00:19:47.620 --> 00:19:50.460
<v Jodie Burchell>It's just going to make you maybe more productive sometimes.

00:19:51.460 --> 00:19:51.580
<v Michael Kennedy>Yeah.

00:19:51.820 --> 00:19:53.020
<v Michael Kennedy>Wait, IDE, you work for me.

00:20:00.500 --> 00:20:05.040
<v Reuven Lerner>I mean, the other thing is a lot of people and a lot of the sort of when people talk about

00:20:05.160 --> 00:20:13.180
<v Reuven Lerner>AI and LLMs and so forth in context of coding, it's the LLM writing code for us. And maybe because

00:20:13.340 --> 00:20:19.160
<v Reuven Lerner>I'm not doing a lot of serious coding, it's more instruction, so forth. I use it as like a sparring

00:20:19.480 --> 00:20:25.920
<v Reuven Lerner>or brainstorming partner. So it does checking of my newsletters for language and for tech edits

00:20:26.400 --> 00:20:31.760
<v Reuven Lerner>and just sort of exploring ideas. And for that, maybe it's because I do everything in the last

00:20:31.740 --> 00:20:35.060
<v Reuven Lerner>minute and I don't have other people around or I'm lazy or cheap and don't want to pay them.

00:20:35.720 --> 00:20:39.840
<v Reuven Lerner>But definitely the quality of my work has improved dramatically. The quality of my understanding has

00:20:40.000 --> 00:20:45.700
<v Reuven Lerner>improved, even if it never wrote a line of code for me. Just getting that feedback on a regular

00:20:45.940 --> 00:20:51.140
<v Michael Kennedy>automatic basis is really helpful. Yeah, I totally agree with you. All right. We don't want to spend

00:20:51.320 --> 00:20:57.300
<v Michael Kennedy>too much time on this topic, even though I believe Jody has put her finger on what might be the

00:20:57.320 --> 00:21:02.360
<v Michael Kennedy>biggest tidal wave of 2025, but still a quick parting thoughts.

00:21:02.480 --> 00:21:02.820
<v Michael Kennedy>Anyone else?

00:21:04.140 --> 00:21:06.520
<v Speaker 5>I'm glad I'll never have the right bash from scratch ever again.

00:21:08.820 --> 00:21:10.300
<v Speaker 6>Tell me about it. Yeah.

00:21:12.240 --> 00:21:14.840
<v Speaker 6>I'll just, I'll just say from, from anecdotally,

00:21:14.860 --> 00:21:20.440
<v Speaker 6>the thing that I love about it is when I need to do something and I need to go

00:21:20.640 --> 00:21:25.800
<v Speaker 6>through docs, online docs for whatever it is, you know,

00:21:25.960 --> 00:21:29.880
<v Speaker 6>It might be GitLab or some library that I want to use or something like that.

00:21:30.760 --> 00:21:32.360
<v Speaker 6>I never even search for the docs.

00:21:32.400 --> 00:21:34.260
<v Speaker 6>I never even try to read the docs anymore.

00:21:34.380 --> 00:21:40.340
<v Speaker 6>I just say, hey, you know, whatever model I need to set up this website,

00:21:41.120 --> 00:21:43.720
<v Speaker 6>and just tell me what to do or just do it.

00:21:43.880 --> 00:21:47.920
<v Speaker 6>And it's an immense time saver and productivity.

00:21:48.060 --> 00:21:52.580
<v Speaker 6>And then it gets me bootstrapped to the place where now I can start to be creative.

00:21:52.920 --> 00:22:00.540
<v Speaker 6>I don't have to worry about just like digging through pages and pages and pages of docs to figure out one little setting here or there.

00:22:01.220 --> 00:22:02.960
<v Speaker 6>That's an amazing time saver.

00:22:03.760 --> 00:22:05.040
<v Gregory Kapfhammer>Yeah, that's a really good point.

00:22:05.320 --> 00:22:12.400
<v Gregory Kapfhammer>Another thing that I have noticed, there might be many things for which I had a really good mental model, but my brain can only store so much information.

00:22:13.080 --> 00:22:18.620
<v Gregory Kapfhammer>So, for example, I know lots about the abstract syntax tree for Python, but I forget that sometimes.

00:22:19.400 --> 00:22:24.400
<v Gregory Kapfhammer>And so it's really nice for me to be able to bring that back into my mind quickly with an LLM.

00:22:24.750 --> 00:22:33.040
<v Gregory Kapfhammer>And if it's generating code for me that's doing a type of AST parsing, I can tell whether that's good code or not because I can refresh that mental model.

00:22:33.500 --> 00:22:40.560
<v Gregory Kapfhammer>So in those situations, it's not only the docs, but it's something that I used to know really well that I have forgotten some of.

00:22:40.790 --> 00:22:47.160
<v Gregory Kapfhammer>And the LLM often is very powerful when it comes to refreshing my memory and helping me to get started and move more quickly.

00:22:49.620 --> 00:22:54.240
<v Michael Kennedy>All right. Out of time, I think. Let's move on to Brett. What do you got, Brett?

00:22:56.780 --> 00:23:10.000
<v Speaker 5>Well, I actually originally said we should talk about AI, but Jody had a way better pitch for it than I did because my internal pitch was literally AI. Do I actually have to write a paragraph explaining why? Then Jody actually did write the paragraph, so she did a much better job than I did.

00:23:10.560 --> 00:23:16.480
<v Speaker 5>So the other topic I had was using tools to run your Python code.

00:23:16.930 --> 00:23:19.440
<v Speaker 5>And what I mean by that is traditionally, if you think about it,

00:23:21.840 --> 00:23:23.280
<v Speaker 5>you install the Python interpreter, right?

00:23:25.300 --> 00:23:27.560
<v Speaker 5>Hopefully you create a virtual environment, install your dependencies,

00:23:27.960 --> 00:23:30.660
<v Speaker 5>and you call the Python interpreter in your virtual environment to run your code.

00:23:31.080 --> 00:23:32.880
<v Speaker 5>And those are all the steps you went through to run stuff.

00:23:33.510 --> 00:23:37.760
<v Speaker 5>But now we've got tools that will compress all that into a run command

00:23:38.250 --> 00:23:39.060
<v Speaker 5>and just do it all for you.

00:23:39.320 --> 00:23:48.800
<v Speaker 5>And it seems like the community has shown a level of comfort with that, that I'd say snuck up on me a little bit.

00:23:49.200 --> 00:23:53.800
<v Speaker 5>But I would say that I think it's a good thing, right?

00:23:53.860 --> 00:23:59.500
<v Speaker 5>It's showing us, I'm going to say us, as the junior core developer here on this call.

00:24:00.940 --> 00:24:08.600
<v Speaker 5>As to, sorry to make you too feel old, but admittedly, Barry did write my letter of recommendation to my master's program.

00:24:08.740 --> 00:24:12.840
<v Speaker 5>So Barry already knows this.

00:24:13.140 --> 00:24:36.840
<v Speaker 5>Anyway, because I think what happened was like, yeah, we had Hatch and BDM and Poetry before that and uv as of last year all kind of come through and all kind of build on each other and take ideas from each other and kind of just slowly build up this kind of repertoire of tool approaches that they all kind of have a baseline kind of, not synergy is the right word,

00:24:37.000 --> 00:24:39.960
<v Speaker 5>but share just kind of approach to certain things

00:24:40.410 --> 00:24:43.060
<v Speaker 5>with their own twists and added takes on things.

00:24:43.300 --> 00:24:45.760
<v Speaker 5>But in general, this whole like, you know what?

00:24:45.830 --> 00:24:47.140
<v Speaker 5>You can just tell us to run this code

00:24:47.230 --> 00:24:48.240
<v Speaker 5>and we will just run it, right?

00:24:48.460 --> 00:24:50.060
<v Speaker 5>Like in-line script metadata coming in

00:24:50.180 --> 00:24:52.060
<v Speaker 5>and help making that more of a thing.

00:24:53.160 --> 00:24:55.080
<v Speaker 5>I just claim where I was the  PEP delegate

00:24:55.400 --> 00:24:56.240
<v Speaker 5>for getting that in.

00:24:57.960 --> 00:25:00.180
<v Speaker 5>But I just think that's been a really awesome trend

00:25:01.500 --> 00:25:05.160
<v Speaker 5>and I'm hoping we can kind of leverage that a bit.

00:25:05.300 --> 00:25:08.040
<v Speaker 5>I have personal plans that we don't need to go into here.

00:25:08.700 --> 00:25:10.520
<v Speaker 5>I'm hoping as a Python core team,

00:25:10.530 --> 00:25:12.880
<v Speaker 5>we can help boost this stuff up a bit

00:25:12.880 --> 00:25:15.160
<v Speaker 5>and help keep a good baseline for this for everyone.

00:25:15.300 --> 00:25:18.000
<v Speaker 5>I think it's shown that Python is still really good for beginners.

00:25:18.270 --> 00:25:21.780
<v Speaker 5>You just have to give them the tools to hide some of the details

00:25:21.990 --> 00:25:23.200
<v Speaker 5>to not shoot yourself in the foot.

00:25:24.210 --> 00:25:25.000
<v Speaker 5>It's a great outcome.

00:25:26.320 --> 00:25:29.700
<v Michael Kennedy>2025 might be the year that the Python tools stepped outside of Python.

00:25:30.230 --> 00:25:34.420
<v Michael Kennedy>Instead of being you install Python and then use the tools,

00:25:35.140 --> 00:25:36.780
<v Michael Kennedy>You do the tool to get Python, right?

00:25:37.080 --> 00:25:38.620
<v Michael Kennedy>Like uv and PDM and others.

00:25:38.820 --> 00:25:40.640
<v Speaker 5>Yeah, and inverted the dependency graph

00:25:40.760 --> 00:25:42.960
<v Speaker 5>in terms of just how you put yourself in, right?

00:25:43.360 --> 00:25:45.800
<v Speaker 5>I think the interesting thing is these tools treat Python

00:25:46.200 --> 00:25:48.860
<v Speaker 5>as an implementation detail almost, right?

00:25:49.640 --> 00:25:53.260
<v Speaker 5>When you just say uv or hatch run or PDM run thing,

00:25:55.580 --> 00:25:57.280
<v Speaker 5>these tools don't make you have to think about the interpreter.

00:25:57.500 --> 00:26:00.420
<v Speaker 5>It's just a thing that they pull in to make your code run, right?

00:26:00.540 --> 00:26:03.180
<v Speaker 5>It's not even necessarily something you have to care about

00:26:03.180 --> 00:26:03.880
<v Speaker 5>if you choose not to.

00:26:04.060 --> 00:26:08.540
<v Speaker 5>And it's an interesting shift in that perspective, at least for me.

00:26:08.670 --> 00:26:10.000
<v Speaker 5>But I've also been doing this for a long time.

00:26:10.780 --> 00:26:13.260
<v Speaker 6>Yeah, I think you're really on to something.

00:26:13.570 --> 00:26:16.260
<v Speaker 6>And what I love at sort of a high level is this,

00:26:16.770 --> 00:26:19.740
<v Speaker 6>I think there's a renewed focus on the user experience.

00:26:21.660 --> 00:26:27.500
<v Speaker 6>And like uv plus the PEP 723, the inline metadata,

00:26:27.870 --> 00:26:31.240
<v Speaker 6>you can put uv in the shebang line of your script.

00:26:31.980 --> 00:26:34.360
<v Speaker 6>And now you don't have to think about anything.

00:26:34.660 --> 00:26:36.680
<v Speaker 6>You know, you get uv from somewhere

00:26:37.400 --> 00:26:39.540
<v Speaker 6>and then it takes care of everything.

00:26:40.720 --> 00:26:42.840
<v Speaker 6>And Hatch can work the same way for,

00:26:43.280 --> 00:26:44.000
<v Speaker 6>I think for developers,

00:26:44.280 --> 00:26:49.880
<v Speaker 6>but like this renewed focus on getting,

00:26:50.340 --> 00:26:52.580
<v Speaker 6>like installing your Python executable.

00:26:52.920 --> 00:26:54.320
<v Speaker 6>Like you don't really have to think about,

00:26:55.060 --> 00:26:56.820
<v Speaker 6>because those things are very complicated

00:26:56.870 --> 00:26:59.220
<v Speaker 6>and people just want to kind of hit the ground running.

00:26:59.840 --> 00:27:01.940
<v Speaker 6>And so if you think about the previous discussion

00:27:01.960 --> 00:27:06.920
<v Speaker 6>about AI, right? Like, like I just want things to work. I have, I know what I want to do.

00:27:07.630 --> 00:27:15.080
<v Speaker 6>I can see it. I can see the vision of it. And I just don't want to. And an analogy is like when

00:27:15.080 --> 00:27:21.060
<v Speaker 6>I first learned Python and I came from C++ and all those languages. And I thought, oh my gosh,

00:27:21.210 --> 00:27:27.120
<v Speaker 6>just to get like, hello world, I have to do a million little things that I shouldn't have to do,

00:27:27.480 --> 00:27:35.160
<v Speaker 6>Like create a main and get my braces right and get all my variables right and get my pound includes correct.

00:27:35.280 --> 00:27:37.360
<v Speaker 6>And now I don't have to think about any of that stuff.

00:27:37.820 --> 00:27:49.960
<v Speaker 6>And the thing that was eye-opening for me with Python was the distance between vision of what I wanted and working code just really narrowed.

00:27:49.980 --> 00:27:56.580
<v Speaker 6>And I think that as we are starting to think about tools and environments and how to bootstrap all this stuff,

00:27:56.800 --> 00:28:01.840
<v Speaker 6>We're also now taking all that stuff away because people honestly don't care.

00:28:01.960 --> 00:28:03.620
<v Speaker 6>I don't care about any of that stuff.

00:28:03.660 --> 00:28:07.540
<v Speaker 6>I just want to go from like, oh, I woke up this morning and had a cool idea

00:28:07.620 --> 00:28:09.600
<v Speaker 6>and I just wanted to get it working.

00:28:10.420 --> 00:28:12.660
<v Michael Kennedy>Or you wanted to share it so you could just share the script

00:28:12.780 --> 00:28:15.880
<v Michael Kennedy>and you don't have to say, here's your steps that you get started with.

00:28:16.899 --> 00:28:17.700
<v Michael Kennedy>Exactly, exactly.

00:28:19.340 --> 00:28:22.220
<v Reuven Lerner>I want to thank the two of you for â€“ I'm sorry, go ahead.

00:28:22.940 --> 00:28:29.080
<v Reuven Lerner>I'm just going to say, like, for years teaching Python that how do we get it installed?

00:28:29.980 --> 00:28:32.940
<v Reuven Lerner>At first, it surprised me how difficult it was for people.

00:28:33.100 --> 00:28:34.620
<v Reuven Lerner>Because like, oh, come on, we just got Python.

00:28:34.800 --> 00:28:35.740
<v Reuven Lerner>Like, what's so hard about this?

00:28:35.920 --> 00:28:40.400
<v Reuven Lerner>But it turns out it's a really big barrier to entry for newcomers.

00:28:40.880 --> 00:28:44.740
<v Reuven Lerner>And I'm very happy that Jupyter Lite now has solved its problems with input.

00:28:45.140 --> 00:28:46.380
<v Reuven Lerner>And it's like huge.

00:28:47.020 --> 00:28:53.080
<v Reuven Lerner>But until now, I hadn't really thought about starting with uv because it's cross-platform.

00:28:53.470 --> 00:29:02.180
<v Reuven Lerner>And if I say to people in the first 10 minutes of class, install uv for your platform, and then say uv in it, your project, bam, you're done.

00:29:02.330 --> 00:29:03.220
<v Reuven Lerner>It just works.

00:29:03.490 --> 00:29:04.280
<v Reuven Lerner>And then it works cross-platform.

00:29:04.660 --> 00:29:07.180
<v Reuven Lerner>This is mind-blowing, and I'm going to try this at some point.

00:29:07.290 --> 00:29:07.640
<v Reuven Lerner>Thank you.

00:29:08.900 --> 00:29:16.460
<v Gregory Kapfhammer>I can comment on the mind-blowing part because now when I teach undergraduate students, we start with uv in the very first class, and it is awesome.

00:29:17.000 --> 00:29:31.960
<v Gregory Kapfhammer>There were things that would take students, even very strong students who've had lots of experience, it would still take them a week to set everything up on their new laptop and get everything ready and to understand all the key concepts and know where something is in their path.

00:29:32.140 --> 00:29:36.460
<v Gregory Kapfhammer>that now we just say install uv for your operating system

00:29:37.140 --> 00:29:39.500
<v Gregory Kapfhammer>and get running on your computer

00:29:39.920 --> 00:29:41.180
<v Gregory Kapfhammer>and then, hey, you're ready to go.

00:29:41.590 --> 00:29:43.700
<v Gregory Kapfhammer>And I don't have to teach them about Docker containers

00:29:43.950 --> 00:29:45.960
<v Gregory Kapfhammer>and I don't have to tell them how to install Python

00:29:46.090 --> 00:29:47.260
<v Gregory Kapfhammer>with some packet manager.

00:29:47.900 --> 00:29:49.660
<v Gregory Kapfhammer>All of those things just work.

00:29:50.120 --> 00:29:51.900
<v Gregory Kapfhammer>And I think from a learning perspective,

00:29:52.210 --> 00:29:55.120
<v Gregory Kapfhammer>whether you're in a class or whether you're in a company

00:29:55.450 --> 00:29:56.600
<v Gregory Kapfhammer>or whether you're teaching yourself,

00:29:57.420 --> 00:29:59.060
<v Gregory Kapfhammer>UV is absolutely awesome.

00:30:00.780 --> 00:30:05.600
<v Jodie Burchell>I'm actually wondering whether I am the one who is newest to Python here.

00:30:05.880 --> 00:30:08.820
<v Jodie Burchell>I taught myself Python in 2011.

00:30:09.740 --> 00:30:12.300
<v Jodie Burchell>So I was like Python 2.7 stage.

00:30:14.040 --> 00:30:15.380
<v Jodie Burchell>But it was my first programming language.

00:30:15.600 --> 00:30:19.080
<v Jodie Burchell>I was just procrastinating during my PhD and I was like, I should learn to program.

00:30:19.860 --> 00:30:21.820
<v Jodie Burchell>So I just taught myself Python.

00:30:22.480 --> 00:30:26.260
<v Jodie Burchell>And I can tell you, you do not come from an engineering background.

00:30:26.720 --> 00:30:27.840
<v Jodie Burchell>And you're like, what is Python?

00:30:28.280 --> 00:30:29.340
<v Jodie Burchell>What is Python doing?

00:30:29.740 --> 00:30:33.320
<v Jodie Burchell>Why am I typing Python to execute this hello world?

00:30:33.380 --> 00:30:39.840
<v Jodie Burchell>And if you're kind of curious, you get down a rabbit hole before you even get to the point where you're just focusing on learning the basics.

00:30:40.900 --> 00:30:54.780
<v Jodie Burchell>And so it's exactly, I was going to say with Reuven, like whether you thought about it for teaching, because we're now debating for humble data, which is a beginner's data science community that I'm part of, whether we switch to uv.

00:30:54.860 --> 00:31:01.800
<v Jodie Burchell>this was Chuck's idea because it does abstract away all these details. The debate I have is,

00:31:02.040 --> 00:31:06.400
<v Jodie Burchell>is it too magic? This is kind of the problem because I also remember learning about things

00:31:06.520 --> 00:31:10.260
<v Jodie Burchell>like virtual environments because again, this was my first programming language and being like,

00:31:10.620 --> 00:31:15.980
<v Jodie Burchell>oh, it's a very good idea. This is best practices. And it's also a debate we have in PyCharm, right?

00:31:16.280 --> 00:31:24.340
<v Jodie Burchell>Like how much do you magic away the fundamentals versus making people think a little bit, but

00:31:24.240 --> 00:31:24.980
<v Jodie Burchell>I'm not sure.

00:31:25.600 --> 00:31:28.540
<v Michael Kennedy>Would you even let somebody run without a virtual environment?

00:31:28.740 --> 00:31:31.020
<v Michael Kennedy>That's a stance you could take.

00:31:31.220 --> 00:31:36.060
<v Jodie Burchell>I used to when I first learned Python because it was too complicated.

00:31:36.520 --> 00:31:38.260
<v Jodie Burchell>But then I learned better.

00:31:38.940 --> 00:31:39.460
<v Jodie Burchell>But yes.

00:31:40.160 --> 00:31:52.480
<v Speaker 3>I think the consideration here is like hiding the magic isn't like hiding the details and having all this magic just work is great as long as it works.

00:31:53.320 --> 00:32:01.360
<v Speaker 3>And the question is, how is it going to break down and how are people going to know how to deal when it breaks down if you hide all the magic?

00:32:02.160 --> 00:32:16.380
<v Speaker 3>And I think virtual ends were, or let's say before we had virtual ends, installing packages was very much in the, you had to know all the details because it was very likely going to break down in some way right before we had virtual ends.

00:32:16.940 --> 00:32:22.440
<v Speaker 3>Because you would end up with weird conflicts or multiple copies of a package installed in different parts of the system.

00:32:23.420 --> 00:32:28.180
<v Speaker 3>when we got virtual ends, we, we sort of didn't have to worry about that anymore

00:32:28.360 --> 00:32:32.440
<v Speaker 3>because we were trained in that you can just blow away the virtual one and it just works.

00:32:33.260 --> 00:32:36.820
<v Speaker 3>And with uv, we're back into, this looks like a single installation.

00:32:37.180 --> 00:32:42.320
<v Speaker 3>We don't know what's going to go on, but we've learned we as a community and also the people

00:32:42.520 --> 00:32:48.460
<v Speaker 3>working on, on uv, we have learned from those earlier mistakes or not, maybe not mistakes,

00:32:48.560 --> 00:32:55.320
<v Speaker 3>but consequences of the design and they have created something that is that appears to be

00:32:55.520 --> 00:33:01.480
<v Speaker 3>very stable where it's unlikely the magic will break and when the magic does break it's obvious

00:33:01.760 --> 00:33:08.520
<v Speaker 3>what the problem is or or it automatically fixes itself so like it's not reusing uh broken uh

00:33:08.840 --> 00:33:15.400
<v Speaker 3>installations and that kind of thing so the risk now as it turns out i think as is proven by the

00:33:15.360 --> 00:33:22.940
<v Speaker 3>community adopting uv so fast and so willingly, I think it's acceptable. I think it's, yeah,

00:33:22.950 --> 00:33:28.680
<v Speaker 3>I think it's proven itself. It's clear that this is, it's worth the potential of discovering

00:33:29.740 --> 00:33:38.140
<v Speaker 3>weird edge cases later, both because it's probably low likelihood, but also the people behind uv,

00:33:38.440 --> 00:33:43.019
<v Speaker 3>Astral, have proven that they would jump in and fix those issues, right? They would do anything

00:33:43.060 --> 00:33:47.140
<v Speaker 3>they need to keep uv workable the same way.

00:33:47.690 --> 00:33:51.260
<v Speaker 3>And they have a focus that Python as a whole cannot have

00:33:51.560 --> 00:33:53.720
<v Speaker 3>because they cater to fewer use cases

00:33:54.020 --> 00:33:55.900
<v Michael Kennedy>than Python as a whole needs to.

00:33:56.600 --> 00:33:56.720
<v Michael Kennedy>Yeah.

00:33:56.910 --> 00:34:00.380
<v Michael Kennedy>And on the audience, Galano says,

00:34:00.580 --> 00:34:02.580
<v Michael Kennedy>as an enterprise tech director and Python coder,

00:34:02.580 --> 00:34:04.040
<v Michael Kennedy>I believe we should hide the magic

00:34:04.170 --> 00:34:06.980
<v Michael Kennedy>which empowers the regular employee to do simple things

00:34:06.990 --> 00:34:08.000
<v Michael Kennedy>that make their job easier.

00:34:08.340 --> 00:34:08.419
<v Michael Kennedy>Yeah.

00:34:09.460 --> 00:34:09.679
<v Michael Kennedy>Yeah.

00:34:10.940 --> 00:34:11.780
<v Michael Kennedy>I'll go ahead, Barry.

00:34:12.600 --> 00:34:21.040
<v Speaker 6>No, I think this notion of abstractions, right, has always been there in computer science.

00:34:22.250 --> 00:34:33.500
<v Speaker 6>And, you know, we've used tools or languages or systems where we've tried to bring that abstraction layer up so that we don't have to think about all these details, as I mentioned before.

00:34:34.840 --> 00:34:38.100
<v Speaker 6>The question is, that's always the happy path.

00:34:38.280 --> 00:34:47.000
<v Speaker 6>And when I'm trying to teach somebody something like, here's how to use this library or here's how to use this tool, I try to be very opinionated to keep people on that happy path.

00:34:47.120 --> 00:34:50.520
<v Speaker 6>Like, assume everything's going to work just right.

00:34:51.220 --> 00:34:55.520
<v Speaker 6>Here's how you just make you go down that path to get the thing done that you want.

00:34:55.520 --> 00:35:04.980
<v Speaker 6>The question really is, when things go wrong, how narrow is that abstraction?

00:35:05.300 --> 00:35:07.680
<v Speaker 6>And are you able, and even when you're just curious,

00:35:08.200 --> 00:35:10.640
<v Speaker 6>like what's really going on underneath the hood?

00:35:11.100 --> 00:35:12.640
<v Speaker 6>Of course, that's not a really good analogy today

00:35:12.820 --> 00:35:15.480
<v Speaker 6>because cars are basically computers on wheels

00:35:15.700 --> 00:35:17.480
<v Speaker 6>that you can't really understand how they work.

00:35:19.760 --> 00:35:20.860
<v Speaker 3>But back in your day.

00:35:21.560 --> 00:35:25.060
<v Speaker 6>But back in my day, we were changing spark plugs, you know.

00:35:26.220 --> 00:35:27.740
<v Speaker 6>And crank that window down.

00:35:28.660 --> 00:35:29.140
<v Speaker 6>Exactly.

00:35:30.600 --> 00:35:33.900
<v Speaker 6>So I think we always have to leave that room

00:35:33.920 --> 00:35:36.840
<v Speaker 6>for the curious and the bad path

00:35:37.380 --> 00:35:38.900
<v Speaker 6>where when things go wrong

00:35:39.140 --> 00:35:40.120
<v Speaker 6>or when you're just like,

00:35:40.420 --> 00:35:41.980
<v Speaker 6>you know what, I understand how this works,

00:35:42.010 --> 00:35:45.380
<v Speaker 6>but I'm kind of curious about what's really going on.

00:35:45.580 --> 00:35:47.780
<v Speaker 6>How easy is it for me to dive in

00:35:47.960 --> 00:35:50.220
<v Speaker 6>and get a little bit more of that background,

00:35:50.610 --> 00:35:53.260
<v Speaker 6>you know, a little bit more of that understanding

00:35:53.440 --> 00:35:54.160
<v Speaker 6>of what's going on.

00:35:55.140 --> 00:35:59.200
<v Speaker 5>Yeah, I want the magic to decompose, right?

00:35:59.400 --> 00:36:01.339
<v Speaker 5>Like you should be able to explain the magic path

00:36:01.360 --> 00:36:03.940
<v Speaker 5>via more decomposed steps using the tool

00:36:04.090 --> 00:36:05.700
<v Speaker 5>all the way down to what the tools actually do

00:36:05.940 --> 00:36:06.400
<v Speaker 5>behind the scenes.

00:36:08.860 --> 00:36:11.640
<v Speaker 5>Just to admit, the reason I brought this up

00:36:11.640 --> 00:36:12.980
<v Speaker 5>and I've been thinking about this a lot

00:36:13.120 --> 00:36:15.120
<v Speaker 5>is I'm thinking of trying to get the Python launcher

00:36:15.840 --> 00:36:17.240
<v Speaker 5>to do a bit more.

00:36:17.580 --> 00:36:20.240
<v Speaker 5>Because one interesting thing we haven't really brought up here

00:36:20.250 --> 00:36:21.800
<v Speaker 5>is we're all seeing uv, uv, uv.

00:36:22.620 --> 00:36:23.400
<v Speaker 5>UV is a company.

00:36:24.440 --> 00:36:25.480
<v Speaker 5>There's always the risk they might disappear.

00:36:26.280 --> 00:36:28.600
<v Speaker 5>And we haven't de-risked ourselves from that.

00:36:28.740 --> 00:36:29.480
<v Speaker 5>Now, we do have Hatch.

00:36:29.490 --> 00:36:30.180
<v Speaker 5>We do have PDM.

00:36:31.200 --> 00:36:34.120
<v Speaker 5>But as I said, there's kind of a baseline I think they all share

00:36:34.170 --> 00:36:37.460
<v Speaker 5>that I think they would probably be okay if the Python launcher just did

00:36:37.550 --> 00:36:38.940
<v Speaker 5>because that's based on standards, right?

00:36:39.060 --> 00:36:40.960
<v Speaker 5>Because that's the other thing that there's been a lot of work

00:36:40.970 --> 00:36:42.320
<v Speaker 5>that has led to this step, right?

00:36:42.480 --> 00:36:44.860
<v Speaker 5>Like we've gotten way more packaging standards.

00:36:45.140 --> 00:36:47.820
<v Speaker 5>We've got PEP 723 like we mentioned.

00:36:48.380 --> 00:36:50.720
<v Speaker 5>There's a lot of work that's come up to lead to this point

00:36:51.000 --> 00:36:54.780
<v Speaker 5>that all these tools can lean on to have them all have an equivalent outcome

00:36:55.060 --> 00:36:57.320
<v Speaker 5>because it's expected as how they should be.

00:36:58.519 --> 00:37:01.160
<v Speaker 5>And so I think it's something we need to consider

00:37:01.180 --> 00:37:03.160
<v Speaker 5>of how do we make sure,

00:37:03.660 --> 00:37:04.160
<v Speaker 5>like, by the way,

00:37:04.840 --> 00:37:05.880
<v Speaker 5>I know the people,

00:37:06.080 --> 00:37:06.360
<v Speaker 5>they're great.

00:37:06.380 --> 00:37:07.780
<v Speaker 5>I'm not trying to spare them

00:37:07.960 --> 00:37:08.800
<v Speaker 5>or think they're going to go away,

00:37:09.000 --> 00:37:09.800
<v Speaker 5>but it is something

00:37:09.860 --> 00:37:10.520
<v Speaker 5>we have to consider.

00:37:11.340 --> 00:37:12.700
<v Speaker 5>And I will also say, Jody,

00:37:14.120 --> 00:37:15.460
<v Speaker 5>I do think about this for teaching

00:37:15.760 --> 00:37:17.160
<v Speaker 5>because I'm a dad now

00:37:17.820 --> 00:37:19.320
<v Gregory Kapfhammer>and I don't want my kid coming home

00:37:20.120 --> 00:37:21.060
<v Speaker 5>when they get old enough

00:37:21.160 --> 00:37:22.040
<v Speaker 5>to learn Python and go,

00:37:22.160 --> 00:37:22.660
<v Speaker 5>hey, dad,

00:37:22.820 --> 00:37:24.020
<v Speaker 5>why is getting Python code

00:37:24.140 --> 00:37:24.920
<v Speaker 5>running so hard?

00:37:25.280 --> 00:37:26.340
<v Speaker 5>So I want to make sure

00:37:26.520 --> 00:37:27.380
<v Speaker 5>that that never happens.

00:37:28.300 --> 00:37:29.660
<v Jodie Burchell>So it is for me.

00:37:29.880 --> 00:37:30.620
<v Jodie Burchell>From the start.

00:37:31.000 --> 00:37:42.940
<v Michael Kennedy>Yeah. I realized something for the 2026 year interview, I have to bring a sign that says time for next topic because we got a bunch of topics and we're running low on time. So Thomas, let's jump over to yours.

00:37:43.680 --> 00:37:50.560
<v Speaker 3>Oh, and I have two topics as well. So I'm only going to have to pick my favorite child, right? That's terrible.

00:37:52.620 --> 00:37:59.480
<v Speaker 3>Yeah. So my second favorite child is Lazy Imports, which is a relatively new development. So we'll probably not get to that.

00:38:00.090 --> 00:38:00.220
<v Speaker 3>And just accepted.

00:38:00.580 --> 00:38:03.220
<v Speaker 3>And yes, it's been accepted and it's going to be awesome.

00:38:03.960 --> 00:38:07.840
<v Speaker 3>So I'll just give that a shout out and then move to my favorite child, which is free-threaded Python.

00:38:09.540 --> 00:38:14.280
<v Speaker 3>For those who were not aware, the global interpreter lock is going away.

00:38:14.770 --> 00:38:16.840
<v Speaker 3>I am stating it as a fact.

00:38:17.020 --> 00:38:22.600
<v Speaker 3>It's not actually a fact yet, but that's because the steering council hasn't realized the fact yet.

00:38:24.120 --> 00:38:25.280
<v Speaker 3>It is trending towards.

00:38:26.160 --> 00:38:26.280
<v Speaker 3>Yeah.

00:38:26.660 --> 00:38:35.100
<v Speaker 3>Well, so I was originally on the steering council that accepted the proposal to add free threading as a, as an experimental feature.

00:38:35.250 --> 00:38:41.960
<v Speaker 3>We had this idea of adding it as experimental and then making it supported, but not the default and then making it the default.

00:38:42.720 --> 00:38:45.260
<v Speaker 3>And it was all a little vague and, and up in the air.

00:38:46.360 --> 00:38:51.900
<v Speaker 3>And then I didn't get reelected for the steering council last year, which I was not sad about at all.

00:38:52.100 --> 00:38:55.040
<v Speaker 3>I sort of ran on a, well, if there's nobody better, I'll do it.

00:38:55.160 --> 00:38:57.200
<v Speaker 3>but otherwise I have other things to do.

00:38:57.820 --> 00:39:01.460
<v Speaker 3>And it turns out those other things were making sure that pre for that Python

00:39:01.720 --> 00:39:03.060
<v Speaker 3>landed in a supported state.

00:39:03.160 --> 00:39:07.600
<v Speaker 3>So I lobbied the steering council quite hard as Barry might remember at the

00:39:07.760 --> 00:39:10.840
<v Speaker 3>start of the year to, to get some movement on this,

00:39:10.940 --> 00:39:12.220
<v Speaker 3>like get some decision going.

00:39:12.940 --> 00:39:15.620
<v Speaker 3>So for Python 3.14, it is officially supported.

00:39:16.100 --> 00:39:17.320
<v Speaker 3>The performance is great.

00:39:17.580 --> 00:39:21.740
<v Speaker 3>It's like between a couple of percent slower and 10% slower,

00:39:22.020 --> 00:39:24.600
<v Speaker 3>depending on the hardware and the compiler that you use.

00:39:25.180 --> 00:39:35.640
<v Speaker 3>It's basically the same speed on macOS, which is really like it's that's a combination of the ARM hardware and Clang specializing things.

00:39:35.820 --> 00:39:37.160
<v Speaker 3>But it's basically the same speed.

00:39:38.020 --> 00:39:38.240
<v Speaker 3>Wow.

00:39:39.220 --> 00:39:43.060
<v Speaker 3>And then on recent GCCs on Linux, it's like a couple of percent slower.

00:39:44.220 --> 00:40:01.860
<v Speaker 3>So the main problem is really community adoption, getting third-party packages to update their extension modules for the new APIs and the things that by necessity sort of broke, and also supporting free threading in a good way in packages.

00:40:02.510 --> 00:40:09.040
<v Speaker 3>For Python code, it turns out there's very few changes that need to be made for things to work well under free threading.

00:40:09.520 --> 00:40:21.620
<v Speaker 3>They might not be entirely thread safe, but usually, like almost always in cases where it wasn't thread safe before either, because the GIL doesn't actually affect thread safety, just the likelihood of things breaking.

00:40:22.560 --> 00:40:32.920
<v Michael Kennedy>I do think there's been a bit of a, the mindset of the Python community hasn't really been focused on creating thread safe code because the GIL is supposed to protect us.

00:40:32.990 --> 00:40:36.700
<v Michael Kennedy>But soon as it takes multiple steps, then all of a sudden it's just less likely.

00:40:36.920 --> 00:40:38.080
<v Michael Kennedy>It's not that it couldn't happen.

00:40:39.060 --> 00:40:39.900
<v Speaker 3>Yeah, that's my point, right?

00:40:40.100 --> 00:40:42.420
<v Speaker 3>It's not, the GIL never gave you threat safety.

00:40:42.550 --> 00:40:46.000
<v Speaker 3>The GIL gave CPython's internals threat safety.

00:40:46.340 --> 00:40:53.100
<v Speaker 3>It never really affected Python code, and it very rarely affected threat safety in extension modules as well.

00:40:53.230 --> 00:41:01.060
<v Speaker 3>So they already had to take care of making sure that the global interpreter law couldn't be released by something that they ended up calling indirectly.

00:41:02.440 --> 00:41:06.420
<v Speaker 3>So it's actually not that hard to port most things to support free threading.

00:41:07.640 --> 00:41:12.960
<v Speaker 3>And the benefits, we've seen some experimental work because, you know, it's still new.

00:41:13.200 --> 00:41:15.800
<v Speaker 3>There's still a lot of things that don't quite support it.

00:41:15.940 --> 00:41:19.860
<v Speaker 3>There's still places where thread contention slows things down a lot.

00:41:20.300 --> 00:41:29.560
<v Speaker 3>But we've seen a lot of examples of really promising, very parallel problems that now speed up by 10x or more.

00:41:30.360 --> 00:41:32.720
<v Speaker 3>And it's going to be really excited in the future.

00:41:32.940 --> 00:41:35.360
<v Speaker 3>And it's in 2025 that this all started.

00:41:35.700 --> 00:41:37.260
<v Speaker 3>I mean, Sam started it earlier.

00:41:37.360 --> 00:41:42.320
<v Speaker 3>But, you know, he's been working on this for years, but it landed in 2025.

00:41:42.900 --> 00:41:45.940
<v Michael Kennedy>It dropped its experimental stage in 314, basically.

00:41:46.560 --> 00:41:46.940
<v Michael Kennedy>Yes.

00:41:48.180 --> 00:41:49.320
<v Speaker 5>I totally agree.

00:41:50.760 --> 00:41:51.060
<v Speaker 5>Go ahead.

00:41:51.880 --> 00:41:57.720
<v Speaker 5>I was going to say, were we all, the three of us, on the steering council at the same time when we decided to start the experiment for free threading?

00:41:58.080 --> 00:41:59.460
<v Speaker 3>I think Barry wasn't on it.

00:42:00.120 --> 00:42:04.160
<v Speaker 6>Yeah, I missed a couple of years there, but I'm not sure.

00:42:05.580 --> 00:42:08.120
<v Speaker 6>But, you know, I totally agree.

00:42:08.120 --> 00:42:11.080
<v Speaker 6>I think free threading is one of the most transformative

00:42:12.120 --> 00:42:15.220
<v Speaker 6>developments for Python, certainly since Python 3,

00:42:15.460 --> 00:42:18.260
<v Speaker 6>but even maybe more impactful because of the size

00:42:18.270 --> 00:42:19.660
<v Speaker 6>of the community today.

00:42:22.559 --> 00:42:25.940
<v Speaker 6>Personally, you know, not necessarily speaking

00:42:26.120 --> 00:42:30.400
<v Speaker 6>as a current or potentially former steering council member,

00:42:30.540 --> 00:42:34.700
<v Speaker 6>we'll see how that shakes out, but I think it's inevitable.

00:42:35.760 --> 00:42:43.600
<v Speaker 6>I think free threading is absolutely the future of Python, and I think it's going to unlock incredible potential and performance.

00:42:45.420 --> 00:42:46.860
<v Speaker 6>I think we just have to do it right.

00:42:47.040 --> 00:42:52.240
<v Speaker 6>And so I talked to lots of teams who are building various software all over the community.

00:42:54.460 --> 00:43:03.300
<v Speaker 6>And I actually think it's more of an educational and maybe an outreach problem than it is a technological problem.

00:43:03.440 --> 00:43:08.520
<v Speaker 6>I mean, yes, there are probably APIs that are missing that will make people's lives easier.

00:43:10.020 --> 00:43:16.220
<v Speaker 6>There's probably some libraries that will make other code a little easier to write or whatever or to understand.

00:43:17.000 --> 00:43:18.180
<v Speaker 6>But like all that's solvable.

00:43:18.320 --> 00:43:27.220
<v Speaker 6>And I think really reaching out to the teams that are, you know, like Thomas said, that are building the ecosystem, that are moving the ecosystem to a free threading world.

00:43:28.100 --> 00:43:31.260
<v Speaker 6>That's where we really need to spend our effort on.

00:43:31.380 --> 00:43:32.320
<v Speaker 6>And we'll get there.

00:43:32.420 --> 00:43:33.380
<v Speaker 6>It won't be that long.

00:43:33.550 --> 00:43:37.140
<v Speaker 6>It certainly won't be as long as it took us to get to Python 3.

00:43:42.240 --> 00:43:50.360
<v Reuven Lerner>I'm sort of curious, as someone who's not super experienced with threading or basic concurrency,

00:43:50.760 --> 00:43:56.760
<v Reuven Lerner>I mean, I've used it, but I feel like now we have threads, especially with free threading,

00:43:57.300 --> 00:44:01.160
<v Reuven Lerner>and subinterpreters, and multiprocessing, and async.io.

00:44:01.920 --> 00:44:03.460
<v Reuven Lerner>and I feel like for many people

00:44:03.720 --> 00:44:05.140
<v Reuven Lerner>now it's like oh my god

00:44:05.780 --> 00:44:07.120
<v Reuven Lerner>which one am I supposed to use

00:44:07.760 --> 00:44:08.860
<v Reuven Lerner>and for someone who's

00:44:09.800 --> 00:44:11.320
<v Reuven Lerner>experienced you can sort of say well

00:44:11.600 --> 00:44:12.860
<v Reuven Lerner>this seems like a better choice but

00:44:13.620 --> 00:44:15.580
<v Reuven Lerner>are there any plans to sort of try

00:44:15.800 --> 00:44:17.860
<v Reuven Lerner>to have a taxonomy

00:44:18.020 --> 00:44:19.660
<v Reuven Lerner>of what problems are solved

00:44:19.760 --> 00:44:20.360
<v Reuven Lerner>by which of these

00:44:22.140 --> 00:44:22.540
<v Speaker 3>I think

00:44:25.260 --> 00:44:27.700
<v Speaker 3>so the premise here

00:44:27.820 --> 00:44:29.600
<v Speaker 3>is that everyone would be using

00:44:30.120 --> 00:44:32.960
<v Speaker 3>one or more of these low-level techniques that you mentioned.

00:44:33.860 --> 00:44:36.800
<v Speaker 3>And I think that's not a good way of looking at it.

00:44:37.320 --> 00:44:39.960
<v Speaker 3>AsyncIO is a library that you want to use

00:44:41.460 --> 00:44:43.560
<v Speaker 3>for the things that AsyncIO is good at.

00:44:44.480 --> 00:44:46.960
<v Speaker 3>And you can actually very nicely combine it

00:44:47.200 --> 00:44:49.620
<v Speaker 3>with multiprocessing, with subprocesses,

00:44:51.700 --> 00:44:55.520
<v Speaker 3>so that subprocesses and subinterpreters,

00:44:55.660 --> 00:44:58.080
<v Speaker 3>just to make it clear that those are two very separate things,

00:44:58.280 --> 00:45:01.460
<v Speaker 3>and multi-threading, both with and without free threading.

00:45:02.100 --> 00:45:06.660
<v Speaker 3>And it solves different problems or it gives you different abilities

00:45:06.910 --> 00:45:08.720
<v Speaker 3>within the AsyncIO framework.

00:45:08.790 --> 00:45:11.140
<v Speaker 3>And the same is true for like GUI frameworks.

00:45:12.870 --> 00:45:15.880
<v Speaker 3>I mean, GUI frameworks usually want threads for multiple reasons,

00:45:16.200 --> 00:45:18.480
<v Speaker 3>but you can use these other things as well.

00:45:18.880 --> 00:45:22.960
<v Speaker 3>I don't think it's down to teaching end users when to use

00:45:22.960 --> 00:45:24.780
<v Speaker 3>or avoid all these different things.

00:45:25.420 --> 00:45:30.360
<v Speaker 3>I think we need higher level abstractions for tasks that people want to solve.

00:45:31.110 --> 00:45:36.800
<v Speaker 3>And then those can decide on what for their particular use case is a better approach.

00:45:38.420 --> 00:45:41.000
<v Speaker 3>For instance, PyTorch has multiple.

00:45:41.340 --> 00:45:53.220
<v Speaker 3>So it's used for people who don't know to train, not just train, but it's used in AI for generating large matrices and LLMs and what have you.

00:45:54.600 --> 00:45:58.880
<v Speaker 3>Part of it is loading data and processing it.

00:46:00.100 --> 00:46:04.220
<v Speaker 3>And the basic ideas of AsyncIO are,

00:46:04.420 --> 00:46:06.280
<v Speaker 3>oh, you can do all these things in parallel

00:46:06.600 --> 00:46:08.080
<v Speaker 3>because you're not waiting on the CPU,

00:46:08.400 --> 00:46:09.400
<v Speaker 3>you're just waiting on I.O.

00:46:10.080 --> 00:46:13.280
<v Speaker 3>Turns out it is still a good idea to use threads

00:46:13.500 --> 00:46:15.020
<v Speaker 3>for massively parallel I.O.

00:46:15.160 --> 00:46:18.360
<v Speaker 3>because otherwise you end up waiting longer than you need to.

00:46:18.640 --> 00:46:22.880
<v Speaker 3>So a problem where we thought AsyncIO would be the solution

00:46:22.960 --> 00:46:24.420
<v Speaker 3>and we never needed threads

00:46:24.460 --> 00:46:28.520
<v Speaker 3>is actually much improved if we tie in threads as well.

00:46:29.220 --> 00:46:33.280
<v Speaker 3>And we've seen massive, massive improvements in data loader.

00:46:33.420 --> 00:46:38.880
<v Speaker 3>There's even an article, a published article from some people at Meta

00:46:39.400 --> 00:46:44.660
<v Speaker 3>showing how much they improve the PyTorch data loader by using multiple threads.

00:46:45.240 --> 00:46:49.240
<v Speaker 3>But at a very low level, we don't want end users to need to make that choice, right?

00:46:49.940 --> 00:46:50.060
<v Speaker 5>Yeah.

00:46:50.380 --> 00:46:50.560
<v Speaker 3>Yeah.

00:46:50.720 --> 00:46:53.280
<v Speaker 5>I mean, I concurred.futures is a good point, right?

00:46:53.340 --> 00:46:57.140
<v Speaker 5>Like all of these approaches are all supported there and it's a unified one.

00:46:57.880 --> 00:46:59.960
<v Speaker 5>So if you were to teach this, for instance, you could say use concurrent

00:47:00.080 --> 00:47:00.340
<v Speaker 5>features.

00:47:01.230 --> 00:47:01.840
<v Speaker 5>These are all there.

00:47:02.359 --> 00:47:03.940
<v Speaker 5>This is the potential trade-off.

00:47:04.030 --> 00:47:05.440
<v Speaker 5>Like basically use threads.

00:47:05.560 --> 00:47:09.000
<v Speaker 5>It's going to be the fastest unless there's like some module you have

00:47:09.060 --> 00:47:11.860
<v Speaker 5>that's not, that's screwing up because of threads and use sub interpreters.

00:47:13.040 --> 00:47:15.900
<v Speaker 5>And if for some reason sub interpreters don't work, you should move to the

00:47:16.500 --> 00:47:17.960
<v Speaker 5>processing pool, the process pool.

00:47:18.580 --> 00:47:21.920
<v Speaker 5>But I mean, basically you just kind of just like, it's not, go sort the fast

00:47:21.940 --> 00:47:23.860
<v Speaker 5>stuff and for some reason it doesn't work use the next

00:47:24.020 --> 00:47:25.420
<v Speaker 5>fastest and just kind of do it that way

00:47:25.819 --> 00:47:27.700
<v Speaker 5>after that then you start to the lower

00:47:27.920 --> 00:47:29.660
<v Speaker 5>level like okay why

00:47:29.880 --> 00:47:31.820
<v Speaker 5>do I want to use sub interpreters instead of threads

00:47:32.619 --> 00:47:33.600
<v Speaker 5>and those kind of threads

00:47:33.820 --> 00:47:35.100
<v Speaker 5>but I think that's a different

00:47:36.020 --> 00:47:37.800
<v Speaker 5>I think we're all saying a different level

00:47:37.960 --> 00:47:39.820
<v Speaker 5>of abstraction which is a term we keep

00:47:39.920 --> 00:47:40.320
<v Speaker 5>bringing up today

00:47:41.920 --> 00:47:43.420
<v Speaker 5>and so I

00:47:44.079 --> 00:47:45.820
<v Speaker 5>think it's a level that a lot of people are not

00:47:45.920 --> 00:47:47.840
<v Speaker 5>going to have to care about I think the libraries are the ones that have

00:47:47.880 --> 00:47:49.840
<v Speaker 5>to care about this and who are going to do a lot

00:47:49.840 --> 00:47:51.900
<v Michael Kennedy>of this for you. I agree I would

00:47:51.920 --> 00:47:56.020
<v Michael Kennedy>Let me throw this out on our way out the door to get to Reuven's topic.

00:47:56.490 --> 00:48:00.120
<v Michael Kennedy>I would love to see it solidify around async and await,

00:48:00.480 --> 00:48:02.060
<v Michael Kennedy>and you just await a thing.

00:48:02.360 --> 00:48:03.500
<v Michael Kennedy>Maybe put a decorator on something.

00:48:03.550 --> 00:48:06.000
<v Michael Kennedy>Say, I want this to be threaded.

00:48:06.170 --> 00:48:07.360
<v Michael Kennedy>I want this to be IO.

00:48:09.780 --> 00:48:13.040
<v Michael Kennedy>And you just use async and await and don't have to think about it.

00:48:13.110 --> 00:48:15.180
<v Michael Kennedy>But that's my dream.

00:48:15.799 --> 00:48:16.900
<v Michael Kennedy>Reuven, what's your dream?

00:48:18.619 --> 00:48:19.780
<v Reuven Lerner>Well, how long do you have?

00:48:20.940 --> 00:48:21.520
<v Michael Kennedy>What's your topic?

00:48:22.559 --> 00:48:28.220
<v Reuven Lerner>So I want to talk about the Python ecosystem and funding.

00:48:29.400 --> 00:48:34.320
<v Reuven Lerner>And when I talk to people about Python and I talk to them about how it's open source, they're like, oh, right, it's open source.

00:48:34.480 --> 00:48:35.720
<v Reuven Lerner>That means I can download it for free.

00:48:35.890 --> 00:48:39.060
<v Reuven Lerner>And from their perspective, that's sort of where it starts and ends.

00:48:39.540 --> 00:48:47.480
<v Reuven Lerner>And the notion that people work on it, the notion that needs funding, the notion that there's a Python software foundation that supports a lot of these activities,

00:48:47.630 --> 00:48:50.680
<v Reuven Lerner>the infrastructure is completely unknown to them.

00:48:51.080 --> 00:48:58.140
<v Reuven Lerner>even quite shocking for them to hear. But Python is in many ways, I think, starting to become a

00:48:58.270 --> 00:49:03.960
<v Reuven Lerner>victim of its own success, that we've been dependent on companies for a number of years

00:49:04.050 --> 00:49:11.380
<v Reuven Lerner>to support developers and development. And we've been assuming that the PSF, which gives money out

00:49:11.500 --> 00:49:16.360
<v Reuven Lerner>to lots of organizations to run conferences and workshops and so forth, can sort of keep scaling

00:49:16.360 --> 00:49:22.700
<v Reuven Lerner>up and that they will have enough funding. And we've seen a few sort of shocks that system in

00:49:22.700 --> 00:49:27.940
<v Reuven Lerner>the last year. Most recently, the PSF announced that it was no longer going to be doing for versus

00:49:28.030 --> 00:49:33.260
<v Reuven Lerner>sort of pared down about a year ago, what it would give money for. And then about five months ago,

00:49:33.360 --> 00:49:36.060
<v Reuven Lerner>six months ago, I think it was in July or August, they said, actually, we're not gonna be able to

00:49:36.080 --> 00:49:41.340
<v Reuven Lerner>fund anything for about a year now. And then there was the government grant, I think from the NSF

00:49:41.740 --> 00:49:45.760
<v Reuven Lerner>that they turned down. And I'm not disputing the reasons for that at all. It basically, it said,

00:49:45.860 --> 00:49:49.060
<v Reuven Lerner>well, we'll give you the money if you don't worry about diversity and inclusion. And given that

00:49:49.120 --> 00:49:53.720
<v Reuven Lerner>that's like a core part of what the PSF is supposed to do, they could not do that without

00:49:54.140 --> 00:49:59.420
<v Reuven Lerner>shutting the doors, which would be kind of counterproductive. And so I feel like we're

00:49:59.800 --> 00:50:06.800
<v Reuven Lerner>not yet there, but we're sort of approaching this, talking about a term like a problem crisis in

00:50:07.060 --> 00:50:12.060
<v Reuven Lerner>funding Python, that the needs of the community keep growing and growing, whether it's workshops,

00:50:12.200 --> 00:50:19.460
<v Reuven Lerner>whether it's PyPI, whether it's conferences, and companies are getting squeezed. And the number of

00:50:19.520 --> 00:50:24.900
<v Reuven Lerner>people, it always shocks me every time there are PSF elections, the incredibly small number of people

00:50:25.140 --> 00:50:31.640
<v Reuven Lerner>who vote, which means that, let's assume half the people who are members, like for the millions and

00:50:31.860 --> 00:50:37.599
<v Reuven Lerner>millions of people who program Python out there, an infinitesimally small proportion of them actually

00:50:37.600 --> 00:50:42.520
<v Reuven Lerner>join and help to fund it. So I'm not quite sure what to do with this other than express concern.

00:50:43.920 --> 00:50:47.580
<v Reuven Lerner>But I feel like we've got to figure out ways to fund Python and the PSF

00:50:47.890 --> 00:50:51.420
<v Reuven Lerner>in new ways that will allow it to grow and scale as needed.

00:50:54.480 --> 00:51:01.940
<v Speaker 3>Yeah, I couldn't agree more. I mean, obviously, the PSF is close to my heart,

00:51:02.900 --> 00:51:09.440
<v Speaker 3>because i was on the board for i think a total of six or nine years or something uh over you know

00:51:09.490 --> 00:51:17.140
<v Speaker 3>the last 25. um i was also uh for six months i was the interim general manager because uh eva left

00:51:17.280 --> 00:51:23.120
<v Speaker 3>and we hadn't hired deb yet uh while i was on the board so i i i remember signing the sponsor

00:51:23.580 --> 00:51:29.599
<v Speaker 3>contracts for the companies that came in uh wanting to sponsor python and it is like it's

00:51:29.620 --> 00:51:34.940
<v Speaker 3>ridiculous how and i can say this working for a company that is one of the biggest sponsors of the

00:51:35.040 --> 00:51:42.080
<v Speaker 3>psf and has done so for years it's ridiculous how small those sponsorships are and yet how grateful

00:51:42.320 --> 00:51:49.020
<v Speaker 3>we were that they came in because every single one has such a big impact you can do so much good with

00:51:49.120 --> 00:51:57.520
<v Speaker 3>the money that comes in uh we need more corporate sponsorships more than we need like i mean obviously

00:51:57.580 --> 00:52:01.960
<v Speaker 3>a million people giving us a couple of bucks, giving the PSF, let's be clear, I'm not on the

00:52:02.080 --> 00:52:09.320
<v Speaker 3>board anymore. Giving the PSF a couple of bucks would be fantastic. But I think the big players

00:52:10.440 --> 00:52:15.860
<v Speaker 3>in the big corporate players, where all the AI money is, for instance, having done basically

00:52:16.180 --> 00:52:24.920
<v Speaker 3>no sponsorship of the PSF is mind boggling. It is a textbook fallacy or no, a tragedy of the

00:52:24.860 --> 00:52:25.880
<v Speaker 3>commons right there, right?

00:52:26.000 --> 00:52:32.600
<v Speaker 3>They rely entirely on PyPI and PyPI is run entirely with community resources, mostly

00:52:32.760 --> 00:52:38.220
<v Speaker 3>because of very, very generous and consistent, sponsorship, basically by Fastly.

00:52:38.900 --> 00:52:46.400
<v Speaker 3>but also the other sponsors of the PSF, and yet a lot, very large players use

00:52:46.640 --> 00:52:51.520
<v Speaker 3>those resources more than anyone else and don't actually contribute.

00:52:51.640 --> 00:52:54.560
<v Speaker 3>And I, yes.

00:52:55.440 --> 00:52:55.720
<v Speaker 3>Frustrating.

00:52:56.580 --> 00:52:57.640
<v Speaker 3>I mean, oh.

00:52:59.920 --> 00:53:01.040
<v Speaker 5>It's okay, Jodi, go ahead.

00:53:01.820 --> 00:53:04.380
<v Jodie Burchell>I was going to say, Georgie Kerr,

00:53:04.880 --> 00:53:08.160
<v Jodie Burchell>she wrote this fantastic blog post saying pretty much this

00:53:08.320 --> 00:53:09.440
<v Jodie Burchell>straight after Europython.

00:53:10.400 --> 00:53:13.260
<v Jodie Burchell>So Europython this year was really big, actually,

00:53:13.700 --> 00:53:16.360
<v Jodie Burchell>and she was wandering around looking at the sponsor booths,

00:53:17.100 --> 00:53:18.500
<v Jodie Burchell>and the usual players were there,

00:53:18.880 --> 00:53:21.180
<v Jodie Burchell>but none of these AI companies were there.

00:53:21.940 --> 00:53:26.220
<v Jodie Burchell>and the relationship actually between AI, if you want to call it that,

00:53:26.460 --> 00:53:28.300
<v Jodie Burchell>let's call it ML and neural networks,

00:53:29.160 --> 00:53:33.080
<v Jodie Burchell>and some of the really big companies, and Python actually is really complex.

00:53:33.360 --> 00:53:37.120
<v Jodie Burchell>Obviously, a lot of these companies, and some of us are here,

00:53:37.580 --> 00:53:39.700
<v Jodie Burchell>employ people to work on Python.

00:53:40.820 --> 00:53:44.440
<v Jodie Burchell>Companies like Meta and Google have contributed massively to frameworks

00:53:44.840 --> 00:53:47.280
<v Jodie Burchell>like PyTorch, TensorFlow, Keras.

00:53:49.540 --> 00:53:53.280
<v Jodie Burchell>So it's not as simple a picture as saying cough up money all the time.

00:53:53.420 --> 00:53:55.300
<v Jodie Burchell>Like there's a more complex picture here,

00:53:55.480 --> 00:53:59.180
<v Jodie Burchell>but definitely there are some notable absences.

00:54:00.220 --> 00:54:03.160
<v Jodie Burchell>And we talked about the volume of money going through.

00:54:05.320 --> 00:54:06.700
<v Jodie Burchell>I totally agree with the sentiment.

00:54:06.800 --> 00:54:11.840
<v Jodie Burchell>Like when the shortfall came and the grants program had to shut down,

00:54:12.640 --> 00:54:16.680
<v Jodie Burchell>we were brainstorming at JetBrains like maybe we can do some sort of,

00:54:17.520 --> 00:54:21.900
<v Jodie Burchell>I don't know, donate some more money and call other companies to do it, or we can call on people

00:54:21.930 --> 00:54:26.660
<v Jodie Burchell>in the community. And I was like, I don't want to call on people in the community to do it,

00:54:27.000 --> 00:54:31.340
<v Jodie Burchell>because they're probably the same people who are also donating their time for Python. Like,

00:54:31.700 --> 00:54:37.040
<v Jodie Burchell>it's just squeezing people who give so much of themselves to this community even more.

00:54:37.680 --> 00:54:42.380
<v Jodie Burchell>And it's not sustainable. Like Reuben said, if we keep doing this, the whole community is going to

00:54:42.280 --> 00:54:47.680
<v Jodie Burchell>collapse like i'm sure we've all had our own forms of burnout from giving too much

00:54:48.940 --> 00:54:53.280
<v Speaker 5>yeah i mean i want to say i'm going to pat ourselves on the back here everyone on this

00:54:53.440 --> 00:54:59.640
<v Speaker 5>call who works at a company are all sponsors of the psf thank goodness but there's obviously a lot

00:54:59.640 --> 00:55:03.780
<v Speaker 5>of people not on this call who are not sponsors and i know personally i wished every company that

00:55:03.920 --> 00:55:11.200
<v Speaker 5>generated revenue from python usage donated to the psf like and it doesn't see i and i think part

00:55:11.220 --> 00:55:14.740
<v Speaker 5>the problem is some people think it has to be like a hundred thousand dollars or something it does not

00:55:14.770 --> 00:55:19.800
<v Speaker 5>have to be a hundred thousand dollars now if you can afford that amount please do or more there are

00:55:19.940 --> 00:55:26.360
<v Speaker 5>many ways to donate more than the maximum amount for uh getting on the website um but it's one of

00:55:26.360 --> 00:55:30.600
<v Speaker 5>these funny things where a lot of people just like oh it's not me right like even startups don't some

00:55:30.780 --> 00:55:35.480
<v Speaker 5>do to give those ones credit but others don't because like oh we're we're burning through capital

00:55:35.500 --> 00:55:40.620
<v Speaker 5>blah blah blah i was like yeah but we're not we're asking for like less than you'd pay a dev

00:55:41.340 --> 00:55:47.300
<v Speaker 5>right by a lot per year right like the amount we actually asked for to get to the highest tier is

00:55:47.420 --> 00:55:52.700
<v Speaker 5>still less than a common developer in silicon valley if we're gonna price point to a geograph

00:55:52.940 --> 00:55:58.840
<v Speaker 5>geographical location we call kind of comprehend right i'm gonna steal annette bachelder's

00:55:58.920 --> 00:56:06.940
<v Speaker 3>observation here and yeah what what the psf would be happy with is less than a medium company spends

00:56:07.200 --> 00:56:15.160
<v Speaker 5>on the tips of expensed meals every year yeah and and yeah yeah and it's a long-running problem

00:56:15.320 --> 00:56:21.280
<v Speaker 5>right like i i mean i i've been on the psf for a long time too i've not served as many years as

00:56:21.580 --> 00:56:25.020
<v Speaker 5>uh it's almost on the board but i was like executive vice president because we had to

00:56:24.860 --> 00:56:31.840
<v Speaker 5>someone with that title uh at some point um but it's it's always been a struggle right like iree

00:56:32.300 --> 00:56:36.780
<v Speaker 5>and i also want to be clear i'm totally appreciative of where we have gotten too right because for the

00:56:36.780 --> 00:56:42.160
<v Speaker 5>longest time i was just dying for paid staff on the core team and now we have three developers

00:56:42.250 --> 00:56:47.760
<v Speaker 5>in presence thank goodness still not enough to be clear i want five and i've always said that but

00:56:48.160 --> 00:56:52.520
<v Speaker 5>i'll happily take three but it's one of these things where it's a constant struggle and it it

00:56:52.540 --> 00:56:56.660
<v Speaker 5>It got a little bit better before the pandemic just because everyone was spending on conferences.

00:56:57.040 --> 00:56:59.600
<v Speaker 5>And PyCon US is a big driver for the Python Software Foundation.

00:57:00.300 --> 00:57:03.680
<v Speaker 5>And I know your Python's a driver for the, your Python Society.

00:57:04.780 --> 00:57:07.640
<v Speaker 5>But then COVID hit and conferences haven't picked back up.

00:57:07.790 --> 00:57:16.000
<v Speaker 5>And then there's a whole new cohort of companies that have come in post-pandemic that have never had that experience of going to PyCon and sponsoring PyCon.

00:57:16.070 --> 00:57:21.580
<v Speaker 5>And so they don't think about, I think, sponsoring PyCon or the PSF because that's also a big kind of in your face.

00:57:21.760 --> 00:57:22.800
<v Speaker 5>You should help sponsor this.

00:57:23.550 --> 00:57:27.020
<v Speaker 5>And I think it's led to this kind of lull where offered spending has gone down.

00:57:27.820 --> 00:57:31.480
<v Speaker 5>New entrants into the community have not had that experience and thought about it.

00:57:31.640 --> 00:57:36.380
<v Speaker 5>And it's led to this kind of dearth where, yeah, that PSF had to stop giving out grant money.

00:57:36.740 --> 00:57:37.220
<v Speaker 5>And it sucks.

00:57:37.880 --> 00:57:40.120
<v Speaker 5>And I would love to see it not be that problem.

00:57:41.280 --> 00:57:44.920
<v Reuven Lerner>I want to add one interesting data point that I discovered in preparing for today.

00:57:47.019 --> 00:57:49.740
<v Reuven Lerner>NumFocus has about twice the budget of the PSF.

00:57:50.900 --> 00:57:52.580
<v Reuven Lerner>I was shocked to discover this.

00:57:54.040 --> 00:57:57.500
<v Reuven Lerner>So basically, it is possible to get money from companies

00:57:58.020 --> 00:58:00.920
<v Reuven Lerner>to sponsor development of Python-related projects.

00:58:01.520 --> 00:58:03.580
<v Reuven Lerner>And I don't know what they're doing that we aren't.

00:58:04.680 --> 00:58:07.300
<v Reuven Lerner>And I think it's worth talking and figuring it out.

00:58:09.839 --> 00:58:15.140
<v Michael Kennedy>We need a fundraiser and marketer in residence, maybe.

00:58:15.400 --> 00:58:15.660
<v Michael Kennedy>Who knows?

00:58:17.040 --> 00:58:18.780
<v Michael Kennedy>Lauren does a great job, to be clear.

00:58:19.380 --> 00:58:19.820
<v Speaker 3>Who does that?

00:58:19.880 --> 00:58:22.040
<v Speaker 3>The PSF has Lauren, and Lauren is that.

00:58:22.040 --> 00:58:22.100
<v Speaker 3>Okay.

00:58:22.360 --> 00:58:22.640
<v Speaker 3>Yes.

00:58:22.800 --> 00:58:22.960
<v Speaker 3>Okay.

00:58:24.560 --> 00:58:25.420
<v Speaker 5>But it's still hard.

00:58:25.980 --> 00:58:27.520
<v Speaker 5>We have someone doing it full-time at the PSF,

00:58:27.560 --> 00:58:28.360
<v Speaker 5>and it's just hard to get.

00:58:28.800 --> 00:58:29.340
<v Michael Kennedy>It's, yeah.

00:58:29.500 --> 00:58:31.260
<v Speaker 5>It's to give cash up, cop up cash.

00:58:31.860 --> 00:58:33.180
<v Michael Kennedy>Yeah, and what do we get in return?

00:58:34.100 --> 00:58:35.220
<v Michael Kennedy>Well, we already get that, so.

00:58:35.680 --> 00:58:36.240
<v Michael Kennedy>Yeah, I know.

00:58:36.980 --> 00:58:37.740
<v Michael Kennedy>All right, Barry.

00:58:40.120 --> 00:58:43.760
<v Speaker 6>Yeah, I guess to just, you know,

00:58:43.960 --> 00:58:46.600
<v Speaker 6>shift gears into a different area,

00:58:46.940 --> 00:58:52.880
<v Speaker 6>something that I've been thinking a lot over this past year on the steering council. Thomas, I'm

00:58:53.000 --> 00:59:01.140
<v Speaker 6>sure, is going to be very well aware, having been instrumental in the lazy imports PEP A10.

00:59:04.680 --> 00:59:14.700
<v Speaker 6>We have to sort of rethink how we evolve Python and how we propose changes to Python and how we

00:59:14.660 --> 00:59:16.680
<v Speaker 6>discuss those changes in the community.

00:59:16.750 --> 00:59:23.500
<v Speaker 6>Because I think one of the things that I have heard over and over and over again is that

00:59:25.100 --> 00:59:32.300
<v Speaker 6>authoring PEPs is incredibly difficult and emotionally draining.

00:59:33.020 --> 00:59:34.460
<v Speaker 6>And it's a time sink.

00:59:36.780 --> 00:59:42.720
<v Speaker 6>And leading those discussions on discuss.python.org, which we typically call DPO,

00:59:43.460 --> 00:59:51.600
<v Speaker 6>is um is can be toxic at times and very difficult so one of the things that i i i realized as i was

00:59:51.760 --> 01:00:00.400
<v Speaker 6>thinking about this is that peps are 25 years old now right so um we've had this and not only just

01:00:00.580 --> 01:00:07.360
<v Speaker 6>peps are old but like we've gone through at least two if not more sort of complete revolutions in

01:00:07.300 --> 01:00:09.140
<v Speaker 6>and the way we discuss things, you know.

01:00:10.260 --> 01:00:11.980
<v Speaker 6>The community has grown incredibly.

01:00:12.860 --> 01:00:16.060
<v Speaker 6>The developer community is somewhat larger,

01:00:17.120 --> 01:00:19.740
<v Speaker 6>but just the number of people who are using Python

01:00:20.080 --> 01:00:24.540
<v Speaker 6>and who have an interest in it has grown exponentially.

01:00:24.960 --> 01:00:30.580
<v Speaker 6>So it has become really difficult to evolve the language

01:00:30.630 --> 01:00:32.440
<v Speaker 6>in the standard library and the interpreter.

01:00:33.120 --> 01:00:42.480
<v Speaker 6>And we need to sort of think about how we can make this easier for people and not lose the voice of the user.

01:00:42.900 --> 01:00:49.580
<v Speaker 6>And I mean, you know, the number of people who actually engage in topics on DPO is the tip of the iceberg.

01:00:49.770 --> 01:01:00.380
<v Speaker 6>You know, we've got millions and millions of users out there in the world who, for example, lazy imports will affect, free threading will affect and don't even know that they have a voice.

01:01:00.640 --> 01:01:04.020
<v Speaker 6>And maybe we have to basically represent that,

01:01:04.020 --> 01:01:07.740
<v Speaker 6>but we have to do it in a much more collaborative and positive way.

01:01:08.780 --> 01:01:11.040
<v Speaker 6>So that's something that I've been thinking about a lot.

01:01:11.180 --> 01:01:14.240
<v Speaker 6>And whether or not I'm on the steering council next year,

01:01:14.260 --> 01:01:17.160
<v Speaker 6>I think this is something that I'm going to spend some time on

01:01:17.500 --> 01:01:21.380
<v Speaker 6>trying to think about and talk to people about ways we can make this easier for everyone.

01:01:22.520 --> 01:01:26.100
<v Michael Kennedy>The diversity of use cases for Python in the last couple of years.

01:01:26.200 --> 01:01:26.780
<v Speaker 6>So complex.

01:01:27.440 --> 01:01:28.060
<v Michael Kennedy>Yes, exactly.

01:01:29.160 --> 01:01:31.400
<v Speaker 5>It should also be prefaced that Barry created the  PEP process.

01:01:31.680 --> 01:01:33.000
<v Speaker 5>He should have started that one.

01:01:36.180 --> 01:01:37.560
<v Speaker 3>It is that old.

01:01:38.600 --> 01:01:38.740
<v Speaker 3>Yeah.

01:01:40.000 --> 01:01:41.480
<v Speaker 5>By the way, just so everyone knows,

01:01:41.620 --> 01:01:43.620
<v Speaker 5>these are not ages jokes to be mean to Barry.

01:01:44.100 --> 01:01:44.640
<v Speaker 5>No, no.

01:01:44.840 --> 01:01:46.120
<v Speaker 5>All of us have known Barry long enough

01:01:46.160 --> 01:01:48.560
<v Speaker 5>that we know Barry's okay with us making these jokes.

01:01:48.600 --> 01:01:49.340
<v Speaker 5>To be very, very...

01:01:49.360 --> 01:01:51.560
<v Speaker 3>Also, I am almost as old as Barry,

01:01:51.780 --> 01:01:53.360
<v Speaker 3>although I don't look as old as Barry.

01:01:54.300 --> 01:01:55.800
<v Speaker 5>Yeah, we're all over the same age anyway.

01:01:57.920 --> 01:02:04.640
<v Speaker 3>Yeah, Barry and I have known each other for 25 years, and I've always made these jokes of him.

01:02:04.820 --> 01:02:10.240
<v Speaker 3>So it is different when you know each other in person, let's put it that way.

01:02:12.760 --> 01:02:20.060
<v Speaker 3>I think for the  PEP process, I think for a lot of people, it's not obvious how difficult the process is.

01:02:20.300 --> 01:02:21.760
<v Speaker 3>I mean, it wasn't even obvious to me.

01:02:23.520 --> 01:02:29.060
<v Speaker 3>I saw people avoiding writing peps multiple times and I was upset, like on the steering

01:02:29.250 --> 01:02:29.700
<v Speaker 3>council, right?

01:02:30.360 --> 01:02:34.460
<v Speaker 3>I saw people making changes where I thought this is definitely something that should have

01:02:34.460 --> 01:02:38.660
<v Speaker 3>been discussed in a  PEP and the discussion should be recorded in a  PEP and all that.

01:02:39.360 --> 01:02:44.680
<v Speaker 3>And I didn't understand why they didn't until basically until  PEP 810.

01:02:44.750 --> 01:02:52.920
<v Speaker 3>So I did  PEP 779, which was the, giving free threading,  supported status at

01:02:52.940 --> 01:02:59.220
<v Speaker 3>the start of the year. And the discussion there was, you know, sort of as expected and it's already,

01:02:59.300 --> 01:03:03.100
<v Speaker 3>was already an accepted peb. It was just the question of how does it become supported?

01:03:03.780 --> 01:03:10.860
<v Speaker 3>That one wasn't too exhausting. And then we got to Lazy Imports, which was Pablo, who is

01:03:11.760 --> 01:03:17.240
<v Speaker 3>another steering council member, as well as a bunch of other contributors, including me and two of my

01:03:17.240 --> 01:03:22.200
<v Speaker 3>co-workers and one of my former co-workers, who had all had a lot of experience with Lazy Imports,

01:03:22.280 --> 01:03:25.300
<v Speaker 3>but not necessarily as much experience with the  PEP process.

01:03:26.280 --> 01:03:30.940
<v Speaker 3>And Pablo took the front seat because he knew the  PEP process and he's done

01:03:31.040 --> 01:03:34.740
<v Speaker 3>like five peps in the last year or something, some ridiculous number.

01:03:36.420 --> 01:03:43.600
<v Speaker 3>And he shared with us the vitriol he got for like offline for the, just the

01:03:43.980 --> 01:03:46.820
<v Speaker 3>audacity of proposing something that people disagreed with or something.

01:03:47.580 --> 01:03:51.860
<v Speaker 3>And that was like, this is a technical, technical, suggestion.

01:03:52.140 --> 01:03:58.520
<v Speaker 3>This is not a code of conduct issue where I have received my fair share of vitriol around.

01:03:59.400 --> 01:04:05.920
<v Speaker 3>This is a technical discussion, and yet he gets these ridiculous accusations in his mailbox.

01:04:06.460 --> 01:04:12.360
<v Speaker 3>And for some reason, only the primary author gets it as well, which is just weird to me.

01:04:13.680 --> 01:04:15.280
<v Speaker 3>I'll point out something.

01:04:15.570 --> 01:04:18.300
<v Speaker 5>People are lazy, Thomas, is what I think you just said.

01:04:19.240 --> 01:04:28.660
<v Speaker 6>Remember, the steering council exists because Guido got the brunt of this for Pet 572, which was the walrus operator, right?

01:04:29.070 --> 01:04:34.620
<v Speaker 6>Which is just like this minor little syntactic thing that is kind of cool when you need it.

01:04:34.930 --> 01:04:48.120
<v Speaker 6>But like just the amount of anger and negative energy and vitriol that he got over that was enough for him to just say, I'm out, you know, and you guys figure it out.

01:04:48.220 --> 01:04:55.700
<v Speaker 6>And, and that's, that, that cannot be an acceptable way to, discuss the evolution of the language.

01:04:56.220 --> 01:05:03.320
<v Speaker 3>Especially since apparently now every single  PEP author of, of any contentious or semi-contentious pep.

01:05:03.700 --> 01:05:07.100
<v Speaker 3>Although I have to say  PEP 810 had such broad support.

01:05:07.260 --> 01:05:09.200
<v Speaker 3>It was hard to call it contentious.

01:05:09.360 --> 01:05:12.660
<v Speaker 3>It's just, there's a couple of very loud opinions, I guess.

01:05:13.040 --> 01:05:15.540
<v Speaker 3>And, and I'm not saying we shouldn't listen to people.

01:05:15.740 --> 01:05:21.600
<v Speaker 3>We should definitely listen to, to especially contrary opinions, but there has to be a limit.

01:05:22.210 --> 01:05:25.360
<v Speaker 3>There has to be an acceptable way of bringing things up.

01:05:25.370 --> 01:05:30.380
<v Speaker 3>There has to be an acceptable way of saying, Hey, you didn't actually read the pep.

01:05:30.730 --> 01:05:36.360
<v Speaker 3>Please go back and reconsider everything you said after you fully digested the things,

01:05:36.840 --> 01:05:38.680
<v Speaker 3>because everything's already been addressed in the pep.

01:05:38.900 --> 01:05:47.520
<v Speaker 3>It's just really hard to do this in a way that doesn't destroy the relationship with the person you're telling this, right?

01:05:48.280 --> 01:05:54.440
<v Speaker 3>It's hard to tell people, hey, I'm not going to listen to you because you've done a bad job.

01:05:55.320 --> 01:05:57.000
<v Speaker 5>You've chosen not to inform yourself.

01:05:58.040 --> 01:06:08.100
<v Speaker 6>And I think you make another really strong point, Thomas, which is that there have been changes that have been made to Python that really should have been a pep.

01:06:08.660 --> 01:06:11.940
<v Speaker 6>and they aren't because people don't want to go through,

01:06:12.080 --> 01:06:14.900
<v Speaker 6>core developers don't want to go through this gauntlet

01:06:15.160 --> 01:06:17.160
<v Speaker 6>and so they'll create a PR and then that,

01:06:17.210 --> 01:06:19.840
<v Speaker 6>but that's also not good because then, you know,

01:06:19.920 --> 01:06:24.200
<v Speaker 6>we don't have the right level of consideration

01:06:25.240 --> 01:06:27.260
<v Speaker 6>and you think about the way that, you know,

01:06:27.400 --> 01:06:29.460
<v Speaker 6>if you're in your job and you're making a change

01:06:29.600 --> 01:06:30.740
<v Speaker 6>to something in your job,

01:06:30.830 --> 01:06:34.060
<v Speaker 6>you have a very close relationship to your teammates

01:06:34.350 --> 01:06:36.359
<v Speaker 6>and so you have that kind of respect

01:06:36.380 --> 01:06:38.260
<v Speaker 6>and hopefully, right?

01:06:38.580 --> 01:06:40.400
<v Speaker 6>Like compassion and consideration.

01:06:41.060 --> 01:06:44.360
<v Speaker 6>And you can have a very productive discussion

01:06:44.620 --> 01:06:46.600
<v Speaker 6>about a thing and you may win some arguments

01:06:46.800 --> 01:06:47.840
<v Speaker 6>and you may lose some arguments,

01:06:47.930 --> 01:06:50.140
<v Speaker 6>but the team moves forward as one.

01:06:50.400 --> 01:06:53.060
<v Speaker 6>And I think we've lost a bit of that in Python.

01:06:53.460 --> 01:06:55.760
<v Michael Kennedy>So yeah, that's not great.

01:06:56.070 --> 01:06:58.160
<v Michael Kennedy>I think society in general

01:06:58.230 --> 01:07:00.000
<v Michael Kennedy>could use a little more civility and kindness,

01:07:00.180 --> 01:07:02.519
<v Michael Kennedy>especially to strangers that they haven't met

01:07:02.540 --> 01:07:06.840
<v Michael Kennedy>in forums, social media, driving, you name it.

01:07:07.380 --> 01:07:11.180
<v Michael Kennedy>Okay, but we're not going to solve that here, I'm sure.

01:07:11.460 --> 01:07:13.940
<v Michael Kennedy>So instead, let's do Gregory's topic.

01:07:14.720 --> 01:07:16.780
<v Gregory Kapfhammer>Hey, I'm going to change topics quite a bit,

01:07:16.980 --> 01:07:20.420
<v Gregory Kapfhammer>but I wanted to call 2025 the year of type checking

01:07:20.640 --> 01:07:21.900
<v Gregory Kapfhammer>and language server protocols.

01:07:22.980 --> 01:07:25.880
<v Gregory Kapfhammer>So many of us probably have used tools like mypy

01:07:26.100 --> 01:07:28.240
<v Gregory Kapfhammer>to check to see if the types line up in our code

01:07:28.780 --> 01:07:32.180
<v Gregory Kapfhammer>or whether or not we happen to be overriding functions correctly.

01:07:32.960 --> 01:07:38.720
<v Gregory Kapfhammer>And so I've used mypy for many years and loved the tool and had a great opportunity to chat with the creator of it.

01:07:39.300 --> 01:07:42.940
<v Gregory Kapfhammer>And I integrate that into my CI, and it's really been wonderful.

01:07:43.220 --> 01:07:47.260
<v Gregory Kapfhammer>And I've also been using a lot of LSPs, like, for example, PyRite or PyLands.

01:07:48.420 --> 01:07:53.360
<v Gregory Kapfhammer>But in this year, one of the things that we've seen is, number one, Pyrefly from the team at Meta.

01:07:53.940 --> 01:07:56.420
<v Gregory Kapfhammer>We've also seen ty from the team at Astral.

01:07:56.920 --> 01:08:00.740
<v Gregory Kapfhammer>And there's another one called Zubon, and Zubon is from David Halter.

01:08:01.240 --> 01:08:07.780
<v Gregory Kapfhammer>David was also the person who created JEDI, which is another system in Python that helped with a lot of LSP tasks.

01:08:08.640 --> 01:08:13.900
<v Gregory Kapfhammer>What's interesting about all three of the tools that I just mentioned is that they're implemented in Rust,

01:08:14.760 --> 01:08:22.200
<v Gregory Kapfhammer>and they have taken a lot of the opportunity to make the type checker and or the LSP significantly faster.

01:08:22.960 --> 01:08:29.160
<v Gregory Kapfhammer>So for me, this has changed how I use the LSP or the type checker and how frequently I use it.

01:08:29.700 --> 01:08:38.759
<v Gregory Kapfhammer>And in my experience, it has helped me to take things that might take tens of seconds or hundreds of seconds and cut them down often to less than a second.

01:08:39.440 --> 01:08:46.380
<v Gregory Kapfhammer>And it's really changed the way in which I'm using a lot of the tools like ty or Pyrefly or Zubon.

01:08:46.880 --> 01:08:54.560
<v Gregory Kapfhammer>So I can have some more details if I'm allowed to share, Michael, but I would say 2025 is the year of type checkers and LSPs.

01:08:54.900 --> 01:08:57.460
<v Michael Kennedy>I think given the timing, let's have people give some feedback.

01:08:57.799 --> 01:09:01.859
<v Michael Kennedy>I personally have been using Pyrefly a ton and am a big fan of it.

01:09:03.560 --> 01:09:03.680
<v Michael Kennedy>Yeah.

01:09:06.660 --> 01:09:07.200
<v Speaker 3>Yeah, I mean.

01:09:07.339 --> 01:09:11.400
<v Speaker 3>I don't know if I'm allowed to have an opinion that isn't Pyrefly is awesome.

01:09:12.640 --> 01:09:17.680
<v Speaker 3>I mean, I'm not on the Pyrefly team, but I do regularly chat with people from the Pyrefly team.

01:09:17.980 --> 01:09:19.920
<v Michael Kennedy>Tell people real quick what it is, Thomas.

01:09:20.720 --> 01:09:25.540
<v Speaker 3>So Pyrefly is meta's attempt at a Rust-based type checker.

01:09:26.720 --> 01:09:28.400
<v Speaker 3>And so it's very similar to ty.

01:09:28.859 --> 01:09:31.700
<v Speaker 3>It started basically at the same time, a little later.

01:09:32.720 --> 01:09:35.299
<v Speaker 3>Meta originally had a type checker called Pyre,

01:09:35.779 --> 01:09:37.020
<v Speaker 3>which was written in OCaml.

01:09:39.460 --> 01:09:42.020
<v Speaker 3>They basically decided to start a rewrite in Rust,

01:09:42.279 --> 01:09:44.200
<v Speaker 3>and then that really took off,

01:09:44.279 --> 01:09:47.279
<v Speaker 3>and that's where we're going now.

01:09:50.380 --> 01:09:51.680
<v Speaker 5>Yeah, I don't know what I can say,

01:09:51.819 --> 01:09:54.600
<v Speaker 5>because I'm actually on the same team as the Pylands team.

01:09:56.740 --> 01:09:58.340
<v Speaker 5>So, but no, I mean, I think it's good.

01:09:58.640 --> 01:10:00.480
<v Speaker 5>I think this is one of those interesting scenarios

01:10:01.180 --> 01:10:03.260
<v Speaker 5>where some people realize like, you know what?

01:10:03.740 --> 01:10:06.860
<v Speaker 5>We're going to pay the penalty of writing a tool

01:10:07.780 --> 01:10:09.620
<v Speaker 5>in a way that's faster, but makes us go slower

01:10:09.820 --> 01:10:11.220
<v Speaker 5>because the overall win for the community

01:10:11.440 --> 01:10:13.040
<v Speaker 5>is going to be a good win.

01:10:13.070 --> 01:10:14.680
<v Speaker 5>So it's worth that headache, right?

01:10:15.000 --> 01:10:16.440
<v Speaker 5>Not to say I don't want to scare people off

01:10:16.490 --> 01:10:17.900
<v Speaker 5>from writing Rust, but let's be honest.

01:10:17.950 --> 01:10:19.320
<v Speaker 5>It takes more work to write Rust code

01:10:19.420 --> 01:10:20.620
<v Speaker 5>than it does take to write Python code.

01:10:22.700 --> 01:10:24.580
<v Speaker 5>But some people chose to make that trade off

01:10:24.580 --> 01:10:25.800
<v Speaker 5>and we're all benefiting from it.

01:10:27.340 --> 01:10:29.360
<v Speaker 5>The one thing I will say that's kind of interesting from this

01:10:29.720 --> 01:10:31.700
<v Speaker 5>that hasn't gotten a lot of play yet

01:10:31.700 --> 01:10:32.520
<v Speaker 5>because it's still being developed,

01:10:33.420 --> 01:10:36.140
<v Speaker 5>but PyLens is actually working with the Pyrefly team

01:10:36.740 --> 01:10:39.640
<v Speaker 5>to define a type server protocol, TSP,

01:10:40.420 --> 01:10:42.020
<v Speaker 5>so that a lot of these type servers

01:10:42.220 --> 01:10:43.900
<v Speaker 5>can just kind of feed the type information

01:10:44.030 --> 01:10:45.040
<v Speaker 5>to a higher level LSP

01:10:45.280 --> 01:10:48.400
<v Speaker 5>and let that LSP handle the stuff like symbol renaming

01:10:48.510 --> 01:10:49.260
<v Speaker 5>and all that stuff, right?

01:10:49.380 --> 01:10:51.880
<v Speaker 5>Because the key thing here

01:10:52.980 --> 01:10:54.520
<v Speaker 5>and the reason there's so many

01:10:54.540 --> 01:10:58.200
<v Speaker 5>different type checkers is there are there is a spec right and everyone's trying to implement it but

01:10:58.880 --> 01:11:03.520
<v Speaker 5>there's differences like in type in terms of type inferencing and um if you actually go listen to

01:11:04.020 --> 01:11:08.600
<v Speaker 5>michael's interview from talk python to me with the powerfly team they actually did a nice little

01:11:08.800 --> 01:11:13.940
<v Speaker 5>explanation of like the difference between pyrites approach and powerfly's approach and so there's a

01:11:13.940 --> 01:11:18.960
<v Speaker 5>bit of variance but for instance i think there's some talk now of trying to like how do we make it

01:11:19.040 --> 01:11:22.480
<v Speaker 5>so everyone doesn't have to reimplement how to rename a symbol right that's kind of boring that's

01:11:22.500 --> 01:11:23.840
<v Speaker 5>where the interesting work is.

01:11:24.100 --> 01:11:26.460
<v Speaker 5>And that's not performant from a perspective of

01:11:26.980 --> 01:11:29.700
<v Speaker 5>you want instantaneously to get that squiggly red line

01:11:30.080 --> 01:11:33.880
<v Speaker 5>in whether it's VS Code or it's in PyCharm

01:11:33.920 --> 01:11:35.220
<v Speaker 5>or whatever your editor is, right?

01:11:35.340 --> 01:11:37.480
<v Speaker 5>You want to get it as fast as possible.

01:11:37.660 --> 01:11:38.340
<v Speaker 5>But the rename...

01:11:38.340 --> 01:11:38.560
<v Speaker 3>Jupyter.

01:11:39.780 --> 01:11:40.080
<v Speaker 5>Jupyter.

01:11:40.620 --> 01:11:40.720
<v Speaker 5>What?

01:11:41.900 --> 01:11:42.860
<v Speaker 5>No, not Emacs.

01:11:43.100 --> 01:11:43.340
<v Speaker 6>What's that?

01:11:43.740 --> 01:11:44.320
<v Speaker 6>No, not Emacs.

01:11:45.980 --> 01:11:47.620
<v Speaker 6>But, you know, just to...

01:11:47.960 --> 01:11:48.300
<v Speaker 6>Oh, sorry.

01:11:49.020 --> 01:11:50.240
<v Speaker 6>Just to bring things full circle,

01:11:51.240 --> 01:11:54.120
<v Speaker 6>It's that focus on user experience, right?

01:11:54.420 --> 01:11:56.500
<v Speaker 6>Which is, yes, you want that squiggly line,

01:11:56.860 --> 01:11:58.080
<v Speaker 6>but when things go wrong,

01:11:58.640 --> 01:11:59.580
<v Speaker 6>when your type checker says,

01:11:59.600 --> 01:12:00.620
<v Speaker 6>oh, you've got a problem,

01:12:01.920 --> 01:12:04.960
<v Speaker 6>how, you know, like I think about as an analogy,

01:12:06.540 --> 01:12:08.760
<v Speaker 6>how Pablo has done an amazing amount of work

01:12:10.200 --> 01:12:12.140
<v Speaker 6>on the error reporting, right?

01:12:12.220 --> 01:12:14.680
<v Speaker 6>When you get an exception and, you know,

01:12:15.020 --> 01:12:17.680
<v Speaker 6>now you have a lot more clues about

01:12:18.160 --> 01:12:20.300
<v Speaker 6>what is it that I actually have to change

01:12:20.680 --> 01:12:24.200
<v Speaker 6>to make the tool, you know, to fix the problem, right?

01:12:24.520 --> 01:12:28.140
<v Speaker 6>Like so many times years ago, you know,

01:12:28.140 --> 01:12:29.920
<v Speaker 6>when people were using mypy, for example,

01:12:30.360 --> 01:12:35.160
<v Speaker 6>and they'd have some complex failure of their type annotations

01:12:35.440 --> 01:12:38.660
<v Speaker 6>and have absolutely no idea what to do about it.

01:12:38.840 --> 01:12:42.360
<v Speaker 6>And so getting to a place where now we're not just telling people

01:12:42.760 --> 01:12:47.780
<v Speaker 6>you've done it wrong, but also here's some ideas about how to fix it.

01:12:48.560 --> 01:12:49.120
<v Speaker 6>That's the reason.

01:12:49.600 --> 01:12:51.400
<v Michael Kennedy>Rather than, I guess we're going to have a squiggly.

01:12:51.410 --> 01:12:51.520
<v Michael Kennedy>How are you telling AI?

01:12:53.680 --> 01:12:55.760
<v Michael Kennedy>I think this is a full circle here,

01:12:55.890 --> 01:12:59.060
<v Michael Kennedy>because honestly, using typing in your Python code

01:12:59.320 --> 01:13:01.740
<v Michael Kennedy>gives a lot of context to the AI when you ask for help

01:13:01.910 --> 01:13:02.960
<v Michael Kennedy>if you just give it a fragment.

01:13:05.700 --> 01:13:06.440
<v Gregory Kapfhammer>That's true.

01:13:06.740 --> 01:13:09.580
<v Gregory Kapfhammer>And also, if you can teach your AI agent

01:13:09.740 --> 01:13:12.700
<v Gregory Kapfhammer>to use the type checkers and use the LSPs,

01:13:13.100 --> 01:13:15.140
<v Gregory Kapfhammer>it will also generate better code for you.

01:13:15.720 --> 01:13:17.420
<v Gregory Kapfhammer>I think the one challenge I would add

01:13:17.640 --> 01:13:19.560
<v Gregory Kapfhammer>to what Barry said a moment ago

01:13:19.580 --> 01:13:22.460
<v Gregory Kapfhammer>is that if you're a developer and you're using, say,

01:13:22.580 --> 01:13:24.620
<v Gregory Kapfhammer>three or four type checkers at the same time,

01:13:25.160 --> 01:13:27.220
<v Gregory Kapfhammer>you also have to be careful about the fact

01:13:27.740 --> 01:13:29.960
<v Gregory Kapfhammer>that some of them won't flag an error

01:13:30.040 --> 01:13:31.560
<v Gregory Kapfhammer>that the other one will flag.

01:13:32.180 --> 01:13:34.620
<v Gregory Kapfhammer>So I've recently written Python programs

01:13:34.900 --> 01:13:37.740
<v Gregory Kapfhammer>and even built a tool with one of my students named Benedict

01:13:38.200 --> 01:13:41.240
<v Gregory Kapfhammer>that will automatically generate Python programs

01:13:41.520 --> 01:13:43.980
<v Gregory Kapfhammer>that will cause type checkers to disagree with each other.

01:13:44.400 --> 01:13:46.080
<v Gregory Kapfhammer>There are cases that,

01:13:46.900 --> 01:13:49.080
<v Gregory Kapfhammer>mypy will flag it as an error,

01:13:49.900 --> 01:13:52.920
<v Gregory Kapfhammer>but none of the other tools will take an error.

01:13:53.470 --> 01:13:57.040
<v Gregory Kapfhammer>And there are also cases where the new tools will all agree with each other,

01:13:57.170 --> 01:13:58.480
<v Gregory Kapfhammer>but disagree with mypy.

01:13:58.960 --> 01:14:01.920
<v Gregory Kapfhammer>So there is a type checker conformance test suite.

01:14:02.300 --> 01:14:03.500
<v Gregory Kapfhammer>But I think as developers,

01:14:03.870 --> 01:14:06.240
<v Gregory Kapfhammer>even though it might be the year of LSP and type checker,

01:14:06.240 --> 01:14:09.920
<v Gregory Kapfhammer>we also have to be aware of the fact that these tools are maturing

01:14:10.210 --> 01:14:12.200
<v Gregory Kapfhammer>and there's still disagreement among them.

01:14:12.570 --> 01:14:15.920
<v Gregory Kapfhammer>And also just different philosophies when it comes to how to type check

01:14:16.360 --> 01:14:17.140
<v Gregory Kapfhammer>and how to infer.

01:14:17.780 --> 01:14:19.480
<v Gregory Kapfhammer>And so we have to think about all of those things

01:14:19.560 --> 01:14:21.800
<v Gregory Kapfhammer>as these tools mature and become part of our ecosystem.

01:14:22.120 --> 01:14:23.940
<v Gregory Kapfhammer>Yeah, Greg, that last point is important.

01:14:24.340 --> 01:14:24.700
<v Michael Kennedy>Sorry, go ahead.

01:14:25.280 --> 01:14:27.780
<v Speaker 3>Out of curiosity, how did the things

01:14:28.000 --> 01:14:29.220
<v Speaker 3>where the type checkers disagree

01:14:29.920 --> 01:14:32.660
<v Speaker 3>match up with the actual runtime behavior of Python?

01:14:33.580 --> 01:14:36.560
<v Speaker 3>Was it like false positives or false negatives?

01:14:37.520 --> 01:14:38.920
<v Gregory Kapfhammer>Ah, that's a really good question.

01:14:39.100 --> 01:14:40.680
<v Gregory Kapfhammer>I'll give you more details in the show notes

01:14:40.820 --> 01:14:43.060
<v Gregory Kapfhammer>because we actually have it in a GitHub repository

01:14:43.380 --> 01:14:44.500
<v Gregory Kapfhammer>and I can share it with people.

01:14:45.120 --> 01:14:47.740
<v Gregory Kapfhammer>But I think some of it might simply be

01:14:47.760 --> 01:14:52.640
<v Gregory Kapfhammer>related to cases where mypy is more conformant to the spec,

01:14:52.690 --> 01:14:56.900
<v Gregory Kapfhammer>but the other new tools are not as conformant.

01:14:57.320 --> 01:14:59.540
<v Gregory Kapfhammer>So you can import overload from typing

01:15:00.200 --> 01:15:02.280
<v Gregory Kapfhammer>and then have a very overloaded function.

01:15:03.100 --> 01:15:05.900
<v Gregory Kapfhammer>And mypy will actually flag the fact

01:15:06.040 --> 01:15:08.380
<v Gregory Kapfhammer>that it's an overloaded function with multiple signatures,

01:15:09.130 --> 01:15:11.860
<v Gregory Kapfhammer>whereas PyRite and Pyrefly and Zubon

01:15:12.300 --> 01:15:14.720
<v Gregory Kapfhammer>will not actually flag that even though they should.

01:15:16.640 --> 01:15:22.240
<v Michael Kennedy>Yeah. Another big area is optional versus not optional. Like, are you allowed to pass a thing

01:15:22.300 --> 01:15:27.100
<v Michael Kennedy>that is an optional string when the thing accepts a string? Some stuff's like, yeah,

01:15:27.160 --> 01:15:31.080
<v Michael Kennedy>it's probably fine. Others are like, no, no, no. This is an error that you have to do a check. And

01:15:31.300 --> 01:15:35.600
<v Michael Kennedy>if you want to switch type checkers, you might end up with a thousand warnings that you didn't

01:15:35.700 --> 01:15:41.000
<v Michael Kennedy>previously had because of an intentional difference of opinion on how strict to be, I think.

01:15:41.260 --> 01:15:45.900
<v Gregory Kapfhammer>Yeah. So you have to think about false positives and false negatives when you're willing to break

01:15:45.920 --> 01:15:50.600
<v Gregory Kapfhammer>the build because of a type error. All of those things are things you have to factor in. But to go

01:15:50.780 --> 01:15:56.660
<v Gregory Kapfhammer>quickly to this connection to AI, I know it's only recently, but the Pyrefly team actually announced

01:15:57.240 --> 01:16:03.420
<v Gregory Kapfhammer>that they're making Pyrefly work directly with Pydantic AI. So there's going to be an interoperability

01:16:03.610 --> 01:16:09.120
<v Gregory Kapfhammer>between those tools so that when you're building an AI agent using Pydantic AI, you can also then

01:16:09.260 --> 01:16:14.740
<v Gregory Kapfhammer>have better guarantees when you're using Pyrefly as your type checker. It makes total sense though,

01:16:14.860 --> 01:16:17.680
<v Jodie Burchell>because then the reasoning LLM that's at the core of the agent

01:16:18.120 --> 01:16:22.580
<v Jodie Burchell>can actually have that information before it tries to execute the code.

01:16:22.820 --> 01:16:27.040
<v Jodie Burchell>And you don't get in that loop that they often get in.

01:16:28.100 --> 01:16:29.460
<v Jodie Burchell>It can correct it before it runs.

01:16:29.980 --> 01:16:31.040
<v Gregory Kapfhammer>Yeah, really good point.

01:16:31.980 --> 01:16:33.960
<v Reuven Lerner>I want to just sort of express my appreciation

01:16:34.080 --> 01:16:36.460
<v Reuven Lerner>to all the people working on this typing stuff.

01:16:37.100 --> 01:16:40.300
<v Reuven Lerner>As someone who's come from many, many years in dynamic languages,

01:16:40.860 --> 01:16:42.940
<v Reuven Lerner>and I was always like, oh, typing.

01:16:43.360 --> 01:16:45.700
<v Reuven Lerner>Those silly people, those statically type languages.

01:16:47.180 --> 01:16:51.480
<v Reuven Lerner>And I see, A, I appreciate the value.

01:16:52.120 --> 01:16:57.660
<v Reuven Lerner>B, I love seeing how easy it is for people to ease into it when they're in Python.

01:16:57.790 --> 01:16:58.840
<v Reuven Lerner>It's not all or nothing.

01:16:59.880 --> 01:17:02.820
<v Reuven Lerner>C, I love the huge number of tools.

01:17:02.950 --> 01:17:05.760
<v Reuven Lerner>The competition in this space is really exciting.

01:17:06.220 --> 01:17:08.200
<v Reuven Lerner>And D, guess what?

01:17:08.290 --> 01:17:09.440
<v Reuven Lerner>It really, really does help.

01:17:09.740 --> 01:17:15.500
<v Reuven Lerner>And I'll even add an E, which is my students who come from Java, C++, C#, and so forth, feel relief.

01:17:16.280 --> 01:17:21.380
<v Reuven Lerner>They find that without type checking, it's like doing a trapeze act without a safety net.

01:17:21.820 --> 01:17:26.700
<v Reuven Lerner>And so they're very happy to have that typing in there, typings in there.

01:17:27.140 --> 01:17:28.520
<v Reuven Lerner>So kudos to everyone.

01:17:29.180 --> 01:17:29.440
<v Michael Kennedy>Yeah.

01:17:30.340 --> 01:17:30.700
<v Michael Kennedy>All right, folks.

01:17:30.920 --> 01:17:31.500
<v Michael Kennedy>We are out of time.

01:17:31.780 --> 01:17:33.920
<v Michael Kennedy>This could literally go for hours longer.

01:17:35.620 --> 01:17:36.300
<v Michael Kennedy>It was a big year.

01:17:36.880 --> 01:17:37.720
<v Michael Kennedy>It was a big year.

01:17:37.880 --> 01:17:41.060
<v Michael Kennedy>I think we need to just have a final word.

01:17:42.840 --> 01:17:44.540
<v Michael Kennedy>I'll start and we'll just go around.

01:17:44.970 --> 01:17:49.400
<v Michael Kennedy>So my final thought here is we've talked about some things that are negatives

01:17:49.760 --> 01:17:51.820
<v Michael Kennedy>or sort of downers or whatever here and there,

01:17:52.940 --> 01:17:58.120
<v Michael Kennedy>but I still think it's an incredibly exciting time to be a developer,

01:17:58.310 --> 01:17:58.760
<v Michael Kennedy>data scientist.

01:17:59.020 --> 01:18:00.500
<v Michael Kennedy>There's so much opportunity out there.

01:18:01.080 --> 01:18:04.020
<v Michael Kennedy>There's so many things to learn and take advantage of and stay on top of.

01:18:05.900 --> 01:18:06.240
<v Michael Kennedy>Amazing.

01:18:06.420 --> 01:18:08.800
<v Michael Kennedy>Every day is slightly more amazing than the previous day.

01:18:08.870 --> 01:18:10.140
<v Michael Kennedy>So I love it.

01:18:10.960 --> 01:18:11.820
<v Michael Kennedy>Gregory, let's go to you next.

01:18:11.920 --> 01:18:12.520
<v Michael Kennedy>Let's go around the circle.

01:18:13.020 --> 01:18:16.960
<v Gregory Kapfhammer>Yeah, I wanted to give a shout out to all of the local Python conferences.

01:18:17.740 --> 01:18:21.180
<v Gregory Kapfhammer>I actually, on a regular basis, have attended the PyOhio conference.

01:18:21.980 --> 01:18:23.020
<v Gregory Kapfhammer>And it is incredible.

01:18:23.320 --> 01:18:26.400
<v Gregory Kapfhammer>The organizers do an absolutely amazing job.

01:18:27.020 --> 01:18:32.120
<v Gregory Kapfhammer>And they have it hosted on a campus, oftentimes at Ohio State or Cleveland State University.

01:18:33.080 --> 01:18:39.180
<v Gregory Kapfhammer>And incredibly, PyOhio is a free conference that anyone can attend with no registration fee.

01:18:39.800 --> 01:18:47.100
<v Gregory Kapfhammer>So Michael, on a comment that I think is really positive, wow, I'm so excited about the regional Python conferences that I've been able to attend.

01:18:51.540 --> 01:18:51.700
<v Michael Kennedy>Thomas.

01:18:53.640 --> 01:18:55.280
<v Speaker 3>Wow, I didn't expect this.

01:18:55.380 --> 01:19:06.860
<v Speaker 3>So, I think, I think I want to give a shout out to new people joining the community and also joining just core developer team as triage or it's just drive by commenters.

01:19:07.360 --> 01:19:17.140
<v Speaker 3>I know we harped a little bit about people, you know, giving strong opinions and discussions, but we, we, I always look to the far future as well as the near future.

01:19:17.340 --> 01:19:19.020
<v Speaker 3>And we always need new people.

01:19:19.110 --> 01:19:20.180
<v Speaker 3>We need new ideas.

01:19:20.290 --> 01:19:21.180
<v Speaker 3>We need new opinions.

01:19:21.480 --> 01:19:26.700
<v Speaker 3>So yeah, I'm excited that there's still people joining and signing up.

01:19:26.980 --> 01:19:34.320
<v Speaker 3>And even when it's thankless work, so I guess I want to say thank you to people doing all the thankless work.

01:19:36.360 --> 01:19:36.580
<v Speaker 3>Jodi.

01:19:37.800 --> 01:19:45.200
<v Jodie Burchell>Yeah, I want to say this is actually really only my third year or so really in the Python community.

01:19:45.460 --> 01:19:47.700
<v Jodie Burchell>So before that, I was just sort of on the fringes, right?

01:19:47.880 --> 01:19:51.600
<v Jodie Burchell>And after I started advocacy, I started going to the conferences and meeting people.

01:19:52.560 --> 01:19:59.160
<v Jodie Burchell>And I think I didn't kind of get how special the community was until I watched the Python documentary this year.

01:19:59.520 --> 01:20:06.620
<v Jodie Burchell>And I talked to Paul about this, Paul Everett afterwards, also made fun of him for his like early 2000s fashion.

01:20:07.340 --> 01:20:16.460
<v Jodie Burchell>But I think I'm a relative newcomer to this community and you've all made me feel so welcome.

01:20:16.900 --> 01:20:27.280
<v Jodie Burchell>And I guess I want to thank all the incumbents for everything you've done to make this such a special tech community for minorities and everyone, newbies.

01:20:28.260 --> 01:20:29.680
<v Jodie Burchell>Python is love.

01:20:33.160 --> 01:20:33.660
<v Speaker 5>Oh, geez.

01:20:33.750 --> 01:20:34.760
<v Speaker 5>How am I supposed to follow that?

01:20:35.880 --> 01:20:36.860
<v Speaker 5>A little tear.

01:20:41.940 --> 01:20:52.180
<v Speaker 5>Yeah, I think one of the interesting things that we're kind of looping on here is I think the language evolution has slowed down, but it's obviously not stopped, right?

01:20:52.340 --> 01:20:55.300
<v Speaker 5>Like as Thomas pointed out, there's a lot more stuff happening behind the scenes.

01:20:56.320 --> 01:21:02.180
<v Speaker 5>Lazy imports are coming, and that was a syntactic change, which apparently brings out the mean side of some people.

01:21:03.960 --> 01:21:06.840
<v Speaker 5>And we've obviously got our challenges and stuff, but things are still going.

01:21:07.020 --> 01:21:08.380
<v Speaker 5>We're still chugging along.

01:21:08.490 --> 01:21:21.700
<v Speaker 5>We're still trying to be an open, welcoming place for people like Jody and everyone else who's new coming on over and continue to be a fun place for all of us slightly graying beard people who have been here for a long time to make us want to stick around.

01:21:24.360 --> 01:21:28.420
<v Speaker 5>So, yeah, I think it's just more of the same, honestly.

01:21:28.660 --> 01:21:33.760
<v Speaker 5>It's all of us just continue to do what we can to help out to keep this community being a great place.

01:21:33.900 --> 01:21:36.740
<v Speaker 5>and it all just keeps going forward.

01:21:37.040 --> 01:21:38.400
<v Speaker 5>And I'll just end with,

01:21:38.510 --> 01:21:39.340
<v Speaker 5>if you work for a company

01:21:39.440 --> 01:21:40.540
<v Speaker 5>that's not sponsoring the PSF,

01:21:40.700 --> 01:21:41.160
<v Speaker 5>please do so.

01:21:48.460 --> 01:21:51.800
<v Reuven Lerner>So it's rare to have,

01:21:52.560 --> 01:21:53.660
<v Reuven Lerner>I mean, a programming language

01:21:53.810 --> 01:21:54.860
<v Reuven Lerner>or any sort of tool

01:21:55.900 --> 01:21:57.640
<v Reuven Lerner>where it is both really,

01:21:57.840 --> 01:21:59.400
<v Reuven Lerner>really beneficial to your career

01:22:00.300 --> 01:22:01.380
<v Reuven Lerner>and you get to hang out

01:22:01.540 --> 01:22:02.520
<v Reuven Lerner>with really special,

01:22:02.960 --> 01:22:09.200
<v Reuven Lerner>nice, interesting people. And it's easy to take all that for granted if you've been steeped in

01:22:09.200 --> 01:22:13.640
<v Reuven Lerner>the community. I went to a conference about six months ago, a non-Python conference,

01:22:14.500 --> 01:22:20.240
<v Reuven Lerner>and that was shocking to me to discover that all the speakers were from advertisers and sponsors.

01:22:21.220 --> 01:22:25.700
<v Reuven Lerner>Everything was super commercialized. People were not interested in just like hanging out and sharing

01:22:25.880 --> 01:22:30.399
<v Reuven Lerner>with each other. And it was a shock to me because I've been to basically only Python conferences

01:22:30.420 --> 01:22:35.620
<v Reuven Lerner>for so many years, I was like, oh, that's not the norm in the industry. So we've got something

01:22:35.790 --> 01:22:40.360
<v Reuven Lerner>really special going that not only is good for the people, but good for everyone's careers and

01:22:40.430 --> 01:22:45.180
<v Reuven Lerner>mutually reinforcing and helping each other. And that's really fantastic. And we should appreciate

01:22:45.420 --> 01:22:54.919
<v Speaker 6>that. Absolutely. Barry, final word. Well, Thomas stole my thunder just a little bit, but just to tie

01:22:54.940 --> 01:22:56.700
<v Speaker 6>a couple of these ideas together.

01:22:58.100 --> 01:23:01.580
<v Speaker 6>Python, and Brett said this, right?

01:23:02.240 --> 01:23:03.680
<v Speaker 6>Python is the community,

01:23:03.940 --> 01:23:05.420
<v Speaker 6>or the community is Python.

01:23:06.060 --> 01:23:10.220
<v Speaker 6>There's no company that is telling anybody

01:23:10.980 --> 01:23:12.080
<v Speaker 6>what Python should be.

01:23:12.560 --> 01:23:14.000
<v Speaker 6>Python is what we make it.

01:23:14.480 --> 01:23:18.020
<v Speaker 6>And as folks like myself get a little older

01:23:18.140 --> 01:23:25.800
<v Speaker 6>and we have younger people coming into the community,

01:23:26.060 --> 01:23:27.940
<v Speaker 6>both developers and everything else,

01:23:28.460 --> 01:23:31.500
<v Speaker 6>who are shaping Python into their vision.

01:23:32.180 --> 01:23:35.680
<v Speaker 6>I encourage you, if you've thought about becoming a core dev,

01:23:36.260 --> 01:23:37.060
<v Speaker 6>find a mentor.

01:23:37.210 --> 01:23:38.920
<v Speaker 6>There are people out there that will help you.

01:23:39.010 --> 01:23:44.320
<v Speaker 6>If you want to be involved in the community, the PSF, reach out.

01:23:44.390 --> 01:23:47.160
<v Speaker 6>There are people who will help guide you into this community.

01:23:47.180 --> 01:23:49.120
<v Speaker 6>You can be involved.

01:23:49.620 --> 01:23:58.700
<v Speaker 6>Do not let any self-imposed limitations stop you from becoming part of the Python community in the way that you want to.

01:23:59.300 --> 01:24:06.060
<v Speaker 6>And eventually run for the steering council because we need many, many, many more candidates next year.

01:24:06.860 --> 01:24:13.300
<v Speaker 3>And you don't need any qualifications either because I'm a high school dropout and I never went to college or anything.

01:24:13.920 --> 01:24:14.720
<v Speaker 3>And look at me.

01:24:15.740 --> 01:24:15.900
<v Speaker 5>Amazing.

01:24:15.980 --> 01:24:17.640
<v Speaker 5>And I have a PhD, and I will tell you,

01:24:17.700 --> 01:24:19.620
<v Speaker 5>I did not need all that to become a Python developer

01:24:19.880 --> 01:24:22.020
<v Speaker 5>because of the Python I've heard about before I got the PhD.

01:24:22.620 --> 01:24:22.820
<v Speaker 5>So--

01:24:24.360 --> 01:24:27.100
<v Gregory Kapfhammer>Well, I'm a bass player, so if I can do it, anybody can do it.

01:24:30.160 --> 01:24:31.580
<v Michael Kennedy>Thank you, everyone, for being here.

01:24:31.900 --> 01:24:33.340
<v Michael Kennedy>This awesome look back in the air,

01:24:33.440 --> 01:24:34.760
<v Michael Kennedy>and I really appreciate you all taking the time.

01:24:35.220 --> 01:24:35.880
<v Gregory Kapfhammer>Thank you, Michael.

01:24:36.040 --> 01:24:36.180
<v Gregory Kapfhammer>Thanks.

01:24:36.560 --> 01:24:36.720
<v Gregory Kapfhammer>Thanks.

01:24:36.720 --> 01:24:37.580
<v Gregory Kapfhammer>This was great fun.

01:24:38.060 --> 01:24:38.360
<v Michael Kennedy>Thanks, everybody.

01:24:38.680 --> 01:24:39.260
<v Gregory Kapfhammer>Bye, everybody.

01:24:39.280 --> 01:24:39.840
<v Gregory Kapfhammer>Good to see everybody.

01:24:40.340 --> 01:24:40.820
<v Gregory Kapfhammer>I thought it was.

