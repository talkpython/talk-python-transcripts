WEBVTT

00:00:00.760 --> 00:00:03.380
<v Speaker 1>Hey, everyone. It's so awesome to be here with you all.

00:00:03.560 --> 00:00:05.840
<v Speaker 1>Thanks for taking the time out of your day to be part of

00:00:05.980 --> 00:00:07.980
<v Speaker 1>TalkPython for this year in review,

00:00:08.420 --> 00:00:09.780
<v Speaker 1>this Python year in review.

00:00:10.620 --> 00:00:13.640
<v Speaker 1>Yeah, let's just jump right into it. Gregory.

00:00:14.930 --> 00:00:16.920
<v Speaker 1>Hi. Welcome to the show. Welcome back to the show.

00:00:17.660 --> 00:00:19.180
<v Speaker 2>Yeah. On a positive note,

00:00:19.250 --> 00:00:20.360
<v Speaker 2>the last time I recorded,

00:00:20.530 --> 00:00:23.600
<v Speaker 2>I had to record in my home in my closet,

00:00:24.290 --> 00:00:26.140
<v Speaker 2>because the power was out throughout my city.

00:00:26.920 --> 00:00:29.980
<v Speaker 2>Today, I'm actually back in my recording studio and glad to be

00:00:30.000 --> 00:00:34.760
<v Speaker 2>to chat with people. I'm an associate professor of computer and information science, and I do

00:00:35.080 --> 00:00:39.300
<v Speaker 2>research in software engineering and software testing. I've built a bunch of Python tools,

00:00:39.620 --> 00:00:43.640
<v Speaker 2>and one of the areas we're studying now is flaky test cases in Python projects.

00:00:44.420 --> 00:00:49.500
<v Speaker 2>I'm also really excited about teaching in a wide variety of areas. In fact, I use Python for

00:00:49.720 --> 00:00:55.220
<v Speaker 2>operating systems classes or theory of computation classes. And one of the things I'm excited about

00:00:55.240 --> 00:00:57.000
<v Speaker 2>is being a podcast host.

00:00:57.520 --> 00:01:00.360
<v Speaker 2>I'm also a host on the Software Engineering Radio podcast

00:01:00.860 --> 00:01:02.740
<v Speaker 2>sponsored by the IEEE Computer Society.

00:01:03.560 --> 00:01:04.940
<v Speaker 2>And I've had the cool opportunity

00:01:05.300 --> 00:01:06.700
<v Speaker 2>to interview a whole bunch of people

00:01:06.810 --> 00:01:07.780
<v Speaker 2>in the Python community.

00:01:08.300 --> 00:01:10.140
<v Speaker 1>So Michael, thanks for welcoming me to the show.

00:01:10.640 --> 00:01:11.900
<v Speaker 1>Yeah, it's awesome to have you back.

00:01:12.120 --> 00:01:14.020
<v Speaker 1>And we talked about FlakyTest last time.

00:01:14.200 --> 00:01:18.020
<v Speaker 1>I do have to say your AV setup is quite good.

00:01:18.600 --> 00:01:20.440
<v Speaker 1>I love the new mic and all that.

00:01:22.719 --> 00:01:23.600
<v Speaker 1>Thomas, welcome.

00:01:24.170 --> 00:01:24.580
<v Speaker 1>Awesome to have you.

00:01:24.660 --> 00:01:31.280
<v Speaker 3>Hi. Thanks for having me. I'm Tomas Wauters. I'm a longtime Python core developer, although

00:01:31.860 --> 00:01:39.140
<v Speaker 3>not as long as one of the other guests on this podcast. I worked at Google for 17 years. For

00:01:39.150 --> 00:01:44.720
<v Speaker 3>the last year or so, I've worked at Meta. In both cases, I work on Python itself within the company

00:01:44.900 --> 00:01:51.320
<v Speaker 3>and just deploying it internally. I've also been a board member of the PSF, although I'm not one

00:01:51.360 --> 00:01:58.580
<v Speaker 3>right now. And I've been a steering council member for five years and currently not because

00:01:58.860 --> 00:02:02.960
<v Speaker 3>of the elections are going and I don't know what the result is going to be, but I think there's like

00:02:04.780 --> 00:02:11.280
<v Speaker 3>five, six chance that I'll be on the steering council since we only have six candidates for

00:02:11.440 --> 00:02:19.160
<v Speaker 1>five positions when this episode probably airs. I don't know. Yeah. Amazing. That's quite the

00:02:19.180 --> 00:02:25.180
<v Speaker 3>contribution to the whole community. Thank you. Oh, I always forget this. I also got the, what is it,

00:02:25.760 --> 00:02:29.160
<v Speaker 3>the Distinguished Service Award from the PSF this year. I should probably mention that.

00:02:30.060 --> 00:02:33.200
<v Speaker 3>So yes, I have been recognized. No need to talk about it further.

00:02:34.460 --> 00:02:38.420
<v Speaker 1>Wonderful. Wonderful. Jodi, welcome back on the show. Awesome to catch up with you.

00:02:39.260 --> 00:02:45.020
<v Speaker 4>Yeah, thanks for having me back. So I am a data scientist and developer advocate at JetBrains

00:02:45.040 --> 00:02:51.140
<v Speaker 4>working on PyCharm. And I've been a data scientist for around 10 years. And prior to that,

00:02:51.330 --> 00:02:57.200
<v Speaker 4>I was actually a clinical psychologist. So that was my training, my PhD, but

00:02:57.860 --> 00:03:02.280
<v Speaker 4>abandoned academia for greener pastures. Let's put it that way. Noah Franz Gregory.

00:03:06.740 --> 00:03:09.080
<v Speaker 1>Brett, hello. Good to see you.

00:03:09.290 --> 00:03:14.020
<v Speaker 5>Hello. Yes. Okay, let's see here. I've been at Microsoft for 10 years.

00:03:15.260 --> 00:03:16.540
<v Speaker 5>started working on

00:03:16.920 --> 00:03:18.720
<v Speaker 5>AI R&D for Python developers.

00:03:19.840 --> 00:03:21.040
<v Speaker 5>Also keep Wazzy running

00:03:21.380 --> 00:03:22.140
<v Speaker 5>for Python here

00:03:22.800 --> 00:03:24.640
<v Speaker 5>and do a lot of internal consulting for teams.

00:03:25.700 --> 00:03:26.080
<v Speaker 5>Outside,

00:03:26.800 --> 00:03:28.820
<v Speaker 5>I am actually the shortest running

00:03:29.640 --> 00:03:30.660
<v Speaker 5>core developer on this call,

00:03:30.800 --> 00:03:32.640
<v Speaker 5>amazingly, even though I've been doing it for 22 years.

00:03:32.940 --> 00:03:34.780
<v Speaker 5>I've also only gotten the Frank Wilson award,

00:03:35.120 --> 00:03:35.760
<v Speaker 5>not the DSA.

00:03:36.720 --> 00:03:38.980
<v Speaker 5>So I feel very underaccomplished here as a core developer.

00:03:41.200 --> 00:03:43.140
<v Speaker 5>Yeah, that's me in a nutshell.

00:03:43.240 --> 00:03:44.220
<v Speaker 5>You might be the most quoted.

00:03:44.220 --> 00:03:45.760
<v Speaker 5>I'm still trying to catch Anthony Shaw.

00:03:46.660 --> 00:03:47.300
<v Speaker 5>Most quoted.

00:03:47.640 --> 00:03:49.020
<v Speaker 6>Yeah, most quoted.

00:03:49.500 --> 00:03:51.300
<v Speaker 5>I will say, actually, at work, it is in my email

00:03:51.520 --> 00:03:53.500
<v Speaker 5>footer that I'm a famous Python quotationist.

00:03:54.300 --> 00:03:56.220
<v Speaker 5>That was Anthony Shaw's suggestion, by the way.

00:03:56.480 --> 00:03:57.200
<v Speaker 5>That was not mine.

00:03:57.830 --> 00:04:00.660
<v Speaker 5>But it does link to the April Fool's joke from last year.

00:04:01.730 --> 00:04:03.680
<v Speaker 5>And I am still trying to catch Anthony Shaw, I think,

00:04:03.720 --> 00:04:04.800
<v Speaker 5>on appearances on this podcast.

00:04:05.200 --> 00:04:06.300
<v Speaker 1>Well, plus one.

00:04:07.080 --> 00:04:08.320
<v Speaker 1>Anthony Shaw shouldn't be here, honestly.

00:04:08.700 --> 00:04:09.820
<v Speaker 1>I mean, I put it out into Discord.

00:04:11.319 --> 00:04:12.540
<v Speaker 1>He could have been here.

00:04:12.660 --> 00:04:13.560
<v Speaker 1>but probably at an odd time.

00:04:17.880 --> 00:04:21.019
<v Speaker 1>You used to work on VS Code a bunch,

00:04:21.019 --> 00:04:22.320
<v Speaker 1>on the Python aspect of VS Code.

00:04:22.350 --> 00:04:24.280
<v Speaker 1>You recently changed roles, right?

00:04:25.360 --> 00:04:26.080
<v Speaker 5>Not recently.

00:04:26.240 --> 00:04:27.840
<v Speaker 5>That was, I used to be the dev manager.

00:04:27.840 --> 00:04:29.340
<v Speaker 1>By the time, years ago?

00:04:31.400 --> 00:04:32.840
<v Speaker 5>Yeah, September of 2024.

00:04:33.770 --> 00:04:34.440
<v Speaker 5>So it's been over a year.

00:04:34.820 --> 00:04:36.220
<v Speaker 1>That account was recent for me.

00:04:37.960 --> 00:04:40.740
<v Speaker 5>Yes, I used to be the dev manager for the Python experience

00:04:40.830 --> 00:04:41.320
<v Speaker 5>of VS Code.

00:04:41.860 --> 00:04:42.180
<v Speaker 1>Okay.

00:04:42.560 --> 00:04:44.200
<v Speaker 1>Very cool. That's quite a shift.

00:04:45.120 --> 00:04:46.480
<v Speaker 5>Yeah, it went back to being on IC, basically.

00:04:49.340 --> 00:04:51.080
<v Speaker 1>You're good at your TPS reports again now?

00:04:53.100 --> 00:04:55.020
<v Speaker 5>Actually, I just did do my Kinect, so I kind of did.

00:04:55.460 --> 00:05:00.040
<v Speaker 1>Awesome. Reuben, I bet you haven't filed a TPS report in at least a year.

00:05:02.260 --> 00:05:03.120
<v Speaker 7>At least, at least.

00:05:04.260 --> 00:05:09.060
<v Speaker 7>So yeah, I'm Reuben. I'm a freelance Python and Pandas trainer.

00:05:09.620 --> 00:05:13.000
<v Speaker 7>I just celebrated this past week 30 years since going freelance.

00:05:14.780 --> 00:05:16.480
<v Speaker 7>So I guess it's working out okay.

00:05:18.280 --> 00:05:20.180
<v Speaker 7>We'll know at some point if I need to get a real job.

00:05:21.120 --> 00:05:25.120
<v Speaker 7>So I teach Python Pandas both at companies and on my online platform.

00:05:25.360 --> 00:05:26.060
<v Speaker 7>I have newsletters.

00:05:26.320 --> 00:05:33.220
<v Speaker 7>I've written books, speak at conferences, and generally try to help people improve their Python and Pandas fluency and confidence.

00:05:33.500 --> 00:05:36.080
<v Speaker 7>And have a lot of fun with this community as well as with the language.

00:05:36.760 --> 00:05:37.140
<v Speaker 1>Yeah, awesome.

00:05:37.380 --> 00:05:38.120
<v Speaker 1>Oh, good to have you here.

00:05:38.720 --> 00:05:41.160
<v Speaker 1>Barry, it's great to have a musician on the show.

00:05:42.280 --> 00:05:42.580
<v Speaker 6>Thanks.

00:05:43.890 --> 00:05:45.320
<v Speaker 6>Yeah, I've got my bases over here.

00:05:45.620 --> 00:05:47.760
<v Speaker 6>So, you know, if you need to be serenaded.

00:05:48.340 --> 00:05:50.820
<v Speaker 1>Yeah, like a Xenopython may break out at any moment.

00:05:53.040 --> 00:05:53.880
<v Speaker 6>Good, good, good.

00:05:55.640 --> 00:05:57.100
<v Speaker 6>Well, thanks for having me here.

00:05:57.840 --> 00:06:01.820
<v Speaker 6>Yeah, I've been a core developer for a long time, since 1994.

00:06:04.480 --> 00:06:11.060
<v Speaker 6>And I've been, you know, in the early days, I did tons of stuff for Python.org,

00:06:12.560 --> 00:06:18.220
<v Speaker 6>worked with Guido at CNRI, and, you know, we moved everything from the mailing,

00:06:19.070 --> 00:06:24.460
<v Speaker 6>you know, the Postmaster stuff and the version control systems back in the day,

00:06:25.660 --> 00:06:27.020
<v Speaker 6>websites, all that kind of stuff.

00:06:27.130 --> 00:06:29.260
<v Speaker 6>I try to not do any of those things anymore.

00:06:30.020 --> 00:06:33.200
<v Speaker 6>There's way more competent people doing that stuff now.

00:06:35.680 --> 00:06:37.400
<v Speaker 6>I have been a release manager

00:06:39.660 --> 00:06:41.560
<v Speaker 6>I'm currently back

00:06:41.660 --> 00:06:42.720
<v Speaker 6>on the steering council

00:06:44.020 --> 00:06:45.060
<v Speaker 6>and running again

00:06:45.140 --> 00:06:47.200
<v Speaker 6>so between Thomas and I

00:06:47.200 --> 00:06:48.900
<v Speaker 6>we'll see who makes it to

00:06:49.320 --> 00:06:50.420
<v Speaker 6>six years I guess

00:06:52.700 --> 00:06:55.060
<v Speaker 6>and I'm currently working for

00:06:55.300 --> 00:06:57.000
<v Speaker 6>NVIDIA and I do

00:06:57.040 --> 00:06:58.100
<v Speaker 6>all Python stuff

00:06:59.440 --> 00:07:00.160
<v Speaker 6>some

00:07:01.540 --> 00:07:03.280
<v Speaker 6>half and half roughly of

00:07:03.300 --> 00:07:11.340
<v Speaker 6>things and external open source community work, both in packaging and in core Python.

00:07:12.490 --> 00:07:14.520
<v Speaker 6>So that's, I guess, quick.

00:07:15.200 --> 00:07:15.860
<v Speaker 1>Yeah, awesome.

00:07:16.110 --> 00:07:16.920
<v Speaker 1>I think that's about it.

00:07:17.520 --> 00:07:20.360
<v Speaker 1>Yeah, you all are living in exciting tech spaces.

00:07:20.640 --> 00:07:21.220
<v Speaker 1>That's for sure.

00:07:21.600 --> 00:07:22.040
<v Speaker 1>That's for sure.

00:07:22.650 --> 00:07:23.040
<v Speaker 1>For sure.

00:07:23.200 --> 00:07:23.280
<v Speaker 1>Yeah.

00:07:23.650 --> 00:07:26.900
<v Speaker 1>Well, great to have you all back on the show.

00:07:28.280 --> 00:07:29.320
<v Speaker 1>Let's start with our first topic.

00:07:29.480 --> 00:07:37.920
<v Speaker 1>So the idea is we've each picked at least a thing that we think stood out in 2025 in the Python space that we can focus on.

00:07:38.100 --> 00:07:41.740
<v Speaker 1>And, yeah, well, let's go with Jodi first.

00:07:42.700 --> 00:07:45.340
<v Speaker 1>I'm excited to hear what you thought was one of the bigger things.

00:07:46.520 --> 00:07:46.620
<v Speaker 4>Yeah.

00:07:46.960 --> 00:07:49.360
<v Speaker 4>So I'm going to mention AI.

00:07:49.960 --> 00:07:52.440
<v Speaker 4>Like, wow, what a, you know, big surprise.

00:07:53.340 --> 00:07:59.700
<v Speaker 4>So to kind of give context of where I'm coming from, I've been working in NLP for a long time.

00:07:59.750 --> 00:08:02.120
<v Speaker 4>I like to say I was working on LLMs before they were cool.

00:08:03.620 --> 00:08:10.240
<v Speaker 4>So sort of playing around with the very first releases from Google in like 2019, incorporating that into search.

00:08:11.280 --> 00:08:16.960
<v Speaker 4>So I've been very interested sort of seeing the unfolding of the GPT models as they've grown.

00:08:17.820 --> 00:08:32.860
<v Speaker 4>And let's say I'm slightly disgusted by the discourse around the models as they become more mainstream, more sort of the talk about people's jobs being replaced, a lot of the hysteria, a lot of the doomsday stuff.

00:08:33.080 --> 00:08:43.120
<v Speaker 4>So I've been doing talks and other content for around two and a half years now, just trying to cut through the hype a bit, being like, you know, they're just language models, they're good for language tasks.

00:08:43.260 --> 00:08:46.080
<v Speaker 4>Let's think about realistically what they're about.

00:08:46.460 --> 00:08:51.940
<v Speaker 4>And what was very interesting for me this year, I've been incorrectly predicting the bubble

00:08:52.220 --> 00:08:53.920
<v Speaker 4>bursting for about two and a half years.

00:08:54.420 --> 00:09:00.880
<v Speaker 4>So I was quite vindicated when in August GPT-5 came out and all of a sudden everyone else

00:09:01.360 --> 00:09:02.800
<v Speaker 4>started saying, maybe this is a bubble.

00:09:03.600 --> 00:09:03.740
<v Speaker 1>Yeah.

00:09:04.060 --> 00:09:08.840
<v Speaker 1>So you think that was the first big release that was kind of a letdown compared to what

00:09:08.840 --> 00:09:09.500
<v Speaker 1>the hype was?

00:09:10.180 --> 00:09:10.360
<v Speaker 4>Yeah.

00:09:10.500 --> 00:09:11.240
<v Speaker 4>And it was really interesting.

00:09:11.560 --> 00:09:15.600
<v Speaker 4>So I found this really nice Atlantic article and I didn't save it, unfortunately.

00:09:16.140 --> 00:09:22.520
<v Speaker 4>but essentially it told sort of the whole story of what was going on behind the scenes. So GPT-4

00:09:22.840 --> 00:09:29.120
<v Speaker 4>came out in March of 2023. And that was the model that came out with this Microsoft research paper

00:09:29.340 --> 00:09:33.980
<v Speaker 4>saying, you know, sparks of AGI, artificial general intelligence, blah, blah, blah. And from that

00:09:34.320 --> 00:09:43.019
<v Speaker 4>point, there was really this big expectation sort of fueled by open AI that GPT-5 was going to be

00:09:42.980 --> 00:09:49.180
<v Speaker 4>AGI model. And it turns out what was happening internally is these scaling laws that were sort of

00:09:49.520 --> 00:09:55.260
<v Speaker 4>considered, you know, this exponential growth thing that would sort of push the power of these models

00:09:55.680 --> 00:10:01.940
<v Speaker 4>perhaps towards human-like performance. They weren't laws at all. And of course, they started failing.

00:10:02.280 --> 00:10:07.180
<v Speaker 4>So the model that they'd originally pitched as GPT-4 just didn't live up to performance. They

00:10:07.340 --> 00:10:11.920
<v Speaker 4>started this post-training stuff where they were going more into like specialized reasoning models.

00:10:12.300 --> 00:10:16.100
<v Speaker 4>And what we have now are good models that are good for specific tasks.

00:10:16.900 --> 00:10:22.460
<v Speaker 4>But I don't know what happened, but eventually they had to put the GPT-5 label on something.

00:10:23.560 --> 00:10:27.920
<v Speaker 4>And yeah, let's say it didn't live up to expectations.

00:10:28.340 --> 00:10:39.920
<v Speaker 4>So I think the cracks are starting to show because the underlying expectation always was this will be improving to the point where anything's possible.

00:10:40.220 --> 00:10:42.380
<v Speaker 4>and you can't put a price on that.

00:10:43.130 --> 00:10:46.340
<v Speaker 4>But it turns out that if maybe there's a limit on what's possible,

00:10:47.300 --> 00:10:48.920
<v Speaker 4>yeah, you can put a price on it.

00:10:49.620 --> 00:10:52.580
<v Speaker 1>And a lot of the valuations are on the first part.

00:10:53.980 --> 00:10:56.180
<v Speaker 4>Yes, and it's always been a bit interesting to me

00:10:56.400 --> 00:10:57.960
<v Speaker 4>because I come from a scientific background

00:10:58.250 --> 00:11:00.260
<v Speaker 4>and you need to know how to measure stuff, right?

00:11:00.900 --> 00:11:03.160
<v Speaker 4>And I'm like, what are you trying to achieve?

00:11:03.520 --> 00:11:05.580
<v Speaker 4>Like Gregory's nodding, like please jump in.

00:11:06.060 --> 00:11:09.000
<v Speaker 4>I'm on my monologue, so please don't interrupt me.

00:11:10.980 --> 00:11:16.080
<v Speaker 4>you really need to understand what you're actually trying to get these models to do. What is AGI?

00:11:16.580 --> 00:11:24.160
<v Speaker 4>No one knows this. And what's going to be possible with this? And it's more science fiction than fact.

00:11:24.720 --> 00:11:28.980
<v Speaker 4>So this for me has been the big news this year. And I'm feeling slightly smug,

00:11:29.180 --> 00:11:32.640
<v Speaker 4>I'm going to be honest, even though my predictions were off by about a year and a half.

00:11:34.800 --> 00:11:38.900
<v Speaker 1>Yeah, maybe it's not an exponential curve. It's a titration S curve with an asymptote.

00:11:40.080 --> 00:11:40.800
<v Speaker 4>Yeah, sigmoid.

00:11:41.280 --> 00:11:41.420
<v Speaker 4>Yeah.

00:11:41.660 --> 00:11:42.460
<v Speaker 1>Yeah, yeah, yeah.

00:11:42.640 --> 00:11:46.720
<v Speaker 7>I mean, I think we have to sort of separate the technology from the business.

00:11:47.370 --> 00:11:58.520
<v Speaker 7>And the technology, even if it doesn't get any better, even if we stay with what we have today, I still think this is like one of the most amazing technologies I've ever seen.

00:11:59.120 --> 00:12:00.140
<v Speaker 7>It's not a god.

00:12:00.500 --> 00:12:01.760
<v Speaker 7>It's not a panacea.

00:12:02.400 --> 00:12:06.380
<v Speaker 7>But it's like a chainsaw that if you know how to use it, it's really effective.

00:12:07.160 --> 00:12:11.000
<v Speaker 7>But in the hands of amateurs, you can really get hurt.

00:12:11.620 --> 00:12:17.220
<v Speaker 7>And so, yes, it's great to see this sort of thing happening and improving, but who knows

00:12:17.320 --> 00:12:17.820
<v Speaker 7>where it's going to go.

00:12:17.920 --> 00:12:19.320
<v Speaker 7>And I'm a little skeptical of the AGI thing.

00:12:19.440 --> 00:12:23.880
<v Speaker 7>What I'm a little more worried about is that these companies seem to have no possible way

00:12:24.220 --> 00:12:27.300
<v Speaker 7>of ever making the money that they're promising to their investors.

00:12:28.140 --> 00:12:36.900
<v Speaker 7>And I do worry a lot that we're sort of like a year 2000 situation where, yeah, the technology

00:12:36.920 --> 00:12:47.320
<v Speaker 7>But the businesses are unsustainable. And out of the ashes of what will happen, we will get some amazing technology and even better than we had before. But there are going to be ashes.

00:12:50.460 --> 00:13:14.880
<v Speaker 4>Yeah. For me, that also makes me worry. And I don't know if anyone reads Ed Zitron here. He's a journalist kind of digging into the state of the AI industry. He does get a bit sort of, he has a bit of a reputation as a bit of a crank now. So I think he's leaned into that pretty hard. But he does take the time to also pull out numbers and point out things that don't make sense.

00:13:15.880 --> 00:13:20.500
<v Speaker 4>And he was one of the first ones to sound the whistle on this circular funding we've been seeing.

00:13:20.880 --> 00:13:39.040
<v Speaker 4>So the worry, of course, is when a lot of this becomes borrowings from banks and then that starts dragging in funding from everyday people and also the effect that this has had on particularly the US economy, like the stock market.

00:13:39.640 --> 00:13:49.320
<v Speaker 4>I think the investment in AI spending now exceeds consumer spending in the US, which is a really scary prospect.

00:13:50.100 --> 00:13:50.780
<v Speaker 1>That is crazy.

00:13:53.580 --> 00:13:56.960
<v Speaker 4>But yeah, also, as Reven said, I love LLMs.

00:13:58.160 --> 00:14:01.420
<v Speaker 4>They are the most powerful tools we've ever had for natural language processing.

00:14:02.120 --> 00:14:04.200
<v Speaker 4>It's phenomenal the problems we can solve with them now.

00:14:04.380 --> 00:14:08.500
<v Speaker 4>I didn't think this sort of stuff would be possible when I started in data science.

00:14:09.680 --> 00:14:12.140
<v Speaker 4>I still think there's a use case for agents

00:14:12.490 --> 00:14:15.100
<v Speaker 4>although I do think they've been a bit overstated

00:14:15.960 --> 00:14:17.440
<v Speaker 4>especially now that I'm building them

00:14:18.680 --> 00:14:21.280
<v Speaker 4>let's say it's not very fun building non-deterministic software

00:14:21.290 --> 00:14:22.440
<v Speaker 4>it's quite frustrating actually

00:14:24.019 --> 00:14:27.400
<v Speaker 4>but I hope we're going to see improvements in the framework

00:14:27.760 --> 00:14:30.080
<v Speaker 4>particularly I've heard good things about Pydantic AI

00:14:30.640 --> 00:14:34.220
<v Speaker 4>and yeah hopefully we can control the input outputs

00:14:34.660 --> 00:14:36.279
<v Speaker 4>and make them a bit more strict

00:14:36.300 --> 00:14:38.360
<v Speaker 4>this will fix a lot of problems.

00:14:40.080 --> 00:14:41.940
<v Speaker 1>One thing I do want to put out in this conversation,

00:14:42.020 --> 00:14:45.520
<v Speaker 1>I think is worth separating.

00:14:45.680 --> 00:14:47.100
<v Speaker 1>And Reuben, you touched on this some,

00:14:47.600 --> 00:14:51.060
<v Speaker 1>but I want to suggest to you,

00:14:51.060 --> 00:14:52.400
<v Speaker 1>I'll throw this out to you all and see what you think.

00:14:53.260 --> 00:14:56.040
<v Speaker 1>I think it's very possible that this AI bubble

00:14:56.920 --> 00:15:00.160
<v Speaker 1>crashes the economy and causes bad things economically to happen

00:15:00.260 --> 00:15:03.100
<v Speaker 1>and a bunch of companies that are like wrappers over OpenAI,

00:15:03.660 --> 00:15:05.440
<v Speaker 1>API, go away.

00:15:07.040 --> 00:15:14.000
<v Speaker 1>but I don't think things like the agentic coding tools will will vanish they might stop training

00:15:14.000 --> 00:15:20.220
<v Speaker 1>they might slow their advance because that's super expensive but I even as if you said even if we just

00:15:20.380 --> 00:15:27.680
<v Speaker 1>had Claude Sonnet 4 and the world never got something else it would be so much far farther

00:15:27.820 --> 00:15:33.380
<v Speaker 1>beyond autocomplete and the other stuff that we had before and Stack Overflow that it's I don't

00:15:33.300 --> 00:15:35.720
<v Speaker 1>think it's going to go out. The reason I'm throwing this out there is I was talking to somebody and

00:15:35.720 --> 00:15:38.580
<v Speaker 1>they were like, well, I don't think it's worth learning because I think the bubble's going to

00:15:39.120 --> 00:15:42.620
<v Speaker 1>pop. And so I don't want to learn this agent at coding because it won't be around very long.

00:15:43.660 --> 00:15:44.020
<v Speaker 1>What do y'all think?

00:15:46.920 --> 00:15:53.780
<v Speaker 5>Yeah, I think it's here to stay. I think it's just where is the limit? Where does it stop

00:15:54.040 --> 00:15:57.860
<v Speaker 5>potentially? I think that's the big open question for everybody, right? Pragmatically,

00:15:58.360 --> 00:16:03.740
<v Speaker 5>it's a tool it's useful in some scenarios and not in others and you just have to learn how to use

00:16:03.740 --> 00:16:07.360
<v Speaker 5>the tool appropriately for your use case and to get what you need out of it and sometimes that's

00:16:07.480 --> 00:16:11.200
<v Speaker 5>not using it because it's just going to take up more time than it will to be productive but other

00:16:11.360 --> 00:16:17.140
<v Speaker 5>times it's fully juices up your productivity and you can get more done it's it's give and take but

00:16:17.150 --> 00:16:21.280
<v Speaker 5>i don't think it's going to go anywhere because as you said michael there's even academic stream

00:16:21.470 --> 00:16:26.659
<v Speaker 5>research now there's open weight models as well right there's a lot of different ways to run this

00:16:26.680 --> 00:16:29.980
<v Speaker 5>whether you're at the scale of the frontier models

00:16:30.220 --> 00:16:32.000
<v Speaker 5>that are doing these huge trainings

00:16:32.560 --> 00:16:35.100
<v Speaker 5>or you're doing something local and more specialized.

00:16:35.460 --> 00:16:38.540
<v Speaker 5>So I think the general use of AI isn't going anywhere.

00:16:38.600 --> 00:16:42.920
<v Speaker 5>I think it's just a question of how far can this current trend go

00:16:43.100 --> 00:16:45.620
<v Speaker 5>and where will it, I don't want to say stop,

00:16:46.520 --> 00:16:47.540
<v Speaker 5>because that plays into the whole,

00:16:48.420 --> 00:16:49.600
<v Speaker 5>it's going to completely go away.

00:16:49.600 --> 00:16:50.280
<v Speaker 5>I don't think it ever will.

00:16:50.280 --> 00:16:51.220
<v Speaker 5>I think it's just going to be,

00:16:51.980 --> 00:16:54.320
<v Speaker 5>where are we going to start to potentially bump up against limits?

00:16:55.600 --> 00:17:00.160
<v Speaker 2>One thing that I'll say is that many of these systems are almost, to me, like a dream come true.

00:17:00.690 --> 00:17:06.860
<v Speaker 2>Now, admittedly, it's the case that the systems I'm building are maybe only tens of thousands of lines or hundreds of thousands of lines.

00:17:07.459 --> 00:17:25.059
<v Speaker 2>But I can remember thinking to myself, how cool would it be if I had a system that could automatically refactor and then add test cases and increase the code coverage and make sure all my checkers and linters pass and do that automatically and continue the process

00:17:25.140 --> 00:17:30.220
<v Speaker 2>until it achieved its goal. And I remember thinking that five to seven years ago, I would

00:17:30.340 --> 00:17:36.500
<v Speaker 2>never realize that goal in my entire lifetime. And now when I use like anthropics models through

00:17:36.600 --> 00:17:43.240
<v Speaker 2>open code or Claude code, it's incredible how much you can achieve so quickly, even for systems that

00:17:43.240 --> 00:17:48.720
<v Speaker 2>are of medium to moderate scale. So from my vantage point, it is a really exciting tool.

00:17:49.360 --> 00:17:55.040
<v Speaker 2>It's incredibly powerful. And what I have found is that the LLMs are much better when I teach them

00:17:55.060 --> 00:18:01.540
<v Speaker 2>use tools and the tools that it's using are actually really quick, fast ones that can give

00:18:01.840 --> 00:18:06.040
<v Speaker 2>rapid feedback to the LLM and tell it whether it's moving in the right direction or not.

00:18:06.560 --> 00:18:12.680
<v Speaker 1>Yeah, there's an engineering angle to this. It's not just Vibe Coding if you take the time to

00:18:13.090 --> 00:18:20.760
<v Speaker 4>learn it. There was actually a very interesting study. I don't think the study itself has been

00:18:20.720 --> 00:18:25.860
<v Speaker 4>released. I haven't found it yet, but I saw a talk on it by some guys at Stanford. So they call it

00:18:25.860 --> 00:18:32.560
<v Speaker 4>the 10K developer study. And basically what they were doing was studying real code bases, including

00:18:32.630 --> 00:18:39.120
<v Speaker 4>I think 80% of them were actually private code bases and seeing the point where the team started

00:18:39.360 --> 00:18:45.040
<v Speaker 4>adopting AI. And so their findings are really interesting and nuanced. And I think they probably

00:18:45.060 --> 00:18:50.840
<v Speaker 4>intuitively align with what a lot of us have experienced with AI. So basically, yes, there

00:18:50.840 --> 00:18:58.060
<v Speaker 4>are productivity boosts, but it produces a lot of code, but the code tends to be worse than the code

00:18:58.060 --> 00:19:04.120
<v Speaker 4>you would write and also introduces more bugs. So when you account for the time that you spend

00:19:04.260 --> 00:19:09.600
<v Speaker 4>refactoring and debugging, you're still more productive. But then it also depends on the type

00:19:09.600 --> 00:19:14.020
<v Speaker 4>of project, as Gregory was saying. So it's better for greenfield projects. It's better for smaller

00:19:14.040 --> 00:19:19.920
<v Speaker 4>code bases it's better for simpler problems and it's better for more um popular languages because

00:19:20.060 --> 00:19:25.340
<v Speaker 4>obviously there's more training data and so this was actually i like this study so much i'll actually

00:19:25.460 --> 00:19:30.560
<v Speaker 4>share it with you michael if you want to put it in the the show notes but um it shows that yeah

00:19:30.570 --> 00:19:34.480
<v Speaker 4>the picture is not that simple and all this conflicting information and conflicting experiences

00:19:34.720 --> 00:19:41.660
<v Speaker 4>people are having line up completely with this so again like i work at an ide company it's it's tools

00:19:41.680 --> 00:19:47.880
<v Speaker 4>for the job. It's not like your IDE will replace you. AI is not going to replace you. It's just

00:19:48.620 --> 00:19:53.020
<v Speaker 1>going to make you maybe more productive sometimes. Yeah. Wait, IDE, you work for me.

00:20:00.440 --> 00:20:06.220
<v Speaker 7>I mean, the other thing is a lot of people and a lot of the sort of when people talk about AI and

00:20:06.240 --> 00:20:13.560
<v Speaker 7>LLMs and so forth in context of coding, it's the LLM writing code for us. And maybe because I'm not

00:20:13.660 --> 00:20:19.540
<v Speaker 7>doing a lot of serious coding, it's more instruction, so forth. I use it as like a sparring or

00:20:19.760 --> 00:20:25.280
<v Speaker 7>brainstorming partner. So it does, you know, checking of my newsletters for language and for

00:20:25.420 --> 00:20:31.440
<v Speaker 7>tech edits and just sort of exploring ideas. And for that, maybe it's because I do everything in

00:20:31.440 --> 00:20:34.940
<v Speaker 7>the last minute and I don't have other people around or I'm lazy or cheap and don't want to pay

00:20:34.960 --> 00:20:38.660
<v Speaker 7>them, but definitely the quality of my work has improved dramatically.

00:20:38.840 --> 00:20:42.840
<v Speaker 7>The quality of my understanding has improved, even if it never wrote a line of

00:20:42.960 --> 00:20:46.820
<v Speaker 7>code for me. Just getting that feedback on a regular automatic basis is

00:20:46.900 --> 00:20:50.860
<v Speaker 1>really helpful. Yeah, I totally agree with you. All right. We don't

00:20:50.900 --> 00:20:54.620
<v Speaker 1>want to spend too much time on this topic, even though I believe

00:20:55.360 --> 00:20:58.860
<v Speaker 1>Jody has put her finger on what might be the biggest tidal

00:20:58.980 --> 00:21:02.740
<v Speaker 1>wave of 2025, but still. Quick parting thoughts. Anyone else?

00:21:04.040 --> 00:21:06.460
<v Speaker 5>I'm glad I'll never have the right bash from scratch ever again.

00:21:08.800 --> 00:21:09.520
<v Speaker 6>Tell me about it.

00:21:10.000 --> 00:21:10.360
<v Speaker 6>Yeah.

00:21:12.120 --> 00:21:16.860
<v Speaker 6>I'll just say anecdotally, the thing that I love about it is

00:21:17.400 --> 00:21:22.280
<v Speaker 6>when I need to do something and I need to go through docs,

00:21:23.150 --> 00:21:25.840
<v Speaker 6>online docs for whatever it is, you know,

00:21:25.900 --> 00:21:29.040
<v Speaker 6>it might be GitLab or some library that I want to use

00:21:29.040 --> 00:21:32.360
<v Speaker 6>or something like that, I never even search for the docs.

00:21:32.520 --> 00:21:34.260
<v Speaker 6>I never even try to read the docs anymore.

00:21:34.380 --> 00:21:38.300
<v Speaker 6>I just say, hey, you know, whatever model,

00:21:38.540 --> 00:21:40.920
<v Speaker 6>I need to set up this website,

00:21:41.120 --> 00:21:43.720
<v Speaker 6>and just tell me what to do or just do it.

00:21:43.880 --> 00:21:47.920
<v Speaker 6>And it's an immense time saver and productivity.

00:21:48.060 --> 00:21:49.940
<v Speaker 6>And then it gets me bootstrapped to the place

00:21:50.120 --> 00:21:52.580
<v Speaker 6>where now I can start to be creative.

00:21:52.820 --> 00:21:56.700
<v Speaker 6>I don't have to worry about just like digging through pages

00:21:56.760 --> 00:21:58.920
<v Speaker 6>and pages and pages of docs to figure out

00:21:59.120 --> 00:22:00.660
<v Speaker 6>one little setting here or there.

00:22:01.100 --> 00:22:02.960
<v Speaker 6>That's an amazing time saver.

00:22:03.700 --> 00:22:05.020
<v Speaker 2>Yeah, that's a really good point.

00:22:05.320 --> 00:22:06.320
<v Speaker 2>Another thing that I have noticed,

00:22:06.450 --> 00:22:09.720
<v Speaker 2>there might be many things for which I had a really good mental model,

00:22:10.340 --> 00:22:12.400
<v Speaker 2>but my brain can only store so much information.

00:22:13.080 --> 00:22:16.800
<v Speaker 2>So for example, I know lots about the abstract syntax tree for Python,

00:22:17.520 --> 00:22:18.620
<v Speaker 2>but I forget that sometimes.

00:22:19.290 --> 00:22:22.180
<v Speaker 2>And so it's really nice for me to be able to bring that back

00:22:22.250 --> 00:22:24.400
<v Speaker 2>into my mind quickly with an LLM.

00:22:24.780 --> 00:22:28.320
<v Speaker 2>And if it's generating code for me that's doing a type of AST parsing,

00:22:28.720 --> 00:22:30.840
<v Speaker 2>I can tell whether that's good code or not,

00:22:30.920 --> 00:22:33.040
<v Speaker 2>because I can refresh that mental model.

00:22:33.480 --> 00:22:35.720
<v Speaker 2>So in those situations, it's not only the docs,

00:22:35.960 --> 00:22:38.480
<v Speaker 2>but it's something that I used to know really well

00:22:39.000 --> 00:22:40.560
<v Speaker 2>that I have forgotten some of.

00:22:40.800 --> 00:22:42.780
<v Speaker 2>And the LLM often is very powerful

00:22:42.900 --> 00:22:44.600
<v Speaker 2>when it comes to refreshing my memory

00:22:45.100 --> 00:22:47.160
<v Speaker 2>and helping me to get started and move more quickly.

00:22:49.380 --> 00:22:49.880
<v Speaker 1>All right.

00:22:50.460 --> 00:22:51.220
<v Speaker 1>Out of time, I think.

00:22:51.920 --> 00:22:53.620
<v Speaker 1>Let's move on to Brett.

00:22:53.720 --> 00:22:54.220
<v Speaker 1>What do you got, Brett?

00:22:56.780 --> 00:22:59.560
<v Speaker 5>Well, I actually originally said we should talk about AI,

00:22:59.640 --> 00:23:01.920
<v Speaker 5>but Jody had a way better pitch for it than I did

00:23:02.040 --> 00:23:04.080
<v Speaker 5>because my internal pitch was literally AI.

00:23:04.640 --> 00:23:06.360
<v Speaker 5>Do I actually have to write a paragraph explaining why?

00:23:07.120 --> 00:23:08.280
<v Speaker 5>Then Jody actually did write the paragraph.

00:23:08.600 --> 00:23:10.000
<v Speaker 5>So she did a much better job than I did.

00:23:10.880 --> 00:23:16.480
<v Speaker 5>So the other topic I had was using tools to run your Python code.

00:23:17.040 --> 00:23:19.440
<v Speaker 5>And what I mean by that is traditionally, if you think about it,

00:23:21.840 --> 00:23:23.480
<v Speaker 5>you install the Python interpreter, right?

00:23:25.300 --> 00:23:27.560
<v Speaker 5>Hopefully you create a virtual environment, install your dependencies,

00:23:27.720 --> 00:23:29.700
<v Speaker 5>and you call the Python interpreter in your virtual

00:23:29.920 --> 00:23:30.660
<v Speaker 5>environment to run your code.

00:23:31.460 --> 00:23:32.880
<v Speaker 5>Those are all the steps you went through to run stuff.

00:23:33.620 --> 00:23:35.820
<v Speaker 5>But now we've got tools that will

00:23:36.200 --> 00:23:37.760
<v Speaker 5>compress all that into a run command

00:23:38.360 --> 00:23:39.060
<v Speaker 5>and just do it all for you.

00:23:39.380 --> 00:23:41.680
<v Speaker 5>It seems like the community has

00:23:41.920 --> 00:23:43.680
<v Speaker 5>shown a level

00:23:43.700 --> 00:23:44.540
<v Speaker 5>of comfort with that.

00:23:46.940 --> 00:23:47.360
<v Speaker 5>I'd say

00:23:47.440 --> 00:23:48.800
<v Speaker 5>it snuck up on me a little bit,

00:23:50.460 --> 00:23:51.700
<v Speaker 5>but I would say that

00:23:52.140 --> 00:23:53.500
<v Speaker 5>I think it's a good thing.

00:23:53.919 --> 00:23:54.680
<v Speaker 5>It's showing

00:23:55.700 --> 00:23:57.040
<v Speaker 5>us, I'm going to say us, as the

00:23:57.060 --> 00:23:59.420
<v Speaker 5>as the junior core developer here on this call,

00:24:00.940 --> 00:24:04.360
<v Speaker 5>as to, sorry to make you too feel old,

00:24:04.520 --> 00:24:07.360
<v Speaker 5>but admittedly, Barry did write my letter of recommendation

00:24:07.640 --> 00:24:08.600
<v Speaker 5>to my master's program.

00:24:11.900 --> 00:24:12.820
<v Speaker 5>Barry already knows this.

00:24:13.140 --> 00:24:16.820
<v Speaker 5>Anyway, because I think what happened was,

00:24:17.130 --> 00:24:21.380
<v Speaker 5>yeah, we had Hatch and BDM and Poetry before that

00:24:21.660 --> 00:24:24.620
<v Speaker 5>and UV as of last year all kind of come through

00:24:24.980 --> 00:24:26.280
<v Speaker 5>and all kind of build on each other

00:24:26.280 --> 00:24:31.560
<v Speaker 5>and take ideas from each other and kind of just slowly build up this kind of repertoire of tool

00:24:31.820 --> 00:24:37.120
<v Speaker 5>approaches that they all kind of have a baseline kind of, not synergy is the right word, but

00:24:37.880 --> 00:24:43.080
<v Speaker 5>share just kind of approach to certain things with their own twists and added takes on things.

00:24:43.230 --> 00:24:47.580
<v Speaker 5>But in general, this whole like, you know what, you can just tell us to run this code and we will

00:24:47.660 --> 00:24:52.060
<v Speaker 5>just run it, right? Like inline script metadata coming in and help making that more of a thing.

00:24:53.180 --> 00:24:56.240
<v Speaker 5>disclaimer, I was the pep delegate for getting that in.

00:24:57.960 --> 00:25:00.220
<v Speaker 5>But I just think that's been a really awesome trend,

00:25:01.419 --> 00:25:05.160
<v Speaker 5>and I'm hoping we can kind of leverage that a bit.

00:25:05.580 --> 00:25:08.040
<v Speaker 5>I have personal plans that we don't need to go into here,

00:25:08.200 --> 00:25:10.520
<v Speaker 5>but I'm hoping as a Python core team,

00:25:10.540 --> 00:25:12.880
<v Speaker 5>we can kind of help boost this stuff up a bit

00:25:12.880 --> 00:25:15.160
<v Speaker 5>and kind of help keep a good baseline for this for everyone,

00:25:15.200 --> 00:25:18.000
<v Speaker 5>because I think it's shown that Python is still really good for beginners.

00:25:18.280 --> 00:25:21.860
<v Speaker 5>You just have to give them the tools to kind of hide some of the details

00:25:21.880 --> 00:25:23.200
<v Speaker 5>to not shoot yourself in the foot.

00:25:24.080 --> 00:25:25.000
<v Speaker 5>And so these are a great outcome.

00:25:26.040 --> 00:25:27.600
<v Speaker 1>Yeah, 2025 might be the year

00:25:27.610 --> 00:25:29.700
<v Speaker 1>that the Python tools stepped outside of Python

00:25:30.340 --> 00:25:32.140
<v Speaker 1>instead of being you install Python

00:25:32.760 --> 00:25:34.460
<v Speaker 1>and then use the tools.

00:25:35.120 --> 00:25:36.780
<v Speaker 1>You do the tool to get Python, right?

00:25:37.040 --> 00:25:38.600
<v Speaker 1>Like UV and PDM and others.

00:25:38.820 --> 00:25:40.640
<v Speaker 5>Yeah, and inverted the dependency graph

00:25:40.730 --> 00:25:43.000
<v Speaker 5>in terms of just how you put yourself in, right?

00:25:43.120 --> 00:25:44.780
<v Speaker 5>Like, I think the interesting thing

00:25:44.780 --> 00:25:45.800
<v Speaker 5>is these tools treat Python

00:25:46.100 --> 00:25:48.800
<v Speaker 5>as an implementation detail almost, right?

00:25:49.000 --> 00:25:53.400
<v Speaker 5>Like when you just say UV or hatch run or PDM run thing,

00:25:55.600 --> 00:25:57.280
<v Speaker 5>these tools don't make you have to think about the interpreter.

00:25:57.500 --> 00:26:00.340
<v Speaker 5>It's just a thing that they pull in to make your code run, right?

00:26:00.540 --> 00:26:03.860
<v Speaker 5>It's not even necessarily something you have to care about if you choose not to.

00:26:03.960 --> 00:26:08.540
<v Speaker 5>And it's an interesting shift in that perspective, at least for me,

00:26:08.780 --> 00:26:10.000
<v Speaker 5>but I've also been doing this for a long time.

00:26:10.780 --> 00:26:13.260
<v Speaker 6>Yeah, I think you're really onto something.

00:26:13.640 --> 00:26:16.260
<v Speaker 6>And what I love at sort of a high level is this,

00:26:16.820 --> 00:26:19.740
<v Speaker 6>I think there's a renewed focus on the user experience.

00:26:21.680 --> 00:26:27.500
<v Speaker 6>And like UV plus the PEP 723, the inline metadata,

00:26:27.830 --> 00:26:31.240
<v Speaker 6>you can put UV in the shebang line of your script.

00:26:31.880 --> 00:26:34.360
<v Speaker 6>And now you don't have to think about anything.

00:26:34.550 --> 00:26:39.540
<v Speaker 6>You get UV from somewhere and then it takes care of everything.

00:26:40.970 --> 00:26:44.000
<v Speaker 6>And Hatch can work the same way for, I think, for developers.

00:26:44.420 --> 00:26:49.880
<v Speaker 6>And like this renewed focus on getting,

00:26:50.320 --> 00:26:52.580
<v Speaker 6>like installing your Python executable.

00:26:52.920 --> 00:26:54.320
<v Speaker 6>Like you don't really have to think about,

00:26:55.060 --> 00:26:56.820
<v Speaker 6>because those things are very complicated

00:26:56.850 --> 00:26:59.220
<v Speaker 6>and people just want to kind of hit the ground running.

00:26:59.840 --> 00:27:02.760
<v Speaker 6>And so if you think about the previous discussion about AI, right?

00:27:02.940 --> 00:27:05.100
<v Speaker 6>Like, I just want things to work.

00:27:05.380 --> 00:27:07.080
<v Speaker 6>I know what I want to do.

00:27:07.630 --> 00:27:08.560
<v Speaker 6>I can see it.

00:27:08.560 --> 00:27:09.740
<v Speaker 6>I can see the vision of it.

00:27:09.740 --> 00:27:11.080
<v Speaker 6>And I just don't want to.

00:27:12.820 --> 00:27:16.340
<v Speaker 6>And an analogy is like when I first learned Python

00:27:16.550 --> 00:27:19.180
<v Speaker 6>and I came from C++ and all those languages,

00:27:19.900 --> 00:27:22.840
<v Speaker 6>and I thought, oh my gosh, just to get like, hello world,

00:27:22.980 --> 00:27:27.080
<v Speaker 6>I have to do a million little things that I shouldn't have to do.

00:27:27.560 --> 00:27:31.500
<v Speaker 6>Like create a main and get my braces right

00:27:31.530 --> 00:27:35.160
<v Speaker 6>and get all my variables right and get my pound includes correct.

00:27:35.330 --> 00:27:37.360
<v Speaker 6>And now I don't have to think about any of that stuff.

00:27:38.160 --> 00:27:49.960
<v Speaker 6>And the thing that was eye-opening for me with Python was the distance between vision of what I wanted and working code just really narrowed.

00:27:49.970 --> 00:27:59.300
<v Speaker 6>And I think that as we are starting to think about tools and environments and how to bootstrap all this stuff, we're also now taking all that stuff away.

00:28:00.160 --> 00:28:01.900
<v Speaker 6>Because people honestly don't care.

00:28:01.930 --> 00:28:03.620
<v Speaker 6>I don't care about any of that stuff.

00:28:03.760 --> 00:28:07.540
<v Speaker 6>I just want to go from like, oh, I woke up this morning and had a cool idea,

00:28:07.620 --> 00:28:09.600
<v Speaker 6>and I just wanted to get it working.

00:28:10.420 --> 00:28:12.660
<v Speaker 1>Or you wanted to share it so you could just share the script

00:28:12.780 --> 00:28:15.780
<v Speaker 1>and you don't have to say, here's your steps that you get started with.

00:28:16.899 --> 00:28:17.700
<v Speaker 1>Exactly, exactly.

00:28:19.340 --> 00:28:22.220
<v Speaker 7>I want to thank the two of you for â€“ I'm sorry, go ahead.

00:28:22.940 --> 00:28:26.340
<v Speaker 7>I'm just going to say, like, for years teaching Python,

00:28:27.240 --> 00:28:29.080
<v Speaker 7>that how do we get it installed?

00:28:29.980 --> 00:28:32.920
<v Speaker 7>At first it surprised me how difficult it was for people.

00:28:33.100 --> 00:28:34.620
<v Speaker 7>I was like, oh, come on, we just got Python.

00:28:34.790 --> 00:28:35.740
<v Speaker 7>Like, what's so hard about this?

00:28:35.910 --> 00:28:40.520
<v Speaker 7>But it turns out it's a really big barrier to entry for newcomers.

00:28:40.870 --> 00:28:44.740
<v Speaker 7>And I'm very happy that Jupyter Lite now has solved its problems with input.

00:28:45.140 --> 00:28:46.380
<v Speaker 7>And it's like huge.

00:28:47.040 --> 00:28:53.080
<v Speaker 7>But until now, I hadn't really thought about starting with UV because it's cross-platform.

00:28:53.500 --> 00:28:59.060
<v Speaker 7>And if I say to people in the first 10 minutes of class, install UV for your platform, and

00:28:59.060 --> 00:29:02.180
<v Speaker 7>then say UV in it, your project, bam, you're done.

00:29:02.380 --> 00:29:03.220
<v Speaker 7>It just works.

00:29:03.520 --> 00:29:04.280
<v Speaker 7>And then it works cross-blog.

00:29:04.660 --> 00:29:07.180
<v Speaker 7>This is mind-blowing, and I'm going to try this at some point.

00:29:07.280 --> 00:29:07.620
<v Speaker 7>Thank you.

00:29:08.680 --> 00:29:16.460
<v Speaker 2>I can comment on the mind-blowing part because now when I teach undergraduate students, we start with UV in the very first class, and it is awesome.

00:29:17.000 --> 00:29:31.840
<v Speaker 2>There were things that would take students, even very strong students who've had lots of experience, it would still take them a week to set everything up on their new laptop and get everything ready and to understand all the key concepts and know where something is in their path.

00:29:32.140 --> 00:29:36.460
<v Speaker 2>that now we just say install UV for your operating system

00:29:37.140 --> 00:29:39.500
<v Speaker 2>and get running on your computer

00:29:39.920 --> 00:29:41.180
<v Speaker 2>and then, hey, you're ready to go.

00:29:41.600 --> 00:29:43.700
<v Speaker 2>And I don't have to teach them about Docker containers

00:29:43.960 --> 00:29:45.960
<v Speaker 2>and I don't have to tell them how to install Python

00:29:46.100 --> 00:29:47.260
<v Speaker 2>with some packet manager.

00:29:47.900 --> 00:29:49.660
<v Speaker 2>All of those things just work.

00:29:50.120 --> 00:29:51.900
<v Speaker 2>And I think from a learning perspective,

00:29:52.220 --> 00:29:55.120
<v Speaker 2>whether you're in a class or whether you're in a company

00:29:55.460 --> 00:29:56.760
<v Speaker 2>or whether you're teaching yourself,

00:29:57.420 --> 00:29:59.060
<v Speaker 2>UV is absolutely awesome.

00:30:00.780 --> 00:30:05.600
<v Speaker 4>I'm actually wondering whether I am the one who is newest to Python here.

00:30:05.880 --> 00:30:08.820
<v Speaker 4>I taught myself Python in 2011.

00:30:09.740 --> 00:30:12.300
<v Speaker 4>So I was like Python 2.7 stage.

00:30:14.040 --> 00:30:15.380
<v Speaker 4>But it was my first programming language.

00:30:15.600 --> 00:30:19.080
<v Speaker 4>I was just procrastinating during my PhD and I was like, I should learn to program.

00:30:19.860 --> 00:30:21.820
<v Speaker 4>So I just taught myself Python.

00:30:22.480 --> 00:30:26.260
<v Speaker 4>And I can tell you, you do not come from an engineering background.

00:30:26.720 --> 00:30:27.840
<v Speaker 4>And you're like, what is Python?

00:30:28.280 --> 00:30:29.340
<v Speaker 4>What is Python doing?

00:30:29.740 --> 00:30:33.320
<v Speaker 4>Why am I typing Python to execute this hello world?

00:30:33.380 --> 00:30:39.840
<v Speaker 4>And if you're kind of curious, you get down a rabbit hole before you even get to the point where you're just focusing on learning the basics.

00:30:40.900 --> 00:30:54.780
<v Speaker 4>And so it's exactly, I was going to say with Reuven, like whether you thought about it for teaching, because we're now debating for humble data, which is a beginner's data science community that I'm part of, whether we switch to UV.

00:30:54.860 --> 00:31:01.800
<v Speaker 4>this was Chuck's idea because it does abstract away all these details. The debate I have is,

00:31:02.040 --> 00:31:06.400
<v Speaker 4>is it too magic? This is kind of the problem because I also remember learning about things

00:31:06.520 --> 00:31:10.260
<v Speaker 4>like virtual environments because again, this was my first programming language and being like,

00:31:10.620 --> 00:31:15.980
<v Speaker 4>oh, it's a very good idea. This is best practices. And it's also a debate we have in PyCharm, right?

00:31:16.280 --> 00:31:24.300
<v Speaker 4>Like how much do you magic away the fundamentals versus making people think a little bit, but

00:31:24.240 --> 00:31:24.980
<v Speaker 4>I'm not sure.

00:31:25.600 --> 00:31:28.540
<v Speaker 1>Would you even let somebody run without a virtual environment?

00:31:28.740 --> 00:31:31.020
<v Speaker 1>That's a stance you could take.

00:31:31.380 --> 00:31:36.060
<v Speaker 4>I used to when I first learned Python because it was too complicated.

00:31:36.520 --> 00:31:38.260
<v Speaker 4>But then I learned better.

00:31:38.940 --> 00:31:39.460
<v Speaker 4>But yes.

00:31:40.160 --> 00:31:52.480
<v Speaker 3>I think the consideration here is like hiding the magic isn't like hiding the details and having all this magic just work is great as long as it works.

00:31:53.320 --> 00:32:01.360
<v Speaker 3>And the question is, how is it going to break down and how are people going to know how to deal when it breaks down if you hide all the magic?

00:32:02.170 --> 00:32:16.380
<v Speaker 3>And I think virtual ends were, or let's say before we had virtual ends, installing packages was very much in the, you had to know all the details because it was very likely going to break down in some way right before we had virtual ends.

00:32:16.940 --> 00:32:22.440
<v Speaker 3>Because you would end up with weird conflicts or multiple copies of a package installed in different parts of the system.

00:32:23.420 --> 00:32:28.180
<v Speaker 3>Um, when we got virtual ends, we, we sort of didn't have to worry about that anymore

00:32:28.360 --> 00:32:32.440
<v Speaker 3>because we were trained in that you can just blow away the virtual one and it just works.

00:32:33.260 --> 00:32:36.820
<v Speaker 3>And with UV, we're back into, this looks like a single installation.

00:32:37.180 --> 00:32:42.320
<v Speaker 3>We don't know what's going to go on, but we've learned we as a community and also the people

00:32:42.520 --> 00:32:48.460
<v Speaker 3>working on, on UV, we have learned from those earlier mistakes or not, maybe not mistakes,

00:32:48.560 --> 00:32:55.320
<v Speaker 3>but consequences of the design and they have created something that is that appears to be

00:32:55.520 --> 00:33:01.480
<v Speaker 3>very stable where it's unlikely the magic will break and when the magic does break it's obvious

00:33:01.760 --> 00:33:08.520
<v Speaker 3>what the problem is or or it automatically fixes itself so like it's not reusing uh broken uh

00:33:08.840 --> 00:33:15.400
<v Speaker 3>installations and that kind of thing so the risk now as it turns out i think as is proven by the

00:33:15.360 --> 00:33:22.940
<v Speaker 3>community adopting UV so fast and so willingly, I think it's acceptable. I think it's, yeah,

00:33:22.950 --> 00:33:28.680
<v Speaker 3>I think it's proven itself. It's clear that this is, it's worth the potential of discovering

00:33:29.740 --> 00:33:38.140
<v Speaker 3>weird edge cases later, both because it's probably low likelihood, but also the people behind UV,

00:33:38.440 --> 00:33:43.020
<v Speaker 3>Astral, have proven that they would jump in and fix those issues, right? They would do anything

00:33:43.060 --> 00:33:47.160
<v Speaker 3>they need to keep UV workable the same way.

00:33:47.700 --> 00:33:51.260
<v Speaker 3>And they have a focus that Python as a whole cannot have

00:33:51.560 --> 00:33:53.720
<v Speaker 3>because they cater to fewer use cases

00:33:54.020 --> 00:33:55.900
<v Speaker 1>than Python as a whole needs to.

00:33:56.600 --> 00:34:00.380
<v Speaker 1>Yeah, and on the audience, Galano says,

00:34:00.580 --> 00:34:02.580
<v Speaker 1>as an enterprise tech director and Python coder,

00:34:02.580 --> 00:34:04.040
<v Speaker 1>I believe we should hide the magic

00:34:04.240 --> 00:34:06.980
<v Speaker 1>which empowers the regular employee to do simple things

00:34:07.120 --> 00:34:08.000
<v Speaker 1>that make their job easier.

00:34:08.340 --> 00:34:08.419
<v Speaker 1>Yeah.

00:34:09.460 --> 00:34:11.780
<v Speaker 1>Yeah, I mean, I'll go ahead, Barry.

00:34:12.600 --> 00:34:21.040
<v Speaker 6>No, I think this notion of abstractions, right, has always been there in computer science.

00:34:21.620 --> 00:34:33.500
<v Speaker 6>And, you know, we've used tools or languages or systems where we've tried to bring that abstraction layer up so that we don't have to think about all these details, as I mentioned before.

00:34:34.840 --> 00:34:38.100
<v Speaker 6>The question is, that's always the happy path.

00:34:38.280 --> 00:34:47.000
<v Speaker 6>And when I'm trying to teach somebody something like, here's how to use this library or here's how to use this tool, I try to be very opinionated to keep people on that happy path.

00:34:47.129 --> 00:34:50.520
<v Speaker 6>Like, assume everything's going to work just right.

00:34:51.220 --> 00:34:55.520
<v Speaker 6>Here's how you just make you go down that path to get the thing done that you want.

00:34:55.530 --> 00:35:04.980
<v Speaker 6>The question really is, when things go wrong, how narrow is that abstraction?

00:35:05.300 --> 00:35:07.680
<v Speaker 6>And are you able, and even when you're just curious,

00:35:08.200 --> 00:35:10.640
<v Speaker 6>like what's really going on underneath the hood?

00:35:11.100 --> 00:35:12.620
<v Speaker 6>Of course, that's not a really good analogy today

00:35:12.820 --> 00:35:15.480
<v Speaker 6>because cars are basically computers on wheels

00:35:15.700 --> 00:35:17.480
<v Speaker 6>that you can't really understand how they work.

00:35:18.180 --> 00:35:20.860
<v Speaker 6>But back in your day.

00:35:21.560 --> 00:35:25.060
<v Speaker 6>But back in my day, we were changing spark plugs, you know.

00:35:26.220 --> 00:35:27.740
<v Speaker 6>And crank that window down.

00:35:28.660 --> 00:35:29.140
<v Speaker 6>Exactly.

00:35:30.600 --> 00:35:33.900
<v Speaker 6>So I think we always have to leave that room

00:35:33.920 --> 00:35:36.840
<v Speaker 6>for the curious and the bad path

00:35:37.380 --> 00:35:38.900
<v Speaker 6>where when things go wrong

00:35:39.140 --> 00:35:40.120
<v Speaker 6>or when you're just like,

00:35:40.420 --> 00:35:41.980
<v Speaker 6>you know what, I understand how this works,

00:35:42.010 --> 00:35:45.380
<v Speaker 6>but I'm kind of curious about what's really going on.

00:35:45.580 --> 00:35:47.780
<v Speaker 6>How easy is it for me to dive in

00:35:47.960 --> 00:35:50.220
<v Speaker 6>and get a little bit more of that background,

00:35:50.610 --> 00:35:53.260
<v Speaker 6>you know, a little bit more of that understanding

00:35:53.440 --> 00:35:54.160
<v Speaker 6>of what's going on.

00:35:55.140 --> 00:35:59.200
<v Speaker 5>Yeah, I want the magic to decompose, right?

00:35:59.400 --> 00:36:01.340
<v Speaker 5>Like you should be able to explain the magic path

00:36:01.360 --> 00:36:03.940
<v Speaker 5>via more decomposed steps using the tool

00:36:04.100 --> 00:36:05.700
<v Speaker 5>all the way down to what the tools actually do

00:36:05.920 --> 00:36:06.400
<v Speaker 5>behind the scenes.

00:36:08.900 --> 00:36:11.640
<v Speaker 5>Just to admit, the reason I brought this up

00:36:11.640 --> 00:36:12.980
<v Speaker 5>and I've been thinking about this a lot

00:36:13.120 --> 00:36:15.120
<v Speaker 5>is I'm thinking of trying to get the Python launcher

00:36:15.920 --> 00:36:17.240
<v Speaker 5>to do a bit more.

00:36:17.580 --> 00:36:20.240
<v Speaker 5>Because one interesting thing we haven't really brought up here

00:36:20.260 --> 00:36:21.800
<v Speaker 5>is we're all seeing UV, UV, UV.

00:36:22.620 --> 00:36:23.400
<v Speaker 5>UV is a company.

00:36:24.440 --> 00:36:25.480
<v Speaker 5>There's always the risk they might disappear.

00:36:26.440 --> 00:36:28.540
<v Speaker 5>And we haven't de-risked ourselves from that.

00:36:28.720 --> 00:36:29.480
<v Speaker 5>Now, we do have Hatch.

00:36:29.500 --> 00:36:30.180
<v Speaker 5>We do have PDM.

00:36:31.120 --> 00:36:37.460
<v Speaker 5>But as I said, there's kind of a baseline I think they all share that I think they would be probably okay if the Python launcher just did.

00:36:37.640 --> 00:36:38.940
<v Speaker 5>Because that's based on standards, right?

00:36:39.060 --> 00:36:42.280
<v Speaker 5>Because that's the other thing that there's been a lot of work that has led to this step, right?

00:36:42.400 --> 00:36:44.860
<v Speaker 5>Like we've gotten way more packaging standards.

00:36:45.140 --> 00:36:47.820
<v Speaker 5>We've got PEP 723 like we mentioned.

00:36:48.380 --> 00:36:57.320
<v Speaker 5>There's a lot of work that's come up to lead to this point that all these tools can lean on to have them all have an equivalent outcome because it's expected as how they should be.

00:36:58.540 --> 00:37:06.360
<v Speaker 5>And so I think it's something we need to consider of how do we make sure, like, by the way, UV, I know the people, they're great.

00:37:06.460 --> 00:37:10.520
<v Speaker 5>I'm not trying to spare them or think they're going to go away, but it is something we have to consider.

00:37:11.340 --> 00:37:21.760
<v Speaker 5>And I will also say, Jody, I do think about this for teaching because I'm a dad now and I don't want my kid coming home when they get old enough to learn Python.

00:37:21.840 --> 00:37:24.920
<v Speaker 5>I go, hey, dad, why is getting Python code running so hard?

00:37:25.300 --> 00:37:27.380
<v Speaker 5>So I want to make sure that that never happens.

00:37:28.340 --> 00:37:30.600
<v Speaker 4>But they fall in love with it from the start.

00:37:30.980 --> 00:37:31.320
<v Speaker 1>Yeah.

00:37:31.480 --> 00:37:31.600
<v Speaker 1>Yes.

00:37:32.020 --> 00:37:34.900
<v Speaker 1>I realized something for the 2026 year interview.

00:37:34.960 --> 00:37:40.240
<v Speaker 1>I have to bring a sign that says time for next topic because we got a bunch of topics and we're running low on time.

00:37:40.940 --> 00:37:42.980
<v Speaker 1>So, Thomas, let's jump over to yours.

00:37:43.640 --> 00:37:45.800
<v Speaker 1>Oh, and I have two topics as well.

00:37:45.940 --> 00:37:49.920
<v Speaker 3>So, I'm only going to have to pick my favorite child, right?

00:37:50.080 --> 00:37:50.560
<v Speaker 3>That's terrible.

00:37:52.580 --> 00:37:52.720
<v Speaker 3>Yeah.

00:37:52.820 --> 00:37:57.440
<v Speaker 3>So, my second favorite child is Lazy Imports, which is a relatively new development.

00:37:57.800 --> 00:37:59.480
<v Speaker 3>So we'll probably not get to that.

00:38:00.420 --> 00:38:03.220
<v Speaker 3>And yes, it's been accepted and it's going to be awesome.

00:38:04.000 --> 00:38:07.840
<v Speaker 3>So I'll just give that a shout out and then move to my favorite child, which is free-threaded Python.

00:38:09.540 --> 00:38:14.280
<v Speaker 3>For those who were not aware, the global interpreter lock is going away.

00:38:14.720 --> 00:38:16.820
<v Speaker 3>I am stating it as a fact.

00:38:17.020 --> 00:38:22.600
<v Speaker 3>It's not actually a fact yet, but that's because the steering council hasn't realized the fact yet.

00:38:24.040 --> 00:38:25.280
<v Speaker 3>It is trending towards.

00:38:26.180 --> 00:38:26.300
<v Speaker 3>Yeah.

00:38:26.660 --> 00:38:35.100
<v Speaker 3>Well, so I was originally on the steering council that accepted the proposal to add free threading as a, as an experimental feature.

00:38:35.250 --> 00:38:41.960
<v Speaker 3>We had this idea of adding it as experimental and then making it supported, but not the default and then making it the default.

00:38:42.720 --> 00:38:45.260
<v Speaker 3>And it was all a little vague and, and up in the air.

00:38:46.360 --> 00:38:51.900
<v Speaker 3>And then I didn't get reelected for the steering council last year, which I was not sad about at all.

00:38:52.140 --> 00:38:55.020
<v Speaker 3>I sort of ran on a, well, if there's nobody better, I'll do it.

00:38:55.030 --> 00:38:57.140
<v Speaker 3>But otherwise I have other things to do.

00:38:57.900 --> 00:39:01.460
<v Speaker 3>And it turns out those other things were making sure that prefer that Python

00:39:01.720 --> 00:39:03.060
<v Speaker 3>landed in a supported state.

00:39:03.170 --> 00:39:07.600
<v Speaker 3>So I lobbied the steering council quite hard as Barry might remember at the

00:39:07.760 --> 00:39:11.880
<v Speaker 3>start of the year, uh, to, to get some movement on this, like get some decision

00:39:12.020 --> 00:39:12.220
<v Speaker 3>going.

00:39:12.880 --> 00:39:15.620
<v Speaker 3>So for Python 3.14, it is officially supported.

00:39:16.010 --> 00:39:17.320
<v Speaker 3>Uh, the performance is great.

00:39:17.580 --> 00:39:24.600
<v Speaker 3>It's like between a couple of percent slower and 10% slower, depending on the hardware and the compiler that you use.

00:39:25.320 --> 00:39:35.640
<v Speaker 3>It's basically the same speed on macOS, which is really like it's that's a combination of the ARM hardware and Clang specializing things.

00:39:35.820 --> 00:39:37.200
<v Speaker 3>But it's basically the same speed.

00:39:38.020 --> 00:39:38.240
<v Speaker 3>Wow.

00:39:39.240 --> 00:39:43.060
<v Speaker 3>And then on recent GCCs on Linux, it's like a couple of percent slower.

00:39:44.240 --> 00:40:01.860
<v Speaker 3>So the main problem is really community adoption, getting third-party packages to update their extension modules for the new APIs and the things that by necessity sort of broke, and also supporting free threading in a good way in packages.

00:40:02.430 --> 00:40:09.040
<v Speaker 3>For Python code, it turns out there's very few changes that need to be made for things to work well under free threading.

00:40:09.520 --> 00:40:21.620
<v Speaker 3>They might not be entirely thread safe, but usually, like almost always in cases where it wasn't thread safe before either, because the GIL doesn't actually affect thread safety, just the likelihood of things breaking.

00:40:22.560 --> 00:40:32.920
<v Speaker 1>I do think there's been a bit of a, the mindset of the Python community hasn't really been focused on creating thread safe code because the GIL is supposed to protect us.

00:40:32.990 --> 00:40:36.700
<v Speaker 1>But soon as it takes multiple steps, then all of a sudden it's just less likely.

00:40:36.920 --> 00:40:38.080
<v Speaker 1>It's not that it couldn't happen.

00:40:39.060 --> 00:40:39.900
<v Speaker 3>Yeah, that's my point, right?

00:40:40.100 --> 00:40:42.420
<v Speaker 3>It's not, the GIL never gave you threat safety.

00:40:42.550 --> 00:40:46.000
<v Speaker 3>The GIL gave CPython's internals threat safety.

00:40:46.340 --> 00:40:53.100
<v Speaker 3>It never really affected Python code, and it very rarely affected threat safety in extension modules as well.

00:40:53.230 --> 00:41:01.060
<v Speaker 3>So they already had to take care of making sure that the global interpreter law couldn't be released by something that they ended up calling indirectly.

00:41:02.440 --> 00:41:06.420
<v Speaker 3>So it's actually not that hard to port most things to support free threading.

00:41:07.640 --> 00:41:12.960
<v Speaker 3>And the benefits, we've seen some experimental work because, you know, it's still new.

00:41:13.200 --> 00:41:15.800
<v Speaker 3>There's still a lot of things that don't quite support it.

00:41:15.940 --> 00:41:19.860
<v Speaker 3>There's still places where thread contention slows things down a lot.

00:41:20.290 --> 00:41:29.560
<v Speaker 3>But we've seen a lot of examples of really promising, very parallel problems that now speed up by 10x or more.

00:41:30.360 --> 00:41:32.720
<v Speaker 3>And it's going to be really excited in the future.

00:41:32.810 --> 00:41:35.360
<v Speaker 3>And it's in 2025 that this all started.

00:41:35.570 --> 00:41:37.260
<v Speaker 3>I mean, Sam started it earlier.

00:41:37.360 --> 00:41:42.320
<v Speaker 3>But, you know, he's been working on this for years, but it landed in 2025.

00:41:42.900 --> 00:41:45.940
<v Speaker 1>It dropped its experimental stage in 314, basically.

00:41:46.560 --> 00:41:46.940
<v Speaker 1>Yes.

00:41:48.180 --> 00:41:49.320
<v Speaker 5>I totally agree.

00:41:50.760 --> 00:41:51.060
<v Speaker 5>Go ahead.

00:41:51.880 --> 00:41:57.720
<v Speaker 5>I was going to say, were we all, the three of us, on the steering council at the same time when we decided to start the experiment for free threading?

00:41:58.080 --> 00:41:59.460
<v Speaker 3>I think Barry wasn't on it.

00:42:00.120 --> 00:42:04.160
<v Speaker 6>Yeah, I missed a couple of years there, but I'm not sure.

00:42:05.580 --> 00:42:08.120
<v Speaker 6>But, you know, I totally agree.

00:42:08.120 --> 00:42:11.080
<v Speaker 6>I think free threading is one of the most transformative

00:42:12.120 --> 00:42:15.220
<v Speaker 6>developments for Python, certainly since Python 3,

00:42:15.460 --> 00:42:18.260
<v Speaker 6>but even maybe more impactful because of the size

00:42:18.270 --> 00:42:19.660
<v Speaker 6>of the community today.

00:42:22.559 --> 00:42:25.940
<v Speaker 6>Personally, you know, not necessarily speaking

00:42:26.120 --> 00:42:30.400
<v Speaker 6>as a current or potentially former steering council member,

00:42:30.540 --> 00:42:34.700
<v Speaker 6>we'll see how that shakes out, but I think it's inevitable.

00:42:35.760 --> 00:42:43.600
<v Speaker 6>I think free threading is absolutely the future of Python, and I think it's going to unlock incredible potential and performance.

00:42:45.420 --> 00:42:46.860
<v Speaker 6>I think we just have to do it right.

00:42:47.060 --> 00:42:52.240
<v Speaker 6>And so I talked to lots of teams who are building various software all over the community.

00:42:54.460 --> 00:43:03.300
<v Speaker 6>And I actually think it's more of an educational and maybe an outreach problem than it is a technological problem.

00:43:03.440 --> 00:43:08.520
<v Speaker 6>I mean, yes, there are probably APIs that are missing that will make people's lives easier.

00:43:10.020 --> 00:43:16.220
<v Speaker 6>There's probably some libraries that will make other code a little easier to write or whatever or to understand.

00:43:17.000 --> 00:43:18.180
<v Speaker 6>But like all that's solvable.

00:43:18.320 --> 00:43:27.220
<v Speaker 6>And I think really reaching out to the teams that are, you know, like Thomas said, that are building the ecosystem, that are moving the ecosystem to a free threading world.

00:43:28.100 --> 00:43:31.260
<v Speaker 6>That's where we really need to spend our effort on.

00:43:31.380 --> 00:43:32.320
<v Speaker 6>And we'll get there.

00:43:32.420 --> 00:43:33.380
<v Speaker 6>It won't be that long.

00:43:33.550 --> 00:43:37.140
<v Speaker 6>It certainly won't be as long as it took us to get to Python 3.

00:43:42.240 --> 00:43:50.360
<v Speaker 7>I'm sort of curious, as someone who's not super experienced with threading or basic concurrency,

00:43:50.760 --> 00:43:56.760
<v Speaker 7>I mean, I've used it, but I feel like now we have threads, especially with free threading,

00:43:57.300 --> 00:44:01.160
<v Speaker 7>and subinterpreters, and multiprocessing, and async.io.

00:44:01.920 --> 00:44:07.080
<v Speaker 7>And I feel like for many people now it's like, oh my God, which one am I supposed to use?

00:44:08.100 --> 00:44:12.600
<v Speaker 7>And for someone who's experienced, you can sort of say, well, this seems like a better choice.

00:44:12.800 --> 00:44:20.360
<v Speaker 7>But are there any plans to sort of try to have a taxonomy of what problems are solved by which of these?

00:44:22.340 --> 00:44:31.120
<v Speaker 3>I think, so the, the premise here is that everyone would be using one or more of these

00:44:31.300 --> 00:44:32.960
<v Speaker 3>low level techniques that you mentioned.

00:44:33.840 --> 00:44:36.800
<v Speaker 3>And I think we, that's not a good way of looking at it.

00:44:36.960 --> 00:44:43.560
<v Speaker 3>Like async IO is a library that you want to use for, uh, for the things that async IO is good at.

00:44:44.540 --> 00:44:49.340
<v Speaker 3>And you can actually very nicely combine it with multiprocessing, with sub processes,

00:44:50.320 --> 00:44:55.460
<v Speaker 3>with, so that subprocesses and subinterpreters,

00:44:55.610 --> 00:44:58.080
<v Speaker 3>just to make it clear that those are two very separate things,

00:44:58.360 --> 00:45:01.460
<v Speaker 3>and multithreading, both with and without free threading.

00:45:02.040 --> 00:45:04.940
<v Speaker 3>And it solves different problems

00:45:05.050 --> 00:45:08.720
<v Speaker 3>or it gives you different abilities within the AsyncIO framework.

00:45:08.790 --> 00:45:11.140
<v Speaker 3>And the same is true for like GUI frameworks.

00:45:12.870 --> 00:45:15.880
<v Speaker 3>I mean, GUI frameworks usually want threads for multiple reasons,

00:45:16.180 --> 00:45:18.480
<v Speaker 3>but you can use these other things as well.

00:45:18.860 --> 00:45:24.780
<v Speaker 3>I don't think it's down to teaching end users when to use or avoid all these different things.

00:45:25.380 --> 00:45:30.360
<v Speaker 3>I think we need higher level abstractions for tasks that people want to solve.

00:45:31.110 --> 00:45:36.800
<v Speaker 3>And then those can decide on what for their particular use case is a better approach.

00:45:38.420 --> 00:45:45.580
<v Speaker 3>For instance, PyTorch has multiple, so it's used for people who don't know to train,

00:45:46.400 --> 00:45:52.880
<v Speaker 3>uh not just train but it's used in ai for for generating large uh matrices and lms and what

00:45:52.960 --> 00:46:03.820
<v Speaker 3>have you um part of it is loading data and uh processing it and the the basic ideas of async

00:46:03.880 --> 00:46:08.600
<v Speaker 3>io are oh you can do all these things in parallel because you're not waiting on the cpu you're just

00:46:08.740 --> 00:46:15.280
<v Speaker 3>waiting on io turns out it is still a good idea to use threads for massively parallel io because

00:46:15.300 --> 00:46:22.260
<v Speaker 3>otherwise you end up waiting longer than you need to so a problem where we thought async io would be

00:46:22.440 --> 00:46:28.460
<v Speaker 3>the solution and we never needed threads is actually much improved if we tie in threads as well

00:46:29.380 --> 00:46:34.840
<v Speaker 3>and and we've seen massive massive improvements in data loader there's a there's even an article

00:46:35.220 --> 00:46:42.440
<v Speaker 3>a published article from some people at meta showing how much they improve the pytorch data

00:46:42.340 --> 00:46:44.560
<v Speaker 3>the loader by using multiple threads.

00:46:45.220 --> 00:46:48.880
<v Speaker 3>But at a very low level, we don't want end users to need to make that choice.

00:46:49.060 --> 00:46:49.180
<v Speaker 3>Right?

00:46:49.900 --> 00:46:50.080
<v Speaker 5>Yeah.

00:46:50.400 --> 00:46:50.560
<v Speaker 3>Yeah.

00:46:50.760 --> 00:46:53.300
<v Speaker 5>I mean, I concurred.futures is a good point, right?

00:46:53.400 --> 00:46:57.140
<v Speaker 5>Like all of these approaches are all supported there and it's a unified one.

00:46:57.780 --> 00:47:00.500
<v Speaker 5>So if you were to teach this for instance, you could say use concurred.futures.

00:47:01.320 --> 00:47:01.840
<v Speaker 5>These are all there.

00:47:02.340 --> 00:47:03.900
<v Speaker 5>This is the potential trade off.

00:47:04.000 --> 00:47:05.440
<v Speaker 5>Like basically use threads.

00:47:05.560 --> 00:47:08.980
<v Speaker 5>It's going to be the fastest, unless there's like some module you have.

00:47:09.060 --> 00:47:12.000
<v Speaker 5>That's not that's screwing up because of threads and use sub interpreters.

00:47:13.040 --> 00:47:14.660
<v Speaker 5>and if for some reason sub interpreters don't work

00:47:14.690 --> 00:47:16.740
<v Speaker 5>you should move to the processing

00:47:17.020 --> 00:47:17.940
<v Speaker 5>pool, the process pool

00:47:18.510 --> 00:47:19.820
<v Speaker 5>but basically you just kind of

00:47:20.620 --> 00:47:22.780
<v Speaker 5>go sort the fast stuff and for some reason

00:47:22.780 --> 00:47:24.640
<v Speaker 5>it doesn't work, use the next fastest and just

00:47:24.740 --> 00:47:26.440
<v Speaker 5>kind of do it that way. After that

00:47:26.740 --> 00:47:28.500
<v Speaker 5>then you start to the lower level like

00:47:28.940 --> 00:47:31.040
<v Speaker 5>okay, why do I want to use sub interpreters

00:47:31.150 --> 00:47:32.320
<v Speaker 5>instead of threads and

00:47:32.880 --> 00:47:34.200
<v Speaker 5>those kind of threads but I think

00:47:34.700 --> 00:47:35.100
<v Speaker 5>that's a different

00:47:36.980 --> 00:47:38.400
<v Speaker 5>different level of abstraction

00:47:38.940 --> 00:47:40.400
<v Speaker 5>which is a term we keep bringing up today

00:47:41.980 --> 00:47:42.480
<v Speaker 5>and so

00:47:43.420 --> 00:47:45.620
<v Speaker 5>I think it's a level that a lot of people

00:47:45.630 --> 00:47:47.640
<v Speaker 5>are not going to have to care about I think the libraries are the ones

00:47:47.700 --> 00:47:49.840
<v Speaker 5>who have to care about this and who are going to do a lot

00:47:49.840 --> 00:47:51.440
<v Speaker 1>of this for you I agree I would

00:47:51.750 --> 00:47:53.440
<v Speaker 1>let me throw this out on our way

00:47:53.650 --> 00:47:55.160
<v Speaker 1>out the door to get to

00:47:55.540 --> 00:47:56.820
<v Speaker 1>Reuven's topic I would

00:47:57.330 --> 00:47:59.280
<v Speaker 1>love to see it solidify around

00:47:59.420 --> 00:48:00.900
<v Speaker 1>async and await and you just

00:48:01.580 --> 00:48:03.340
<v Speaker 1>await a thing maybe put a decorator on

00:48:03.440 --> 00:48:05.260
<v Speaker 1>something say this this one I want this to be

00:48:05.700 --> 00:48:07.500
<v Speaker 1>threaded I want this to be I.O.

00:48:08.100 --> 00:48:08.520
<v Speaker 1>I want this

00:48:09.840 --> 00:48:12.040
<v Speaker 1>and you just use async and await

00:48:12.260 --> 00:48:13.040
<v Speaker 1>and don't have to think about it.

00:48:13.200 --> 00:48:15.180
<v Speaker 1>But that's my dream.

00:48:15.799 --> 00:48:16.980
<v Speaker 1>Reuven, what's your dream?

00:48:18.619 --> 00:48:19.780
<v Speaker 7>Well, how long do you have?

00:48:20.839 --> 00:48:21.520
<v Speaker 1>What's your topic?

00:48:22.559 --> 00:48:24.120
<v Speaker 7>So I want to talk about

00:48:25.330 --> 00:48:28.220
<v Speaker 7>the Python ecosystem and funding.

00:48:29.400 --> 00:48:30.940
<v Speaker 7>And when I talk to people about Python

00:48:31.710 --> 00:48:33.100
<v Speaker 7>and I talk to them about how it's open source,

00:48:33.170 --> 00:48:34.320
<v Speaker 7>they're like, oh, right, it's open source.

00:48:34.430 --> 00:48:35.760
<v Speaker 7>That means I can download it for free.

00:48:35.980 --> 00:48:37.020
<v Speaker 7>And from their perspective,

00:48:37.180 --> 00:48:37.980
<v Speaker 7>that's sort of where it starts.

00:48:38.440 --> 00:48:43.520
<v Speaker 7>and ends. And the notion that people work on it, the notion that needs funding, the notion that

00:48:43.640 --> 00:48:48.280
<v Speaker 7>there's a Python software foundation that supports a lot of these activities, the infrastructure

00:48:48.900 --> 00:48:56.560
<v Speaker 7>is completely unknown to them and even quite shocking for them to hear. But Python is in many

00:48:56.740 --> 00:49:02.200
<v Speaker 7>ways, I think, starting to become a victim of its own success, that we've been dependent on

00:49:02.200 --> 00:49:08.340
<v Speaker 7>companies for a number of years to support developers and development. And we've been

00:49:08.560 --> 00:49:13.820
<v Speaker 7>assuming that the PSF, which gives money out to lots of organizations to run conferences and

00:49:13.940 --> 00:49:20.320
<v Speaker 7>workshops and so forth, can sort of keep scaling up and that they will have enough funding. And

00:49:20.480 --> 00:49:25.800
<v Speaker 7>we've seen a few sort of shocks that system in the last year. Most recently, the PSF announced that

00:49:25.800 --> 00:49:30.460
<v Speaker 7>it was no longer going to be doing for first and sort of pared down about a year ago, what it would

00:49:30.380 --> 00:49:34.600
<v Speaker 7>give money for. And then about five months ago, six months ago, I think it was in July or August,

00:49:34.800 --> 00:49:37.680
<v Speaker 7>they said, actually, we're not going to be able to fund anything for about a year now.

00:49:38.720 --> 00:49:43.140
<v Speaker 7>And then there was the government grant, I think from the NSF that they turned down. And I'm not

00:49:43.340 --> 00:49:47.040
<v Speaker 7>disputing the reasons for that at all. It basically, it said, well, we'll give you the money if you

00:49:47.140 --> 00:49:50.960
<v Speaker 7>don't worry about diversity and inclusion. And given that that's like a core part of what the

00:49:51.080 --> 00:49:55.840
<v Speaker 7>PSF is supposed to do, they could not do that without shutting the doors, which would be kind

00:49:55.860 --> 00:50:03.540
<v Speaker 7>of counterproductive. And so I feel like we're not yet there, but we're sort of approaching this,

00:50:04.220 --> 00:50:10.340
<v Speaker 7>talking about a term like a problem crisis in funding Python, that the needs of the community

00:50:10.480 --> 00:50:13.960
<v Speaker 7>keep growing and growing, whether it's workshops, whether it's PyPI, whether it's conferences,

00:50:15.660 --> 00:50:21.300
<v Speaker 7>and companies are getting squeezed. And the number of people, it always shocks me every time there

00:50:21.200 --> 00:50:27.720
<v Speaker 7>PSF elections, the incredibly small number of people who vote, which means that, let's assume

00:50:27.780 --> 00:50:33.240
<v Speaker 7>half the people who are members, like for the millions and millions of people who program Python

00:50:33.320 --> 00:50:38.860
<v Speaker 7>out there, an infinitesimally small proportion of them actually join and help to fund it.

00:50:39.360 --> 00:50:44.940
<v Speaker 7>So I'm not quite sure what to do with this other than express concern. But I feel like we've got

00:50:44.960 --> 00:50:50.600
<v Speaker 7>to figure out ways to fund Python and the PSF in new ways that will allow it to grow and scale

00:50:51.020 --> 00:50:51.440
<v Speaker 7>as needed.

00:50:54.380 --> 00:50:56.560
<v Speaker 3>Yeah, I couldn't agree more.

00:50:57.420 --> 00:51:04.620
<v Speaker 3>I mean, obviously, the PSF is close to my heart, because I was on the board for I think

00:51:04.620 --> 00:51:07.140
<v Speaker 3>a total of six or nine years or something.

00:51:08.680 --> 00:51:10.140
<v Speaker 3>Over, you know, the last 25.

00:51:11.860 --> 00:51:17.840
<v Speaker 3>I was also for six months, I was the interim general manager because Eva left and we hadn't

00:51:17.890 --> 00:51:19.800
<v Speaker 3>hired Deb yet while I was on the board.

00:51:20.300 --> 00:51:26.520
<v Speaker 3>So I, I, I remember signing the sponsor contracts for the companies that came in, uh, wanting

00:51:26.540 --> 00:51:27.440
<v Speaker 3>to sponsor Python.

00:51:27.860 --> 00:51:33.420
<v Speaker 3>And it is like, it's ridiculous how, and I can say this working for a company that is

00:51:33.460 --> 00:51:36.480
<v Speaker 3>one of the biggest sponsors of the PSF and has done so for years.

00:51:37.220 --> 00:51:43.620
<v Speaker 3>It's ridiculous how small those sponsorships are and yet how grateful we were that they

00:51:43.780 --> 00:51:46.540
<v Speaker 3>came in because every single one has such a big impact.

00:51:46.820 --> 00:51:50.240
<v Speaker 3>You can do so much good with the money that comes in.

00:51:51.960 --> 00:51:55.440
<v Speaker 3>We need more corporate sponsorships more than we need.

00:51:55.600 --> 00:52:01.200
<v Speaker 3>Like, I mean, obviously a million people giving us a couple of bucks, giving the PSF, let's

00:52:01.200 --> 00:52:01.480
<v Speaker 3>be clear.

00:52:01.480 --> 00:52:02.380
<v Speaker 3>I'm not on the board anymore.

00:52:02.620 --> 00:52:06.440
<v Speaker 3>Giving the PSF a couple of bucks would be fantastic.

00:52:07.750 --> 00:52:14.240
<v Speaker 3>But I think the big players in the big corporate players where all the AI money is, for instance,

00:52:14.540 --> 00:52:18.780
<v Speaker 3>having done basically no sponsorship of the PSF is mind boggling.

00:52:19.000 --> 00:52:25.540
<v Speaker 3>It is, it is a textbook, uh, um, fallacy or no tragedy of the commons right there.

00:52:25.740 --> 00:52:25.880
<v Speaker 3>Right.

00:52:26.000 --> 00:52:32.600
<v Speaker 3>They rely entirely on PyPI and PyPI is run entirely with community resources, mostly

00:52:32.820 --> 00:52:38.220
<v Speaker 3>because of very, very generous and consistent, uh, sponsorship, basically by Fastly.

00:52:39.020 --> 00:52:41.940
<v Speaker 3>But also the other sponsors of the PSF.

00:52:43.660 --> 00:52:49.420
<v Speaker 3>And yet very large players use those resources more than anyone else

00:52:49.880 --> 00:52:51.500
<v Speaker 3>and don't actually contribute.

00:52:51.820 --> 00:52:55.700
<v Speaker 3>And I, yes, frustrating.

00:52:56.520 --> 00:53:01.040
<v Speaker 5>I mean, oh, it's okay, Jodi, go ahead.

00:53:01.820 --> 00:53:04.360
<v Speaker 4>I was going to say, Georgie Kerr,

00:53:04.840 --> 00:53:08.240
<v Speaker 4>she wrote this fantastic blog post saying pretty much this

00:53:08.260 --> 00:53:14.640
<v Speaker 4>straight after Europython. So Europython this year was really big actually. And she was wandering

00:53:14.840 --> 00:53:20.660
<v Speaker 4>around looking at the sponsor booths and the usual players were there, but none of these AI companies

00:53:20.750 --> 00:53:27.300
<v Speaker 4>were there. And the relationship actually between AI, if you want to call it that, let's call it ML

00:53:27.480 --> 00:53:33.080
<v Speaker 4>and neural networks and like some of the really big companies and Python actually is really complex.

00:53:33.280 --> 00:53:39.720
<v Speaker 4>Obviously, a lot of these companies and some of us are here employ people to work on Python.

00:53:40.790 --> 00:53:46.440
<v Speaker 4>Companies like Meta and Google have contributed massively to frameworks like PyTorch, TensorFlow,

00:53:47.140 --> 00:53:47.280
<v Speaker 4>Keras.

00:53:49.600 --> 00:53:53.280
<v Speaker 4>So it's not as simple a picture as saying cough up money all the time.

00:53:53.480 --> 00:53:55.300
<v Speaker 4>Like there's a more complex picture here.

00:53:55.500 --> 00:53:59.180
<v Speaker 4>But definitely there are some notable absences.

00:54:00.220 --> 00:54:06.700
<v Speaker 4>and we talked about the volume of money going through um i totally agree with the sentiment

00:54:06.860 --> 00:54:12.980
<v Speaker 4>like when when the shortfall came and the the grants um program had to shut down we were

00:54:13.120 --> 00:54:18.860
<v Speaker 4>brainstorming at jet brains like maybe we can do some sort of i don't know donate some more money

00:54:19.120 --> 00:54:24.600
<v Speaker 4>and call other companies to do it or we can call on people in the community and i was like i don't

00:54:24.700 --> 00:54:28.980
<v Speaker 4>want to call on people in the community to do it because they're probably the same people who are

00:54:28.880 --> 00:54:30.900
<v Speaker 4>also donating their time for Python.

00:54:31.230 --> 00:54:35.000
<v Speaker 4>Like, it's just squeezing people who give so much of themselves

00:54:35.260 --> 00:54:37.040
<v Speaker 4>to this community even more.

00:54:37.720 --> 00:54:38.840
<v Speaker 4>And it's not sustainable.

00:54:39.040 --> 00:54:40.780
<v Speaker 4>Like Reuben said, if we keep doing this,

00:54:41.360 --> 00:54:42.660
<v Speaker 4>the whole community is going to collapse.

00:54:43.640 --> 00:54:46.360
<v Speaker 4>Like, I'm sure we've all had our own forms of burnout

00:54:46.700 --> 00:54:47.640
<v Speaker 4>from giving too much.

00:54:49.260 --> 00:54:50.680
<v Speaker 5>Yeah, I mean, I want to say,

00:54:51.140 --> 00:54:52.500
<v Speaker 5>I'm going to pat ourselves on the back here.

00:54:52.540 --> 00:54:54.340
<v Speaker 5>Everyone on this call who works at a company

00:54:54.680 --> 00:54:57.380
<v Speaker 5>are all sponsors of the PSF, thank goodness.

00:54:58.380 --> 00:55:01.100
<v Speaker 5>But there's obviously a lot of people not on this call who are not sponsors.

00:55:01.480 --> 00:55:08.760
<v Speaker 5>And I know personally, I wished every company that generated revenue from Python usage donated to the PSF.

00:55:09.120 --> 00:55:13.760
<v Speaker 5>And I think part of the problem is some people think it has to be like $100,000 or something.

00:55:14.440 --> 00:55:15.600
<v Speaker 5>It does not have to be $100,000.

00:55:15.800 --> 00:55:19.040
<v Speaker 5>Now, if you can afford that amount, please do, or more.

00:55:19.540 --> 00:55:23.540
<v Speaker 5>There are many ways to donate more than the maximum amount for getting on the website.

00:55:25.220 --> 00:55:27.600
<v Speaker 5>But it's one of these funny things where a lot of people are just like,

00:55:27.600 --> 00:55:28.340
<v Speaker 5>oh, it's not me, right?

00:55:28.420 --> 00:55:29.700
<v Speaker 5>Like even startups don't.

00:55:30.520 --> 00:55:33.320
<v Speaker 5>Some do to give those ones credit, but others don't.

00:55:33.440 --> 00:55:35.760
<v Speaker 5>Because like, oh, we're burning through capital, blah, blah, blah.

00:55:35.800 --> 00:55:37.940
<v Speaker 5>I was like, yeah, but we're not.

00:55:38.280 --> 00:55:41.340
<v Speaker 5>We're asking for like less than you'd pay a dev, right?

00:55:41.440 --> 00:55:44.100
<v Speaker 5>By a lot per year, right?

00:55:44.260 --> 00:55:47.100
<v Speaker 5>Like the amount we actually asked for to get to the highest tier

00:55:47.200 --> 00:55:49.760
<v Speaker 5>is still less than a common developer in Silicon Valley

00:55:49.920 --> 00:55:54.360
<v Speaker 5>if we're going to price point to a geographical location

00:55:54.380 --> 00:56:00.940
<v Speaker 5>we call kind of comprehend right i'm gonna steal annette bachelder's observation here and yeah

00:56:01.600 --> 00:56:08.800
<v Speaker 3>what what the psf would be happy with is less than a medium company spends on the tips of expensed

00:56:09.040 --> 00:56:16.940
<v Speaker 5>meals every year yeah and yeah and it's a long-running problem right like i i mean i i've

00:56:17.460 --> 00:56:22.520
<v Speaker 5>been on the psf for a long time too i've not served as many years as uh thomas on the board

00:56:22.460 --> 00:56:27.040
<v Speaker 5>but I was like executive vice president because we had to have someone with that title at some point.

00:56:28.700 --> 00:56:31.100
<v Speaker 5>But it's always been a struggle, right?

00:56:32.100 --> 00:56:36.000
<v Speaker 5>And I also want to be clear, I'm totally appreciative of where we have gotten to, right?

00:56:36.140 --> 00:56:40.620
<v Speaker 5>Because for the longest time, I was just dying for paid staff on the core team.

00:56:40.740 --> 00:56:42.600
<v Speaker 5>And now we have three developers in presence.

00:56:43.280 --> 00:56:43.740
<v Speaker 5>Thank goodness.

00:56:44.140 --> 00:56:45.200
<v Speaker 5>Still not enough, to be clear.

00:56:45.320 --> 00:56:46.000
<v Speaker 5>I want five.

00:56:46.640 --> 00:56:48.940
<v Speaker 5>And I've always said that, but I'll happily take three.

00:56:49.620 --> 00:56:51.380
<v Speaker 5>But it's one of these things where it's a constant struggle.

00:56:51.440 --> 00:56:56.660
<v Speaker 5>It got a little bit better before the pandemic just because everyone was spending on conferences.

00:56:57.040 --> 00:56:59.600
<v Speaker 5>And PyCon US is a big driver for the Python Software Foundation.

00:57:00.240 --> 00:57:03.680
<v Speaker 5>And I know your Python is a driver for the European Society.

00:57:04.780 --> 00:57:07.640
<v Speaker 5>But then COVID hit and conferences haven't picked back up.

00:57:07.840 --> 00:57:16.000
<v Speaker 5>And then there's a whole new cohort of companies that have come in post-pandemic that have never had that experience of going to PyCon and sponsoring PyCon.

00:57:16.140 --> 00:57:20.620
<v Speaker 5>and so they don't think about i think sponsoring python or pi the psf because that's also a big

00:57:20.800 --> 00:57:25.360
<v Speaker 5>kind of in your face you should help sponsor this and i think it's led to this kind of lull where

00:57:26.000 --> 00:57:30.740
<v Speaker 5>offered spending has gone down new new entrants into the community have not had that experience

00:57:30.900 --> 00:57:35.880
<v Speaker 5>and thought about it and it's led to this kind of dearth where yeah that yes i've had to stop giving

00:57:35.890 --> 00:57:41.980
<v Speaker 5>out grant money and it sucks and i would love to see it not be that problem i want to add one

00:57:41.980 --> 00:57:44.120
<v Speaker 7>interesting data point that I discovered in preparing today.

00:57:44.120 --> 00:57:44.840
<v Speaker 7>Short, keep it short.

00:57:45.580 --> 00:57:45.680
<v Speaker 7>Yes.

00:57:46.820 --> 00:57:49.740
<v Speaker 7>NumFocus has about twice the budget of the PSF.

00:57:50.790 --> 00:57:52.580
<v Speaker 7>I was shocked to discover this.

00:57:54.020 --> 00:58:00.400
<v Speaker 7>So basically it is possible to get money from companies to sponsor development of Python-related

00:58:00.600 --> 00:58:00.920
<v Speaker 7>projects.

00:58:01.580 --> 00:58:03.580
<v Speaker 7>And I don't know what they're doing that we aren't.

00:58:04.760 --> 00:58:07.300
<v Speaker 7>And I think it's worth talking and figuring it out.

00:58:10.040 --> 00:58:15.140
<v Speaker 1>We need a fundraiser and marketer in residence, maybe.

00:58:15.460 --> 00:58:15.660
<v Speaker 1>Who knows?

00:58:17.220 --> 00:58:18.780
<v Speaker 1>Lauren does a good job, to be clear.

00:58:19.340 --> 00:58:19.660
<v Speaker 3>Who does?

00:58:19.800 --> 00:58:21.940
<v Speaker 3>The PSF has Lauren, and Lauren is that.

00:58:21.980 --> 00:58:22.120
<v Speaker 3>Okay.

00:58:22.360 --> 00:58:22.640
<v Speaker 3>Yes.

00:58:22.800 --> 00:58:22.960
<v Speaker 3>Okay.

00:58:24.560 --> 00:58:25.420
<v Speaker 5>But it's still hard.

00:58:25.960 --> 00:58:28.440
<v Speaker 5>We have someone doing a full-time at the PSF, and it's just hard to get.

00:58:29.260 --> 00:58:29.660
<v Speaker 5>Yeah, it is.

00:58:29.860 --> 00:58:31.300
<v Speaker 5>It's a good job, to be clear.

00:58:31.900 --> 00:58:33.180
<v Speaker 1>Yeah, and what do we get in return?

00:58:34.100 --> 00:58:35.220
<v Speaker 1>Well, we already get that, so.

00:58:35.680 --> 00:58:36.240
<v Speaker 1>Yeah, I know.

00:58:36.980 --> 00:58:37.740
<v Speaker 1>All right, Barry.

00:58:39.619 --> 00:58:52.140
<v Speaker 6>Yeah, I guess to just shift gears into a different area, something that I've been thinking a lot over this past year on the Steering Council.

00:58:52.460 --> 00:59:01.140
<v Speaker 6>Thomas, I'm sure, is going to be very well aware, having been instrumental in the lazy imports PEP A10.

00:59:04.520 --> 00:59:16.680
<v Speaker 6>We have to sort of rethink how we evolve Python and how we propose changes to Python and how we discuss those changes in the community.

00:59:16.740 --> 00:59:22.740
<v Speaker 6>because I think one of the things that I have heard over and over and over again

00:59:23.100 --> 00:59:32.300
<v Speaker 6>is that authoring PEPs is incredibly difficult and emotionally draining,

00:59:33.020 --> 00:59:34.460
<v Speaker 6>and it's a time sink.

00:59:37.400 --> 00:59:41.000
<v Speaker 6>And leading those discussions on discuss.python.org,

00:59:41.160 --> 00:59:49.660
<v Speaker 6>which we typically call DPO, can be toxic at times and very difficult. So one of the things that I

00:59:50.810 --> 00:59:58.980
<v Speaker 6>realized as I was thinking about this is that peps are 25 years old now, right? So we've had this,

00:59:59.180 --> 01:00:06.060
<v Speaker 6>and not only just peps are old, but like we've gone through at least two, if not more, sort of

01:00:06.080 --> 01:00:08.580
<v Speaker 6>complete revolutions in the way we discuss things.

01:00:08.840 --> 01:00:12.080
<v Speaker 6>You know, the community has grown incredibly.

01:00:12.850 --> 01:00:16.060
<v Speaker 6>The developer community is somewhat larger,

01:00:17.120 --> 01:00:19.740
<v Speaker 6>but just the number of people who are using Python

01:00:20.080 --> 01:00:24.540
<v Speaker 6>and who have an interest in it has grown exponentially.

01:00:24.980 --> 01:00:30.580
<v Speaker 6>So it has become really difficult to evolve the language

01:00:30.630 --> 01:00:32.440
<v Speaker 6>in the standard library and the interpreter.

01:00:33.120 --> 01:00:42.480
<v Speaker 6>And we need to sort of think about how we can make this easier for people and not lose the voice of the user.

01:00:42.900 --> 01:00:49.580
<v Speaker 6>And I mean, you know, the number of people who actually engage in topics on DPO is the tip of the iceberg.

01:00:49.770 --> 01:01:00.380
<v Speaker 6>You know, we've got millions and millions of users out there in the world who, for example, lazy imports will affect, free threading will affect and don't even know that they have a voice.

01:01:00.640 --> 01:01:04.020
<v Speaker 6>And maybe we have to basically represent that,

01:01:04.020 --> 01:01:07.740
<v Speaker 6>but we have to do it in a much more collaborative and positive way.

01:01:08.780 --> 01:01:11.040
<v Speaker 6>So that's something that I've been thinking about a lot.

01:01:11.180 --> 01:01:14.240
<v Speaker 6>And whether or not I'm on the steering council next year,

01:01:14.250 --> 01:01:17.160
<v Speaker 6>I think this is something that I'm going to spend some time on

01:01:17.490 --> 01:01:19.640
<v Speaker 6>trying to think about and talk to people about ways

01:01:19.640 --> 01:01:21.380
<v Speaker 6>we can make this easier for everyone.

01:01:22.440 --> 01:01:26.100
<v Speaker 1>The diversity of use cases for Python in the last couple of years.

01:01:26.200 --> 01:01:26.780
<v Speaker 6>So complex.

01:01:27.360 --> 01:01:28.060
<v Speaker 1>Yes, exactly.

01:01:29.160 --> 01:01:31.400
<v Speaker 5>It should also be prefaced that Barry created the pep process.

01:01:31.680 --> 01:01:33.000
<v Speaker 5>He should have started that one.

01:01:36.180 --> 01:01:37.560
<v Speaker 3>It is that old.

01:01:38.600 --> 01:01:38.740
<v Speaker 3>Yeah.

01:01:40.000 --> 01:01:41.480
<v Speaker 5>By the way, just so everyone knows,

01:01:41.620 --> 01:01:43.620
<v Speaker 5>these are not ages jokes to be mean to Barry.

01:01:44.100 --> 01:01:44.640
<v Speaker 5>No, no.

01:01:44.840 --> 01:01:46.120
<v Speaker 5>All of us have known Barry long enough

01:01:46.150 --> 01:01:48.560
<v Speaker 5>that we know Barry's okay with us making these jokes.

01:01:48.610 --> 01:01:49.560
<v Speaker 5>To be very, very, very old.

01:01:49.580 --> 01:01:51.560
<v Speaker 3>Also, I am almost as old as Barry,

01:01:51.790 --> 01:01:53.360
<v Speaker 3>although I don't look as old as Barry.

01:01:54.380 --> 01:01:55.800
<v Speaker 5>Yeah, we're all over the same age anyway.

01:01:57.920 --> 01:02:04.620
<v Speaker 3>Yeah, Barry and I have known each other for 25 years, and I've always made these jokes of him.

01:02:04.820 --> 01:02:10.240
<v Speaker 3>So it is different when you know each other in person, let's put it that way.

01:02:12.760 --> 01:02:20.060
<v Speaker 3>I think for the pep process, I think for a lot of people, it's not obvious how difficult the process is.

01:02:20.300 --> 01:02:21.760
<v Speaker 3>I mean, it wasn't even obvious to me.

01:02:23.520 --> 01:02:29.060
<v Speaker 3>I saw people avoiding writing peps multiple times and I was upset, like on the steering

01:02:29.250 --> 01:02:29.700
<v Speaker 3>council, right?

01:02:30.360 --> 01:02:34.460
<v Speaker 3>I saw people making changes where I thought this is definitely something that should have

01:02:34.460 --> 01:02:38.660
<v Speaker 3>been discussed in a pep and the discussion should be recorded in a pep and all that.

01:02:39.360 --> 01:02:44.680
<v Speaker 3>And I didn't understand why they didn't until basically until pep 810.

01:02:44.750 --> 01:02:52.920
<v Speaker 3>So I did pep 779, which was the, uh, giving free threading, um, uh, supported status at

01:02:52.940 --> 01:02:59.220
<v Speaker 3>the start of the year. And the discussion there was, you know, sort of as expected and it's already,

01:02:59.300 --> 01:03:03.100
<v Speaker 3>was already an accepted peb. It was just the question of how does it become supported?

01:03:03.780 --> 01:03:10.860
<v Speaker 3>That one wasn't too exhausting. And then we got to Lazy Imports, which was Pablo, who is

01:03:11.760 --> 01:03:17.240
<v Speaker 3>another steering council member, as well as a bunch of other contributors, including me and two of my

01:03:17.240 --> 01:03:22.200
<v Speaker 3>co-workers and one of my former co-workers, who had all had a lot of experience with Lazy Imports,

01:03:22.280 --> 01:03:25.300
<v Speaker 3>but not necessarily as much experience with the pep process.

01:03:26.280 --> 01:03:30.940
<v Speaker 3>And Pablo took the front seat because he knew the pep process and he's done

01:03:31.040 --> 01:03:34.740
<v Speaker 3>like five peps in the last year or something, some ridiculous number.

01:03:36.420 --> 01:03:43.640
<v Speaker 3>And he shared with us the vitriol he got for like offline for the, just the

01:03:43.980 --> 01:03:46.820
<v Speaker 3>audacity of proposing something that people disagreed with or something.

01:03:47.580 --> 01:03:51.860
<v Speaker 3>And that was like, this is a technical, technical, uh, suggestion.

01:03:52.140 --> 01:03:58.520
<v Speaker 3>This is not a code of conduct issue where I have received my fair share of vitriol around.

01:03:59.400 --> 01:04:05.920
<v Speaker 3>This is a technical discussion, and yet he gets these ridiculous accusations in his mailbox.

01:04:06.460 --> 01:04:12.360
<v Speaker 3>And for some reason, only the primary author gets it as well, which is just weird to me.

01:04:13.760 --> 01:04:15.180
<v Speaker 3>I'll point out something.

01:04:15.400 --> 01:04:18.300
<v Speaker 5>People are lazy, Thomas, is what I think you just said.

01:04:19.240 --> 01:04:28.660
<v Speaker 6>Remember, the steering council exists because Guido got the brunt of this for Pet 572, which was the walrus operator, right?

01:04:29.070 --> 01:04:34.620
<v Speaker 6>Which is just like this minor little syntactic thing that is kind of cool when you need it.

01:04:34.930 --> 01:04:48.120
<v Speaker 6>But like just the amount of anger and negative energy and vitriol that he got over that was enough for him to just say, I'm out, you know, and you guys figure it out.

01:04:48.220 --> 01:04:55.700
<v Speaker 6>And, and that's, that, that cannot be an acceptable way to, uh, discuss the evolution of the language.

01:04:56.220 --> 01:05:03.320
<v Speaker 3>Especially since apparently now every single pep author of, of any contentious or semi-contentious pep.

01:05:03.700 --> 01:05:07.100
<v Speaker 3>Although I have to say pep 810 had such broad support.

01:05:07.260 --> 01:05:09.200
<v Speaker 3>It was hard to call it contentious.

01:05:09.360 --> 01:05:12.660
<v Speaker 3>It's just, there's a couple of very loud opinions, I guess.

01:05:13.040 --> 01:05:15.540
<v Speaker 3>And, and I'm not saying we shouldn't listen to people.

01:05:15.620 --> 01:05:21.600
<v Speaker 3>We should definitely listen to, to especially contrary opinions, but there has to be a limit.

01:05:22.210 --> 01:05:25.360
<v Speaker 3>There has to be an acceptable way of bringing things up.

01:05:25.370 --> 01:05:30.380
<v Speaker 3>There has to be an acceptable way of saying, Hey, you didn't actually read the pep.

01:05:30.780 --> 01:05:36.360
<v Speaker 3>Please go back and reconsider everything you said after you fully digested the things,

01:05:36.840 --> 01:05:38.700
<v Speaker 3>because everything's already been addressed in the pep.

01:05:38.920 --> 01:05:47.520
<v Speaker 3>It's just really hard to do this in a way that doesn't destroy the relationship with the person you're telling this, right?

01:05:48.240 --> 01:05:54.300
<v Speaker 3>It's hard to tell people, hey, I'm not going to listen to you because you've done a bad job.

01:05:55.320 --> 01:05:57.000
<v Speaker 5>You've chosen not to inform yourself.

01:05:57.910 --> 01:05:58.040
<v Speaker 5>Yeah.

01:05:58.050 --> 01:06:08.100
<v Speaker 6>And I think you make another really strong point, Thomas, which is that there have been changes that have been made to Python that really should have been a pep.

01:06:08.460 --> 01:06:24.200
<v Speaker 6>And they aren't because people don't want to go through core developers don't want to go through this gauntlet. And so they'll create a PR and then that but that's also not good because then, you know, we don't have that we don't have the right level of consideration.

01:06:24.240 --> 01:06:27.260
<v Speaker 6>and you think about the way that, you know,

01:06:27.400 --> 01:06:28.220
<v Speaker 6>if you're in your job

01:06:28.340 --> 01:06:30.700
<v Speaker 6>and you're making a change to something in your job,

01:06:30.880 --> 01:06:34.040
<v Speaker 6>you have a very close relationship to your teammates.

01:06:34.380 --> 01:06:36.200
<v Speaker 6>And so you have that kind of respect

01:06:36.600 --> 01:06:38.260
<v Speaker 6>and hopefully, right,

01:06:38.580 --> 01:06:40.400
<v Speaker 6>like compassion and consideration

01:06:41.020 --> 01:06:45.000
<v Speaker 6>and you can have a very productive discussion about a thing

01:06:45.240 --> 01:06:46.600
<v Speaker 6>and you may win some arguments

01:06:46.800 --> 01:06:47.840
<v Speaker 6>and you may lose some arguments,

01:06:48.060 --> 01:06:50.160
<v Speaker 6>but the team moves forward as one.

01:06:50.420 --> 01:06:53.060
<v Speaker 6>And I think we've lost a bit of that in Python.

01:06:53.640 --> 01:07:13.940
<v Speaker 1>Yeah, that's not great. I think society in general could use a little more civility and kindness, especially to strangers that they haven't met in forums, social media, driving, you name it. Okay, but we're not going to solve that here, I'm sure. So instead, let's do Gregory's topic.

01:07:14.780 --> 01:07:21.900
<v Speaker 2>Hey, I'm going to change topics quite a bit, but I wanted to call 2025 the year of type checking and language server protocols.

01:07:22.980 --> 01:07:32.180
<v Speaker 2>So many of us probably have used tools like MyPy to check to see if the types line up in our code or whether or not we happen to be overriding functions correctly.

01:07:32.980 --> 01:07:38.720
<v Speaker 2>And so I've used MyPy for many years and loved the tool and had a great opportunity to chat with the creator of it.

01:07:39.300 --> 01:07:42.960
<v Speaker 2>And I integrate that into my CI and it's really been wonderful.

01:07:43.280 --> 01:07:47.740
<v Speaker 2>And I've also been using a lot of LSPs, like, for example, Pyrite or PyLance.

01:07:48.420 --> 01:07:53.360
<v Speaker 2>But in this year, one of the things that we've seen is, number one, Pyrefly from the team at Meta.

01:07:53.940 --> 01:07:56.420
<v Speaker 2>We've also seen TY from the team at Astral.

01:07:56.920 --> 01:07:58.540
<v Speaker 2>And there's another one called Zubon.

01:07:59.020 --> 01:08:00.700
<v Speaker 2>And Zubon is from David Halter.

01:08:01.260 --> 01:08:07.780
<v Speaker 2>David was also the person who created JEDI, which is another system in Python that helped with a lot of LSP tasks.

01:08:08.340 --> 01:08:22.200
<v Speaker 2>What's interesting about all three of the tools that I just mentioned is that they're implemented in Rust, and they have taken a lot of the opportunity to make the type checker and or the LSP significantly faster.

01:08:22.920 --> 01:08:46.380
<v Speaker 2>So for me, this has changed how I use the LSP or the type checker and how frequently I use it. And in my experience, it has helped me to take things that might take tens of seconds or hundreds of seconds and cut them down often to less than a second. And it's really changed the way in which I'm using a lot of the tools like TY or Pyrefly or Zubon.

01:08:46.859 --> 01:08:54.680
<v Speaker 2>So I can have some more details if I'm allowed to share, Michael, but I would say 2025 is the year of type checkers and LSPs.

01:08:54.880 --> 01:08:57.460
<v Speaker 1>I think given the timing, let's have people give some feedback.

01:08:57.759 --> 01:09:01.859
<v Speaker 1>I personally have been using Pyrefly a ton and am a big fan of it.

01:09:03.560 --> 01:09:03.680
<v Speaker 1>Yeah.

01:09:06.660 --> 01:09:07.120
<v Speaker 3>Yeah, I mean.

01:09:07.339 --> 01:09:11.400
<v Speaker 3>I don't know if I'm allowed to have an opinion that isn't Pyrefly is awesome.

01:09:12.700 --> 01:09:17.680
<v Speaker 3>I mean, I'm not on the Pyrefly team, but I do regularly chat with people from the Pyrefly team.

01:09:18.339 --> 01:09:19.920
<v Speaker 1>Tell people real quick what it is, Thomas.

01:09:20.660 --> 01:09:25.540
<v Speaker 3>So Pyrefly is Meta's attempt at a Rust-based type checker.

01:09:26.600 --> 01:09:28.400
<v Speaker 3>And it's very similar to TY.

01:09:28.920 --> 01:09:31.700
<v Speaker 3>Started basically at the same time, a little later.

01:09:32.740 --> 01:09:37.020
<v Speaker 3>Meta originally had a type checker called Pyre, which was written in OCaml.

01:09:39.200 --> 01:09:47.180
<v Speaker 3>They basically decided to start a rewrite in Rust, and then that really took off, and that's where we're going now.

01:09:50.600 --> 01:09:54.560
<v Speaker 5>Yeah, I don't know what I can say because I'm actually on the same team as the PyLens team.

01:09:56.720 --> 01:09:58.460
<v Speaker 5>But no, I mean, I think it's good.

01:09:58.580 --> 01:10:03.260
<v Speaker 5>I think this is one of those interesting scenarios where some people realize, like, you know what?

01:10:03.620 --> 01:10:13.020
<v Speaker 5>We're going to pay the penalty of writing a tool in a way that's faster, but makes us go slower because the overall win for the community is going to be a good win.

01:10:13.070 --> 01:10:14.160
<v Speaker 5>So it's worth that headache.

01:10:14.600 --> 01:10:14.680
<v Speaker 5>Right.

01:10:15.020 --> 01:10:20.620
<v Speaker 5>Not to say I don't want to scare people off from writing Rust, but let's be honest, it takes more work to write Rust code than it does take to write Python code.

01:10:22.640 --> 01:10:25.800
<v Speaker 5>But some people chose to make that trade off and we're all benefiting from it.

01:10:27.340 --> 01:10:32.520
<v Speaker 5>The one thing I will say that's kind of interesting from this that hasn't gotten a lot of play yet because it's still being developed.

01:10:32.600 --> 01:10:39.640
<v Speaker 5>but um pylance is actually working with the powerfly team uh to define a type server protocol tsp

01:10:40.380 --> 01:10:45.060
<v Speaker 5>so that a lot of these type servers can just kind of feed the type information to a higher level lsp

01:10:45.260 --> 01:10:49.580
<v Speaker 5>and let that lsp handle the stuff like symbol renaming and all that stuff right because

01:10:50.380 --> 01:10:55.640
<v Speaker 5>the the key the key thing here the the and the reason there's so many different type checkers is

01:10:55.800 --> 01:10:59.700
<v Speaker 5>there are there is a spec right and everyone's trying to implement it but there's differences

01:10:59.720 --> 01:11:01.360
<v Speaker 5>like in terms of type inferencing.

01:11:01.600 --> 01:11:04.480
<v Speaker 5>And if I actually go listen to Michael's interview

01:11:05.080 --> 01:11:07.300
<v Speaker 5>from Talk Python to me with the Pyrefly team,

01:11:07.400 --> 01:11:08.880
<v Speaker 5>they actually did a nice little explanation

01:11:09.000 --> 01:11:10.780
<v Speaker 5>of the difference between Pyrites' approach

01:11:11.540 --> 01:11:12.780
<v Speaker 5>and Pyrefly's approach.

01:11:13.360 --> 01:11:14.320
<v Speaker 5>And so there's a bit of variance.

01:11:14.580 --> 01:11:17.680
<v Speaker 5>But for instance, I think there's some talk now

01:11:17.880 --> 01:11:19.040
<v Speaker 5>of trying to like, how do we make it

01:11:19.040 --> 01:11:20.060
<v Speaker 5>so everyone doesn't have to reimplement

01:11:20.180 --> 01:11:21.580
<v Speaker 5>how to rename a symbol, right?

01:11:21.620 --> 01:11:22.200
<v Speaker 5>That's kind of boring.

01:11:22.360 --> 01:11:23.820
<v Speaker 5>That's not where the interesting work is.

01:11:24.080 --> 01:11:26.460
<v Speaker 5>And that's not performant from perspective of

01:11:27.000 --> 01:11:29.680
<v Speaker 5>you want instantaneously to get that squiggly red line

01:11:29.680 --> 01:11:33.880
<v Speaker 5>in whether it's VS Code or it's in PyCharm

01:11:33.940 --> 01:11:35.220
<v Speaker 5>or whatever your editor is, right?

01:11:35.520 --> 01:11:37.480
<v Speaker 5>You want to get it as fast as possible,

01:11:37.660 --> 01:11:38.340
<v Speaker 5>but the rename...

01:11:38.340 --> 01:11:38.680
<v Speaker 3>Jupyter.

01:11:39.740 --> 01:11:40.100
<v Speaker 5>Jupyter.

01:11:40.620 --> 01:11:40.700
<v Speaker 5>What?

01:11:41.880 --> 01:11:42.040
<v Speaker 5>What?

01:11:42.220 --> 01:11:42.860
<v Speaker 5>No, not Emacs.

01:11:43.100 --> 01:11:43.340
<v Speaker 6>What's that?

01:11:43.740 --> 01:11:44.320
<v Speaker 6>No, not Emacs.

01:11:46.140 --> 01:11:47.620
<v Speaker 6>But, you know, just to...

01:11:47.960 --> 01:11:48.300
<v Speaker 6>Oh, sorry.

01:11:49.020 --> 01:11:50.240
<v Speaker 6>Just to bring things full circle,

01:11:51.340 --> 01:11:54.160
<v Speaker 6>it's that focus on user experience, right?

01:11:54.340 --> 01:11:56.500
<v Speaker 6>Which is, yes, you want that squiggly line,

01:11:56.880 --> 01:11:58.080
<v Speaker 6>but when things go wrong,

01:11:58.640 --> 01:11:59.560
<v Speaker 6>when your type checker says,

01:11:59.640 --> 01:12:08.060
<v Speaker 6>oh, you've got a problem, you know, like I think about as an analogy, how Pablo has done an amazing

01:12:08.260 --> 01:12:15.820
<v Speaker 6>amount of work on the error reporting, right? When you get an exception and, you know, now you have a

01:12:16.000 --> 01:12:22.780
<v Speaker 6>lot more clues about what is it that I actually have to change to make the tool, you know, to make,

01:12:23.100 --> 01:12:29.600
<v Speaker 6>to fix the problem, right? Like so many times years ago, you know, when people were using MyPy

01:12:29.620 --> 01:12:36.480
<v Speaker 6>example, and they'd have some complex failure of their type annotations and have absolutely

01:12:36.560 --> 01:12:38.660
<v Speaker 6>no idea what to do about it.

01:12:38.960 --> 01:12:43.560
<v Speaker 6>And so getting to a place where now we're not just telling people you've done it wrong,

01:12:44.100 --> 01:12:47.780
<v Speaker 6>but also here's some ideas about how to fix it.

01:12:53.380 --> 01:12:59.580
<v Speaker 1>I think this is a full circle here because honestly, using typing in your Python code

01:12:59.600 --> 01:13:02.980
<v Speaker 1>lot of context to the AI when you ask for help if you just give it a fragment.

01:13:05.660 --> 01:13:12.700
<v Speaker 2>That's true. And also, if you can teach your AI agent to use the type checkers and use the LSPs,

01:13:13.080 --> 01:13:18.180
<v Speaker 2>it will also generate better code for you. I think the one challenge I would add to what

01:13:18.360 --> 01:13:23.140
<v Speaker 2>Barry said a moment ago is that if you're a developer and you're using, say, three or four

01:13:23.360 --> 01:13:28.580
<v Speaker 2>type checkers at the same time, you also have to be careful about the fact that some of them

01:13:28.600 --> 01:13:31.560
<v Speaker 2>won't flag an error that the other one will flag.

01:13:32.180 --> 01:13:34.680
<v Speaker 2>So I've recently written Python programs

01:13:34.810 --> 01:13:37.900
<v Speaker 2>and even built a tool with one of my students named Benedek

01:13:38.340 --> 01:13:41.220
<v Speaker 2>that will automatically generate Python programs

01:13:41.520 --> 01:13:43.960
<v Speaker 2>that will cause type checkers to disagree with each other.

01:13:46.940 --> 01:13:49.080
<v Speaker 2>MyPy will flag it as an error,

01:13:50.020 --> 01:13:52.920
<v Speaker 2>but none of the other tools will flag it as an error.

01:13:53.480 --> 01:13:55.600
<v Speaker 2>And there are also cases where the new tools

01:13:55.780 --> 01:13:58.440
<v Speaker 2>will all agree with each other but disagree with MyPy.

01:13:58.960 --> 01:14:01.860
<v Speaker 2>So there is a type checker conformance test suite.

01:14:02.250 --> 01:14:12.200
<v Speaker 2>But I think as developers, even though it might be the year of LSP and type checker, we also have to be aware of the fact that these tools are maturing and there's still disagreement among them.

01:14:12.680 --> 01:14:17.140
<v Speaker 2>And also just different philosophies when it comes to how to type check and how to infer.

01:14:17.740 --> 01:14:21.800
<v Speaker 2>And so we have to think about all of those things as these tools mature and become part of our ecosystem.

01:14:22.380 --> 01:14:23.960
<v Speaker 2>Yeah, Greg, that last point is important.

01:14:24.340 --> 01:14:24.700
<v Speaker 1>Sorry, go ahead.

01:14:25.060 --> 01:14:36.560
<v Speaker 3>Out of curiosity, how did the things where the type checkers disagree match up with the actual runtime behavior of Python? Was it like false positives or false negatives?

01:14:37.740 --> 01:14:56.900
<v Speaker 2>That's a really good question. I'll give you more details in the show notes because we actually have it in a GitHub repository and I can share it with people. But I think some of it might simply be related to cases where MyPy is more conformant to the spec, but the other new tools are not as conformant.

01:14:57.300 --> 01:15:02.280
<v Speaker 2>So like you can import overload from typing and then have a very overloaded function.

01:15:03.040 --> 01:15:14.720
<v Speaker 2>And MyPy will actually flag the fact that it's an overloaded function with multiple signatures, whereas PyRite and Pyrefly and Zubon actually flag that even though they should.

01:15:16.800 --> 01:15:19.680
<v Speaker 1>Yeah, another big area is optional versus not optional.

01:15:20.300 --> 01:15:26.240
<v Speaker 1>Like, are you allowed to pass a thing that is an optional string when the thing accepts a string?

01:15:26.340 --> 01:15:29.260
<v Speaker 1>some stuff's like, yeah, it's probably fine. Others are like, no, no, no, this is an error

01:15:29.310 --> 01:15:34.140
<v Speaker 1>that you have to do a check. And if you want to switch type checkers, you might end up with a

01:15:34.200 --> 01:15:39.680
<v Speaker 1>thousand warnings that you didn't previously had because of an intentional difference of opinion

01:15:39.770 --> 01:15:44.140
<v Speaker 1>on how strict to be, I think. Yeah. So you have to think about false positives and false negatives

01:15:45.000 --> 01:15:48.980
<v Speaker 2>when you're willing to break the build because of a type error. All of those things are things you

01:15:49.030 --> 01:15:54.100
<v Speaker 2>have to factor in. But to go quickly to this connection to AI, I know it's only recently,

01:15:54.300 --> 01:16:00.440
<v Speaker 2>But the Pyrefly team actually announced that they're making Pyrefly work directly with Pydantic AI.

01:16:01.100 --> 01:16:12.520
<v Speaker 2>So there's going to be an interoperability between those tools so that when you're building an AI agent using Pydantic AI, you can also then have better guarantees when you're using Pyrefly as your type checker.

01:16:13.080 --> 01:16:26.940
<v Speaker 4>It makes total sense, though, because then the reasoning LLM that's at the core of the agent can actually have that information before it tries to execute the code and you don't get in that loop that they often get in.

01:16:28.100 --> 01:16:29.460
<v Speaker 4>It can correct it before it runs.

01:16:30.100 --> 01:16:31.100
<v Speaker 2>Yeah, really good point.

01:16:32.060 --> 01:16:36.460
<v Speaker 7>I want to just sort of express my appreciation to all the people working on this typing stuff.

01:16:37.040 --> 01:16:40.300
<v Speaker 7>As someone who's come from many, many years in dynamic languages,

01:16:40.860 --> 01:16:42.980
<v Speaker 7>and I was always like, oh, typing.

01:16:43.440 --> 01:16:45.700
<v Speaker 7>Those silly people, those statically type languages.

01:16:47.180 --> 01:16:51.480
<v Speaker 7>And I see, A, I appreciate the value.

01:16:52.120 --> 01:16:57.660
<v Speaker 7>B, I love seeing how easy it is for people to ease into it when they're in Python.

01:16:57.790 --> 01:16:58.840
<v Speaker 7>It's not all or nothing.

01:16:59.880 --> 01:17:02.820
<v Speaker 7>C, I love the huge number of tools.

01:17:02.950 --> 01:17:05.760
<v Speaker 7>The competition in this space is really exciting.

01:17:06.240 --> 01:17:08.200
<v Speaker 7>And D, guess what?

01:17:08.330 --> 01:17:09.360
<v Speaker 7>It really, really does help.

01:17:09.740 --> 01:17:10.440
<v Speaker 7>And I'll even add an E,

01:17:10.600 --> 01:17:13.740
<v Speaker 7>which is my students who come from Java, C++, C Sharp,

01:17:13.750 --> 01:17:15.500
<v Speaker 7>and so forth, feel relief.

01:17:16.360 --> 01:17:18.540
<v Speaker 7>They find that without type checking,

01:17:19.080 --> 01:17:21.520
<v Speaker 7>it's like doing a trapeze act without a safety net.

01:17:21.920 --> 01:17:25.980
<v Speaker 7>And so they're very happy to have that typing in there,

01:17:26.200 --> 01:17:26.700
<v Speaker 7>typings in there.

01:17:27.140 --> 01:17:28.520
<v Speaker 7>So kudos to everyone.

01:17:29.320 --> 01:17:29.500
<v Speaker 1>Yeah.

01:17:30.340 --> 01:17:30.700
<v Speaker 1>All right, folks.

01:17:30.880 --> 01:17:31.500
<v Speaker 1>We are out of time.

01:17:31.780 --> 01:17:33.920
<v Speaker 1>This could literally go for hours longer.

01:17:35.520 --> 01:17:36.300
<v Speaker 1>It was a big year.

01:17:36.720 --> 01:17:37.720
<v Speaker 1>It was a big year.

01:17:37.860 --> 01:17:40.960
<v Speaker 1>But I think we need to just have a final word.

01:17:42.960 --> 01:17:44.540
<v Speaker 1>I'll start and we'll just go around.

01:17:45.000 --> 01:17:51.820
<v Speaker 1>So my final thought here is we've talked about some things that are negatives or sort of downers or whatever here and there.

01:17:52.940 --> 01:17:58.760
<v Speaker 1>But I still think it's an incredibly exciting time to be a developer, data scientist.

01:17:59.020 --> 01:18:00.500
<v Speaker 1>There's so much opportunity out there.

01:18:01.080 --> 01:18:04.020
<v Speaker 1>There's so many things to learn and take advantage of and stay on top of.

01:18:05.660 --> 01:18:11.140
<v Speaker 1>amazing. Every day is slightly more amazing than the previous day. So I love it. Gregory,

01:18:11.340 --> 01:18:15.400
<v Speaker 1>let's go to you next. Let's go around the circle. Yeah, I wanted to give a shout out to all of the

01:18:15.700 --> 01:18:21.180
<v Speaker 2>local Python conferences. I actually, on a regular basis, have attended the PyOhio conference,

01:18:21.920 --> 01:18:28.040
<v Speaker 2>and it is incredible. The organizers do an absolutely amazing job, and they have it hosted

01:18:28.060 --> 01:18:33.840
<v Speaker 2>on a campus, oftentimes at Ohio State or Cleveland State University. And incredibly,

01:18:34.160 --> 01:18:40.240
<v Speaker 2>PyOhio is a free conference that anyone can attend with no registration fee. So Michael,

01:18:40.480 --> 01:18:45.320
<v Speaker 2>on a comment that I think is really positive, wow, I'm so excited about the regional Python

01:18:45.720 --> 01:18:57.260
<v Speaker 3>conferences that I've been able to attend. Thomas. Wow, I didn't expect this. So I think

01:18:57.840 --> 01:19:03.840
<v Speaker 3>I think I want to give a shout out to new people joining the community and also joining just core

01:19:04.000 --> 01:19:08.680
<v Speaker 3>developer team as triagers or it's just drive by commenters. I know we harped a little bit about

01:19:09.000 --> 01:19:15.340
<v Speaker 3>people, you know, giving strong opinions and discussions, but we, we, I always look to the

01:19:15.520 --> 01:19:20.440
<v Speaker 3>far future as well as the near future. And we always need new people. We need new ideas. We

01:19:20.560 --> 01:19:27.140
<v Speaker 3>need new opinions. So yeah, I'm, I'm excited that there's still people joining and signing up and

01:19:27.160 --> 01:19:29.480
<v Speaker 3>And even when it's thankless work,

01:19:30.760 --> 01:19:32.400
<v Speaker 3>so I guess I want to say thank you to people

01:19:33.000 --> 01:19:34.320
<v Speaker 3>doing all the thankless work.

01:19:36.360 --> 01:19:36.580
<v Speaker 3>Jodi.

01:19:37.780 --> 01:19:43.360
<v Speaker 4>Yeah, I want to say this is actually really only my third year or so

01:19:43.780 --> 01:19:45.200
<v Speaker 4>really in the Python community.

01:19:45.460 --> 01:19:47.700
<v Speaker 4>So before that, I was just sort of on the fringes, right?

01:19:47.900 --> 01:19:49.260
<v Speaker 4>And after I started advocacy,

01:19:49.520 --> 01:19:51.600
<v Speaker 4>I started going to the conferences and meeting people.

01:19:52.560 --> 01:19:57.120
<v Speaker 4>And I think I didn't kind of get how special the community was

01:19:57.140 --> 01:19:59.160
<v Speaker 4>until I watched the Python documentary this year.

01:19:59.520 --> 01:20:02.160
<v Speaker 4>And I talked to Paul about this, Paul Everett afterwards,

01:20:02.840 --> 01:20:06.620
<v Speaker 4>also made fun of him for his like early 2000s fashion.

01:20:06.960 --> 01:20:14.660
<v Speaker 4>But I think I'm a relative newcomer to this community

01:20:14.900 --> 01:20:16.460
<v Speaker 4>and you've all made me feel so welcome.

01:20:16.780 --> 01:20:19.620
<v Speaker 4>And I guess I want to thank all the incumbents

01:20:20.520 --> 01:20:22.180
<v Speaker 4>for everything you've done to make this

01:20:22.320 --> 01:20:26.620
<v Speaker 4>such a special tech community for minorities and everyone,

01:20:27.000 --> 01:20:29.640
<v Speaker 4>newbies, you know, Python is love.

01:20:33.160 --> 01:20:34.760
<v Speaker 5>Oh, geez, how am I supposed to follow that?

01:20:35.860 --> 01:20:36.860
<v Speaker 5>A little tear.

01:20:42.020 --> 01:20:44.320
<v Speaker 5>Yeah, I think one of the interesting things

01:20:45.100 --> 01:20:47.680
<v Speaker 5>that we're kind of looping on here is

01:20:48.680 --> 01:20:50.660
<v Speaker 5>I think the language evolution has slowed down,

01:20:50.800 --> 01:20:52.240
<v Speaker 5>but it's obviously not stopped, right?

01:20:52.340 --> 01:20:53.360
<v Speaker 5>Like as Thomas pointed out,

01:20:53.820 --> 01:20:55.480
<v Speaker 5>there's a lot more stuff happening behind the scenes.

01:20:56.400 --> 01:20:58.360
<v Speaker 5>lazy imports are coming and that was the syntactic change,

01:20:58.480 --> 01:21:00.220
<v Speaker 5>which apparently brings out the,

01:21:00.380 --> 01:21:00.500
<v Speaker 5>the,

01:21:00.600 --> 01:21:02.200
<v Speaker 5>the mean side of some people.

01:21:03.080 --> 01:21:03.400
<v Speaker 5>Um,

01:21:03.980 --> 01:21:05.760
<v Speaker 5>and we've obviously got our challenge and stuff,

01:21:06.040 --> 01:21:06.900
<v Speaker 5>but things are still going.

01:21:07.080 --> 01:21:08.380
<v Speaker 5>We're still chugging along.

01:21:08.560 --> 01:21:09.820
<v Speaker 5>We're still trying to be an open,

01:21:09.980 --> 01:21:14.220
<v Speaker 5>welcoming place for people like Jody and everyone else who's new coming on

01:21:14.360 --> 01:21:18.600
<v Speaker 5>over and continue to be a fun place for all of us slightly grain beard

01:21:18.860 --> 01:21:21.700
<v Speaker 5>people who have been here for a long time to make us want to stick around.

01:21:22.800 --> 01:21:23.080
<v Speaker 5>Um,

01:21:24.280 --> 01:21:24.620
<v Speaker 5>so yeah,

01:21:24.640 --> 01:21:24.780
<v Speaker 5>I,

01:21:24.900 --> 01:21:25.080
<v Speaker 5>I,

01:21:25.100 --> 01:21:30.580
<v Speaker 5>i think it's just more more the same honestly it's all of us just continuing to do what we

01:21:31.080 --> 01:21:36.760
<v Speaker 5>can to help out to keep this community being a great place and it all just keeps going forward

01:21:36.960 --> 01:21:41.160
<v Speaker 5>and i'll just end with if you work for a company that's not sponsoring the psf please do so

01:21:46.640 --> 01:21:54.780
<v Speaker 7>Um, so it's, it's rare to have, I mean, a programming language or any sort of tool

01:21:55.800 --> 01:22:01.900
<v Speaker 7>where it is both really, really beneficial to your career and you get to hang out with really

01:22:02.380 --> 01:22:08.720
<v Speaker 7>special, nice, interesting people. Um, and it's easy to take all that for granted. If you've been

01:22:08.920 --> 01:22:13.640
<v Speaker 7>steeped in the community, I went to a conference about six months ago, a non Python conference,

01:22:14.440 --> 01:22:20.160
<v Speaker 7>and that was shocking to me to discover that all the speakers were from advertisers and sponsors.

01:22:21.220 --> 01:22:25.700
<v Speaker 7>Everything was super commercialized. People were not interested in just like hanging out and sharing

01:22:25.880 --> 01:22:30.560
<v Speaker 7>with each other. And it was a shock to me because I've been to basically only Python conferences for

01:22:30.560 --> 01:22:35.900
<v Speaker 7>so many years. I was like, oh, that's not the norm in the industry. So we've got something really

01:22:36.060 --> 01:22:40.659
<v Speaker 7>special going that not only is good for the people, but good for everyone's careers and mutually

01:22:40.680 --> 01:22:42.140
<v Speaker 7>reinforcing and helping each other.

01:22:42.800 --> 01:22:44.540
<v Speaker 7>And that's really fantastic.

01:22:44.570 --> 01:22:45.440
<v Speaker 7>And we should appreciate that.

01:22:46.900 --> 01:22:47.100
<v Speaker 1>Absolutely.

01:22:48.300 --> 01:22:49.180
<v Speaker 1>Barry, final word.

01:22:50.940 --> 01:22:53.560
<v Speaker 6>Well, Thomas stole my thunder just a little bit,

01:22:53.740 --> 01:22:56.580
<v Speaker 6>but just to tie a couple of these ideas together,

01:22:58.140 --> 01:23:01.600
<v Speaker 6>Python, and, you know, Brett said this, right?

01:23:01.800 --> 01:23:03.680
<v Speaker 6>This is Python is the community

01:23:03.910 --> 01:23:05.400
<v Speaker 6>or the community is Python.

01:23:06.100 --> 01:23:10.640
<v Speaker 6>There's no, you know, company that is telling anybody

01:23:10.680 --> 01:23:17.600
<v Speaker 6>what Python should be. Python is what we make it. And, you know, as folks like myself get a little

01:23:17.860 --> 01:23:27.140
<v Speaker 6>older and, you know, and we have younger people coming into the community, both developers and

01:23:27.500 --> 01:23:34.740
<v Speaker 6>everything else who are shaping Python into their vision, I encourage you, if you've thought about

01:23:34.960 --> 01:23:39.960
<v Speaker 6>becoming a core dev, find a mentor. There are people out there that will help you. If you want

01:23:39.980 --> 01:23:45.720
<v Speaker 6>to be involved in the community, the PSF, you know, reach out. There are people who will help

01:23:45.980 --> 01:23:53.580
<v Speaker 6>guide you into this community. You can be involved. Do not let any self-imposed limitations stop you

01:23:53.780 --> 01:24:01.480
<v Speaker 6>from becoming part of the Python community in the way that you want to. And eventually run for the

01:24:01.640 --> 01:24:08.700
<v Speaker 6>steering council because we need many, many, many more candidates next year. And you don't need any

01:24:08.720 --> 01:24:12.400
<v Speaker 3>qualifications either because I'm a high school dropout and I never went to

01:24:12.600 --> 01:24:14.680
<v Speaker 3>college or anything and look at me.

01:24:15.580 --> 01:24:15.900
<v Speaker 5>Amazing.

01:24:15.960 --> 01:24:19.040
<v Speaker 5>And I have a PhD and I'll tell you, I did not need all that to become a

01:24:19.140 --> 01:24:22.020
<v Speaker 5>Python developer because of the Python I've heard about before I got the PhD.

01:24:24.360 --> 01:24:25.520
<v Speaker 6>So I'm a bass player.

01:24:25.660 --> 01:24:27.120
<v Speaker 2>So if I can do it, anybody can do it.

01:24:30.180 --> 01:24:31.580
<v Speaker 1>Thank you everyone for being here.

01:24:32.020 --> 01:24:34.580
<v Speaker 1>This awesome look back in the air and I really appreciate you all taking the

01:24:34.660 --> 01:24:34.720
<v Speaker 1>time.

01:24:35.460 --> 01:24:35.880
<v Speaker 2>Thank you, Michael.

01:24:36.040 --> 01:24:36.180
<v Speaker 2>Thanks.

01:24:37.880 --> 01:24:38.360
<v Speaker 1>Thanks everybody.

01:24:38.800 --> 01:24:39.260
<v Speaker 2>Bye, everybody.

01:24:39.300 --> 01:24:39.840
<v Speaker 2>Good to see everybody.

01:24:40.260 --> 01:24:40.560
<v Speaker 2>I promise.

