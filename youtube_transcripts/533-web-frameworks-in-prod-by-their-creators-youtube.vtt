WEBVTT

00:00:03.399 --> 00:00:11.940
<v Michael Kennedy>Hello, hello, Carlton, Sebastian, David, Cody, Yannick, Phil, Jeff, welcome back to

00:00:12.040 --> 00:00:12.920
<v Michael Kennedy>Talk Python To Me, all of you.

00:00:13.920 --> 00:00:14.840
<v Michael Kennedy>Thanks for having us.

00:00:15.440 --> 00:00:16.820
<v Michael Kennedy>Yeah, it's...

00:00:20.140 --> 00:00:23.200
<v Michael Kennedy>We're here for what may be my favorite topic, for sure.

00:00:23.590 --> 00:00:29.380
<v Michael Kennedy>Something I spend most of my time on is web API stuff, which is awesome.

00:00:29.560 --> 00:00:37.200
<v Michael Kennedy>I'm so excited to have you here to give your inside look at how people should be running your framework,

00:00:38.480 --> 00:00:43.620
<v Michael Kennedy>at least the one that you significantly contribute to, depending on which framework we're talking about, right?

00:00:45.340 --> 00:00:50.420
<v Michael Kennedy>So it's going to be a lot of fun, and I'm really excited to talk about it.

00:00:50.620 --> 00:01:02.480
<v Michael Kennedy>However, there's an interesting fact that I've been throwing out a lot lately is that fully half of the people doing professional Python development have only been doing it for two years or less.

00:01:03.739 --> 00:01:05.280
<v Michael Kennedy>And some of you have been on the show.

00:01:05.360 --> 00:01:07.020
<v Michael Kennedy>It was maybe two years longer than that.

00:01:07.480 --> 00:01:12.000
<v Michael Kennedy>Let's just do a quick round of introductions for people who don't necessarily know you.

00:01:12.020 --> 00:01:14.380
<v Michael Kennedy>We'll go around the squares here in the screen sharing.

00:01:14.640 --> 00:01:15.820
<v Michael Kennedy>So Carlton, you're up first.

00:01:16.440 --> 00:01:17.380
<v Carlton Gibson>Oh, I get to go first.

00:01:17.600 --> 00:01:17.680
<v Carlton Gibson>Brilliant.

00:01:17.840 --> 00:01:18.800
<v Carlton Gibson>Well, I'm Carlton.

00:01:18.940 --> 00:01:21.540
<v Carlton Gibson>I work on the Django Red framework mostly.

00:01:21.740 --> 00:01:22.980
<v Carlton Gibson>I'm a former Django fellow.

00:01:23.090 --> 00:01:25.380
<v Carlton Gibson>I maintain a number of packages in the ecosystem.

00:01:25.640 --> 00:01:29.400
<v Carlton Gibson>And the last few years, I've been back to building stuff with Django rather than working on it.

00:01:29.870 --> 00:01:32.720
<v Carlton Gibson>So I run a build startup that's, well, we're still going.

00:01:32.790 --> 00:01:33.820
<v Carlton Gibson>So I'm quite excited about that.

00:01:34.759 --> 00:01:35.200
<v Michael Kennedy>Awesome.

00:01:35.720 --> 00:01:38.520
<v Michael Kennedy>How is it to be building with Django than building Django?

00:01:39.120 --> 00:01:42.000
<v Carlton Gibson>Oh, I'm literally having the time of my life.

00:01:42.180 --> 00:01:44.740
<v Carlton Gibson>I spent five years as a Django fellow working on Django.

00:01:45.160 --> 00:01:48.760
<v Carlton Gibson>And I just built up this backlog of things I wanted to do.

00:01:49.160 --> 00:01:53.580
<v Carlton Gibson>And I had no time and no capacity and no sort of nothing to work on with them.

00:01:53.640 --> 00:01:55.040
<v Carlton Gibson>And it's just a delight.

00:01:55.800 --> 00:01:59.760
<v Carlton Gibson>And every day I sit down on my computer thinking, oh, what's today?

00:01:59.920 --> 00:02:00.740
<v Carlton Gibson>I look at the background.

00:02:00.980 --> 00:02:01.440
<v Carlton Gibson>Oh, yes.

00:02:01.980 --> 00:02:03.820
<v Carlton Gibson>And every day a delight.

00:02:03.980 --> 00:02:06.520
<v Carlton Gibson>So I'm still just loving it.

00:02:06.780 --> 00:02:07.460
<v Michael Kennedy>That's awesome.

00:02:07.600 --> 00:02:14.160
<v Michael Kennedy>So more often you're appreciating your former self than cursing your former self for the way you built.

00:02:17.300 --> 00:02:21.260
<v Carlton Gibson>Yeah, that's an interesting one. I think we should move on before I have a chance.

00:02:21.280 --> 00:02:28.260
<v Michael Kennedy>All right. All right. Speaking of building with and for Sebastian, FastAPI. Hello.

00:02:29.280 --> 00:02:35.940
<v Sebastian Ramirez>Hello. Okay. Intro for the ones that don't know me. I'm Sebastian Ramirez. I created FastAPI.

00:02:36.580 --> 00:02:40.980
<v Sebastian Ramirez>Yeah, that's pretty much it. And now I have been building a company since the last two years,

00:02:41.000 --> 00:02:43.240
<v Sebastian Ramirez>FastAPI Cloud to deploy FastAPI.

00:02:43.250 --> 00:02:47.040
<v Sebastian Ramirez>So I get to drink from funny cups.

00:02:48.170 --> 00:02:49.660
<v Michael Kennedy>JOHN MUELLER: The world's best boss.

00:02:50.420 --> 00:02:50.860
<v Michael Kennedy>Amazing.

00:02:51.570 --> 00:02:54.020
<v Michael Kennedy>So I think you deserve to give a bit of a shout out

00:02:54.020 --> 00:02:55.020
<v Michael Kennedy>to FastAPI Cloud.

00:02:55.140 --> 00:02:55.640
<v Michael Kennedy>That's a big deal.

00:02:56.440 --> 00:02:57.100
<v Sebastian Ramirez>Thank you.

00:02:57.240 --> 00:02:57.860
<v Sebastian Ramirez>Thank you very much.

00:02:58.000 --> 00:02:59.220
<v Sebastian Ramirez>Yeah, it's super fun.

00:03:00.120 --> 00:03:03.000
<v Sebastian Ramirez>The idea is to make it super simple to deploy FastAPI

00:03:03.140 --> 00:03:03.460
<v Sebastian Ramirez>applications.

00:03:03.860 --> 00:03:06.120
<v Sebastian Ramirez>The idea with FastAPI was to make it very simple

00:03:06.380 --> 00:03:08.520
<v Sebastian Ramirez>to build applications, build APIs.

00:03:09.760 --> 00:03:14.300
<v Sebastian Ramirez>like get the idea from from idea to product in your record time.

00:03:14.400 --> 00:03:15.600
<v Sebastian Ramirez>That was the idea with FastAPI.

00:03:15.820 --> 00:03:19.560
<v Sebastian Ramirez>But then deploying that in many cases is just too conversant.

00:03:19.560 --> 00:03:20.280
<v Sebastian Ramirez>It's too complicated.

00:03:20.560 --> 00:03:22.000
<v Sebastian Ramirez>There are just so many things to learn.

00:03:22.480 --> 00:03:26.760
<v Sebastian Ramirez>So I wanted to bring something for people to be able to say like, hey, just one

00:03:26.860 --> 00:03:29.080
<v Sebastian Ramirez>command FastAPI deploy and we take care of the rest.

00:03:29.640 --> 00:03:33.760
<v Sebastian Ramirez>And then we and the team, I have an amazing thing that I've been able to work with.

00:03:34.400 --> 00:03:38.520
<v Sebastian Ramirez>We suffer all the cloud pain so that people don't have to deal with that.

00:03:38.640 --> 00:03:43.640
<v Sebastian Ramirez>And yeah, it's painful to build, but it's so cool to use it.

00:03:43.670 --> 00:03:47.220
<v Sebastian Ramirez>You know, like that's the part when I say like, yes, this was worth it.

00:03:47.290 --> 00:03:50.140
<v Sebastian Ramirez>When I get to use the thing myself, that is super cool.

00:03:50.720 --> 00:03:54.240
<v Michael Kennedy>Yeah, I'm assuming you build FastAPI Cloud with FastAPI somewhat.

00:03:55.240 --> 00:03:56.840
<v Sebastian Ramirez>Yes, yes, yes, exactly.

00:03:57.220 --> 00:03:59.120
<v Sebastian Ramirez>FastAPI Cloud runs on FastAPI Cloud.

00:03:59.780 --> 00:04:03.740
<v Sebastian Ramirez>And I get just to like now run random things in there and I'm like, yes.

00:04:05.920 --> 00:04:06.120
<v Michael Kennedy>Awesome.

00:04:06.920 --> 00:04:08.700
<v Michael Kennedy>Well, yeah, congrats to that again.

00:04:08.880 --> 00:04:09.400
<v Michael Kennedy>That's super cool.

00:04:10.120 --> 00:04:10.820
<v Michael Kennedy>David Lord, welcome.

00:04:11.200 --> 00:04:11.480
<v Michael Kennedy>Welcome back.

00:04:12.740 --> 00:04:13.240
<v David Lord>Yeah, hello.

00:04:14.480 --> 00:04:15.220
<v David Lord>I'm David Lord.

00:04:15.440 --> 00:04:32.220
<v David Lord>I'm the lead maintainer of Pallets, which is Flask, Jinja, Click, Perixote, It's Dangerous, Markup Safe, and now Pallets Eco, which is a bunch of the famous extensions for Flask that are getting community maintenance now.

00:04:34.360 --> 00:04:41.120
<v David Lord>I've been doing that since, I think I've been the lead maintainer since like 2019, but a maintainer since like 2017.

00:04:41.700 --> 00:04:42.360
<v David Lord>So it's been a while.

00:04:43.820 --> 00:04:46.760
<v Michael Kennedy>Yeah, that is, you know, that's been a while.

00:04:46.920 --> 00:04:49.240
<v Michael Kennedy>We're coming up on seven, eight years.

00:04:49.540 --> 00:04:49.900
<v Michael Kennedy>That's crazy.

00:04:51.440 --> 00:04:51.920
<v Michael Kennedy>Time flies.

00:04:51.960 --> 00:04:54.660
<v David Lord>It's always funny because I always feel like I've been doing it for way, way longer.

00:04:54.980 --> 00:04:57.720
<v David Lord>And then I look at like the actual date that I got added as a maintainer.

00:04:57.720 --> 00:04:59.040
<v David Lord>I'm like, well, it couldn't have been that late.

00:04:59.120 --> 00:05:00.320
<v David Lord>I was doing stuff before that, right?

00:05:01.620 --> 00:05:05.060
<v Michael Kennedy>I'm sure you're deep in Flask before you got added as a maintainer of it, right?

00:05:06.370 --> 00:05:06.500
<v David Lord>Yeah.

00:05:07.120 --> 00:05:07.900
<v Michael Kennedy>Yeah, yeah.

00:05:09.780 --> 00:05:15.520
<v Michael Kennedy>Let's say welcome to Phil Jones, since you are also on the same org.

00:05:15.980 --> 00:05:16.080
<v Michael Kennedy>Next.

00:05:16.700 --> 00:05:17.380
<v Michael Kennedy>Hey, welcome back.

00:05:18.020 --> 00:05:19.580
<v Phil Jones>Hello, yeah, I'm Phil Jones.

00:05:19.710 --> 00:05:23.320
<v Phil Jones>I am the author of Quart, which is also part of Palette.

00:05:23.720 --> 00:05:27.920
<v Phil Jones>I also work on Berkshagen and Flask and help out there.

00:05:28.820 --> 00:05:31.520
<v Phil Jones>And I've done a server called Hypercorn as well.

00:05:31.610 --> 00:05:34.900
<v Phil Jones>So a bit of interest in that part of the ecosystem.

00:05:36.620 --> 00:05:38.020
<v Phil Jones>So what is Quart for people who don't know?

00:05:38.880 --> 00:05:42.080
<v Phil Jones>So Quart is basically Flask with Async await.

00:05:42.580 --> 00:05:46.120
<v Phil Jones>And that was the idea behind it really to make it possible to do Async await.

00:05:47.000 --> 00:05:48.720
<v Phil Jones>So yeah, that's pretty much it.

00:05:48.720 --> 00:05:50.980
<v Phil Jones>If we only manage to merge them, we will.

00:05:52.040 --> 00:05:58.580
<v David Lord>And the goal now with Quart as part of Palettes is to eventually have it be one code base with Flask.

00:05:59.780 --> 00:06:04.300
<v David Lord>but given that we both have small children now we're moving a lot slower

00:06:06.360 --> 00:06:11.220
<v Michael Kennedy>having kids is great i have three kids productivity is not a thing that they are known to

00:06:12.240 --> 00:06:18.160
<v Michael Kennedy>imbue on the parents right especially in the early days i want to say phil thank you i've been

00:06:18.320 --> 00:06:23.940
<v Michael Kennedy>running court for a couple of my websites lately and it's been amazing nice yeah we i also use it

00:06:24.080 --> 00:06:28.640
<v Phil Jones>work we've got all our stuff in in court which is yeah it's really good fun a bit like yeah yeah

00:06:28.840 --> 00:06:33.340
<v Michael Kennedy>So when people, if they get, if they listen to the show or they go to the website of the

00:06:33.340 --> 00:06:36.440
<v Michael Kennedy>show and they're not on YouTube, then that somehow involves court.

00:06:37.420 --> 00:06:38.040
<v Michael Kennedy>Janek, welcome.

00:06:40.620 --> 00:06:40.740
<v Speaker 6>Hey.

00:06:41.940 --> 00:06:43.160
<v Speaker 6>Yeah, I'm Janek Nivertny.

00:06:43.260 --> 00:06:45.120
<v Speaker 6>I work on Litestar.

00:06:45.120 --> 00:06:48.140
<v Speaker 6>I just looked up how long it's been because I was curious myself.

00:06:49.540 --> 00:06:54.080
<v Speaker 6>I also had the same feeling that it's been a lot longer than, it's actually only been

00:06:54.320 --> 00:06:54.740
<v Speaker 6>three years.

00:06:56.140 --> 00:06:56.220
<v Speaker 6>Yeah.

00:06:56.620 --> 00:06:59.820
<v Speaker 6>And I also noticed something with all you guys here in the room.

00:07:00.160 --> 00:07:07.820
<v Speaker 6>I use almost all of the projects you maintain at work, which is quite nice.

00:07:07.880 --> 00:07:10.200
<v Speaker 6>We have a very big Django deployment.

00:07:10.360 --> 00:07:11.680
<v Speaker 6>We have some Flask deployments.

00:07:11.680 --> 00:07:13.300
<v Speaker 6>We have a few FastAPI deployments.

00:07:13.780 --> 00:07:18.080
<v Speaker 6>I think we have one core deployment, and we also have two Light Store deployments,

00:07:18.980 --> 00:07:21.480
<v Speaker 6>which obviously is a lot of fun to work with.

00:07:21.780 --> 00:07:27.760
<v Speaker 6>But I find it really nice actually to work with all these different things.

00:07:27.960 --> 00:07:32.080
<v Speaker 6>It's super interesting also because everything has its own niche

00:07:32.300 --> 00:07:34.440
<v Speaker 6>that it's really good at.

00:07:34.680 --> 00:07:38.860
<v Speaker 6>And even, you know, you think if you maintain a framework yourself,

00:07:40.000 --> 00:07:42.400
<v Speaker 6>you tend to always recommend it for everything.

00:07:43.200 --> 00:07:44.980
<v Speaker 6>But I noticed it's not actually true.

00:07:45.180 --> 00:07:49.100
<v Speaker 6>There's actually a few cases where I don't recommend Litestar.

00:07:49.380 --> 00:07:55.220
<v Speaker 6>recommend just use Django for this, or use Flask for that,

00:07:55.220 --> 00:07:59.600
<v Speaker 6>or use FastAPI for this, because they are quite different after all.

00:08:01.140 --> 00:08:05.420
<v Speaker 6>And I find that really interesting and nice.

00:08:05.440 --> 00:08:09.020
<v Speaker 6>And I think it's a good sign of a healthy ecosystem

00:08:09.460 --> 00:08:11.880
<v Speaker 6>if it's not just the same thing but different,

00:08:12.180 --> 00:08:14.520
<v Speaker 6>but it actually brings something very unique and different

00:08:14.520 --> 00:08:15.020
<v Speaker 6>to the table.

00:08:16.100 --> 00:08:18.500
<v Michael Kennedy>I think that's a great attitude.

00:08:18.780 --> 00:08:19.360
<v Michael Kennedy>It's very interesting.

00:08:19.760 --> 00:08:22.640
<v Michael Kennedy>You know, I feel like there's a lot of people who feel like

00:08:23.540 --> 00:08:26.100
<v Michael Kennedy>they've kind of got to pick their tech team for everything.

00:08:26.880 --> 00:08:28.100
<v Michael Kennedy>You know, I'm going to build a static site.

00:08:28.230 --> 00:08:30.360
<v Michael Kennedy>Like, well, I've got to have a Python-based static site.

00:08:30.500 --> 00:08:31.420
<v Michael Kennedy>Builder like, well, it's a static site.

00:08:31.450 --> 00:08:33.539
<v Michael Kennedy>Who cares what technology makes it turn--

00:08:33.900 --> 00:08:35.479
<v Michael Kennedy>you're writing Markdown, out comes HTML.

00:08:35.840 --> 00:08:37.479
<v Michael Kennedy>Who cares what's in the middle, for example, right?

00:08:38.080 --> 00:08:42.039
<v Michael Kennedy>And I feel like that's kind of a life lessons learned.

00:08:43.039 --> 00:08:43.539
<v Michael Kennedy>There, I did.

00:08:44.180 --> 00:08:44.900
<v Michael Kennedy>Yeah, that's awesome.

00:08:45.860 --> 00:08:46.140
<v Michael Kennedy>Cody.

00:08:47.140 --> 00:08:47.380
<v Michael Kennedy>Hello, hello.

00:08:48.180 --> 00:08:49.600
<v Cody Fincher>Yeah, hey guys, I'm Cody Fincher.

00:08:49.780 --> 00:08:51.380
<v Cody Fincher>I'm also one of the maintainers of Litestar.

00:08:51.680 --> 00:08:54.240
<v Cody Fincher>I've been there just a little bit longer than Yannick.

00:08:55.319 --> 00:08:57.220
<v Cody Fincher>And so it's been about four years now.

00:08:58.439 --> 00:09:00.240
<v Cody Fincher>And Yannick actually teed this up perfectly

00:09:00.260 --> 00:09:01.720
<v Cody Fincher>'cause I was gonna say something very similar.

00:09:02.120 --> 00:09:03.180
<v Cody Fincher>I currently work for Google.

00:09:03.280 --> 00:09:04.800
<v Cody Fincher>I've been there for about three and a half years now.

00:09:05.080 --> 00:09:07.840
<v Cody Fincher>And we literally have every one of the frameworks

00:09:07.920 --> 00:09:09.820
<v Cody Fincher>you guys just mentioned, and they're all in production.

00:09:10.040 --> 00:09:14.620
<v Cody Fincher>And so one of the things that you'll see on the Litestar org

00:09:14.780 --> 00:09:16.439
<v Cody Fincher>and part of the projects that we maintain

00:09:16.460 --> 00:09:18.380
<v Cody Fincher>that we have these optional batteries

00:09:18.720 --> 00:09:20.500
<v Cody Fincher>and most of the batteries that we have

00:09:20.700 --> 00:09:22.680
<v Cody Fincher>all work with the frameworks for you guys.

00:09:22.790 --> 00:09:26.360
<v Cody Fincher>And so it's nice to be able to use that stuff,

00:09:26.650 --> 00:09:29.120
<v Cody Fincher>you know, regardless of what tooling you've got

00:09:29.280 --> 00:09:31.100
<v Cody Fincher>or what, you know, what project it is.

00:09:31.130 --> 00:09:34.080
<v Cody Fincher>And so, yeah, having that interoperability

00:09:34.340 --> 00:09:36.080
<v Cody Fincher>and the ability to kind of go between the frameworks

00:09:36.320 --> 00:09:38.740
<v Cody Fincher>that work the best for the right situation is crucial.

00:09:38.870 --> 00:09:40.920
<v Cody Fincher>And so I'm glad you mentioned that, Yannick.

00:09:40.950 --> 00:09:42.040
<v Cody Fincher>But yeah, nice to see you guys

00:09:42.130 --> 00:09:43.020
<v Cody Fincher>and nice to be back on the show.

00:09:43.960 --> 00:09:45.160
<v Michael Kennedy>Cody, tell people what Litestar is.

00:09:45.300 --> 00:09:48.820
<v Michael Kennedy>I know I had both you guys and Jacob on a while ago,

00:09:48.840 --> 00:09:49.980
<v Michael Kennedy>but it's been a couple of years, I think.

00:09:50.620 --> 00:09:53.460
<v Cody Fincher>Yeah, so, I mean, Litestar, at its core,

00:09:53.660 --> 00:09:56.540
<v Cody Fincher>is really a web framework that kind of sits somewhere in between,

00:09:56.800 --> 00:10:00.720
<v Cody Fincher>I'd say, Flask and FastAPI and Django.

00:10:00.900 --> 00:10:04.940
<v Cody Fincher>So whereas Flask doesn't really bundle a lot of batteries,

00:10:05.100 --> 00:10:08.860
<v Cody Fincher>there's a huge amount of third-party libraries and ecosystem

00:10:09.240 --> 00:10:10.740
<v Cody Fincher>that's built around it that people can add into it,

00:10:10.740 --> 00:10:13.719
<v Cody Fincher>but there's not really, like, for instance, a database adapter

00:10:13.740 --> 00:10:16.900
<v Cody Fincher>or a database plugin or plugins for VEAT

00:10:16.930 --> 00:10:17.960
<v Cody Fincher>or something like that, right?

00:10:18.060 --> 00:10:19.000
<v Cody Fincher>For front end development.

00:10:19.090 --> 00:10:22.440
<v Cody Fincher>And so what we have been doing is building a API framework

00:10:22.620 --> 00:10:25.680
<v Cody Fincher>that is very similar in concept to FastAPI

00:10:25.920 --> 00:10:27.200
<v Cody Fincher>that is also extensible.

00:10:27.270 --> 00:10:29.700
<v Cody Fincher>So if you want to use the batteries, they're there for you.

00:10:30.460 --> 00:10:32.160
<v Cody Fincher>But if you don't want to use them, you don't have to, right?

00:10:32.280 --> 00:10:35.840
<v Cody Fincher>And so a lot of the tooling that we built for LightSolar

00:10:35.980 --> 00:10:39.360
<v Cody Fincher>was birthed out of a startup that I was in

00:10:39.700 --> 00:10:40.860
<v Cody Fincher>prior to joining Google.

00:10:41.050 --> 00:10:43.700
<v Cody Fincher>And so having all this boilerplate

00:10:43.960 --> 00:10:44.740
<v Cody Fincher>It needed somewhere to go.

00:10:44.880 --> 00:10:47.540
<v Cody Fincher>And so a lot of this stuff ended up being plugins,

00:10:47.880 --> 00:10:50.040
<v Cody Fincher>which is what we bundled into Litestar

00:10:50.180 --> 00:10:52.660
<v Cody Fincher>so that you can kind of add in this extra functionality.

00:10:53.980 --> 00:10:55.660
<v Cody Fincher>And so I know I'm getting long-winded.

00:10:55.820 --> 00:10:59.160
<v Cody Fincher>It's somewhere between Django and Flask,

00:10:59.200 --> 00:11:01.100
<v Cody Fincher>if you were to think about it in terms of a spectrum,

00:11:01.160 --> 00:11:04.680
<v Cody Fincher>in terms of what it gives you in terms of a web framework.

00:11:04.960 --> 00:11:07.160
<v Cody Fincher>But in short, it does everything that all the other guys do.

00:11:08.119 --> 00:11:09.600
<v Michael Kennedy>Yeah, very neat, very neat.

00:11:10.160 --> 00:11:11.720
<v Michael Kennedy>It's definitely a framework I admire.

00:11:12.600 --> 00:11:14.480
<v Michael Kennedy>Jeff Triplett, so glad you could make it.

00:11:15.680 --> 00:11:16.440
<v Jeff Triplett>Yeah, thanks for having me.

00:11:16.930 --> 00:11:17.780
<v Jeff Triplett>Yeah, I'm Jeff Triplett.

00:11:17.780 --> 00:11:18.660
<v Jeff Triplett>I'm out of Lawrence, Kansas.

00:11:19.080 --> 00:11:21.180
<v Jeff Triplett>I'm a consultant at a company called Revolution Systems.

00:11:21.930 --> 00:11:24.720
<v Jeff Triplett>I was on, some people know me from being on the Python Software Foundation board.

00:11:25.080 --> 00:11:26.200
<v Jeff Triplett>I've been off that for a few years.

00:11:27.460 --> 00:11:30.140
<v Jeff Triplett>As of last week, I'm the president of the Django Software Foundation.

00:11:30.490 --> 00:11:31.800
<v Jeff Triplett>So I've been on that board for a year.

00:11:32.340 --> 00:11:34.240
<v Jeff Triplett>I'm kind of a Django power user, I guess.

00:11:34.340 --> 00:11:35.520
<v Jeff Triplett>I've used it for about 20 years.

00:11:36.300 --> 00:11:39.920
<v Jeff Triplett>And I've kind of not really worked on, I don't even think I have a patch anymore in Django.

00:11:40.820 --> 00:11:42.660
<v Jeff Triplett>but I've done a lot with the community,

00:11:43.570 --> 00:11:45.800
<v Jeff Triplett>done a lot with contributing through conferences

00:11:46.620 --> 00:11:47.500
<v Jeff Triplett>and using utilities.

00:11:48.190 --> 00:11:51.120
<v Jeff Triplett>I try to promote Carleton's applications like Neapolitan.

00:11:52.080 --> 00:11:54.120
<v Jeff Triplett>If I like tools, Python tools in general,

00:11:54.250 --> 00:11:55.260
<v Jeff Triplett>I try to advocate for it.

00:11:56.140 --> 00:11:59.640
<v Jeff Triplett>Like Yannick, I've also used all of these applications.

00:11:59.920 --> 00:12:00.980
<v Jeff Triplett>Litestar, I haven't, but I have a friend

00:12:01.010 --> 00:12:02.040
<v Jeff Triplett>who talks about it a lot.

00:12:02.430 --> 00:12:04.020
<v Jeff Triplett>And so I feel like I know a lot from it.

00:12:04.600 --> 00:12:06.960
<v Jeff Triplett>As a consultant, we tend to go with the best tool for the job.

00:12:07.070 --> 00:12:08.300
<v Jeff Triplett>So I've done a little bit of FastAPI.

00:12:08.820 --> 00:12:10.320
<v Jeff Triplett>I worked with Flask a lot over the years.

00:12:10.820 --> 00:12:12.580
<v Jeff Triplett>even though we're primarily a Django shop.

00:12:13.430 --> 00:12:14.660
<v Jeff Triplett>It just depends on what the client needs.

00:12:15.300 --> 00:12:18.800
<v Michael Kennedy>Yeah, and you see a lot of different sizes of web app deployments,

00:12:18.960 --> 00:12:21.020
<v Michael Kennedy>so I think that's going to be an interesting angle for sure.

00:12:21.920 --> 00:12:22.500
<v Jeff Triplett>Yeah, absolutely.

00:12:22.800 --> 00:12:25.140
<v Jeff Triplett>Small ones to hundreds of servers.

00:12:25.540 --> 00:12:27.680
<v Jeff Triplett>We don't see it as much anymore the last four or five years,

00:12:28.540 --> 00:12:30.120
<v Jeff Triplett>especially with CDNs and caching.

00:12:30.900 --> 00:12:33.780
<v Jeff Triplett>We just don't see load like we did 10 years ago or so.

00:12:34.500 --> 00:12:36.320
<v Jeff Triplett>And then I also do a lot of small,

00:12:36.730 --> 00:12:38.620
<v Jeff Triplett>I kind of call some of them little dumb projects,

00:12:38.790 --> 00:12:39.540
<v Jeff Triplett>but some are just fun.

00:12:40.120 --> 00:12:44.740
<v Jeff Triplett>Like I've got a FastAPI WebRing that I wrote a year ago for April Fool's Day.

00:12:44.900 --> 00:12:48.160
<v Jeff Triplett>And for some reason, that kind of took off and people liked it, even though it was kind

00:12:48.160 --> 00:12:48.480
<v Jeff Triplett>of a joke.

00:12:49.100 --> 00:12:51.160
<v Jeff Triplett>So I started like peppering it on a bunch of sites.

00:12:51.310 --> 00:12:52.940
<v Jeff Triplett>And I maintain like Django packages.

00:12:53.330 --> 00:12:55.120
<v Jeff Triplett>I do a newsletter, Django News Newsletter.

00:12:55.980 --> 00:12:56.920
<v Jeff Triplett>Just kind of lots of fun stuff.

00:12:57.580 --> 00:12:58.380
<v Michael Kennedy>Yeah, awesome.

00:12:59.320 --> 00:13:01.520
<v Michael Kennedy>Well, definitely looking forward to hearing all of your opinions.

00:13:02.560 --> 00:13:06.760
<v Michael Kennedy>So I've got a bunch of different Your App in production topics.

00:13:07.020 --> 00:13:10.300
<v Michael Kennedy>I thought we could just work around and talk over.

00:13:11.180 --> 00:13:13.180
<v Michael Kennedy>So I thought maybe the first one is,

00:13:13.840 --> 00:13:16.900
<v Michael Kennedy>what would you recommend, or if you don't really

00:13:16.900 --> 00:13:18.160
<v Michael Kennedy>have a strong recommendation, what

00:13:18.200 --> 00:13:21.860
<v Michael Kennedy>would you choose for yourself to put your app

00:13:22.180 --> 00:13:24.120
<v Michael Kennedy>in your framework in production?

00:13:24.360 --> 00:13:27.040
<v Michael Kennedy>I'm thinking app servers, reverse proxies

00:13:27.040 --> 00:13:28.400
<v Michael Kennedy>like Nginx or Caddy.

00:13:29.760 --> 00:13:31.080
<v Michael Kennedy>Do you go for threaded--

00:13:31.620 --> 00:13:32.960
<v Michael Kennedy>try to scale out with threads.

00:13:33.160 --> 00:13:38.240
<v Michael Kennedy>You try to scale out with processes, you know, Docker, no Docker, Kubernetes.

00:13:39.600 --> 00:13:40.380
<v Michael Kennedy>What are we doing here, folks?

00:13:41.600 --> 00:13:41.900
<v Michael Kennedy>Carlton.

00:13:42.460 --> 00:13:43.840
<v Michael Kennedy>I think we'll just keep going around the circle here.

00:13:44.000 --> 00:13:47.460
<v Michael Kennedy>So you may get the first round of everyone.

00:13:47.580 --> 00:13:48.300
<v Michael Kennedy>No, I'll try to mix it up.

00:13:48.400 --> 00:13:52.320
<v Carlton Gibson>Okay, so I do the oldest school thing in the book.

00:13:52.390 --> 00:13:56.280
<v Carlton Gibson>I run Nginx as my front end.

00:13:56.580 --> 00:14:00.480
<v Carlton Gibson>I'll stick a WSGI server behind it with a pre-fork, you know, a few workers,

00:14:00.860 --> 00:14:04.740
<v Carlton Gibson>depending on CPU size, depending on the kind of requests I'm handling.

00:14:05.440 --> 00:14:09.040
<v Carlton Gibson>These days, in order to handle long-lived requests,

00:14:09.140 --> 00:14:11.540
<v Carlton Gibson>like server-sent events, that kind of WebSocket type things,

00:14:11.620 --> 00:14:13.580
<v Carlton Gibson>I'll run an ASGII server as a kind of sidecar.

00:14:14.759 --> 00:14:16.740
<v Michael Kennedy>Okay. I've been thinking about this a lot, actually.

00:14:17.160 --> 00:14:18.020
<v Michael Kennedy>But yeah, this is interesting.

00:14:18.300 --> 00:14:22.120
<v Carlton Gibson>If you're running a small site and you want long-lived requests,

00:14:22.160 --> 00:14:23.740
<v Carlton Gibson>just run ASGII. Just use ASGII.

00:14:23.880 --> 00:14:27.240
<v Carlton Gibson>Because any of the servers, Hypercorn, Uvicorn, Daphne,

00:14:27.660 --> 00:14:31.200
<v Carlton Gibson>Well, Grannion is the new hot kid on the bot, right?

00:14:31.680 --> 00:14:33.740
<v Carlton Gibson>All of those will handle your traffic, no problem.

00:14:34.020 --> 00:14:37.680
<v Carlton Gibson>But for me, the scaling paddles in Whiskey are so well-known

00:14:38.080 --> 00:14:40.920
<v Carlton Gibson>and just, like, I can do the maths on the back of the pencil.

00:14:40.980 --> 00:14:44.120
<v Carlton Gibson>I know exactly how to scale it up, having done it for so long.

00:14:44.720 --> 00:14:46.560
<v Carlton Gibson>For me, for my core application,

00:14:46.860 --> 00:14:48.460
<v Carlton Gibson>I would still rather use the WSGI server

00:14:48.500 --> 00:14:53.880
<v Carlton Gibson>and then limit the async stuff to just to the use cases

00:14:54.080 --> 00:14:55.360
<v Carlton Gibson>where it's particularly suited.

00:14:55.840 --> 00:14:56.520
<v Carlton Gibson>So we'll do that.

00:14:57.340 --> 00:14:59.700
<v Carlton Gibson>Process Manager, I deploy using Systemd.

00:15:00.999 --> 00:15:04.020
<v Carlton Gibson>If I want a container, I'll use Podman via Systemd.

00:15:05.260 --> 00:15:06.620
<v Carlton Gibson>It's as old school as it gets.

00:15:06.800 --> 00:15:10.440
<v Carlton Gibson>I'll very often run a Redis instance on local hosts for caching,

00:15:10.660 --> 00:15:12.520
<v Carlton Gibson>and that will be it.

00:15:13.020 --> 00:15:14.300
<v Carlton Gibson>And that will get me an awful long way.

00:15:15.639 --> 00:15:16.900
<v Carlton Gibson>Just get a bigger box.

00:15:17.620 --> 00:15:18.480
<v Carlton Gibson>Yeah, yeah, yeah.

00:15:19.040 --> 00:15:21.580
<v Carlton Gibson>If you really, really, really need multiple boxes,

00:15:21.720 --> 00:15:22.420
<v Carlton Gibson>well, then we'll talk.

00:15:22.740 --> 00:15:24.620
<v Michael Kennedy>I feel like you and I are in a similar vibe.

00:15:25.040 --> 00:15:26.900
<v Michael Kennedy>But one thing I want to sort of throw out there to you,

00:15:27.020 --> 00:15:28.520
<v Michael Kennedy>but also sort of the others is,

00:15:29.400 --> 00:15:30.360
<v Michael Kennedy>what are we talking with databases?

00:15:30.880 --> 00:15:33.140
<v Michael Kennedy>Like, who's bold enough to go SQLite?

00:15:33.440 --> 00:15:34.740
<v Michael Kennedy>Anyone's going SQLite out there?

00:15:36.200 --> 00:15:36.500
<v Cody Fincher>Yeah.

00:15:36.780 --> 00:15:37.540
<v Cody Fincher>It depends, right?

00:15:38.140 --> 00:15:39.560
<v Cody Fincher>It just depends on what you're doing, right?

00:15:39.560 --> 00:15:41.580
<v Cody Fincher>And how many concurrent users you're going to have.

00:15:42.080 --> 00:15:42.900
<v David Lord>It really depends on there.

00:15:43.860 --> 00:15:49.720
<v David Lord>The Palette's website is running on Flask,

00:15:50.040 --> 00:15:50.940
<v David Lord>which I wasn't doing for a while.

00:15:50.940 --> 00:15:52.280
<v David Lord>I was doing a static site generator.

00:15:52.900 --> 00:15:57.100
<v David Lord>Then I got inspired by Andrew Godwin's static dynamic sites.

00:15:58.000 --> 00:16:03.460
<v David Lord>And so it loads up all these markdown files, static markdown files into a SQLite database

00:16:04.880 --> 00:16:08.680
<v David Lord>at runtime and then serves off of that because you can query really fast.

00:16:09.080 --> 00:16:09.820
<v Michael Kennedy>Oh, that's awesome.

00:16:09.900 --> 00:16:10.300
<v Michael Kennedy>I love it.

00:16:11.120 --> 00:16:11.760
<v David Lord>So yeah, that's cool.

00:16:11.800 --> 00:16:13.080
<v David Lord>SQLite for the balance website.

00:16:14.080 --> 00:16:14.560
<v Michael Kennedy>Awesome.

00:16:14.680 --> 00:16:21.899
<v Speaker 6>Also, do you have a few small apps that use SQLite and one recently that's Cody's fault

00:16:21.940 --> 00:16:23.480
<v Speaker 6>because he put me on that track

00:16:24.520 --> 00:16:28.100
<v Speaker 6>where it's running a SQLite database in the browser

00:16:28.300 --> 00:16:32.160
<v Speaker 6>because it's really, nowadays, it's quite easy to do that.

00:16:33.100 --> 00:16:35.660
<v Speaker 6>And then you can do all sorts of stuff with it,

00:16:35.860 --> 00:16:40.340
<v Speaker 6>like hook into it with DuckDB and perform some analysis.

00:16:40.580 --> 00:16:44.280
<v Speaker 6>So you don't actually need to run any sort of server at all.

00:16:44.320 --> 00:16:48.040
<v Speaker 6>You can just throw some files into Nginx and serve your data.

00:16:49.240 --> 00:16:52.140
<v Speaker 6>As long as that static, you have a super, super simple deployment.

00:16:53.200 --> 00:16:55.740
<v Speaker 6>So yeah, definitely SQLite if you can.

00:16:56.540 --> 00:16:56.900
<v Speaker 6>I like it.

00:16:57.180 --> 00:16:58.220
<v Michael Kennedy>I agree.

00:16:58.400 --> 00:16:58.760
<v Michael Kennedy>It's interesting.

00:16:58.940 --> 00:17:01.000
<v Michael Kennedy>Like the database probably won't go down with that.

00:17:01.780 --> 00:17:01.960
<v Michael Kennedy>Probably.

00:17:02.879 --> 00:17:04.260
<v Michael Kennedy>Let's do this by framework.

00:17:04.400 --> 00:17:06.579
<v Michael Kennedy>So we'll do vertical slices in the visual here.

00:17:06.839 --> 00:17:07.280
<v Michael Kennedy>So Jeff.

00:17:09.400 --> 00:17:11.980
<v Jeff Triplett>Yeah, Django, Postgres, pretty old school stack.

00:17:12.819 --> 00:17:15.540
<v Jeff Triplett>I think putting a CD in front of anything is just a win.

00:17:15.620 --> 00:17:18.800
<v Jeff Triplett>So whether you like Fastly or Cloudflare, you get a lot of mileage out of it.

00:17:18.900 --> 00:17:22.380
<v Jeff Triplett>You learn a lot about caching because it's kind of hard to cache Django by default.

00:17:22.680 --> 00:17:25.740
<v Jeff Triplett>So you get to play with curl and kind of figure out why very headers are there.

00:17:26.000 --> 00:17:28.720
<v Jeff Triplett>And it's a good learning experience to get through that.

00:17:29.320 --> 00:17:33.420
<v Jeff Triplett>I also like Coolify, which is kind of new, at least new to me and new to Michael.

00:17:33.520 --> 00:17:35.060
<v Jeff Triplett>We talked about this in our spare time a lot.

00:17:35.680 --> 00:17:39.000
<v Jeff Triplett>It's just kind of a boring service that will launch a bunch of containers for you.

00:17:39.620 --> 00:17:41.080
<v Jeff Triplett>There's a bunch of one-click installs.

00:17:41.200 --> 00:17:42.380
<v Jeff Triplett>So Postgres is a one-click.

00:17:42.620 --> 00:17:45.580
<v Jeff Triplett>It also does backups for you, which is really nice to have for free.

00:17:46.240 --> 00:17:49.520
<v Jeff Triplett>I run a couple dozen sites through it and really like it.

00:17:49.850 --> 00:17:51.140
<v Jeff Triplett>You can either do a hosted forum.

00:17:51.270 --> 00:17:52.480
<v Jeff Triplett>I don't get any money from it,

00:17:52.480 --> 00:17:54.160
<v Jeff Triplett>or you can run the open source version.

00:17:54.540 --> 00:17:55.120
<v Jeff Triplett>I do both.

00:17:55.290 --> 00:17:57.100
<v Jeff Triplett>I've got like a home lab that I just run stuff

00:17:57.330 --> 00:17:58.480
<v Jeff Triplett>using the open source version.

00:17:59.060 --> 00:18:01.180
<v Jeff Triplett>For five bucks a month, it's worth it to run a couple servers.

00:18:01.990 --> 00:18:03.040
<v Jeff Triplett>Yeah, Coolify is great.

00:18:03.040 --> 00:18:03.780
<v Jeff Triplett>You can just scale up.

00:18:05.920 --> 00:18:07.460
<v Michael Kennedy>Yeah, it's got a bunch of one-click deploy

00:18:07.820 --> 00:18:10.120
<v Michael Kennedy>for self-hosted SaaS things as well.

00:18:10.300 --> 00:18:13.460
<v Michael Kennedy>I want an analytics stack of containers

00:18:13.680 --> 00:18:14.940
<v Michael Kennedy>that run in its own isolated bit.

00:18:14.970 --> 00:18:16.080
<v Michael Kennedy>Just click here and go.

00:18:16.120 --> 00:18:17.520
<v Michael Kennedy>So it's, yeah.

00:18:17.820 --> 00:18:18.000
<v Jeff Triplett>Yeah.

00:18:18.380 --> 00:18:20.160
<v Jeff Triplett>One click, it's installed and you're up.

00:18:20.380 --> 00:18:26.160
<v Jeff Triplett>And then once you get one Django, Blast, FastAPI site working with it, and it uses like a Docker container.

00:18:27.160 --> 00:18:34.200
<v Jeff Triplett>Once you get that set up, it's really easy to just kind of duplicate that site, plug it in the GitHub or whatever your Git provider is.

00:18:34.280 --> 00:18:40.000
<v Jeff Triplett>And it's a nice experience for what normally is just R-syncing files and life's too short for that.

00:18:41.140 --> 00:18:41.380
<v Michael Kennedy>Yep.

00:18:41.980 --> 00:18:42.280
<v Michael Kennedy>All right.

00:18:42.660 --> 00:18:45.180
<v Michael Kennedy>Sebastian, I want to have you go last on this one

00:18:45.180 --> 00:18:48.200
<v Michael Kennedy>because I think you've got something pretty interesting

00:18:48.220 --> 00:18:50.300
<v Michael Kennedy>with FastAPI Cloud to dive into.

00:18:50.520 --> 00:18:52.140
<v Michael Kennedy>But let's do Litestar next.

00:18:52.460 --> 00:18:52.560
<v Michael Kennedy>Cody.

00:18:54.340 --> 00:18:58.260
<v Cody Fincher>So I have actually bought all the way in on Gradient.

00:18:58.520 --> 00:19:02.060
<v Cody Fincher>So for the ASCII server, I've actually been running Gradient

00:19:02.100 --> 00:19:03.900
<v Cody Fincher>now for, I'd say, a year in production.

00:19:04.519 --> 00:19:05.820
<v Cody Fincher>It's worked pretty well.

00:19:06.740 --> 00:19:09.660
<v Cody Fincher>There's a couple of new things that I'm actually kind of experimenting with.

00:19:09.700 --> 00:19:11.000
<v Cody Fincher>I don't know how well they're going to work out.

00:19:11.000 --> 00:19:12.160
<v Cody Fincher>So I'm going to go ahead and throw this out there.

00:19:12.340 --> 00:19:15.220
<v Cody Fincher>but Granian is one of the few ASI servers

00:19:15.380 --> 00:19:17.080
<v Cody Fincher>that supports HTTP/2,

00:19:17.780 --> 00:19:20.500
<v Cody Fincher>and it actually can do HTTP/2 clear text.

00:19:20.640 --> 00:19:22.820
<v Cody Fincher>And so this is part of the next thing I'm gonna say.

00:19:23.020 --> 00:19:23.900
<v Cody Fincher>Because I work for Google,

00:19:24.120 --> 00:19:27.660
<v Cody Fincher>I'm actively using lots of Kubernetes and Cloud Run mainly.

00:19:27.880 --> 00:19:29.580
<v Cody Fincher>And so most of the things that I deploy

00:19:29.780 --> 00:19:31.880
<v Cody Fincher>are containerized on Cloud Run.

00:19:32.020 --> 00:19:33.700
<v Cody Fincher>And I typically would suggest

00:19:34.360 --> 00:19:35.740
<v Cody Fincher>if you're not using something like Systemd

00:19:35.900 --> 00:19:37.200
<v Cody Fincher>and deploying it directly on bare metal,

00:19:37.740 --> 00:19:39.859
<v Cody Fincher>then you are gonna wanna let the container

00:19:39.880 --> 00:19:42.140
<v Cody Fincher>or whatever you're using to manage your processes,

00:19:43.100 --> 00:19:44.220
<v Cody Fincher>manage that and spin that up.

00:19:44.280 --> 00:19:47.060
<v Cody Fincher>And so I typically try to allocate, you know,

00:19:47.060 --> 00:19:48.600
<v Cody Fincher>like one CPU for the container

00:19:48.740 --> 00:19:51.480
<v Cody Fincher>and let the actual framework scale it up and down as needed.

00:19:52.740 --> 00:19:55.840
<v Cody Fincher>Cloud Run itself has like an ingress,

00:19:56.640 --> 00:19:57.980
<v Cody Fincher>like a load balancer that sits in front

00:19:58.180 --> 00:19:59.200
<v Cody Fincher>that it automatically configures.

00:19:59.240 --> 00:20:02.940
<v Cody Fincher>And you're required to basically serve up clear text traffic

00:20:03.260 --> 00:20:04.600
<v Cody Fincher>in when you run Cloud Run.

00:20:05.640 --> 00:20:08.899
<v Cody Fincher>And because now Gradient supports HTTP2

00:20:08.920 --> 00:20:11.460
<v Cody Fincher>And Cloud Run supports HTTP2 clear text.

00:20:11.510 --> 00:20:15.100
<v Cody Fincher>You can now serve Gradient as HTTP2 traffic.

00:20:15.350 --> 00:20:18.680
<v Cody Fincher>The good thing about that is that you get an unlimited upload size.

00:20:18.710 --> 00:20:22.380
<v Cody Fincher>And so there are max thresholds to what you can upload into the various cloud environments.

00:20:23.180 --> 00:20:26.820
<v Cody Fincher>HTTP2 usually circumvents that or gets around it because of the way the protocol works.

00:20:26.890 --> 00:20:29.920
<v Cody Fincher>And so you get additional features and functionality because of that.

00:20:30.060 --> 00:20:31.800
<v Cody Fincher>So anyway, that's what I typically do.

00:20:32.000 --> 00:20:38.660
<v Cody Fincher>And most of my databases are usually Postgres, AlloyDB, if it needs to be something that's on the analytical side.

00:20:38.860 --> 00:20:39.920
<v Michael Kennedy>So yeah, cool.

00:20:40.390 --> 00:20:41.960
<v Michael Kennedy>Yeah, I'm on Team Granian as well.

00:20:41.960 --> 00:20:43.420
<v Michael Kennedy>I think that's a super neat framework.

00:20:43.600 --> 00:20:46.440
<v Michael Kennedy>I had Giovanni on who's behind it a while ago.

00:20:47.420 --> 00:20:53.640
<v Michael Kennedy>And it seems like it's not as popular,

00:20:54.060 --> 00:20:56.100
<v Michael Kennedy>but it's based on Hyper from the Rust world, which

00:20:56.280 --> 00:21:00.040
<v Michael Kennedy>has like 130,000 projects based on it or something.

00:21:00.160 --> 00:21:04.220
<v Michael Kennedy>So at its core, it's still pretty battle-tested.

00:21:05.900 --> 00:21:06.980
<v Michael Kennedy>Yannick, how about you?

00:21:08.020 --> 00:21:09.180
<v Michael Kennedy>You got a variety, it sounds like.

00:21:09.720 --> 00:21:10.680
<v Speaker 6>Yeah, definitely.

00:21:11.800 --> 00:21:15.640
<v Speaker 6>There's a pretty clear split between what I do at work

00:21:15.940 --> 00:21:18.880
<v Speaker 6>and what I do outside of that.

00:21:18.890 --> 00:21:22.260
<v Speaker 6>So at work, it's Kubernetes deployments,

00:21:22.480 --> 00:21:26.220
<v Speaker 6>and we manage that pretty much the same way that Cody described.

00:21:26.420 --> 00:21:31.180
<v Speaker 6>So it's one or two processors per pod max,

00:21:31.520 --> 00:21:33.960
<v Speaker 6>so you can have Kubernetes scale it

00:21:34.020 --> 00:21:36.160
<v Speaker 6>or even manually easily scale it up.

00:21:36.280 --> 00:21:41.620
<v Speaker 6>You can just go into Kubernetes and say, okay, do me one to five more pods or whatever.

00:21:42.180 --> 00:21:42.740
<v Phil Jones>And don't have to worry.

00:21:42.960 --> 00:21:44.660
<v Speaker 6>You don't have to start calculating, whatever.

00:21:45.280 --> 00:21:56.580
<v Speaker 6>Most of the stuff we run nowadays with UVcorn, our Django deployment up until I think three months ago or so was running on the Unicorn.

00:21:56.760 --> 00:21:57.860
<v Speaker 6>But we switched that actually.

00:21:58.860 --> 00:22:00.900
<v Speaker 6>And it's been a really great experience.

00:22:01.800 --> 00:22:06.920
<v Speaker 6>I think we tried that a year ago, and it didn't work out quite so well.

00:22:06.980 --> 00:22:12.520
<v Speaker 6>There were some things that didn't work as expected or didn't perform great,

00:22:12.800 --> 00:22:17.540
<v Speaker 6>or Django was throwing some errors, or UVicorn was throwing some errors.

00:22:17.640 --> 00:22:22.640
<v Speaker 6>And then, apparently, all of that got fixed, because now it runs without any issue.

00:22:23.080 --> 00:22:23.420
<v Michael Kennedy>Great.

00:22:24.580 --> 00:22:29.400
<v Michael Kennedy>Yeah, for people who don't know, the vibe used to be run G Unicorn,

00:22:29.440 --> 00:22:32.400
<v Michael Kennedy>but then with UVicorn workers, if you're doing async stuff.

00:22:32.620 --> 00:22:35.560
<v Michael Kennedy>And then UVicorn kind of stepped up its game

00:22:35.600 --> 00:22:38.820
<v Michael Kennedy>and said, you can actually treat us as our own app server.

00:22:39.140 --> 00:22:40.700
<v Michael Kennedy>We will manage lifecycle and stuff.

00:22:40.800 --> 00:22:42.360
<v Michael Kennedy>And so that's the path you took, right?

00:22:42.980 --> 00:22:43.600
<v Speaker 6>Yeah, exactly.

00:22:43.840 --> 00:22:44.240
<v Speaker 6>Before that.

00:22:44.580 --> 00:22:46.160
<v Speaker 6>Well, no, actually, before that, we didn't

00:22:46.340 --> 00:22:48.900
<v Speaker 6>because our Django is fully synchronous.

00:22:49.040 --> 00:22:50.880
<v Speaker 6>It doesn't do any async.

00:22:51.080 --> 00:22:53.720
<v Speaker 6>So it was just bare metal unicorn.

00:22:53.840 --> 00:22:55.880
<v Speaker 6>And it's still synchronous.

00:22:56.180 --> 00:22:57.780
<v Speaker 6>We're just running it under UVicorn.

00:22:58.980 --> 00:23:02.940
<v Speaker 6>But interestingly, it's still quite a bit faster in a few cases.

00:23:03.560 --> 00:23:07.980
<v Speaker 6>We tried that out and we low-tested it in a couple of scenarios

00:23:08.130 --> 00:23:10.540
<v Speaker 6>and we found that it makes a lot of sense.

00:23:10.930 --> 00:23:14.980
<v Phil Jones>But outside of that, I do have a lot of, well,

00:23:15.720 --> 00:23:19.200
<v Speaker 6>very simplistic deployments that are also just systemd

00:23:19.480 --> 00:23:24.479
<v Speaker 6>and a couple of Docker compose files and containers

00:23:24.500 --> 00:23:31.260
<v Speaker 6>that are managed through some old coupled together Ansible things.

00:23:32.520 --> 00:23:36.300
<v Speaker 6>But I think the oldest one that I have still running is from 2017,

00:23:37.180 --> 00:23:41.320
<v Speaker 6>and it's been running without a change for like four or five years.

00:23:41.820 --> 00:23:42.520
<v Speaker 6>That is awesome.

00:23:42.980 --> 00:23:46.900
<v Speaker 6>I don't see a reason to do anything about it because the app works.

00:23:47.120 --> 00:23:48.720
<v Speaker 6>It's being used productively.

00:23:50.840 --> 00:23:52.820
<v Speaker 6>So why change anything about that?

00:23:52.940 --> 00:23:53.560
<v Speaker 6>No need to introduce.

00:23:54.680 --> 00:23:55.580
<v Speaker 6>Just don't touch it.

00:23:56.020 --> 00:23:59.940
<v Speaker 6>Yeah, I was actually looking into Coolify that you two guys mentioned.

00:24:00.820 --> 00:24:03.500
<v Speaker 6>I was thinking about maybe upgrading it to that,

00:24:03.680 --> 00:24:06.980
<v Speaker 6>but I played around with it and I thought, well, why?

00:24:08.140 --> 00:24:12.720
<v Speaker 6>It doesn't, you know, if I have to look into that deployment maybe once a year.

00:24:13.180 --> 00:24:17.960
<v Speaker 6>So that's really nothing to gain for me to make it more complicated.

00:24:18.920 --> 00:24:21.260
<v Michael Kennedy>Right. Awesome.

00:24:22.580 --> 00:24:24.100
<v Michael Kennedy>David, Team Flask.

00:24:27.980 --> 00:24:29.660
<v David Lord>I was trying to pull up a bunch of links really quick.

00:24:32.160 --> 00:24:34.680
<v David Lord>So I mentioned this before the show started,

00:24:35.920 --> 00:24:39.700
<v David Lord>and I think I'm pretty sure I've said this the last time I was on Talk Python,

00:24:40.420 --> 00:24:48.100
<v David Lord>but the projects I do for work typically have less than 100 users.

00:24:48.980 --> 00:24:51.840
<v David Lord>And so my deployment is usually really simple.

00:24:52.120 --> 00:24:55.120
<v David Lord>And usually they've chosen like Azure or AWS already.

00:24:55.520 --> 00:25:03.720
<v David Lord>So we just have a Docker container and we put it on the relevant Docker container host and it just works for them.

00:25:04.440 --> 00:25:07.120
<v David Lord>We have a Postgres database and we have like Redis.

00:25:09.140 --> 00:25:15.740
<v David Lord>But I never really had to deal with like scaling or that sort of stuff.

00:25:16.040 --> 00:25:23.860
<v David Lord>But the funny thing is, at least for my work, we're often replacing older systems.

00:25:24.170 --> 00:25:37.880
<v David Lord>And so even a single Docker container running a Flask application is way more performant and responsive than anything they're used to from some 20-year-old or 30-year-old Java system.

00:25:39.020 --> 00:25:44.720
<v David Lord>And it can just respond on a small container with a little bit of CPU and a little bit of memory.

00:25:45.060 --> 00:25:47.940
<v David Lord>They're always shocked at like, how much do we need to pay for?

00:25:48.100 --> 00:25:50.340
<v David Lord>Oh, just like it'll run a potato.

00:25:51.260 --> 00:25:52.420
<v David Lord>You know, there's only 100 users.

00:25:52.620 --> 00:25:53.760
<v David Lord>And they're like, that's a lot of users.

00:25:56.639 --> 00:26:01.860
<v David Lord>So my recommendation is always start small and then scale up from there.

00:26:02.020 --> 00:26:04.680
<v David Lord>Don't try to overthink it ahead of time.

00:26:07.419 --> 00:26:11.620
<v David Lord>But yeah, for my personal stuff, I'm using like Docker containers now and fly.io.

00:26:11.760 --> 00:26:18.460
<v David Lord>I haven't gotten to it. I do want to look into Granian and coolify, but I haven't gotten there yet.

00:26:21.440 --> 00:26:26.480
<v David Lord>And for the Docker container, I can definitely recommend pythonspeed.org. I don't remember off

00:26:26.500 --> 00:26:31.940
<v David Lord>the top of my head who writes that, but it's somebody in the Python ecosystem. And they have

00:26:32.040 --> 00:26:36.480
<v David Lord>a whole series of articles on how to optimize your Docker container. And that sounds really

00:26:36.640 --> 00:26:41.720
<v David Lord>complicated, but you end up with a Docker file that's like 20 lines long or something. It's not

00:26:43.520 --> 00:26:44.480
<v David Lord>there's crazy things.

00:26:44.590 --> 00:26:46.660
<v David Lord>It's just you have to know how to structure it.

00:26:46.960 --> 00:26:48.620
<v David Lord>And then I just copy and paste that to the next project.

00:26:49.020 --> 00:26:49.580
<v Michael Kennedy>Nice, yeah.

00:26:50.030 --> 00:26:51.980
<v Michael Kennedy>I resisted doing Docker for a long time because I'm like,

00:26:52.010 --> 00:26:53.100
<v Michael Kennedy>I don't want that extra complexity.

00:26:53.310 --> 00:26:56.020
<v Michael Kennedy>But then I realized, like, the stuff you put in the Docker file

00:26:56.200 --> 00:26:58.100
<v Michael Kennedy>is really what you just type in the terminal once,

00:26:58.130 --> 00:26:59.520
<v Michael Kennedy>and then you forget it.

00:26:59.600 --> 00:27:01.280
<v David Lord>Or type the Ansible, or, yeah, yeah.

00:27:02.760 --> 00:27:07.380
<v David Lord>And so, like, I'm always using Postgres, Redis,

00:27:07.680 --> 00:27:09.280
<v David Lord>probably if I need, like, some background tasks,

00:27:09.620 --> 00:27:12.080
<v David Lord>just plain SMTP server for email.

00:27:13.960 --> 00:27:17.120
<v David Lord>I wrote, for all three of those things,

00:27:17.160 --> 00:27:19.340
<v David Lord>I wrote new extensions in the Flask ecosystem

00:27:19.660 --> 00:27:21.640
<v David Lord>that I'm trying to get more people to know about now.

00:27:22.240 --> 00:27:25.680
<v David Lord>So Flask SQLAlchemy Lite, L-I-T-E,

00:27:26.240 --> 00:27:27.460
<v David Lord>instead of Flask SQLAlchemy,

00:27:28.560 --> 00:27:29.760
<v David Lord>it takes a much more lightweight approach

00:27:30.000 --> 00:27:32.220
<v David Lord>to integrating SQLAlchemy with Flask.

00:27:33.060 --> 00:27:33.660
<v David Lord>Yeah, awesome.

00:27:34.540 --> 00:27:35.560
<v David Lord>And then Flask Redis,

00:27:35.880 --> 00:27:39.580
<v David Lord>I revived from like 10 years of non-maintenance

00:27:41.060 --> 00:27:49.780
<v David Lord>And then I wrote this whole system, this whole pluggable email system called Email Simplified, kind of inspired by Django, Django's pluggable system.

00:27:51.500 --> 00:27:55.080
<v David Lord>And so there's like Flask Email Simplified to integrate that with Flask.

00:27:55.280 --> 00:28:01.120
<v David Lord>But unlike Django, you can use Email Simplified in any library you're writing, in any Python application you're writing.

00:28:01.160 --> 00:28:02.800
<v David Lord>It doesn't have to be a Flask web framework.

00:28:03.620 --> 00:28:05.280
<v David Lord>It's pluggable as the library itself.

00:28:06.020 --> 00:28:08.600
<v David Lord>And then you can also integrate it with Flask or something else.

00:28:09.240 --> 00:28:09.360
<v David Lord>Cool.

00:28:09.460 --> 00:28:11.120
<v David Lord>So Flask email simplified.

00:28:12.480 --> 00:28:15.220
<v David Lord>I've been doing email right now, so it needs some popularity.

00:28:15.500 --> 00:28:15.900
<v Michael Kennedy>Awesome.

00:28:16.120 --> 00:28:18.400
<v Michael Kennedy>I've been doing the non-simplified email lately,

00:28:18.660 --> 00:28:20.960
<v Michael Kennedy>so I'm happy to hear that there might be a better way.

00:28:21.580 --> 00:28:21.880
<v Speaker 6>Yeah.

00:28:23.560 --> 00:28:26.760
<v Michael Kennedy>Yeah, I think people do underappreciate just how much

00:28:27.080 --> 00:28:29.520
<v Michael Kennedy>performance you got out of Python web apps.

00:28:29.780 --> 00:28:32.080
<v Michael Kennedy>You know, they're like, oh, we're

00:28:32.080 --> 00:28:34.940
<v Michael Kennedy>going to need to rewrite this in something else because the gil

00:28:35.140 --> 00:28:35.620
<v Michael Kennedy>or whatever.

00:28:35.920 --> 00:28:41.640
<v Michael Kennedy>Like I decided just to make a point to pull up the tail till my log running court,

00:28:41.670 --> 00:28:41.940
<v Michael Kennedy>by the way.

00:28:42.540 --> 00:28:46.520
<v Michael Kennedy>And each one of these requests is doing like multiple DB calls and it's like 23

00:28:46.820 --> 00:28:50.960
<v Michael Kennedy>milliseconds, six milliseconds, three milliseconds, nine milliseconds.

00:28:51.180 --> 00:28:54.860
<v Michael Kennedy>It's like, that's good enough for,

00:28:55.480 --> 00:28:59.080
<v Michael Kennedy>that's a lot of requests per second per worker until you got to,

00:28:59.080 --> 00:28:59.880
<v Michael Kennedy>you got to have a lot of traffic.

00:29:01.840 --> 00:29:04.760
<v Michael Kennedy>Speaking of court, Phil, what's your take on this one?

00:29:05.920 --> 00:29:06.800
<v Phil Jones>I think it's very similar.

00:29:07.100 --> 00:29:08.960
<v Phil Jones>I also build Docker containers

00:29:10.860 --> 00:29:12.960
<v Phil Jones>with a Postgres database on the back end.

00:29:13.080 --> 00:29:15.840
<v Phil Jones>And I run Hypercorn as the ASCII server

00:29:16.460 --> 00:29:18.740
<v Phil Jones>and put them behind an AWS load balancer

00:29:19.180 --> 00:29:20.400
<v Phil Jones>and just run them in ECS.

00:29:20.620 --> 00:29:22.480
<v Phil Jones>And I think it's pretty simple,

00:29:22.760 --> 00:29:24.360
<v Phil Jones>but I guess it depends on your biases.

00:29:24.640 --> 00:29:26.540
<v Phil Jones>But yeah, that's all we do, really.

00:29:26.660 --> 00:29:27.460
<v Phil Jones>And it goes a long way.

00:29:27.620 --> 00:29:29.720
<v Phil Jones>There are multiple ECS tasks,

00:29:30.160 --> 00:29:32.400
<v Phil Jones>mostly because if one falls over rather than scaling,

00:29:32.600 --> 00:29:35.240
<v Phil Jones>it's usually the database that you need to scale, I find.

00:29:36.000 --> 00:29:37.720
<v Phil Jones>yeah that's how we run it

00:29:37.890 --> 00:29:39.760
<v Phil Jones>the nice thing for me about Hypercorn

00:29:40.160 --> 00:29:41.720
<v Phil Jones>is that I can play with HTTP3

00:29:41.980 --> 00:29:43.360
<v Phil Jones>so that's what we're doing at times

00:29:45.700 --> 00:29:46.440
<v Michael Kennedy>HTTP3 okay

00:29:47.300 --> 00:29:49.460
<v Michael Kennedy>I've just been getting my HTTP2 game down

00:29:49.640 --> 00:29:51.240
<v Michael Kennedy>so I'm already behind the game

00:29:53.060 --> 00:29:54.300
<v Michael Kennedy>what's the deal with HTTP3?

00:29:56.900 --> 00:29:57.760
<v Phil Jones>well I mean it's

00:29:58.540 --> 00:29:59.880
<v Phil Jones>obviously a totally new way of doing it

00:29:59.910 --> 00:30:01.820
<v Phil Jones>over UDP now rather than TCP

00:30:03.040 --> 00:30:04.540
<v Phil Jones>although at the application level

00:30:04.560 --> 00:30:05.920
<v Phil Jones>you can't tell any difference really.

00:30:06.180 --> 00:30:08.520
<v Phil Jones>But I mean, I just find it interesting.

00:30:08.720 --> 00:30:10.600
<v Phil Jones>I'm not really sure it will help too much.

00:30:10.960 --> 00:30:13.000
<v Phil Jones>And it's probably best if you've got users

00:30:13.090 --> 00:30:15.460
<v Phil Jones>who have not that great a network connection.

00:30:16.140 --> 00:30:19.600
<v Phil Jones>But for most other cases, it doesn't matter too much.

00:30:19.980 --> 00:30:24.600
<v Michael Kennedy>Just keep blasting packets until some of them get through.

00:30:25.220 --> 00:30:25.860
<v Michael Kennedy>Okay, fine.

00:30:25.860 --> 00:30:26.780
<v Michael Kennedy>We'll give you a page eventually.

00:30:26.960 --> 00:30:27.760
<v Michael Kennedy>Here's three pages actually.

00:30:29.700 --> 00:30:30.340
<v Michael Kennedy>All right, Sebastian.

00:30:31.240 --> 00:30:34.800
<v Michael Kennedy>You are running not just FastAPI from your experience,

00:30:35.080 --> 00:30:37.480
<v Michael Kennedy>but you're running FastAPI for a ton of people

00:30:37.820 --> 00:30:41.240
<v Michael Kennedy>through FastAPI Cloud at, I'm sure, many different levels.

00:30:42.740 --> 00:30:46.280
<v Sebastian Ramirez>Yeah, so this probably sounds like a shameless plug.

00:30:46.280 --> 00:30:48.840
<v Sebastian Ramirez>And it kind of is, but it's sort of expected.

00:30:50.100 --> 00:30:52.140
<v Sebastian Ramirez>I will deploy FastAPI or FastAPI Cloud.

00:30:52.700 --> 00:30:54.140
<v Sebastian Ramirez>Just because-- well, the idea is just

00:30:54.140 --> 00:30:55.940
<v Sebastian Ramirez>to make it super simple to do that.

00:30:56.320 --> 00:30:59.620
<v Sebastian Ramirez>If you are being able to run the command FastAPI run,

00:31:00.040 --> 00:31:06.300
<v Sebastian Ramirez>fast api run has like the production server that is using ubicor underneath and if you can run that

00:31:06.460 --> 00:31:11.880
<v Sebastian Ramirez>then you can run also fast api deploy and then like you know like it will most probably just work

00:31:12.600 --> 00:31:18.760
<v Sebastian Ramirez>and you know we just wrap everything and like deploy build install deploy handle https all the

00:31:18.780 --> 00:31:23.740
<v Sebastian Ramirez>stuff without needing any docker file or anything like that and i think for many use cases it's just

00:31:23.840 --> 00:31:27.860
<v Sebastian Ramirez>like simpler being able just to do that there are there are so many projects that i have been now

00:31:27.880 --> 00:31:33.560
<v Sebastian Ramirez>building, you're not a random stuff that is not really important, but now I can. And before

00:31:33.700 --> 00:31:38.000
<v Sebastian Ramirez>it was like, yeah, well, I know how to deploy this thing, like fully with like all the bells

00:31:38.020 --> 00:31:42.940
<v Sebastian Ramirez>and whistles, but it's just so much work that yeah, no later. So for that, I will end up just

00:31:42.980 --> 00:31:48.960
<v Michael Kennedy>like going with that. Now, if I didn't, sorry, go ahead. Well, what I was going to ask is

00:31:50.200 --> 00:31:54.380
<v Michael Kennedy>how much are you willing to tell us how things run inside FastAPI Cloud?

00:31:55.660 --> 00:32:02.240
<v Sebastian Ramirez>oh like it's just so much stuff i'm sure i mean you know like it's like and it's also it's fun

00:32:02.260 --> 00:32:06.180
<v Sebastian Ramirez>that you know like nowadays that they're like uh you know like we have docker and we have

00:32:06.260 --> 00:32:10.740
<v Sebastian Ramirez>to get swarm and there there was nomad and kubernetes and oh kubernetes one and then we

00:32:10.820 --> 00:32:16.580
<v Sebastian Ramirez>have the cloud providers and there's you know like aws and like google and asher and you will expect

00:32:16.760 --> 00:32:22.920
<v Sebastian Ramirez>that all these things and all this complexity is like now that it's like okay these are the clear

00:32:22.920 --> 00:32:28.700
<v Sebastian Ramirez>winner so it's like a lot of complexity to take on but like you once you do it all works but it

00:32:28.820 --> 00:32:34.940
<v Sebastian Ramirez>doesn't and it's just like so much you know like so much work to get things to work together to

00:32:35.080 --> 00:32:40.180
<v Sebastian Ramirez>work correctly and the official you know like the official resources from the different providers

00:32:40.280 --> 00:32:45.040
<v Sebastian Ramirez>and things in many cases like oh the solution is hidden in this issue somewhere in github because

00:32:45.160 --> 00:32:49.940
<v Sebastian Ramirez>the previous version was obsolete but now the new version of like this package or whatever is like

00:32:49.800 --> 00:32:57.460
<v Sebastian Ramirez>you know like it's just it's crazy but like yeah so then if i didn't have fast api cloud

00:32:58.320 --> 00:33:02.780
<v Sebastian Ramirez>uh i will probably use containers i will probably use docker if it's like something simple i will

00:33:02.800 --> 00:33:08.060
<v Sebastian Ramirez>deploy with a docker compose probably try to scale the minimum replicas i don't remember

00:33:08.500 --> 00:33:13.380
<v Sebastian Ramirez>docker compose has that i remember that docker swarm had that but then docker sort of lost

00:33:13.400 --> 00:33:21.420
<v Sebastian Ramirez>against where net is um i will put a traffic a load balancer in front to handle https and yeah

00:33:21.430 --> 00:33:27.660
<v Sebastian Ramirez>well like regular load balancing and uh yeah just regular uvicon what we were what some of the

00:33:27.660 --> 00:33:33.940
<v Sebastian Ramirez>folks we were talking about before at some point we needed to have unicorn on top of ubicorne because

00:33:34.100 --> 00:33:38.820
<v Sebastian Ramirez>ubicorne wouldn't be able to handle workers but now ubicorne can handle its workers like everything

00:33:38.840 --> 00:33:43.780
<v Sebastian Ramirez>and like handle the main thing was the zombie processes and like uh you know like ripping

00:33:44.240 --> 00:33:48.620
<v Sebastian Ramirez>the processes and like handling the stuff now it's conscious to that so you can just like run

00:33:49.160 --> 00:33:54.680
<v Sebastian Ramirez>playing ubicarn so if you are using fast api and you say fast api run that already does that so if

00:33:54.740 --> 00:33:59.480
<v Sebastian Ramirez>you're deploying on your own you can just use the fast api run command then of course you have to

00:33:59.520 --> 00:34:04.980
<v Sebastian Ramirez>deal with scaling and https and balancing like all the stuff but like you know like the core

00:34:05.880 --> 00:34:12.440
<v Sebastian Ramirez>server you can just like run it directly if going beyond that then like will probably be like some

00:34:12.879 --> 00:34:18.820
<v Sebastian Ramirez>cluster kubernetes i'm trying to scale things figure out the ways to scale things based on

00:34:19.120 --> 00:34:25.860
<v Sebastian Ramirez>the load of the requests you know like scaling automatically i having one normally one container

00:34:26.220 --> 00:34:30.480
<v Sebastian Ramirez>per process to be able to scale that more dynamically without depending on the local memory

00:34:30.700 --> 00:34:35.840
<v Sebastian Ramirez>for each one of the servers and things like that i probably saying too much but yeah actually you

00:34:35.860 --> 00:34:48.000
<v Sebastian Ramirez>If I didn't have a CPI cloud, I would probably use one of the providers that abstract those things a little bit away, you know, like render, railway, fly, like, I don't know.

00:34:48.280 --> 00:35:01.200
<v Sebastian Ramirez>I don't really think that a regular developer should be dealing with, you know, like the big hyperscalers and like Kubernetes and like all the complexity for a common app.

00:35:01.560 --> 00:35:06.460
<v Sebastian Ramirez>Most of the cases I think it's just really too much complexity to deal with.

00:35:07.560 --> 00:35:12.020
<v Michael Kennedy>It's kind of eye-watering to open up the AWS console or Azure or something.

00:35:12.400 --> 00:35:12.540
<v Michael Kennedy>Whoa.

00:35:13.480 --> 00:35:19.820
<v Sebastian Ramirez>The other day, in one of the AWS accounts, I had to change the account email.

00:35:20.320 --> 00:35:21.420
<v Sebastian Ramirez>I think I spent four hours.

00:35:22.120 --> 00:35:22.600
<v Sebastian Ramirez>I know.

00:35:23.660 --> 00:35:27.360
<v Sebastian Ramirez>Because I had to create a delegate account that has the right permissions.

00:35:27.720 --> 00:35:33.020
<v Sebastian Ramirez>often like oh no this is you know like it's sometimes it's just overwhelming the amount

00:35:33.020 --> 00:35:39.220
<v Sebastian Ramirez>of complexity that needs to be dealt with and uh yeah i mean it's it's great to really have like

00:35:39.350 --> 00:35:45.760
<v Sebastian Ramirez>you know like the uh infra people that i have working with me at the company that i can deal

00:35:45.880 --> 00:35:50.380
<v Sebastian Ramirez>with all that mess and like and make sure that everything is just running perfectly and

00:35:51.200 --> 00:35:57.680
<v Sebastian Ramirez>it just works so it's like you know like sort of uh sre as a service they work as a service for

00:35:57.860 --> 00:36:01.560
<v Sebastian Ramirez>It's like a cloud that provides the old social site research.

00:36:02.000 --> 00:36:02.560
<v Cody Fincher>Yeah, that's awesome.

00:36:03.940 --> 00:36:07.100
<v Cody Fincher>So I spent a number of years doing nothing but cloud migrations

00:36:07.220 --> 00:36:09.680
<v Cody Fincher>to these hyperscalers for like enterprises.

00:36:10.280 --> 00:36:13.820
<v Cody Fincher>And I can tell you that when you mentioned the eye-watering comment

00:36:14.080 --> 00:36:15.560
<v Cody Fincher>about like the network and all that stuff,

00:36:15.700 --> 00:36:17.940
<v Cody Fincher>it's so incredibly complicated now, right?

00:36:17.980 --> 00:36:20.920
<v Cody Fincher>Like there's literally every kind of concept that you need to know

00:36:21.060 --> 00:36:25.820
<v Cody Fincher>to deploy these enterprises now and move them from on-prem to the cloud.

00:36:25.840 --> 00:36:27.760
<v Cody Fincher>So it does get incredibly complicated.

00:36:27.910 --> 00:36:30.560
<v Cody Fincher>Having something simple like what Sebastian is talking about,

00:36:30.570 --> 00:36:31.940
<v Cody Fincher>I think is, is, you know,

00:36:32.270 --> 00:36:35.140
<v Cody Fincher>super helpful when you're just trying to get started and get something up and

00:36:35.240 --> 00:36:36.080
<v Cody Fincher>running, you know, quickly.

00:36:37.000 --> 00:36:39.540
<v Michael Kennedy>Yeah, for sure. All right.

00:36:40.380 --> 00:36:43.560
<v Michael Kennedy>I've got a lot of questions and I realized that we will not be getting through

00:36:43.630 --> 00:36:47.320
<v Michael Kennedy>all of them. So I want to, I want to pick carefully.

00:36:47.540 --> 00:36:50.060
<v Michael Kennedy>So let's do, let's do this one next.

00:36:52.039 --> 00:36:54.120
<v Michael Kennedy>Performance. What's your best

00:36:55.260 --> 00:37:01.180
<v Michael Kennedy>low effort tip, not like something super complicated, but I know there's a bunch of

00:37:01.190 --> 00:37:07.040
<v Michael Kennedy>low hanging fruit that people maybe missed out on. And this time, let's start with Litestar.

00:37:07.510 --> 00:37:12.520
<v Cody Fincher>Cody, back at you. All right. Well, so I'm going to stick to what I know, which is databases,

00:37:12.730 --> 00:37:17.580
<v Cody Fincher>because I deal with that every single day. There's a couple of things that I see as like

00:37:17.600 --> 00:37:24.960
<v Cody Fincher>gotchas that I constantly see over and over. One, SeqWalcom, E-Trans, kind of obfuscates

00:37:25.900 --> 00:37:30.120
<v Cody Fincher>the way it's going to execute things and what kind of queries it's going to actually execute. So

00:37:30.440 --> 00:37:37.060
<v Cody Fincher>it's really easy if you're not kind of fluent in how it works to create N plus one types of issues.

00:37:37.160 --> 00:37:41.860
<v Cody Fincher>And so when people start talking about sync or async, it's really, in my mind, it's less of that

00:37:41.920 --> 00:37:45.860
<v Cody Fincher>because you're going to spend more time waiting on the network and database and those kinds of

00:37:45.800 --> 00:37:51.240
<v Cody Fincher>things, then you're going to spend serializing just generally, right? And or processing things

00:37:51.260 --> 00:37:58.260
<v Cody Fincher>on the web framework. And so one, making sure that you have your relationships dialed in correctly

00:37:58.340 --> 00:38:07.420
<v Cody Fincher>so that you don't have N plus one queries. The other thing is oversized connection pooling into

00:38:07.580 --> 00:38:13.140
<v Cody Fincher>Postgres and just databases in general, because what people don't tend to know is that each of

00:38:13.000 --> 00:38:17.740
<v Cody Fincher>those connections takes up CPU cycles and RAM of the database. And so when you slam the database

00:38:17.960 --> 00:38:23.180
<v Cody Fincher>with hundreds of connections, you're just taking away processing power that can be done for other

00:38:23.340 --> 00:38:27.860
<v Cody Fincher>things, right? And so you end up ultimately slowing things down. So I've seen databases that

00:38:28.240 --> 00:38:32.620
<v Cody Fincher>have had so many connections that all of the CPU and all the stuff is actually doing things,

00:38:32.740 --> 00:38:35.020
<v Cody Fincher>just managing connections and can't actually do any database work.

00:38:35.160 --> 00:38:39.440
<v Michael Kennedy>What about this socket? Is it busy? What about this socket? Is it busy? It's just round robin

00:38:39.460 --> 00:38:46.720
<v Cody Fincher>that, right? Exactly. So yeah, so paying attention to the database is kind of my first kind of rule

00:38:46.740 --> 00:38:53.080
<v Michael Kennedy>of thumb. 100%. I like that one a lot. Yannick. Yeah, I'll throw in putting stuff or identifying

00:38:54.320 --> 00:38:58.540
<v David Lord>work that doesn't need to be done immediately for the user and putting in a background task.

00:38:59.340 --> 00:39:05.780
<v David Lord>Having a background worker defer things till later. So sending email is an example,

00:39:05.840 --> 00:39:11.680
<v David Lord>although there's nuances there about knowing that it's sent and everything but um yeah if you if

00:39:11.820 --> 00:39:18.360
<v David Lord>you if user kicks off some process and then you wait to do that process in the worker you're

00:39:18.460 --> 00:39:24.940
<v David Lord>holding that worker up which is more relevant in wsgi than asgi but uh and you're making them wait

00:39:25.060 --> 00:39:31.980
<v David Lord>for their page to load again versus record what they wanted to do send it off to the background

00:39:32.000 --> 00:39:35.520
<v David Lord>let them see the status of it, but let the background worker handle it.

00:39:36.060 --> 00:39:37.080
<v Michael Kennedy>Yeah, that's great advice.

00:39:39.040 --> 00:39:40.660
<v Michael Kennedy>All right, Yannick, I said, you guys, go for it.

00:39:40.760 --> 00:39:40.960
<v Speaker 6>Yeah, yeah.

00:39:43.540 --> 00:39:50.780
<v Speaker 6>Well, I want to, I'm not sure if that's some sort of, it's not really a trick or a tip,

00:39:50.860 --> 00:39:58.240
<v Speaker 6>or more like, I think the most common mistake I see when I, this is ASCII specific,

00:39:59.060 --> 00:40:01.240
<v Speaker 6>but when I look at ASCII apps that people have written,

00:40:01.770 --> 00:40:06.200
<v Speaker 6>who are maybe not as familiar with ASCII or async Python at all,

00:40:07.120 --> 00:40:13.400
<v Speaker 6>is if you make something an async function,

00:40:13.560 --> 00:40:16.540
<v Speaker 6>you should be absolutely sure that it's non-blocking.

00:40:17.519 --> 00:40:23.140
<v Speaker 6>Because if you're running an ASCII app and you're blocking anywhere,

00:40:23.580 --> 00:40:25.920
<v Speaker 6>your whole application server is blocked completely.

00:40:25.990 --> 00:40:28.420
<v Speaker 6>It doesn't handle any other requests at the same time.

00:40:28.440 --> 00:40:29.580
<v Speaker 6>It's blocked fully.

00:40:30.480 --> 00:40:39.500
<v Speaker 6>And I don't think I've had any mistake more times

00:40:39.790 --> 00:40:44.140
<v Speaker 6>when I've looked through some apps that someone has written

00:40:44.290 --> 00:40:47.040
<v Speaker 6>or that I've came across somewhere.

00:40:47.890 --> 00:40:50.460
<v Speaker 6>So this is really, it's super, super common.

00:40:50.530 --> 00:40:55.160
<v Speaker 6>And it has such a big impact on the overall performance

00:40:56.380 --> 00:40:59.660
<v Speaker 6>in every metric imaginable.

00:41:00.200 --> 00:41:01.000
<v Speaker 6>So I would say,

00:41:02.320 --> 00:41:05.180
<v Speaker 6>and that's nowadays what I tell people,

00:41:06.440 --> 00:41:08.960
<v Speaker 6>unless you're 100% sure that you know what you're doing

00:41:09.140 --> 00:41:11.460
<v Speaker 6>and you know it's non-blocking,

00:41:12.140 --> 00:41:13.180
<v Speaker 6>don't make it async.

00:41:13.740 --> 00:41:16.640
<v Speaker 6>Put it in a thread, execute it in a thread, whatever.

00:41:17.260 --> 00:41:19.540
<v Speaker 6>All of the ASCII frameworks and Django

00:41:21.560 --> 00:41:23.500
<v Speaker 6>give you a lot of tools at hand

00:41:23.520 --> 00:41:30.440
<v Speaker 6>to translate your stuff from sync to async so you can still run it, do that unless you're

00:41:30.660 --> 00:41:34.380
<v Speaker 6>very sure that it actually fully supports async.

00:41:35.300 --> 00:41:37.920
<v Michael Kennedy>Yeah, that's good advice. Sebastian.

00:41:41.020 --> 00:41:48.620
<v Sebastian Ramirez>Hey, I'm actually going to second, Yannick. I think, yeah, like it's maybe counterintuitive

00:41:48.640 --> 00:41:54.560
<v Sebastian Ramirez>that like one of the tips of performance is to try to not optimize that much performance at the

00:41:54.640 --> 00:42:00.000
<v Sebastian Ramirez>beginning you know like async the idea with async is like oh you can get so much performance and

00:42:00.100 --> 00:42:06.740
<v Sebastian Ramirez>throughput in terms of accuracy whatever but the thing is in most of the cases uh you know like

00:42:07.160 --> 00:42:12.640
<v Sebastian Ramirez>until apps grow so large they actually don't need that much extra throughput that much extra

00:42:12.560 --> 00:42:19.080
<v Sebastian Ramirez>performance and in a framework like you know like as janet was saying well in my case i know fast

00:42:19.120 --> 00:42:24.020
<v Sebastian Ramirez>api but like you know like also many others if you define the function with async it's going to be

00:42:24.180 --> 00:42:29.140
<v Sebastian Ramirez>run async if you define it non-async and regular depth it's going to be run on a thread worker

00:42:29.380 --> 00:42:36.140
<v Sebastian Ramirez>automatically so it's just going to do the smart thing automatically so it's like fair you know

00:42:36.140 --> 00:42:41.740
<v Sebastian Ramirez>like it's going to be good enough and then you can just start with that and just keep blocking

00:42:41.760 --> 00:42:46.620
<v Sebastian Ramirez>code everywhere you know like just not use async until you actually know that you really need to

00:42:46.720 --> 00:42:53.980
<v Sebastian Ramirez>use async and once you do you have to be as you know like 100 sure that you are not running blocking

00:42:54.160 --> 00:43:00.160
<v Sebastian Ramirez>code inside of it and if you need to run blocking code inside of async code then make sure that you

00:43:00.220 --> 00:43:07.580
<v Sebastian Ramirez>are sending it through to a thread worker sending it through to a thread worker sounds uh down thing

00:43:07.600 --> 00:43:13.680
<v Sebastian Ramirez>but yeah like you know like django has tools any io has tools i also built something on top of any

00:43:13.700 --> 00:43:19.020
<v Sebastian Ramirez>iog all the sinker that is just to simplify these things to asyncify a blocking function

00:43:19.740 --> 00:43:23.820
<v Sebastian Ramirez>keeping all the type information so you get out of completion and inline errors and everything

00:43:24.420 --> 00:43:29.560
<v Sebastian Ramirez>even though it's actually doing all the stuff of sending the thing to the to the thread worker so

00:43:29.760 --> 00:43:33.900
<v Sebastian Ramirez>the goal is super simple you keep very simple code but then in there underneath it's just like doing

00:43:33.940 --> 00:43:38.120
<v Sebastian Ramirez>all the stuff that should be doing but you know like that's normally when you actually need to

00:43:38.740 --> 00:43:44.340
<v Sebastian Ramirez>hyper optimize things in most of the cases you can just start with just not using async at first

00:43:45.140 --> 00:43:49.660
<v Sebastian Ramirez>also now that you're gonna have python multi-threaded then suddenly you're gonna have

00:43:49.920 --> 00:43:56.240
<v Sebastian Ramirez>just so much more performance out of the blue without even having to do much more so yeah yeah

00:43:56.440 --> 00:44:02.380
<v Sebastian Ramirez>actually that's you know like sorry i kept speaking so much but the here's a tip for

00:44:02.400 --> 00:44:09.280
<v Sebastian Ramirez>improving performance uh upgrade your patient python version i was just chatting today with savannah

00:44:11.240 --> 00:44:16.940
<v Sebastian Ramirez>she was adding the benchmarks to the you know like python benchmark the python the official

00:44:17.120 --> 00:44:23.480
<v Sebastian Ramirez>python bearing benchmarks that they run for the c python faster the faster c python program and

00:44:24.800 --> 00:44:34.980
<v Sebastian Ramirez>the change from Python 3.10 to Python 3.14 when running FastAPI is like almost double the

00:44:35.280 --> 00:44:40.220
<v Sebastian Ramirez>performance or something like that. It was like, it was crazy. It was just crazy improvement in

00:44:40.340 --> 00:44:45.260
<v Sebastian Ramirez>performance. So you can just upgrade your Python version, you're going to get so much better

00:44:45.440 --> 00:44:51.520
<v Michael Kennedy>performance. That's an awesome piece of advice that I think is often overlooked. And it's not

00:44:51.440 --> 00:44:54.260
<v Michael Kennedy>Not only CPU speed, it's also memory gets a lot lower.

00:44:54.800 --> 00:44:55.580
<v Michael Kennedy>Whoever's going to jump in, go ahead.

00:44:56.260 --> 00:44:56.600
<v David Lord>Oh, yeah.

00:44:57.400 --> 00:45:02.660
<v David Lord>Last year, I was looking at Markup Safe, which is an HTML escaping library that we use.

00:45:03.580 --> 00:45:05.500
<v David Lord>And it has a C extension for speedups.

00:45:05.560 --> 00:45:12.580
<v David Lord>And I almost convinced myself that I can stop maintaining the C extension because just Python itself got way faster.

00:45:12.840 --> 00:45:16.820
<v David Lord>But then it turned out that I could do something to the C extension to make it faster also.

00:45:18.220 --> 00:45:27.800
<v David Lord>But just the fact that I almost convinced myself, like, oh, I can drop a C extension for just a Python upgrade instead was pretty impressive.

00:45:28.380 --> 00:45:29.180
<v David Lord>Yeah, that's really cool.

00:45:30.140 --> 00:45:34.520
<v David Lord>Especially with, like, string handling, you know, which you're going to use for templating for web apps.

00:45:37.240 --> 00:45:37.400
<v Phil Jones>Phil?

00:45:38.900 --> 00:45:45.760
<v Phil Jones>Yeah, well, I definitely echo looking at your DB queries, because by far and large, that's always where our performance issues have been.

00:45:45.940 --> 00:45:49.720
<v Phil Jones>it's either badly written query or we're returning most of the database when the user just wants

00:45:49.720 --> 00:45:54.580
<v Phil Jones>to know about one thing or something silly like that. But I was thinking about low hanging ones,

00:45:54.670 --> 00:46:00.440
<v Phil Jones>which I think you asked about. So I'd say uv loop, which is still a noticeable improvement.

00:46:01.380 --> 00:46:06.320
<v Phil Jones>And also because I think it's likely a lot of us are returning JSON, often changing the

00:46:06.820 --> 00:46:11.780
<v Phil Jones>JSON serializer to one of the faster ones can be noticeable as well and obviously quite easy to do.

00:46:12.040 --> 00:46:14.980
<v Michael Kennedy>So yeah, that's really good advice.

00:46:15.080 --> 00:46:16.800
<v Michael Kennedy>I didn't think about the JSON serializer.

00:46:17.460 --> 00:46:18.100
<v Michael Kennedy>What one do you recommend?

00:46:19.440 --> 00:46:22.220
<v Phil Jones>I think is it you, JSON, or is it all JSON?

00:46:22.780 --> 00:46:23.840
<v Phil Jones>I can't remember which one was different.

00:46:23.980 --> 00:46:24.240
<v Phil Jones>Yeah, yeah.

00:46:24.520 --> 00:46:25.080
<v Phil Jones>Replace it.

00:46:27.000 --> 00:46:30.160
<v Phil Jones>But yeah, if you look at the Tech Empower benchmarks,

00:46:30.480 --> 00:46:32.420
<v Phil Jones>everyone's changing their JSON serializer

00:46:32.600 --> 00:46:33.760
<v Phil Jones>to get that bit extra speed.

00:46:33.940 --> 00:46:34.280
<v Phil Jones>It's--

00:46:34.620 --> 00:46:35.820
<v Michael Kennedy>Yeah, you're like, our framework looks

00:46:36.100 --> 00:46:38.280
<v Michael Kennedy>bad because our JSON serializer is like third

00:46:38.300 --> 00:46:38.920
<v Michael Kennedy>of the performance.

00:46:39.480 --> 00:46:39.660
<v Michael Kennedy>Yeah.

00:46:41.540 --> 00:46:44.900
<v Phil Jones>We changed, well, David added a JSON provider to Flask,

00:46:45.100 --> 00:46:47.160
<v Phil Jones>and yeah, you could see it make a difference

00:46:47.270 --> 00:46:49.200
<v Phil Jones>in the tech and power benchmarks, so that was really good.

00:46:49.200 --> 00:46:49.620
<v Michael Kennedy>Oh, interesting.

00:46:50.540 --> 00:46:50.840
<v Michael Kennedy>Yeah, cool.

00:46:51.800 --> 00:46:52.880
<v David Lord>Yeah, it's pluggable now,

00:46:53.100 --> 00:46:56.300
<v David Lord>but if you're not installing Flask or JSON,

00:46:56.640 --> 00:46:59.540
<v David Lord>I mean, I don't know what other JSON library

00:46:59.740 --> 00:47:00.580
<v David Lord>you'd be using at this point,

00:47:00.590 --> 00:47:01.540
<v David Lord>unless you're already using one,

00:47:01.880 --> 00:47:04.180
<v David Lord>but or JSON is very, very fast.

00:47:04.860 --> 00:47:06.520
<v Michael Kennedy>Okay, this is something I'm going to be looking into later.

00:47:08.699 --> 00:47:10.380
<v Michael Kennedy>So over to Django, Jeff,

00:47:10.640 --> 00:47:14.680
<v Michael Kennedy>David talked about running stuff in the background and I said Django five or

00:47:14.840 --> 00:47:16.540
<v Michael Kennedy>Django six that got the background task thing.

00:47:17.300 --> 00:47:17.420
<v Jeff Triplett>Yeah.

00:47:17.480 --> 00:47:17.940
<v Jeff Triplett>Django six,

00:47:18.010 --> 00:47:21.640
<v Jeff Triplett>which just came out a couple of weeks ago and I'll hand that off to Carlton in

00:47:21.640 --> 00:47:21.980
<v Jeff Triplett>a second.

00:47:22.160 --> 00:47:22.600
<v Jeff Triplett>Cause I think,

00:47:22.970 --> 00:47:23.060
<v Jeff Triplett>um,

00:47:23.420 --> 00:47:26.020
<v Jeff Triplett>problems had more to do with the actual plumbing,

00:47:26.450 --> 00:47:26.540
<v Jeff Triplett>uh,

00:47:26.660 --> 00:47:27.580
<v Jeff Triplett>being on the steering council.

00:47:28.230 --> 00:47:28.320
<v Jeff Triplett>Uh,

00:47:28.580 --> 00:47:31.600
<v Jeff Triplett>my advice to people is the best way to scale something is just to not do it,

00:47:31.660 --> 00:47:32.820
<v Jeff Triplett>avoid the process completely.

00:47:32.990 --> 00:47:34.440
<v Jeff Triplett>So like I mentioned the CDN earlier,

00:47:34.800 --> 00:47:35.720
<v Jeff Triplett>it's content heavy science,

00:47:35.900 --> 00:47:36.960
<v Jeff Triplett>cash the crap out of stuff.

00:47:37.390 --> 00:47:37.480
<v Jeff Triplett>Um,

00:47:37.640 --> 00:47:38.660
<v Jeff Triplett>it doesn't even have to hit your servers.

00:47:39.270 --> 00:47:39.360
<v Jeff Triplett>Um,

00:47:39.510 --> 00:47:40.280
<v Jeff Triplett>you can go a lot,

00:47:40.340 --> 00:47:41.220
<v Jeff Triplett>as we mentioned earlier too,

00:47:41.380 --> 00:47:43.620
<v Jeff Triplett>just by doubling the amount of resources a project has.

00:47:44.540 --> 00:47:45.880
<v Jeff Triplett>Django is pretty efficient these days,

00:47:46.160 --> 00:47:47.040
<v Jeff Triplett>especially with async views.

00:47:48.300 --> 00:47:49.240
<v Jeff Triplett>Like everybody else has said too,

00:47:50.180 --> 00:47:52.780
<v Jeff Triplett>any blocking code, move off to threads,

00:47:53.280 --> 00:47:54.800
<v Jeff Triplett>move off to a background queue.

00:47:55.600 --> 00:47:57.860
<v Jeff Triplett>Django Q2 is my favorite one to use

00:47:57.880 --> 00:47:58.900
<v Jeff Triplett>because you can use a database.

00:47:59.640 --> 00:48:00.880
<v Jeff Triplett>So for those little side projects

00:48:00.960 --> 00:48:02.680
<v Jeff Triplett>where you just want to run one or two processes,

00:48:02.860 --> 00:48:03.420
<v Jeff Triplett>you can use it.

00:48:03.420 --> 00:48:03.900
<v Jeff Triplett>It works great.

00:48:05.520 --> 00:48:08.560
<v Jeff Triplett>And Carlton, if you want to talk about Django internals.

00:48:09.300 --> 00:48:10.020
<v Carlton Gibson>Yeah, okay.

00:48:10.200 --> 00:48:12.260
<v Carlton Gibson>So the new task framework I just mentioned,

00:48:12.850 --> 00:48:15.920
<v Carlton Gibson>the main sort of bit about it is that it's, again,

00:48:16.070 --> 00:48:17.400
<v Carlton Gibson>this pluggable Django API.

00:48:17.610 --> 00:48:19.360
<v Carlton Gibson>So it gives a standard task API.

00:48:19.470 --> 00:48:20.920
<v Carlton Gibson>So if you're writing a third-party library,

00:48:21.190 --> 00:48:23.700
<v Carlton Gibson>and you need to send an email in,

00:48:23.880 --> 00:48:25.100
<v Carlton Gibson>it's the canonical example, right?

00:48:25.140 --> 00:48:27.160
<v Carlton Gibson>You need to send an email in your third-party library

00:48:27.400 --> 00:48:28.840
<v Carlton Gibson>before you'd have had to tie yourself

00:48:29.010 --> 00:48:30.340
<v Carlton Gibson>to a specific queue implementation,

00:48:30.990 --> 00:48:32.600
<v Carlton Gibson>whereas now Django's providing a kind of,

00:48:33.480 --> 00:48:34.920
<v Carlton Gibson>like an ORM of tasks.

00:48:35.000 --> 00:48:35.460
<v Carlton Gibson>Right, right.

00:48:35.460 --> 00:48:37.060
<v Michael Kennedy>You got to do Redis, you got to do Celery,

00:48:37.290 --> 00:48:38.960
<v Carlton Gibson>and you got to manage things and all that.

00:48:39.020 --> 00:48:41.960
<v Carlton Gibson>You don't have to pick that now as the third-party package author.

00:48:42.040 --> 00:48:45.780
<v Carlton Gibson>You can just say, right, just wrap this as a Django task and queue it.

00:48:46.080 --> 00:48:49.920
<v Carlton Gibson>And then the developer, when they come to choose their backend,

00:48:50.040 --> 00:48:52.080
<v Carlton Gibson>if they want to use Celery or they want to use Django Q2

00:48:52.200 --> 00:48:53.860
<v Carlton Gibson>or they want to use the Django task backend,

00:48:54.080 --> 00:48:58.420
<v Carlton Gibson>which Jake Howard, who wrote this for Django provided as well,

00:48:58.640 --> 00:49:00.020
<v Carlton Gibson>you can just plug that in.

00:49:00.280 --> 00:49:02.780
<v Carlton Gibson>So it's a pluggable interface for tasks,

00:49:03.020 --> 00:49:05.860
<v Carlton Gibson>which is, I think, the really nice thing about it.

00:49:06.280 --> 00:49:09.320
<v Carlton Gibson>In terms of quick wins, everybody's mentioned almost all of mine.

00:49:10.120 --> 00:49:12.240
<v Carlton Gibson>Cody and Phil, they mentioned the database.

00:49:12.740 --> 00:49:13.420
<v Carlton Gibson>That's the big one.

00:49:13.620 --> 00:49:17.100
<v Carlton Gibson>Django, the ORM, because it does lazy related lookups,

00:49:17.240 --> 00:49:22.080
<v Carlton Gibson>it's very easy to trigger M plus one where a book has multiple authors

00:49:22.300 --> 00:49:23.940
<v Carlton Gibson>and suddenly you're iterating through the books

00:49:24.080 --> 00:49:26.040
<v Carlton Gibson>and you're iterating through the authors and it's a lookup.

00:49:26.560 --> 00:49:29.280
<v Carlton Gibson>So you need to do things like prefetch related, select related.

00:49:29.380 --> 00:49:30.980
<v Carlton Gibson>You need to just check that you've got those.

00:49:31.180 --> 00:49:33.840
<v Carlton Gibson>Django debug toolbars are a great thing to run in development

00:49:34.000 --> 00:49:35.680
<v Carlton Gibson>where you can see the queries and it'll tell you

00:49:35.680 --> 00:49:36.660
<v Carlton Gibson>where you've got the duplicates.

00:49:37.280 --> 00:49:39.980
<v Carlton Gibson>Then the slightly bigger one is to just check your indexes.

00:49:40.300 --> 00:49:42.480
<v Carlton Gibson>The ORM will create the right indexes

00:49:42.500 --> 00:49:45.460
<v Carlton Gibson>if you're going through primary keys or unique fields,

00:49:45.500 --> 00:49:48.180
<v Carlton Gibson>but sometimes you're doing a filter on some field,

00:49:48.740 --> 00:49:50.400
<v Carlton Gibson>and then there's not the right index there,

00:49:50.400 --> 00:49:51.480
<v Carlton Gibson>and that can really slow you down.

00:49:51.660 --> 00:49:56.000
<v Carlton Gibson>Again, you can do the SQL explain on that and find that.

00:49:56.440 --> 00:49:59.360
<v Carlton Gibson>Then the thing I was going to say originally was caching.

00:50:00.540 --> 00:50:04.080
<v Carlton Gibson>Get a Redis instance, stick it next to your Django app,

00:50:04.180 --> 00:50:07.020
<v Carlton Gibson>and as Jeff said, don't do the work.

00:50:07.020 --> 00:50:09.540
<v Carlton Gibson>If you're continually rendering the same page

00:50:09.580 --> 00:50:10.380
<v Carlton Gibson>and it never changes,

00:50:11.080 --> 00:50:12.740
<v Carlton Gibson>cache it and pull it from the cache

00:50:12.910 --> 00:50:13.420
<v Carlton Gibson>rather than rendering.

00:50:13.580 --> 00:50:13.880
<v Carlton Gibson>Because template,

00:50:14.520 --> 00:50:16.000
<v Carlton Gibson>DB queries are one of your biggest things.

00:50:16.080 --> 00:50:18.040
<v Carlton Gibson>The second one's always going to be serialization.

00:50:18.160 --> 00:50:19.860
<v Carlton Gibson>That's either serialization or template rendering.

00:50:20.220 --> 00:50:22.460
<v Carlton Gibson>So if you can avoid that by caching,

00:50:22.800 --> 00:50:24.660
<v Carlton Gibson>you can save an awful lot of time on your requests.

00:50:24.960 --> 00:50:25.140
<v Michael Kennedy>Yeah.

00:50:25.590 --> 00:50:26.940
<v Michael Kennedy>I was wondering if somebody would come back

00:50:26.970 --> 00:50:28.020
<v Michael Kennedy>with database indexes

00:50:28.120 --> 00:50:32.760
<v Michael Kennedy>because that's like a 100x multiplier for free almost.

00:50:32.920 --> 00:50:34.920
<v Michael Kennedy>It's such a big deal.

00:50:35.200 --> 00:50:36.040
<v Carlton Gibson>It really can be.

00:50:36.100 --> 00:50:37.380
<v Carlton Gibson>If you're making a particular query

00:50:37.460 --> 00:50:38.600
<v Carlton Gibson>and it's doing a full table scan

00:50:38.720 --> 00:50:40.180
<v Carlton Gibson>and all of a sudden you put the index in,

00:50:40.280 --> 00:50:40.820
<v Carlton Gibson>it's instant.

00:50:41.160 --> 00:50:41.700
<v Carlton Gibson>It's like, oh, wow.

00:50:42.360 --> 00:50:44.200
<v Michael Kennedy>And you don't have to be a DBA

00:50:44.420 --> 00:50:47.460
<v Michael Kennedy>or master information architect sort of thing.

00:50:47.880 --> 00:50:48.880
<v Michael Kennedy>I don't know about Postgres.

00:50:49.000 --> 00:50:49.660
<v Michael Kennedy>I'm sure it has it.

00:50:49.720 --> 00:50:50.420
<v Michael Kennedy>Somebody can tell me.

00:50:50.600 --> 00:50:53.380
<v Michael Kennedy>But with Mongo, you can turn on in the database,

00:50:54.140 --> 00:50:55.780
<v Michael Kennedy>I want you to log all slow queries

00:50:56.040 --> 00:50:58.820
<v Michael Kennedy>and slow for me means 20 millisecond or whatever.

00:50:58.940 --> 00:50:59.880
<v Michael Kennedy>Like you put a number in

00:51:00.380 --> 00:51:02.220
<v Michael Kennedy>and then you run your app for a while

00:51:02.160 --> 00:51:04.660
<v Michael Kennedy>and you go look at what's slow, sort by slowest.

00:51:04.820 --> 00:51:06.620
<v Michael Kennedy>And then you can see, well, maybe that needs an index, right?

00:51:06.840 --> 00:51:09.060
<v Michael Kennedy>Like just let your app tell you what you got to do.

00:51:10.240 --> 00:51:11.660
<v Carlton Gibson>Yeah, there is a post.

00:51:11.860 --> 00:51:13.560
<v Carlton Gibson>I'm just trying to see if I can quickly look it up now.

00:51:13.700 --> 00:51:14.800
<v Carlton Gibson>There's a Postgres extension,

00:51:15.200 --> 00:51:18.360
<v Carlton Gibson>which will automatically run explain on the slow queries

00:51:18.640 --> 00:51:19.360
<v Carlton Gibson>and log them for you.

00:51:19.500 --> 00:51:20.640
<v Carlton Gibson>Nice. There you go.

00:51:21.480 --> 00:51:23.820
<v Cody Fincher>It's PG stat statements, I think, is what we're thinking about.

00:51:24.320 --> 00:51:24.740
<v Cody Fincher>Right, okay.

00:51:25.200 --> 00:51:25.520
<v Cody Fincher>Awesome.

00:51:26.759 --> 00:51:30.100
<v Michael Kennedy>If you're unsure about your database indexes, do this,

00:51:30.560 --> 00:51:32.500
<v Michael Kennedy>or at least go back and review your queries.

00:51:32.820 --> 00:51:33.400
<v Michael Kennedy>Yeah, I agree.

00:51:34.200 --> 00:51:34.700
<v Michael Kennedy>Very good.

00:51:35.300 --> 00:51:37.460
<v Michael Kennedy>All right, I can see we're blazing through these questions.

00:51:38.200 --> 00:51:39.280
<v David Lord>I have one other.

00:51:40.340 --> 00:51:41.100
<v David Lord>Yeah, please go ahead.

00:51:41.240 --> 00:51:41.820
<v Michael Kennedy>Yeah, go ahead, David.

00:51:42.720 --> 00:51:48.080
<v David Lord>If you want to get some more responsive parts of your website,

00:51:48.300 --> 00:51:51.140
<v David Lord>like make your website a little more responsive or interactive

00:51:51.320 --> 00:51:55.280
<v David Lord>with the user, htmx or datastar, especially

00:51:55.620 --> 00:51:57.800
<v David Lord>like if you're using court or another ASGI,

00:51:58.060 --> 00:52:01.240
<v David Lord>where you can do SSE, server-send events, or WebSockets.

00:52:03.480 --> 00:52:06.340
<v David Lord>Streaming little bits of changes to the web front end

00:52:06.340 --> 00:52:09.920
<v David Lord>and then rendering them with the same HTML you're already

00:52:10.140 --> 00:52:13.680
<v David Lord>writing can make things a lot more responsive.

00:52:14.050 --> 00:52:18.340
<v David Lord>We had a talk about that from Chris May at FlaskCon last year,

00:52:18.720 --> 00:52:19.600
<v David Lord>which you can find on YouTube.

00:52:20.280 --> 00:52:20.800
<v Michael Kennedy>Awesome.

00:52:22.080 --> 00:52:25.580
<v Michael Kennedy>You know, this is not one of the questions,

00:52:25.840 --> 00:52:29.240
<v Michael Kennedy>But let me just start out for a quick riff on this, folks.

00:52:29.940 --> 00:52:32.320
<v Michael Kennedy>Out in the audience, someone was asking, what about HTMX?

00:52:32.840 --> 00:52:35.840
<v Michael Kennedy>And I think more broadly, I am actually

00:52:35.920 --> 00:52:40.100
<v Michael Kennedy>a huge fan of server-side-based, template-based apps.

00:52:40.300 --> 00:52:42.400
<v Michael Kennedy>I think it just keeps things simpler in a lot of ways,

00:52:42.500 --> 00:52:43.640
<v Michael Kennedy>unless you need a lot of interactivity.

00:52:44.180 --> 00:52:47.620
<v Michael Kennedy>But things like HTMX or a little bit of JavaScript

00:52:47.920 --> 00:52:50.740
<v Michael Kennedy>can reduce a lot of the traffic and stuff.

00:52:50.860 --> 00:52:52.440
<v Michael Kennedy>Where do people land on those kinds of things?

00:52:53.860 --> 00:52:55.480
<v Speaker 6>I absolutely love, love HTML.

00:52:57.050 --> 00:53:02.700
<v Speaker 6>Not, not just because you don't have to write a lot of JavaScript or whatever, but mostly

00:53:02.820 --> 00:53:09.660
<v Speaker 6>because if, if, if I'm just building a simple app that needs a bit more than just be a static

00:53:10.080 --> 00:53:14.580
<v Speaker 6>HTML page, it needs some interactivity, a little bit of reactivity.

00:53:15.500 --> 00:53:22.800
<v Speaker 6>I feel like having the whole overhead of building an SPA or whatever tools you need for the

00:53:22.720 --> 00:53:24.840
<v Speaker 6>whole JavaScript, TypeScript, whatever stack.

00:53:25.380 --> 00:53:28.460
<v Speaker 6>It's just so much work to get a little bit,

00:53:28.680 --> 00:53:31.040
<v Speaker 6>to make a simple thing a little bit nicer,

00:53:31.220 --> 00:53:32.100
<v Speaker 6>a little bit more reactive.

00:53:32.670 --> 00:53:35.520
<v Speaker 6>And I feel like HTMX just fits right in there.

00:53:35.660 --> 00:53:37.320
<v Speaker 6>It's super great.

00:53:37.480 --> 00:53:39.300
<v Speaker 6>I've got a couple of things with it now,

00:53:39.870 --> 00:53:42.940
<v Speaker 6>a few of my own projects, a few things that work.

00:53:43.440 --> 00:53:46.060
<v Speaker 6>And it makes things so much easier where,

00:53:47.160 --> 00:53:49.860
<v Speaker 6>I don't know, the work probably wouldn't have been done

00:53:49.930 --> 00:53:51.700
<v Speaker 6>if it was just, you know, because it's too much.

00:53:51.900 --> 00:53:56.840
<v Speaker 6>if you're doing a whole front end thing that you have then to deploy and build and whatever,

00:53:57.360 --> 00:54:03.420
<v Speaker 6>or it would have been less nice. So it's an amazing, really amazing thing.

00:54:04.820 --> 00:54:12.560
<v Cody Fincher>As the maintainer and author, though, one of the things that is, well, it's not frustrating,

00:54:12.840 --> 00:54:17.280
<v Cody Fincher>but it's understandable is that HTMX is not for everybody, right? There's not like it's,

00:54:17.360 --> 00:54:20.520
<v Cody Fincher>you can't use HTMX in all occasions or Datastar, right?

00:54:20.590 --> 00:54:23.160
<v Cody Fincher>And so there are people that are always going to want to use React

00:54:23.370 --> 00:54:25.680
<v Cody Fincher>and there's going to be people that want to use all these other frameworks.

00:54:25.790 --> 00:54:28.980
<v Cody Fincher>And so having some cohesive way to make them all talk together,

00:54:29.110 --> 00:54:29.860
<v Cody Fincher>I think is important.

00:54:30.620 --> 00:54:34.040
<v Cody Fincher>I don't have that answer yet, but I just know that like,

00:54:34.440 --> 00:54:36.840
<v Cody Fincher>I can't always say HTMX is it, right?

00:54:37.320 --> 00:54:39.860
<v Cody Fincher>And then you'll have a great time because I'll inevitably meet somebody

00:54:39.970 --> 00:54:41.700
<v Cody Fincher>that says I need to do this and it's right.

00:54:41.700 --> 00:54:45.500
<v Cody Fincher>And it's in a single page application or something is more appropriate for that.

00:54:45.560 --> 00:54:50.100
<v Cody Fincher>And so, you know, it's obviously the right tool for the right job when you need it.

00:54:50.240 --> 00:54:55.180
<v Cody Fincher>But, you know, I want to make something that is cohesive depending on whatever library you want to use.

00:54:56.620 --> 00:54:57.820
<v Jeff Triplett>I would throw one thing in there, though.

00:54:57.910 --> 00:55:02.040
<v Jeff Triplett>I would rather somebody start with HTMLX than I would start with React if you don't need it.

00:55:02.190 --> 00:55:03.740
<v Jeff Triplett>Because React can be total overkill.

00:55:03.770 --> 00:55:05.080
<v Jeff Triplett>It can be great for some applications.

00:55:05.720 --> 00:55:10.040
<v Jeff Triplett>But oftentimes, a consultant will see people like having an About page and they throw a React at it.

00:55:10.160 --> 00:55:10.940
<v Jeff Triplett>It's like, why do you need that?

00:55:11.420 --> 00:55:13.220
<v Jeff Triplett>Like, especially for small things with partials.

00:55:13.900 --> 00:55:15.320
<v Cody Fincher>You mean you don't want to start with Angular?

00:55:16.980 --> 00:55:20.920
<v Jeff Triplett>You know, it's fine if you need it, but I don't think you really need it.

00:55:21.110 --> 00:55:22.840
<v Jeff Triplett>Like, introduce tools as you need them.

00:55:23.680 --> 00:55:28.720
<v Jeff Triplett>Django60 just added template partials, and I guess my job here is to hand off to Carlton, because this is his feature.

00:55:29.580 --> 00:55:31.820
<v Michael Kennedy>Yeah, I was having to see that come in there, Carlton. Nice job.

00:55:31.890 --> 00:55:33.800
<v Carlton Gibson>No, it's okay. Plug the new feature.

00:55:33.890 --> 00:55:39.060
<v Carlton Gibson>So, I mean, I stepped down as a fellow in 2023 into a new business,

00:55:39.440 --> 00:55:43.420
<v Carlton Gibson>and I read the essay about template fragments on the HTMLX website,

00:55:43.720 --> 00:55:47.380
<v Carlton Gibson>where it's named reusable bits in the templates.

00:55:48.000 --> 00:55:48.900
<v Carlton Gibson>And I was like, I need that.

00:55:48.940 --> 00:55:50.520
<v Carlton Gibson>So I built Django template partials,

00:55:50.900 --> 00:55:52.000
<v Carlton Gibson>released it as a third-party package,

00:55:52.240 --> 00:55:54.820
<v Carlton Gibson>and it's now just been merged into core for Django 6.0.

00:55:55.460 --> 00:55:57.220
<v Carlton Gibson>And I have to say about HTML,

00:55:57.460 --> 00:55:59.180
<v Carlton Gibson>it's really changed the way I write websites.

00:55:59.480 --> 00:56:00.480
<v Carlton Gibson>Before I was the fellow,

00:56:00.480 --> 00:56:01.880
<v Carlton Gibson>I used to write mobile applications

00:56:02.300 --> 00:56:04.460
<v Carlton Gibson>and do the front end of the mobile application,

00:56:04.560 --> 00:56:06.580
<v Carlton Gibson>then the back end in Django using Django REST framework.

00:56:06.780 --> 00:56:09.520
<v Carlton Gibson>And that's how I got into open source

00:56:09.620 --> 00:56:10.700
<v Carlton Gibson>was via Django REST framework.

00:56:11.520 --> 00:56:15.500
<v Carlton Gibson>And since starting the new application, we're three years in.

00:56:15.620 --> 00:56:17.500
<v Carlton Gibson>We've hardly got a JSON endpoint in sight.

00:56:17.720 --> 00:56:21.140
<v Carlton Gibson>It's like two, three, four of them in the whole application.

00:56:21.560 --> 00:56:24.140
<v Carlton Gibson>And it's just a delight.

00:56:24.320 --> 00:56:26.700
<v Carlton Gibson>Again, you asked me at the beginning, Michael, am I having fun?

00:56:26.760 --> 00:56:28.040
<v Carlton Gibson>Yeah, I really am having fun.

00:56:28.140 --> 00:56:29.160
<v Carlton Gibson>And HTMX is the reason.

00:56:29.480 --> 00:56:33.460
<v Carlton Gibson>I do grant there are these use cases where it's not right, but go for it.

00:56:36.960 --> 00:56:37.280
<v Michael Kennedy>Awesome.

00:56:37.460 --> 00:56:40.080
<v Michael Kennedy>All right, let's talk about our last topic.

00:56:40.400 --> 00:56:44.700
<v Michael Kennedy>And we have five minutes-ish to do that.

00:56:44.730 --> 00:56:46.560
<v Michael Kennedy>So we got to stay on target quick.

00:56:46.590 --> 00:56:48.780
<v Michael Kennedy>But let's just go around real quick here.

00:56:50.240 --> 00:56:52.480
<v Michael Kennedy>We talked about upgrading the Python version,

00:56:53.460 --> 00:56:55.500
<v Michael Kennedy>getting better performance out of it.

00:56:56.480 --> 00:56:58.060
<v Michael Kennedy>I mentioned the lower memory side.

00:56:58.410 --> 00:57:02.840
<v Michael Kennedy>But I think one of the under-appreciated aspects

00:57:02.870 --> 00:57:03.420
<v Michael Kennedy>of this--

00:57:04.210 --> 00:57:08.399
<v Michael Kennedy>the Instagram team did a huge talk keynote on it a while ago--

00:57:08.420 --> 00:57:12.800
<v Michael Kennedy>is the memory that you run into when you start to scale out

00:57:12.980 --> 00:57:13.860
<v Michael Kennedy>your stuff on the server.

00:57:14.080 --> 00:57:15.920
<v Michael Kennedy>Because you're like, oh, I want to have four workers

00:57:16.120 --> 00:57:18.000
<v Michael Kennedy>so I can have more concurrency because of the gills.

00:57:18.200 --> 00:57:20.020
<v Michael Kennedy>So now you've got four copies of everything

00:57:20.140 --> 00:57:21.960
<v Michael Kennedy>that you cache in memory and just like the runtime.

00:57:22.180 --> 00:57:25.300
<v Michael Kennedy>And now you need eight gigs instead of what would have been

00:57:25.560 --> 00:57:27.180
<v Michael Kennedy>one or who knows, right?

00:57:28.640 --> 00:57:30.960
<v Michael Kennedy>But with free threaded Python coming on,

00:57:31.660 --> 00:57:34.320
<v Michael Kennedy>which I've seen a couple of comments in the chat like, hey,

00:57:34.500 --> 00:57:35.080
<v Michael Kennedy>tell us about this.

00:57:37.460 --> 00:57:43.420
<v Michael Kennedy>we could have true concurrency and we wouldn't need to scale as much on the process side, I think,

00:57:43.580 --> 00:57:47.220
<v Michael Kennedy>giving us both better performance and the ability to say, well, you actually have four times less

00:57:47.500 --> 00:57:52.960
<v Michael Kennedy>memory, so you could run smaller servers or whatever. What's the free threaded story for

00:57:53.010 --> 00:57:58.660
<v Michael Kennedy>all the frameworks? Carlton, let's go back to you for doing reverse. I'm really excited about it. I

00:57:58.760 --> 00:58:01.799
<v Carlton Gibson>don't know how it's going to play out, but I'm really excited about it. All it can do is help

00:58:01.860 --> 00:58:09.220
<v Carlton Gibson>django um you know the async story in django is nice and mature now uh but still most of it's

00:58:09.220 --> 00:58:12.220
<v Carlton Gibson>sync like you know you're still going to default the sync you're still going to write your sync

00:58:12.360 --> 00:58:16.520
<v Carlton Gibson>views you still got template rendering you know django's template template based kind of framework

00:58:16.680 --> 00:58:25.959
<v Carlton Gibson>really you're still gonna want you're still gonna want to run things synchronously concurrently and

00:58:26.860 --> 00:58:32.180
<v Carlton Gibson>proper threads are going to be yeah they can't but help i don't i don't know how it's going to roll

00:58:32.240 --> 00:58:36.340
<v Carlton Gibson>out i'll let someone else go because i'm getting well yeah i just like elaborated that for people

00:58:36.510 --> 00:58:43.100
<v Michael Kennedy>out there uh before we move on is you could set up your worker process to say i want you to actually

00:58:43.360 --> 00:58:50.160
<v Michael Kennedy>run eight threads in this one worker process and when multiple requests come in they could both be

00:58:50.340 --> 00:58:54.519
<v Michael Kennedy>sent off to the same worker to be processed and that allows that worker to do more unless the gill

00:58:54.540 --> 00:58:59.900
<v Michael Kennedy>comes along and says, stop, you only get to do one thing in threads in Python. And all of a sudden,

00:58:59.910 --> 00:59:04.260
<v Michael Kennedy>a lot of that falls down. This basically uncorks that and makes that easy all of a sudden. Even if

00:59:04.270 --> 00:59:09.200
<v Michael Kennedy>you yourself are not writing async, your server can be more async. Yeah. And this is the thing

00:59:09.230 --> 00:59:15.340
<v Carlton Gibson>that we found with ASCII is that you dispatch to a, you know, using to async or you dispatch it to

00:59:15.340 --> 00:59:20.920
<v Carlton Gibson>a thread, a threadable executor, but Python doesn't run that concurrently. And so it's like,

00:59:21.100 --> 00:59:26.460
<v Carlton Gibson>in parallel. So it's like, ah, it doesn't actually go as fast as you want it to. And so you end up

00:59:26.650 --> 00:59:30.960
<v Michael Kennedy>wanting multiple processes still. Yeah. All right. Let's keep it with Django. Jeff, what do you think?

00:59:33.000 --> 00:59:35.340
<v Jeff Triplett>I'm going to defer to the others on this. I have the least thoughts.

00:59:37.100 --> 00:59:43.200
<v Michael Kennedy>All right. Write down the stack, Sebastian. Write down the video, not website, web framework.

00:59:45.040 --> 00:59:48.200
<v Sebastian Ramirez>I think it's going to be awesome. This is going to help so much, so many things.

00:59:48.780 --> 00:59:56.020
<v Sebastian Ramirez>The challenge is going to be third-party libraries used by each individual application and if they are compatible or not.

00:59:56.940 --> 00:59:58.340
<v Sebastian Ramirez>That's where the challenge is going to be.

00:59:58.480 --> 01:00:03.120
<v Sebastian Ramirez>But other than that, it's just going to be free extra performance for everyone.

01:00:03.520 --> 01:00:06.200
<v Sebastian Ramirez>Just, you know, like just upgrading the version of Python.

01:00:06.310 --> 01:00:07.100
<v Sebastian Ramirez>So that's going to be awesome.

01:00:10.000 --> 01:00:10.180
<v Cody Fincher>Cody.

01:00:11.580 --> 01:00:13.160
<v Cody Fincher>Yeah, I'm going to echo what Sebastian just said.

01:00:13.220 --> 01:00:16.280
<v Cody Fincher>The third-party libraries, I think, are going to be the big kind of sticky point here.

01:00:16.840 --> 01:00:18.220
<v Cody Fincher>I'm looking forward to seeing what we can do.

01:00:18.440 --> 01:00:21.640
<v Cody Fincher>I'm going to kind of hold my thoughts and let Janik kind of speak a little bit on it

01:00:21.720 --> 01:00:23.960
<v Cody Fincher>because I know that he's looked at message specs specifically

01:00:24.240 --> 01:00:26.400
<v Cody Fincher>and some of the other things that might, you know,

01:00:26.470 --> 01:00:27.460
<v Cody Fincher>give some better context here.

01:00:27.620 --> 01:00:32.780
<v Cody Fincher>But yes, the third-party libraries are going to be the kind of the sticky issue,

01:00:33.060 --> 01:00:35.640
<v Cody Fincher>but I'm looking forward to seeing what we can, you know, make happen.

01:00:39.239 --> 01:00:44.120
<v Speaker 6>Well, I'm super excited actually specifically about async stuff

01:00:44.310 --> 01:00:47.760
<v Speaker 6>because for most of the time it was like, you know,

01:00:47.860 --> 01:00:53.580
<v Speaker 6>So if you can already saturate your CPU, you know, async doesn't help you much.

01:00:53.970 --> 01:01:01.900
<v Speaker 6>Well, now, if you have proper threads, you can actually do that in async as well.

01:01:02.540 --> 01:01:08.480
<v Speaker 6>And I think it's going to speed up a lot of applications just by default,

01:01:08.860 --> 01:01:16.320
<v Speaker 6>because almost all async applications out there use threads in some capacity,

01:01:16.420 --> 01:01:20.320
<v Speaker 6>because, well, most of the things aren't async by nature.

01:01:21.590 --> 01:01:22.940
<v Speaker 6>So they will use a thread pool

01:01:23.240 --> 01:01:26.000
<v Speaker 6>and it will run more concurrently.

01:01:26.030 --> 01:01:29.160
<v Speaker 6>And so that's going to be better.

01:01:29.690 --> 01:01:33.880
<v Speaker 6>But I'm also a bit scared about a few things

01:01:34.100 --> 01:01:37.600
<v Speaker 6>that mainly, as a few others have said now,

01:01:38.260 --> 01:01:39.780
<v Speaker 6>third-party libraries extension,

01:01:40.440 --> 01:01:44.420
<v Speaker 6>specifically those that are Python C extensions.

01:01:45.320 --> 01:01:56.000
<v Speaker 6>We just recently, I think like three weeks ago, also got a msgspec released for Python 3.14 and proper free threading support.

01:01:57.440 --> 01:01:58.820
<v Speaker 6>And that took a lot of work.

01:01:59.360 --> 01:02:06.740
<v Speaker 6>Unfortunately, a few of the CPython core devs chimed in and contributed three hours and helped out with that.

01:02:07.440 --> 01:02:11.680
<v Speaker 6>And all around the ecosystem, the last few years, there's been a lot of work going on.

01:02:12.580 --> 01:02:18.320
<v Speaker 6>But especially for more niche libraries that are still here and there,

01:02:19.360 --> 01:02:28.820
<v Speaker 6>I think there's still a lot to do and possibly also quite a few bugs lurking here and there

01:02:28.960 --> 01:02:32.420
<v Speaker 6>that haven't been found or are really hard to track down.

01:02:33.240 --> 01:02:38.500
<v Speaker 6>And I'm curious and a bit maybe scarce, too hard of a word.

01:02:39.720 --> 01:02:44.440
<v Speaker 6>It's going to be a little bit of a bumpy ride as people turn that on

01:02:44.660 --> 01:02:46.420
<v Michael Kennedy>and then the reality of what's happening.

01:02:47.010 --> 01:02:50.500
<v Michael Kennedy>However, I want to take Cody's warning and turn it on its head

01:02:50.860 --> 01:02:52.000
<v Michael Kennedy>about these third-party libraries,

01:02:52.940 --> 01:02:57.400
<v Michael Kennedy>because I think it's also an opportunity for regular Python developers

01:02:57.550 --> 01:03:02.480
<v Michael Kennedy>who are not async fanatics to actually capture some of that capability.

01:03:03.680 --> 01:03:05.240
<v Michael Kennedy>Say if some library says,

01:03:05.420 --> 01:03:08.680
<v Michael Kennedy>hey, I realize that if we actually implement this lower-level thing,

01:03:08.820 --> 01:03:11.580
<v Michael Kennedy>you don't actually see the implementation of in true

01:03:11.800 --> 01:03:14.220
<v Michael Kennedy>threading, and then you use it.

01:03:14.220 --> 01:03:15.300
<v Michael Kennedy>But you don't actually do threading.

01:03:15.300 --> 01:03:17.560
<v Michael Kennedy>You just call even a blocking function.

01:03:18.080 --> 01:03:19.640
<v Michael Kennedy>You might get a huge performance boost,

01:03:20.080 --> 01:03:23.400
<v Michael Kennedy>a little bit like David was talking about with markup safe.

01:03:23.960 --> 01:03:26.060
<v Michael Kennedy>And you could just all of a sudden,

01:03:26.260 --> 01:03:27.960
<v Michael Kennedy>with doing nothing with your code,

01:03:28.980 --> 01:03:31.180
<v Michael Kennedy>goes five times faster on an eight-core machine

01:03:31.520 --> 01:03:33.720
<v Michael Kennedy>or something in little places where it used to matter.

01:03:34.520 --> 01:03:37.999
<v Speaker 6>Yeah, I'm super excited for what--

01:03:38.020 --> 01:03:41.780
<v Speaker 6>We currently be focused on the things that are out there right now

01:03:41.980 --> 01:03:43.840
<v Speaker 6>and that might need to be updated,

01:03:43.910 --> 01:03:48.340
<v Speaker 6>but I'm super excited for what else might come of this, right?

01:03:49.750 --> 01:03:51.640
<v Speaker 6>New things that will be developed

01:03:51.890 --> 01:03:55.500
<v Speaker 6>or stuff that we are currently not thinking about

01:03:55.530 --> 01:04:00.140
<v Speaker 6>or that hadn't been considered for the past 30 years or so

01:04:00.230 --> 01:04:02.540
<v Speaker 6>because it wasn't feasible or wasn't possible

01:04:02.740 --> 01:04:03.820
<v Speaker 6>or didn't make sense at all.

01:04:04.480 --> 01:04:08.560
<v Speaker 6>And now, yeah, I think it would pay off, definitely.

01:04:10.660 --> 01:04:13.980
<v Michael Kennedy>All right, Team Flask, you guys got the final word.

01:04:14.940 --> 01:04:16.300
<v David Lord>Okay, Phil, do you want to go first?

01:04:17.340 --> 01:04:18.120
<v Phil Jones>Sure, I can, yeah.

01:04:18.940 --> 01:04:21.900
<v Phil Jones>I think it would probably be more advantageous to Whiskey apps

01:04:22.040 --> 01:04:23.540
<v Phil Jones>than it will for ASCII apps.

01:04:24.060 --> 01:04:25.140
<v Phil Jones>And when I've been playing with it,

01:04:25.200 --> 01:04:27.000
<v Phil Jones>it's mostly on the Whiskey Flask side,

01:04:27.100 --> 01:04:28.480
<v Phil Jones>where I'm quite excited about it.

01:04:28.940 --> 01:04:31.260
<v Phil Jones>At the same time, like the others, I'm a bit worried

01:04:31.480 --> 01:04:33.320
<v Phil Jones>because it's not clear to me, for example,

01:04:33.440 --> 01:04:36.740
<v Phil Jones>that green threading is going to work that well with free threading.

01:04:38.040 --> 01:04:40.080
<v Phil Jones>And that may have been fixed, but I don't think it has yet.

01:04:40.300 --> 01:04:43.040
<v Phil Jones>And that might then break a lot of whiskey apps.

01:04:43.980 --> 01:04:45.140
<v Phil Jones>So next, I think.

01:04:45.190 --> 01:04:48.160
<v Phil Jones>But yeah, very excited for Flask in particular.

01:04:51.280 --> 01:04:52.900
<v David Lord>Thanks for bringing up green threading.

01:04:52.960 --> 01:04:56.600
<v David Lord>I added that to my notes right now.

01:04:57.570 --> 01:05:03.400
<v David Lord>So Flask already has emphasized for years and years and years

01:05:03.800 --> 01:05:06.140
<v David Lord>don't store stuff globally, don't have global state,

01:05:06.600 --> 01:05:10.180
<v David Lord>bind stuff to the request response cycle if you need to store stuff,

01:05:10.440 --> 01:05:11.860
<v David Lord>look stuff up from a cache otherwise.

01:05:13.640 --> 01:05:15.960
<v David Lord>And my impression is that that emphasis is pretty successful.

01:05:15.970 --> 01:05:19.860
<v David Lord>I don't think there's any well-known extensions using like global state

01:05:19.930 --> 01:05:20.840
<v David Lord>or anything like that.

01:05:22.440 --> 01:05:26.600
<v David Lord>It's helped that the dev server that we have is threaded by default.

01:05:27.600 --> 01:05:29.220
<v David Lord>Like it's not going for performance, obviously.

01:05:29.360 --> 01:05:30.440
<v David Lord>It's just running on your local machine,

01:05:30.700 --> 01:05:33.520
<v David Lord>but it's already running in a threaded environment,

01:05:33.720 --> 01:05:35.260
<v David Lord>running your application in a threaded environment,

01:05:35.440 --> 01:05:37.560
<v David Lord>not a process-based one by default.

01:05:38.940 --> 01:05:40.420
<v David Lord>I don't know if anybody even knows

01:05:40.460 --> 01:05:42.460
<v David Lord>that you can run the dev server as process-based.

01:05:43.460 --> 01:05:47.560
<v David Lord>And we also already had for a decade or more than decade,

01:05:48.380 --> 01:05:50.940
<v David Lord>G event to enable the exact same thing

01:05:51.100 --> 01:05:54.200
<v David Lord>that free threading is enabling for Flask,

01:05:54.300 --> 01:05:58.420
<v David Lord>which is concurrent work and connections.

01:05:59.820 --> 01:06:03.100
<v David Lord>And so plenty of applications are already deployed that way

01:06:03.380 --> 01:06:07.140
<v David Lord>using Geovent to do what kind of ASCII is enabling.

01:06:09.360 --> 01:06:13.340
<v David Lord>I've run all the test suites with pytest FreeThreaded,

01:06:13.740 --> 01:06:17.740
<v David Lord>which checks that your tests can run concurrently

01:06:17.740 --> 01:06:18.740
<v David Lord>in the FreeThreaded builds.

01:06:20.280 --> 01:06:21.840
<v David Lord>So go check that out by Anthony Shaw.

01:06:22.620 --> 01:06:24.800
<v David Lord>And I'm pretty sure Granian already supports FreeThreading.

01:06:25.880 --> 01:06:26.500
<v David Lord>I'm not sure, though.

01:06:26.500 --> 01:06:27.580
<v David Lord>I haven't looked into Granian enough.

01:06:27.860 --> 01:06:29.120
<v Michael Kennedy>You know, I'm not sure either.

01:06:29.300 --> 01:06:32.620
<v Michael Kennedy>It does have a runtime threaded mode,

01:06:32.650 --> 01:06:34.640
<v Michael Kennedy>but I don't know if that's truly free threaded or not.

01:06:35.280 --> 01:06:38.040
<v David Lord>Yeah, but all of those things combined

01:06:38.440 --> 01:06:40.860
<v David Lord>make me pretty optimistic that Flask

01:06:40.870 --> 01:06:42.620
<v David Lord>will be able to take advantage of this

01:06:44.100 --> 01:06:45.680
<v David Lord>without much work from us.

01:06:45.800 --> 01:06:47.420
<v David Lord>I mean, I know that's a big statement right there.

01:06:47.420 --> 01:06:48.480
<v David Lord>I haven't tested it,

01:06:49.690 --> 01:06:51.260
<v David Lord>but the fact that we've emphasized

01:06:51.510 --> 01:06:53.680
<v David Lord>all these different parts for so long already

01:06:53.960 --> 01:06:54.960
<v David Lord>makes me confident about it.

01:06:55.720 --> 01:06:56.560
<v Michael Kennedy>Yeah, awesome.

01:06:57.440 --> 01:06:58.720
<v Michael Kennedy>I'm also super excited about it.

01:06:58.780 --> 01:07:00.740
<v Michael Kennedy>And just one final thought I'll throw out there

01:07:00.940 --> 01:07:03.680
<v Michael Kennedy>before we call it a show, because we could go on for much longer,

01:07:03.750 --> 01:07:04.320
<v Michael Kennedy>but we're out of time.

01:07:05.300 --> 01:07:09.360
<v Michael Kennedy>I think once this comes along, whatever framework out

01:07:09.360 --> 01:07:11.160
<v Michael Kennedy>of this choice you're using out there,

01:07:11.960 --> 01:07:14.280
<v Michael Kennedy>there's a bunch of inner working pieces.

01:07:15.260 --> 01:07:16.840
<v Michael Kennedy>One of them may have some kind of issue.

01:07:17.010 --> 01:07:20.980
<v Michael Kennedy>And I think it's worth doing some proper load testing on your app.

01:07:21.090 --> 01:07:24.300
<v Michael Kennedy>You know, point something like locus.io at it and just say,

01:07:24.310 --> 01:07:27.240
<v Michael Kennedy>well, what if we gave it 10,000 concurrent users for an hour?

01:07:27.290 --> 01:07:28.140
<v Michael Kennedy>Does it stop working?

01:07:28.600 --> 01:07:30.060
<v Michael Kennedy>Does it crash or does it just keep going?

01:07:30.240 --> 01:07:32.120
<v Michael Kennedy>You're like, it's a pretty good thing

01:07:32.150 --> 01:07:34.700
<v Michael Kennedy>to do the first time before you deploy your first free

01:07:34.780 --> 01:07:35.320
<v Michael Kennedy>threaded version.

01:07:38.839 --> 01:07:39.200
<v Michael Kennedy>Yeah.

01:07:40.539 --> 01:07:41.180
<v Michael Kennedy>All right, everyone.

01:07:42.199 --> 01:07:43.800
<v Michael Kennedy>I would love to talk some more.

01:07:43.800 --> 01:07:45.400
<v Michael Kennedy>This is such a good conversation, but I also

01:07:45.640 --> 01:07:47.840
<v Michael Kennedy>want to respect your time and all that.

01:07:48.260 --> 01:07:50.840
<v Michael Kennedy>So thank you for being here.

01:07:51.400 --> 01:07:53.340
<v Michael Kennedy>It's been an honor to get you all together

01:07:53.450 --> 01:07:54.240
<v Michael Kennedy>and have this conversation.

01:07:56.240 --> 01:07:57.580
<v Phil Jones>Thank you very much for having us all.

01:07:57.820 --> 01:07:58.120
<v Phil Jones>Thanks, everybody.

01:07:58.520 --> 01:07:58.980
<v Speaker 6>Nice being here.

01:07:59.200 --> 01:07:59.940
<v Speaker 6>Yeah, thanks for having us.

01:08:00.360 --> 01:08:01.080
<v Michael Kennedy>Thanks for having us.

01:08:01.700 --> 01:08:01.840
<v Michael Kennedy>Bye.

