WEBVTT

00:00:00.020 --> 00:00:03.540
<v Michael Kennedy>Python in 2025 is a delightfully refreshing place.

00:00:04.080 --> 00:00:05.100
<v Michael Kennedy>The guild's days are numbered,

00:00:05.560 --> 00:00:07.220
<v Michael Kennedy>packaging is getting sharper tools,

00:00:07.620 --> 00:00:09.200
<v Michael Kennedy>and the type checkers are multiplying

00:00:09.400 --> 00:00:11.040
<v Michael Kennedy>like gremlins snacking after midnight.

00:00:11.500 --> 00:00:13.720
<v Michael Kennedy>On this episode, we have an amazing panel

00:00:13.920 --> 00:00:15.500
<v Michael Kennedy>to give us a range of perspectives

00:00:15.940 --> 00:00:18.480
<v Michael Kennedy>on what mattered in 2025 in Python.

00:00:19.040 --> 00:00:20.940
<v Michael Kennedy>We have Barry Warsaw, Brett Cannon,

00:00:21.380 --> 00:00:24.160
<v Michael Kennedy>Gregory Kampfhammer, Jody Burchell, Reuven Lerner,

00:00:24.580 --> 00:00:27.480
<v Michael Kennedy>and Thomas Worders on the show to give us their thoughts.

00:00:28.040 --> 00:00:33.260
<v Michael Kennedy>This is Talk Python To Me, episode 532, recorded December 9th, 2025.

00:00:50.460 --> 00:00:55.180
<v Michael Kennedy>Welcome to Talk Python To Me, the number one Python podcast for developers and data scientists.

00:00:55.700 --> 00:00:57.100
<v Michael Kennedy>This is your host, Michael Kennedy.

00:00:57.480 --> 00:01:01.020
<v Michael Kennedy>I'm a PSF fellow who's been coding for over 25 years.

00:01:01.660 --> 00:01:02.780
<v Michael Kennedy>Let's connect on social media.

00:01:03.100 --> 00:01:06.180
<v Michael Kennedy>You'll find me and Talk Python on Mastodon, BlueSky, and X.

00:01:06.540 --> 00:01:08.360
<v Michael Kennedy>The social links are all in your show notes.

00:01:09.140 --> 00:01:12.640
<v Michael Kennedy>You can find over 10 years of past episodes at talkpython.fm.

00:01:12.820 --> 00:01:16.020
<v Michael Kennedy>And if you want to be part of the show, you can join our recording live streams.

00:01:16.380 --> 00:01:16.860
<v Michael Kennedy>That's right.

00:01:17.160 --> 00:01:20.300
<v Michael Kennedy>We live stream the raw uncut version of each episode on YouTube.

00:01:20.660 --> 00:01:25.320
<v Michael Kennedy>Just visit talkpython.fm/youtube to see the schedule of upcoming events.

00:01:25.530 --> 00:01:29.200
<v Michael Kennedy>Be sure to subscribe there and press the bell so you'll get notified anytime we're recording.

00:01:29.940 --> 00:01:32.740
<v Michael Kennedy>Look into the future and see bugs before they make it to production.

00:01:33.480 --> 00:01:38.840
<v Michael Kennedy>Sentry's SEER AI code review uses historical error and performance information at Sentry

00:01:39.150 --> 00:01:43.160
<v Michael Kennedy>to find and flag bugs in your PRs before you even start to review them.

00:01:43.840 --> 00:01:45.660
<v Michael Kennedy>Stop bugs before they enter your code base.

00:01:46.160 --> 00:01:50.040
<v Michael Kennedy>Get started at talkpython.fm/seer-code-review.

00:01:50.880 --> 00:01:58.920
<v Michael Kennedy>Hey, before we jump into the interview, I just want to send a little message to all the companies out there with products and services trying to reach developers.

00:01:59.620 --> 00:02:01.180
<v Michael Kennedy>That is the listeners of this show.

00:02:01.680 --> 00:02:05.500
<v Michael Kennedy>As we're rolling into 2026, I have a bunch of spots open.

00:02:05.600 --> 00:02:12.360
<v Michael Kennedy>So please reach out to me if you're looking to sponsor a podcast or just generally sponsor things in the community.

00:02:12.960 --> 00:02:14.500
<v Michael Kennedy>And you haven't necessarily considered podcasts.

00:02:14.700 --> 00:02:19.620
<v Michael Kennedy>You really should reach out to me and I'll help you connect with the Talk Python audience.

00:02:20.600 --> 00:02:27.280
<v Michael Kennedy>thanks everyone for listening all of 2025 and here we go into 2026 cheers hey everyone it's so

00:02:27.370 --> 00:02:31.560
<v Michael Kennedy>awesome to be here with you all thanks for taking the time out of your day to be part of talk python

00:02:31.820 --> 00:02:37.740
<v Michael Kennedy>for this year in review this python year in review so yeah let's just jump right into it gregory

00:02:38.180 --> 00:02:42.500
<v Michael Kennedy>welcome welcome to the show welcome back to the show how you doing hi i'm an associate professor

00:02:42.660 --> 00:02:46.559
<v Gregory Kapfhammer>of computer and information science and i do research and software engineering and software

00:02:46.580 --> 00:02:51.720
<v Gregory Kapfhammer>testing. I've built a bunch of Python tools, and one of the areas we're studying now is flaky test

00:02:51.920 --> 00:02:57.720
<v Gregory Kapfhammer>cases in Python projects. I'm also really excited about teaching in a wide variety of areas. In fact,

00:02:57.720 --> 00:03:02.960
<v Gregory Kapfhammer>I use Python for operating systems classes or theory of computation classes. And one of the

00:03:02.960 --> 00:03:08.560
<v Gregory Kapfhammer>things I'm excited about is being a podcast host. I'm also a host on the Software Engineering Radio

00:03:08.820 --> 00:03:14.540
<v Gregory Kapfhammer>podcast sponsored by the IEEE Computer Society, and I've had the cool opportunity to interview a

00:03:14.540 --> 00:03:18.460
<v Gregory Kapfhammer>whole bunch of people in the Python community. So Michael, thanks for welcoming me to the show.

00:03:18.640 --> 00:03:22.640
<v Michael Kennedy>Yeah, it's awesome to have you back. And we talked about FlakyTest last time. I do have to say

00:03:23.100 --> 00:03:29.140
<v Michael Kennedy>your AV setup is quite good. I love the new mic and all that. Thomas, welcome. Awesome to have

00:03:29.160 --> 00:03:34.100
<v Thomas Wourters>you here. Thanks for having me. I'm Thomas Wauters. I'm a longtime Python core developer,

00:03:34.300 --> 00:03:40.320
<v Thomas Wourters>although not as long as one of the other guests on this podcast. I worked at Google for 17 years.

00:03:40.460 --> 00:03:45.380
<v Thomas Wourters>for the last year or so I've worked at Meta. In both cases, I work on Python itself within the

00:03:45.600 --> 00:03:50.920
<v Thomas Wourters>company and just deploying it internally. I've also been a board member of the PSF, although I'm not

00:03:51.100 --> 00:03:58.020
<v Thomas Wourters>one right now. And I've been a steering council member for five years and currently not because

00:03:58.280 --> 00:04:02.380
<v Thomas Wourters>the elections are going and I don't know what the result is going to be. But I think there's like

00:04:02.820 --> 00:04:09.099
<v Thomas Wourters>five, six chance that I'll be on the steering council since we only have six candidates for

00:04:09.120 --> 00:04:14.680
<v Michael Kennedy>five positions when this episode probably airs. I don't know. That's quite the contribution to the

00:04:14.740 --> 00:04:19.299
<v Thomas Wourters>whole community. Thank you. I always forget this. I also got the, what is it, the Distinguished

00:04:19.400 --> 00:04:23.780
<v Thomas Wourters>Service Award from the PSF this year. I should probably mention that. So yes, I have been

00:04:24.040 --> 00:04:29.680
<v Michael Kennedy>recognized. No need to talk about it further. Wonderful. Wonderful. Jody, welcome back on the

00:04:29.840 --> 00:04:34.039
<v Michael Kennedy>show. Awesome to catch up with you. Yeah, thanks for having me back. I am a data scientist and

00:04:34.060 --> 00:04:39.560
<v Jodie Burchell>developer advocate at JetBrains working on PyCharm. And I've been a data scientist for around 10

00:04:39.840 --> 00:04:45.220
<v Jodie Burchell>years. And prior to that, I was actually a clinical psychologist. So that was my training,

00:04:45.610 --> 00:04:49.860
<v Jodie Burchell>my PhD, but abandoned academia for greener pastures. Let's put it that way.

00:04:50.190 --> 00:04:50.860
<v Jodie Burchell>Noah Franz-Gurig.

00:04:53.180 --> 00:04:55.000
<v Michael Kennedy>Brett, hello. Good to see you.

00:04:55.100 --> 00:05:00.200
<v Brett Cannon>Hello. Yes. Yeah, let's see here. I've been at Microsoft for 10 years. I started doing,

00:05:00.300 --> 00:05:03.080
<v Brett Cannon>working on AI R&D for Python developers.

00:05:03.880 --> 00:05:06.040
<v Brett Cannon>Also keep Wazzy running for Python here

00:05:06.380 --> 00:05:09.140
<v Brett Cannon>and do a lot of internal consulting for teams outside.

00:05:09.860 --> 00:05:11.880
<v Brett Cannon>I am actually the shortest running

00:05:12.700 --> 00:05:14.060
<v Brett Cannon>core developer on this call, amazingly,

00:05:14.200 --> 00:05:15.660
<v Brett Cannon>even though I've been doing it for 22 years.

00:05:16.060 --> 00:05:17.840
<v Brett Cannon>I've also only gotten the Frank Wilson award,

00:05:18.080 --> 00:05:18.820
<v Brett Cannon>not the DSA.

00:05:19.300 --> 00:05:20.900
<v Brett Cannon>So I feel very under accomplished here

00:05:20.900 --> 00:05:21.600
<v Brett Cannon>as a core developer.

00:05:22.040 --> 00:05:23.700
<v Brett Cannon>Yeah, that's me in a nutshell.

00:05:24.060 --> 00:05:25.900
<v Brett Cannon>Otherwise, I'm still trying to catch that.

00:05:26.940 --> 00:05:27.460
<v Barry Warsaw>Most quoted.

00:05:27.900 --> 00:05:29.160
<v Barry Warsaw>Yeah, most quoted.

00:05:29.220 --> 00:05:33.360
<v Brett Cannon>I will say actually at work, it is in my email footer that I'm a famous Python quotationist.

00:05:33.700 --> 00:05:35.660
<v Brett Cannon>That was Anthony Shaw's suggestion, by the way.

00:05:35.860 --> 00:05:39.600
<v Brett Cannon>That was not mine, but does link to the April Fool's joke from last year.

00:05:39.850 --> 00:05:42.920
<v Brett Cannon>And I am still trying to catch Anthony Shaw, I think, on appearances on this podcast.

00:05:43.060 --> 00:05:44.120
<v Michael Kennedy>Well, plus one.

00:05:44.850 --> 00:05:46.060
<v Michael Kennedy>Anthony Shaw should be here, honestly.

00:05:46.440 --> 00:05:47.540
<v Michael Kennedy>I mean, I put it out into Discord.

00:05:48.520 --> 00:05:50.740
<v Michael Kennedy>He could have been here, but probably at an odd time.

00:05:51.000 --> 00:05:54.820
<v Michael Kennedy>You used to work on VS Code a bunch on the Python aspect of VS Code.

00:05:54.870 --> 00:05:56.800
<v Michael Kennedy>You recently changed roles, right?

00:05:57.000 --> 00:05:57.520
<v Brett Cannon>Not recently.

00:05:57.560 --> 00:05:59.500
<v Brett Cannon>That was, I used to be the dev manager.

00:05:59.500 --> 00:06:00.880
<v Michael Kennedy>Every seven years, years ago.

00:06:01.100 --> 00:06:02.580
<v Brett Cannon>Yeah, September of 2024.

00:06:03.530 --> 00:06:04.200
<v Brett Cannon>So it's been over a year.

00:06:04.330 --> 00:06:04.940
<v Brett Cannon>But yeah, I used to be the dev manager.

00:06:04.940 --> 00:06:06.040
<v Michael Kennedy>That counts as recent for me.

00:06:06.240 --> 00:06:09.400
<v Brett Cannon>Yes, I used to be the dev manager for the Python experience in VS Code.

00:06:09.520 --> 00:06:10.340
<v Michael Kennedy>Okay, very cool.

00:06:10.540 --> 00:06:11.340
<v Michael Kennedy>That's quite a shift.

00:06:11.480 --> 00:06:12.820
<v Brett Cannon>Yeah, it went back to being an IC basically.

00:06:13.820 --> 00:06:16.220
<v Michael Kennedy>You got all, you're good at your TPS reports again now?

00:06:17.500 --> 00:06:19.480
<v Brett Cannon>Actually, I just did do my connect, so I kind of did.

00:06:19.580 --> 00:06:19.900
<v Michael Kennedy>Awesome.

00:06:20.800 --> 00:06:23.480
<v Michael Kennedy>Reuven, I bet you haven't filed a TPS report in at least a year.

00:06:23.660 --> 00:06:24.420
<v Reuven Lerner>So yeah, I'm Reuven.

00:06:24.600 --> 00:06:27.960
<v Reuven Lerner>I'm a freelance Python and Pandas trainer.

00:06:28.460 --> 00:06:31.860
<v Reuven Lerner>I just celebrated this past week 30 years since going freelance.

00:06:32.660 --> 00:06:34.340
<v Reuven Lerner>So I guess it's working out okay.

00:06:35.700 --> 00:06:37.720
<v Reuven Lerner>We'll know at some point if I need to get a real job.

00:06:38.020 --> 00:06:41.740
<v Reuven Lerner>I teach Python Pandas both at companies and on my online platform.

00:06:41.970 --> 00:06:42.660
<v Reuven Lerner>I have newsletters.

00:06:42.850 --> 00:06:47.160
<v Reuven Lerner>I've written books, speaking conferences, and generally try to help people improve their

00:06:47.590 --> 00:06:51.660
<v Reuven Lerner>Python and Pandas fluency and confidence and have a lot of fun with this community as well

00:06:51.660 --> 00:06:52.200
<v Reuven Lerner>as with the language.

00:06:52.520 --> 00:06:53.260
<v Michael Kennedy>Oh, good to have you here.

00:06:53.480 --> 00:06:55.840
<v Michael Kennedy>Barry, it's great to have a musician on the show.

00:06:56.840 --> 00:06:57.200
<v Barry Warsaw>Thanks.

00:06:58.340 --> 00:06:59.780
<v Barry Warsaw>Yeah, I've got my bases over here.

00:07:00.060 --> 00:07:02.200
<v Barry Warsaw>So, you know, if you need to be serenaded.

00:07:02.740 --> 00:07:05.280
<v Michael Kennedy>Yeah, like a Zen of Python may break out at any moment.

00:07:05.380 --> 00:07:06.640
<v Michael Kennedy>You never know when it's going to happen.

00:07:07.000 --> 00:07:07.880
<v Barry Warsaw>Thanks for having me here.

00:07:08.160 --> 00:07:12.140
<v Barry Warsaw>Yeah, I've been a core developer for a long time, since 1994.

00:07:13.840 --> 00:07:19.240
<v Barry Warsaw>And I've been, you know, in the early days, I did tons of stuff for Python.org.

00:07:20.000 --> 00:07:27.060
<v Barry Warsaw>I worked with Guido at CNRI and we moved everything from the mailing, the Postmaster stuff,

00:07:27.580 --> 00:07:32.480
<v Barry Warsaw>and the version control systems back in the day, websites, all that kind of stuff.

00:07:32.560 --> 00:07:34.720
<v Barry Warsaw>I try to not do any of those things anymore.

00:07:35.500 --> 00:07:38.500
<v Barry Warsaw>There's way more competent people doing that stuff now.

00:07:39.120 --> 00:07:41.120
<v Barry Warsaw>I have been a release manager.

00:07:42.920 --> 00:07:46.860
<v Barry Warsaw>I'm currently back on the steering council and running again.

00:07:47.940 --> 00:07:52.220
<v Barry Warsaw>between Thomas and I, we'll see who makes it to six years, I guess.

00:07:52.880 --> 00:07:55.460
<v Barry Warsaw>And I'm currently working for NVIDIA,

00:07:56.050 --> 00:07:57.780
<v Barry Warsaw>and I do all Python stuff.

00:07:58.680 --> 00:08:01.860
<v Barry Warsaw>Some half and half, roughly, of internal things

00:08:02.120 --> 00:08:05.140
<v Barry Warsaw>and external open source community work,

00:08:05.600 --> 00:08:08.160
<v Barry Warsaw>both in packaging and in core Python.

00:08:08.700 --> 00:08:10.800
<v Michael Kennedy>That's, I guess, I think that's about it.

00:08:10.920 --> 00:08:14.660
<v Michael Kennedy>Yeah, you all are living in exciting tech spaces, that's for sure.

00:08:14.900 --> 00:08:15.520
<v Michael Kennedy>That's for sure.

00:08:15.520 --> 00:08:15.960
<v Michael Kennedy>For sure.

00:08:16.160 --> 00:08:20.780
<v Michael Kennedy>Yeah. Well, great to have you all back on the show. Let's start with our first topic. So the

00:08:20.850 --> 00:08:26.740
<v Michael Kennedy>idea is we've each picked at least a thing that we think stood out in 2025 in the Python space

00:08:27.580 --> 00:08:33.200
<v Michael Kennedy>that we can focus on. And let's go with Jody first. I'm excited to hear what you thought was

00:08:33.360 --> 00:08:40.080
<v Jodie Burchell>one of the bigger things. I'm going to mention AI. Like, wow, what a big surprise. So to kind of

00:08:40.140 --> 00:08:45.360
<v Jodie Burchell>give context of where I'm coming from, I've been working in NLP for a long time. I like to say I was

00:08:45.260 --> 00:08:50.180
<v Jodie Burchell>working on LLMs before they were cool. So sort of playing around with the very first releases from

00:08:50.320 --> 00:08:56.400
<v Jodie Burchell>Google in like 2019, incorporating that into search. So I've been very interested sort of

00:08:56.620 --> 00:09:03.160
<v Jodie Burchell>seeing the unfolding of the GPT models as they've grown. And let's say slightly disgusted by the

00:09:03.520 --> 00:09:09.519
<v Jodie Burchell>discourse around the models as they become more mainstream, more sort of the talk about people's

00:09:09.540 --> 00:09:15.200
<v Jodie Burchell>jobs being replaced, a lot of the hysteria, a lot of the doomsday stuff. So I've been doing talks

00:09:15.310 --> 00:09:19.820
<v Jodie Burchell>and other content for around two and a half years now, just trying to cut through the hype a bit,

00:09:19.900 --> 00:09:23.660
<v Jodie Burchell>being like, you know, they're just language models, they're good for language tasks. Let's think about

00:09:23.860 --> 00:09:29.360
<v Jodie Burchell>realistically what they're about. And what was very interesting for me this year, I've been

00:09:29.620 --> 00:09:34.759
<v Jodie Burchell>incorrectly predicting the bubble bursting for about two and a half years. So I was quite vindicated

00:09:34.840 --> 00:09:37.600
<v Jodie Burchell>when in August, GPT-5 came out,

00:09:38.030 --> 00:09:40.420
<v Jodie Burchell>and all of a sudden, everyone else started saying,

00:09:40.500 --> 00:09:41.500
<v Michael Kennedy>maybe this is a bubble.

00:09:41.740 --> 00:09:43.800
<v Michael Kennedy>Don't you think that was the first big release

00:09:44.060 --> 00:09:46.940
<v Michael Kennedy>that was kind of a letdown compared to what the hype was?

00:09:47.100 --> 00:09:48.200
<v Jodie Burchell>Yeah, and it was really interesting.

00:09:48.560 --> 00:09:50.980
<v Jodie Burchell>So I found this really nice Atlantic article,

00:09:51.110 --> 00:09:52.540
<v Jodie Burchell>and I didn't save it, unfortunately,

00:09:52.960 --> 00:09:56.140
<v Jodie Burchell>but essentially it told sort of the whole story

00:09:56.350 --> 00:09:57.760
<v Jodie Burchell>of what was going on behind the scenes.

00:09:58.000 --> 00:10:01.820
<v Jodie Burchell>So GPT-4 came out in March of 2023,

00:10:02.390 --> 00:10:03.939
<v Jodie Burchell>and that was the model that came out

00:10:03.960 --> 00:10:08.520
<v Jodie Burchell>with this Microsoft research paper saying, you know, sparks of AGI, artificial general intelligence,

00:10:08.660 --> 00:10:14.740
<v Jodie Burchell>blah, blah, blah. And from that point, there was really this big expectation sort of fueled by

00:10:15.220 --> 00:10:21.460
<v Jodie Burchell>OpenAI that GPT-5 was going to be the AGI model. And it turns out what was happening internally

00:10:22.080 --> 00:10:27.300
<v Jodie Burchell>is these scaling laws that were sort of considered, you know, this exponential growth thing that would

00:10:27.620 --> 00:10:33.199
<v Jodie Burchell>sort of push the power of these models perhaps towards human-like performance. They weren't

00:10:33.220 --> 00:10:38.200
<v Jodie Burchell>laws at all. And of course they started failing. So the model that they had originally pitched as

00:10:38.320 --> 00:10:42.780
<v Jodie Burchell>GPT-4 just didn't live up to performance. They started this post-training stuff where they were

00:10:43.200 --> 00:10:48.160
<v Jodie Burchell>going more into like specialized reasoning models. And what we have now are good models that are good

00:10:48.300 --> 00:10:54.400
<v Jodie Burchell>for specific tasks, but I don't know what happened, but eventually they had to put the GPT-5 label on

00:10:54.560 --> 00:11:01.959
<v Jodie Burchell>something. And yeah, let's say it didn't live up to expectations. So I think the cracks are starting

00:11:01.980 --> 00:11:08.620
<v Jodie Burchell>to show because the underlying expectation always was this will be improving to the point where

00:11:08.960 --> 00:11:14.200
<v Jodie Burchell>anything's possible and you can't put a price on that. But it turns out that if maybe there's a

00:11:14.320 --> 00:11:19.180
<v Michael Kennedy>limit on what's possible, yeah, you can put a price on it. And a lot of the valuations are on the

00:11:19.660 --> 00:11:23.780
<v Jodie Burchell>first part. Yes. And it's always been a bit interesting to me because I come from a scientific

00:11:24.000 --> 00:11:28.459
<v Jodie Burchell>background and you need to know how to measure stuff, right? And I'm like, what are you trying

00:11:28.480 --> 00:11:34.120
<v Jodie Burchell>to achieve? Like Gregory's nodding, like, please jump in. I'm on my monologue, so please don't

00:11:34.380 --> 00:11:38.700
<v Jodie Burchell>interrupt me. You really need to understand what you're actually trying to get these models to do.

00:11:38.920 --> 00:11:46.180
<v Jodie Burchell>What is AGI? No one knows this. And what's going to be possible with this? And it's more science

00:11:46.420 --> 00:11:51.580
<v Jodie Burchell>fiction than fact. So this for me has been the big news this year, and I'm feeling slightly smug,

00:11:51.800 --> 00:11:55.180
<v Jodie Burchell>I'm going to be honest, even though my predictions were off by about a year and a half.

00:11:55.320 --> 00:11:56.720
<v Michael Kennedy>Yeah, maybe it's not an exponential curve.

00:11:56.920 --> 00:11:59.580
<v Michael Kennedy>It's a titration S curve with an asymptote.

00:11:59.650 --> 00:11:59.880
<v Michael Kennedy>We'll see.

00:12:00.020 --> 00:12:01.320
<v Jodie Burchell>Yeah, sigmoid.

00:12:01.820 --> 00:12:01.940
<v Jodie Burchell>Yeah.

00:12:02.200 --> 00:12:03.020
<v Reuven Lerner>Yeah, yeah, yeah.

00:12:03.320 --> 00:12:06.740
<v Reuven Lerner>I mean, I think we have to sort of separate the technology from the business.

00:12:07.310 --> 00:12:12.780
<v Reuven Lerner>And the technology, even if it doesn't get any better, even if we stay with what we have today,

00:12:13.260 --> 00:12:17.720
<v Reuven Lerner>I still think this is like one of the most amazing technologies I've ever seen.

00:12:18.180 --> 00:12:19.200
<v Reuven Lerner>It's not a god.

00:12:19.520 --> 00:12:20.820
<v Reuven Lerner>It's not a panacea.

00:12:21.280 --> 00:12:25.200
<v Reuven Lerner>But it's like a chainsaw that if you know how to use it, it's really effective.

00:12:25.760 --> 00:12:31.980
<v Reuven Lerner>but in the hands of amateurs, you can really get hurt. And so, yes, it's great to see this sort of

00:12:32.100 --> 00:12:36.260
<v Reuven Lerner>thing happening and improving, but who knows where it's going to go. And I'm a little skeptical of

00:12:36.260 --> 00:12:40.280
<v Reuven Lerner>the AGI thing. What I'm a little more worried about is that these companies seem to have no

00:12:40.720 --> 00:12:47.260
<v Reuven Lerner>possible way of ever making the money that they're promising to their investors. And I do worry a lot

00:12:47.700 --> 00:12:53.580
<v Reuven Lerner>that we're sort of like a year 2000 situation where, yeah, the technology is fantastic,

00:12:53.660 --> 00:13:03.400
<v Reuven Lerner>But the businesses are unsustainable. And out of the ashes of what will happen, we will get some amazing technology and even better than we had before. But there are going to be ashes.

00:13:03.520 --> 00:13:09.500
<v Jodie Burchell>For me, that also makes me worry. And I don't know if anyone reads Ed Zitron here. He's a

00:13:09.750 --> 00:13:15.020
<v Jodie Burchell>journalist kind of digging into the state of the AI industry. He does get a bit sort of,

00:13:15.340 --> 00:13:19.480
<v Jodie Burchell>his reputation is a bit of a crank now. So I think he's leaned into that pretty hard,

00:13:20.020 --> 00:13:24.880
<v Jodie Burchell>but he does take the time to also pull out numbers and point out things that don't make sense.

00:13:25.320 --> 00:13:29.920
<v Jodie Burchell>And he was one of the first ones to sound the whistle on this circular funding we've been seeing.

00:13:30.160 --> 00:13:40.860
<v Jodie Burchell>So the worry, of course, is when a lot of this becomes borrowings from banks and then that starts dragging in funding from everyday people.

00:13:41.400 --> 00:13:45.720
<v Jodie Burchell>And also the effect that this has had on particularly the U.S. economy, like the stock market.

00:13:45.980 --> 00:13:54.380
<v Jodie Burchell>I think the investment in AI spending now exceeds consumer spending in the U.S., which is a really scary prospect.

00:13:54.860 --> 00:13:55.600
<v Michael Kennedy>That is crazy.

00:13:55.700 --> 00:14:02.080
<v Jodie Burchell>Mm-hmm. But yeah, also as Reven said, I love LLMs. They are the most powerful tools we've

00:14:02.090 --> 00:14:06.060
<v Jodie Burchell>ever had for natural language processing. It's phenomenal the problems we can solve with them

00:14:06.140 --> 00:14:10.100
<v Jodie Burchell>now. I didn't think this sort of stuff would be possible when I started in data science.

00:14:10.710 --> 00:14:15.560
<v Jodie Burchell>I still think there's a use case for agents, although I do think they've been a bit overstated,

00:14:16.120 --> 00:14:20.060
<v Jodie Burchell>especially now that I'm building them. Let's say it's not very fun building

00:14:20.150 --> 00:14:25.099
<v Jodie Burchell>non-deterministic software. It's quite frustrating, actually. But I hope we're going to see improvements

00:14:25.100 --> 00:14:30.540
<v Jodie Burchell>in the framework, particularly I've heard good things about Pydantic AI. And yeah, hopefully we

00:14:30.640 --> 00:14:36.080
<v Jodie Burchell>can control the input outputs and make them a bit more strict. This will fix a lot of the problems.

00:14:36.340 --> 00:14:41.220
<v Michael Kennedy>One thing I do want to put out in this conversation, I think is worth separating. And Reuven,

00:14:41.220 --> 00:14:45.260
<v Michael Kennedy>you touched on this some. I want to suggest to you, I'll throw this out to you all and see what

00:14:45.260 --> 00:14:51.599
<v Michael Kennedy>you think. I think it's very possible that this AI bubble crashes the economy and causes bad things

00:14:51.620 --> 00:14:57.780
<v Michael Kennedy>economically to happen and a bunch of companies that are like wrappers over open ai api go away

00:14:58.300 --> 00:15:03.800
<v Michael Kennedy>but i don't think things like the agentic coding tools will vanish they might stop training they

00:15:03.920 --> 00:15:08.880
<v Michael Kennedy>might slow their advance because that's super expensive but i even as if you said even if we

00:15:09.160 --> 00:15:16.000
<v Michael Kennedy>just had claude sonnet 4 and the world never got something else it would be so much far farther

00:15:16.150 --> 00:15:20.980
<v Michael Kennedy>beyond autocomplete and the other stuff that we had before and stack overflow that it's i don't

00:15:20.860 --> 00:15:23.320
<v Michael Kennedy>think it's going to go. The reason I'm throwing this out there is I was talking to somebody and

00:15:23.340 --> 00:15:26.160
<v Michael Kennedy>they were like, well, I don't think it's worth learning because I think the bubble is going to

00:15:26.520 --> 00:15:30.020
<v Michael Kennedy>pop. And so I don't want to learn this agent at coding because it won't be around very long.

00:15:30.340 --> 00:15:34.680
<v Brett Cannon>What do you all think? It's here to stay. I think it's just, where's the limit? Where does it stop?

00:15:34.940 --> 00:15:40.340
<v Brett Cannon>I think that's the big open question for everybody, right? Like pragmatically, it's a tool. It's useful

00:15:40.410 --> 00:15:44.100
<v Brett Cannon>in some scenarios and not in others. And you just have to learn how to use the tool appropriately

00:15:44.300 --> 00:15:47.939
<v Brett Cannon>for your use case and to get what you need out of it. And sometimes that's not using it because

00:15:47.960 --> 00:15:51.540
<v Brett Cannon>it's just going to take up more time than it will to be productive. But other times it's

00:15:51.960 --> 00:15:56.440
<v Brett Cannon>fully juices up your productivity and you can get more done. It's give and take. But I don't think

00:15:56.500 --> 00:16:00.100
<v Brett Cannon>it's going to go anywhere because as you said, Michael, there's even academics doing research now.

00:16:00.300 --> 00:16:05.160
<v Brett Cannon>There's open weight models as well. There's a lot of different ways to run this, whether you're

00:16:05.520 --> 00:16:11.280
<v Brett Cannon>at the scale of the frontier models that are doing these huge trainings or you're doing something

00:16:11.740 --> 00:16:16.140
<v Brett Cannon>local and more specialized. So I think the general use of AI isn't going anywhere. I think it's just

00:16:16.080 --> 00:16:21.980
<v Brett Cannon>the question of how far can this current trend go and where will it be i want to say stop that's

00:16:22.260 --> 00:16:25.580
<v Brett Cannon>because that plays into the whole it's never it's going to completely go away i don't think it ever

00:16:25.680 --> 00:16:29.160
<v Brett Cannon>will i think it's just going to be where where are we going to start to potentially bump up against

00:16:29.280 --> 00:16:33.540
<v Gregory Kapfhammer>limits one thing that i'll say is that many of these systems are almost to me like a dream come

00:16:33.750 --> 00:16:38.640
<v Gregory Kapfhammer>true now admittedly it's the case that the systems i'm building are maybe only tens of thousands of

00:16:38.700 --> 00:16:44.019
<v Gregory Kapfhammer>lines or hundreds of thousands of lines but i can remember thinking to myself how cool would it be

00:16:44.080 --> 00:16:46.880
<v Gregory Kapfhammer>if I had a system that could automatically refactor

00:16:47.440 --> 00:16:51.000
<v Gregory Kapfhammer>and then add test cases and increase the code coverage

00:16:51.380 --> 00:16:54.140
<v Gregory Kapfhammer>and make sure all my checkers and linters pass

00:16:54.440 --> 00:16:57.320
<v Gregory Kapfhammer>and do that automatically and continue the process

00:16:57.650 --> 00:16:58.920
<v Gregory Kapfhammer>until it achieved its goal.

00:16:59.260 --> 00:17:01.620
<v Gregory Kapfhammer>And I remember thinking that five to seven years ago,

00:17:01.750 --> 00:17:04.680
<v Gregory Kapfhammer>I would never realize that goal in my entire lifetime.

00:17:05.189 --> 00:17:07.819
<v Gregory Kapfhammer>And now when I use like anthropics models

00:17:08.010 --> 00:17:09.839
<v Gregory Kapfhammer>through open code or Claude code,

00:17:10.220 --> 00:17:13.120
<v Gregory Kapfhammer>it's incredible how much you can achieve so quickly,

00:17:13.459 --> 00:17:16.480
<v Gregory Kapfhammer>even for systems that are of medium to moderate scale.

00:17:17.040 --> 00:17:19.860
<v Gregory Kapfhammer>So from my vantage point, it is a really exciting tool.

00:17:20.260 --> 00:17:21.420
<v Gregory Kapfhammer>It's incredibly powerful.

00:17:21.870 --> 00:17:24.339
<v Gregory Kapfhammer>And what I have found is that the LLMs are much better

00:17:24.640 --> 00:17:26.500
<v Gregory Kapfhammer>when I teach them how to use tools

00:17:27.040 --> 00:17:28.900
<v Gregory Kapfhammer>and the tools that it's using

00:17:29.260 --> 00:17:31.220
<v Gregory Kapfhammer>are actually really quick, fast ones

00:17:31.660 --> 00:17:33.920
<v Gregory Kapfhammer>that can give rapid feedback to the LLM

00:17:34.240 --> 00:17:35.380
<v Gregory Kapfhammer>and tell it whether it's moving

00:17:35.450 --> 00:17:36.540
<v Gregory Kapfhammer>in the right direction or not.

00:17:36.680 --> 00:17:38.900
<v Michael Kennedy>Yeah, there's an engineering angle to this.

00:17:39.040 --> 00:17:40.180
<v Michael Kennedy>It's not just Vibe Coding

00:17:40.340 --> 00:17:42.700
<v Michael Kennedy>if you take the time to learn it.

00:17:42.860 --> 00:17:48.040
<v Jodie Burchell>There was actually a very interesting study. I don't think the study itself has been released.

00:17:48.060 --> 00:17:53.340
<v Jodie Burchell>I haven't found it yet, but I saw a talk on it by some guys at Stanford. So they call it the 10K

00:17:53.580 --> 00:17:59.160
<v Jodie Burchell>developer study. And basically what they were doing was studying real code bases, including,

00:17:59.260 --> 00:18:05.260
<v Jodie Burchell>I think 80% of them were actually private code bases and seeing the point where the team started

00:18:05.500 --> 00:18:10.699
<v Jodie Burchell>adopting AI. And so their findings are really interesting and nuanced. And I think they probably

00:18:10.720 --> 00:18:16.080
<v Jodie Burchell>intuitively align with what a lot of us have experienced with AI. So basically, yes, there

00:18:16.080 --> 00:18:21.720
<v Jodie Burchell>are productivity boosts, but it produces a lot of code, but the code tends to be worse than the code

00:18:21.720 --> 00:18:27.400
<v Jodie Burchell>you would write and also introduces more bugs. So when you account for the time that you spend

00:18:27.540 --> 00:18:32.260
<v Jodie Burchell>refactoring and debugging, you're still more productive. But then it also depends on the

00:18:32.380 --> 00:18:36.500
<v Jodie Burchell>type of project, as Gregory was saying. So it's better for greenfield projects, it's better for

00:18:36.520 --> 00:18:41.380
<v Jodie Burchell>smaller code bases. It's better for simpler problems and it's better for more popular languages because

00:18:41.540 --> 00:18:46.200
<v Jodie Burchell>obviously there's more training data. And so this was actually, I like this study so much. I'll

00:18:46.260 --> 00:18:49.900
<v Jodie Burchell>actually share it with you, Michael, if you want to put it in the show notes, but it shows that,

00:18:50.000 --> 00:18:53.940
<v Jodie Burchell>yeah, the picture is not that simple and all this conflicting information and conflicting experiences

00:18:54.180 --> 00:19:00.400
<v Jodie Burchell>people were having line up completely with this. So again, like I work at an IDE company, it's tools

00:19:00.540 --> 00:19:06.480
<v Jodie Burchell>for the job. It's not like your IDE will replace you. AI is not going to replace you. It's just

00:19:06.500 --> 00:19:08.200
<v Jodie Burchell>going to make you maybe more productive sometimes.

00:19:08.700 --> 00:19:08.880
<v Michael Kennedy>Yeah.

00:19:09.080 --> 00:19:10.400
<v Michael Kennedy>Wait, IDE, you work for me.

00:19:11.600 --> 00:19:11.700
<v Michael Kennedy>Right.

00:19:12.500 --> 00:19:13.000
<v Michael Kennedy>It's not about you.

00:19:13.000 --> 00:19:14.400
<v Jodie Burchell>But then I work for the IDE.

00:19:18.360 --> 00:19:21.320
<v Michael Kennedy>This portion of Talk Python To Me is brought to you by Sentry.

00:19:22.640 --> 00:19:23.500
<v Michael Kennedy>Let me ask you a question.

00:19:24.280 --> 00:19:25.880
<v Michael Kennedy>What if you could see into the future?

00:19:26.640 --> 00:19:27.900
<v Michael Kennedy>We're talking about Sentry, of course.

00:19:28.160 --> 00:19:33.460
<v Michael Kennedy>So that means seeing potential errors, crashes, and bugs before they happen, before you even

00:19:33.780 --> 00:19:34.720
<v Michael Kennedy>accept them into your code base.

00:19:35.380 --> 00:19:38.500
<v Michael Kennedy>That's what Sentry's AI Sears Code Review offers.

00:19:39.300 --> 00:19:42.640
<v Michael Kennedy>You get error prediction based on real production history.

00:19:43.180 --> 00:19:49.620
<v Michael Kennedy>AI Sear Code Review flags the most impactful errors your PR is likely to introduce before merge

00:19:50.180 --> 00:19:54.980
<v Michael Kennedy>using your app's error and performance context, not just generic LLM pattern matching.

00:19:55.800 --> 00:20:00.880
<v Michael Kennedy>Sear will then jump in on new PRs with feedback and warning if it finds any potential issues.

00:20:01.680 --> 00:20:02.460
<v Michael Kennedy>Here's a real example.

00:20:03.240 --> 00:20:10.560
<v Michael Kennedy>On a new PR related to a search feature in a web app, we see a comment from seer bicenturybot in the PR.

00:20:11.220 --> 00:20:18.820
<v Michael Kennedy>And it says, potential bug, the process search results function, can enter an infinite recursion when a search query finds no matches.

00:20:19.620 --> 00:20:23.800
<v Michael Kennedy>As the recursive call lacks a return statement and a proper termination condition.

00:20:24.360 --> 00:20:32.000
<v Michael Kennedy>And Seer AI Code Review also provides additional details which you can expand for further information on the issue and suggested fixes.

00:20:32.760 --> 00:20:37.780
<v Michael Kennedy>And bam, just like that, Seer AI Code Review has stopped a bug in its tracks without any

00:20:37.980 --> 00:20:38.560
<v Michael Kennedy>devs in the loop.

00:20:38.880 --> 00:20:41.720
<v Michael Kennedy>A nasty infinite loop bug never made it into production.

00:20:42.440 --> 00:20:43.200
<v Michael Kennedy>Here's how you set it up.

00:20:43.620 --> 00:20:48.940
<v Michael Kennedy>You enable the GitHub Sentry integration on your Sentry account, enable Seer AI on your

00:20:49.180 --> 00:20:53.840
<v Michael Kennedy>Sentry account, and on GitHub, you install the Seer by Sentry app and connect it to your

00:20:53.960 --> 00:20:55.600
<v Michael Kennedy>repositories that you want it to validate.

00:20:55.940 --> 00:20:58.800
<v Michael Kennedy>So jump over to Sentry and set up Code Review for yourself.

00:20:59.320 --> 00:21:03.420
<v Michael Kennedy>Just visit talkpython.fm/seer-code-review.

00:21:03.650 --> 00:21:05.340
<v Michael Kennedy>The link is in your podcast player show notes

00:21:05.580 --> 00:21:06.460
<v Michael Kennedy>and on the episode page.

00:21:06.980 --> 00:21:09.260
<v Michael Kennedy>Thank you to Sentry for supporting Talk Python and me.

00:21:10.140 --> 00:21:12.000
<v Reuven Lerner>I mean, the other thing is a lot of people

00:21:12.440 --> 00:21:15.060
<v Reuven Lerner>and a lot of the sort of when people talk about AI

00:21:15.400 --> 00:21:17.280
<v Reuven Lerner>and LLMs and so forth in context of coding,

00:21:17.800 --> 00:21:20.500
<v Reuven Lerner>it's the LLM writing code for us.

00:21:20.920 --> 00:21:23.440
<v Reuven Lerner>And maybe because I'm not doing a lot of serious coding,

00:21:23.600 --> 00:21:25.060
<v Reuven Lerner>it's more instruction and so forth.

00:21:25.320 --> 00:21:29.280
<v Reuven Lerner>I use it as like a sparring or brainstorming partner

00:21:29.620 --> 00:21:36.800
<v Reuven Lerner>So it does, you know, checking of my newsletters for language and for tech edits and just sort of exploring ideas.

00:21:37.300 --> 00:21:43.320
<v Reuven Lerner>And for that, maybe it's because I do everything in the last minute and I don't have other people around or I'm lazy or cheap and don't want to pay them.

00:21:43.800 --> 00:21:46.620
<v Reuven Lerner>But definitely the quality of my work has improved dramatically.

00:21:46.860 --> 00:21:50.680
<v Reuven Lerner>The quality of my understanding has improved, even if it never wrote a line of code for me.

00:21:50.920 --> 00:21:53.860
<v Reuven Lerner>Just getting that feedback on a regular automatic basis is really helpful.

00:21:54.120 --> 00:21:55.140
<v Michael Kennedy>Yeah, I totally agree with you.

00:21:55.360 --> 00:22:05.520
<v Michael Kennedy>All right. We don't want to spend too much time on this topic, even though I believe Jody has put her finger on what might be the biggest tidal wave of 2025.

00:22:06.040 --> 00:22:08.560
<v Michael Kennedy>But still, a quick parting thoughts. Anyone else?

00:22:08.900 --> 00:22:11.220
<v Brett Cannon>I'm glad I'll never have the right bash from scratch ever again.

00:22:12.960 --> 00:22:13.640
<v Michael Kennedy>Tell me about it.

00:22:13.740 --> 00:22:14.040
<v Michael Kennedy>Yeah.

00:22:15.800 --> 00:22:21.580
<v Barry Warsaw>I'll just say from anecdotally, the thing that I love about it is when I need to do something

00:22:22.020 --> 00:22:28.220
<v Barry Warsaw>and I need to go through docs, online docs for whatever it is, you know, it might be

00:22:28.380 --> 00:22:31.900
<v Barry Warsaw>GitLab or some library that I want to use or something like that.

00:22:32.150 --> 00:22:33.800
<v Barry Warsaw>I never even search for the docs.

00:22:33.810 --> 00:22:35.680
<v Barry Warsaw>I never even try to read the docs anymore.

00:22:35.810 --> 00:22:40.940
<v Barry Warsaw>I just say, hey, you know, whatever model I need to set up this website.

00:22:41.300 --> 00:22:43.720
<v Barry Warsaw>And I just, just tell me what to do or just do it.

00:22:43.960 --> 00:22:47.460
<v Barry Warsaw>And it's an immense time saver and productivity.

00:22:47.680 --> 00:22:52.120
<v Barry Warsaw>And then it gets me bootstrapped to the place where now I can start to be creative.

00:22:52.350 --> 00:22:57.800
<v Barry Warsaw>I don't have to worry about just like digging through pages and pages and pages of docs to

00:22:57.950 --> 00:23:00.000
<v Barry Warsaw>figure out one little setting here or there.

00:23:00.320 --> 00:23:02.040
<v Barry Warsaw>That's an amazing time saver.

00:23:02.120 --> 00:23:03.220
<v Gregory Kapfhammer>Yeah, that's a really good point.

00:23:03.500 --> 00:23:07.160
<v Gregory Kapfhammer>Another thing that I have noticed, there might be many things for which I had a really good

00:23:07.390 --> 00:23:10.420
<v Gregory Kapfhammer>mental model, but my brain can only store so much information.

00:23:10.960 --> 00:23:16.000
<v Gregory Kapfhammer>So for example, I know lots about the abstract syntax tree for Python, but I forget that

00:23:16.150 --> 00:23:16.280
<v Gregory Kapfhammer>sometimes.

00:23:16.870 --> 00:23:21.280
<v Gregory Kapfhammer>And so it's really nice for me to be able to bring that back into my mind quickly with

00:23:21.280 --> 00:23:21.960
<v Gregory Kapfhammer>an LLM.

00:23:22.250 --> 00:23:26.940
<v Gregory Kapfhammer>And if it's generating code for me that's doing a type of AST parsing, I can tell whether

00:23:27.080 --> 00:23:30.380
<v Gregory Kapfhammer>that's good code or not because I can refresh that mental model.

00:23:30.740 --> 00:23:34.960
<v Gregory Kapfhammer>So in those situations, it's not only the docs, but it's something that I used to know

00:23:35.070 --> 00:23:37.600
<v Gregory Kapfhammer>really well that I have forgotten some of.

00:23:37.940 --> 00:23:44.180
<v Gregory Kapfhammer>And the LLM often is very powerful when it comes to refreshing my memory and helping me to get started and move more quickly.

00:23:44.320 --> 00:23:48.680
<v Michael Kennedy>All right. Out of time, I think. Let's move on to Brett. What do you got, Brett?

00:23:48.920 --> 00:23:56.020
<v Brett Cannon>Well, I actually originally said we should talk about AI, but Jody had a way better pitch for it than I did because my internal pitch was a little bit AI.

00:23:56.360 --> 00:24:01.720
<v Brett Cannon>Do I actually have to write a paragraph explaining why? Then Jody actually did write the paragraph. So she did a much better job than I did.

00:24:01.940 --> 00:24:06.320
<v Brett Cannon>So the other topic I had was using tools to run your Python code.

00:24:06.680 --> 00:24:09.060
<v Brett Cannon>And what I mean by that is traditionally, if you think about it,

00:24:10.120 --> 00:24:11.760
<v Brett Cannon>you install the Python interpreter, right?

00:24:13.480 --> 00:24:15.840
<v Brett Cannon>Hopefully you create a virtual environment, install your dependencies,

00:24:16.140 --> 00:24:18.940
<v Brett Cannon>and you call the Python interpreter in your virtual environment to run your code.

00:24:19.560 --> 00:24:21.020
<v Brett Cannon>Those are all the steps you went through to run stuff.

00:24:21.360 --> 00:24:25.460
<v Brett Cannon>But now we've got tools that will compress all that into a run command,

00:24:25.920 --> 00:24:26.640
<v Brett Cannon>just do it all for you.

00:24:26.960 --> 00:24:31.520
<v Brett Cannon>And it seems like the community has shown a level of comfort with that,

00:24:31.940 --> 00:24:34.380
<v Brett Cannon>that I'd say snuck up on me a little bit,

00:24:34.680 --> 00:24:37.620
<v Brett Cannon>but I would say that I think it's a good thing, right?

00:24:37.780 --> 00:24:40.200
<v Brett Cannon>It's showing us, I'm going to say us,

00:24:40.370 --> 00:24:43.060
<v Brett Cannon>as the junior core developer here on this call,

00:24:43.440 --> 00:24:45.700
<v Brett Cannon>as to, sorry to make you too feel old,

00:24:45.840 --> 00:24:48.680
<v Brett Cannon>but admittedly, Barry did write my letter of recommendation

00:24:48.910 --> 00:24:49.940
<v Brett Cannon>to my master's program.

00:24:51.260 --> 00:24:52.800
<v Brett Cannon>So what happened was like, yeah,

00:24:53.100 --> 00:24:54.740
<v Brett Cannon>we had Hatch and PDM,

00:24:55.290 --> 00:24:58.180
<v Brett Cannon>poetry before that, and uv as of last year,

00:24:58.680 --> 00:24:59.360
<v Brett Cannon>all kind of come through

00:24:59.720 --> 00:25:00.880
<v Brett Cannon>and all kind of build on each other

00:25:01.200 --> 00:25:02.100
<v Brett Cannon>and take ideas from each other

00:25:02.240 --> 00:25:03.680
<v Brett Cannon>and kind of just slowly build up

00:25:03.680 --> 00:25:05.940
<v Brett Cannon>this kind of repertoire of tool approaches

00:25:06.260 --> 00:25:08.580
<v Brett Cannon>that they all kind of have a baseline kind of,

00:25:08.900 --> 00:25:09.740
<v Brett Cannon>not synergy is the right word,

00:25:09.960 --> 00:25:12.720
<v Brett Cannon>but share just kind of approach to certain things

00:25:13.220 --> 00:25:15.640
<v Brett Cannon>with their own twists and added takes on things.

00:25:15.790 --> 00:25:17.300
<v Brett Cannon>But in general, this whole like,

00:25:17.580 --> 00:25:19.300
<v Brett Cannon>you know what, you can just tell us to run this code

00:25:19.400 --> 00:25:20.440
<v Brett Cannon>and we will just run it, right?

00:25:20.540 --> 00:25:22.160
<v Brett Cannon>Like inline script metadata coming in

00:25:22.260 --> 00:25:23.980
<v Brett Cannon>and help making that more of a thing.

00:25:24.380 --> 00:25:26.860
<v Brett Cannon>Disclaimer, I was the  PEP delegate for getting that in.

00:25:27.140 --> 00:25:29.400
<v Brett Cannon>But I just think that's been a really awesome trend

00:25:29.420 --> 00:25:33.900
<v Brett Cannon>And I'm hoping we can kind of leverage that a bit.

00:25:34.190 --> 00:25:36.660
<v Brett Cannon>Like I have personal plans that we don't need to go into here,

00:25:36.820 --> 00:25:38.820
<v Brett Cannon>but like I'm hoping as a Python core team,

00:25:38.870 --> 00:25:41.020
<v Brett Cannon>we can kind of like help boost this stuff up a bit

00:25:41.020 --> 00:25:43.300
<v Brett Cannon>and kind of help keep a good baseline for this for everyone.

00:25:43.350 --> 00:25:45.700
<v Brett Cannon>Because I think it's shown that Python is still really good for beginners.

00:25:45.970 --> 00:25:48.900
<v Brett Cannon>You just have to give them the tools to kind of hide some of the details

00:25:49.280 --> 00:25:51.800
<v Brett Cannon>to not shoot yourself in the foot and still leads to a great outcome.

00:25:52.000 --> 00:25:55.640
<v Michael Kennedy>Yeah, 2025 might be the year that the Python tools stepped outside of Python.

00:25:56.180 --> 00:25:59.740
<v Michael Kennedy>Instead of being, you install Python and then use the tools.

00:26:00.190 --> 00:26:01.920
<v Michael Kennedy>You do the tool to get Python, right?

00:26:02.140 --> 00:26:03.660
<v Michael Kennedy>Like uv and PDM and others.

00:26:03.670 --> 00:26:07.880
<v Brett Cannon>Yeah, and inverted the dependency graph in terms of just how you put yourself in, right?

00:26:08.040 --> 00:26:13.260
<v Brett Cannon>I think the interesting thing is these tools treat Python as an implementation detail almost, right?

00:26:13.520 --> 00:26:17.480
<v Brett Cannon>Like when you just say uv or hatch run or PDM run thing,

00:26:17.920 --> 00:26:19.520
<v Brett Cannon>these tools don't make you have to think about the interpreter.

00:26:19.740 --> 00:26:22.480
<v Brett Cannon>It's just a thing that they pull in to make your code run, right?

00:26:22.600 --> 00:26:25.940
<v Brett Cannon>It's not even necessarily something you have to care about if you choose not to.

00:26:26.100 --> 00:26:29.940
<v Brett Cannon>And it's an interesting shift in that perspective, at least for me.

00:26:30.050 --> 00:26:31.360
<v Brett Cannon>But I've also been doing this for a long time.

00:26:31.360 --> 00:26:33.080
<v Barry Warsaw>I think you're really onto something.

00:26:33.460 --> 00:26:39.480
<v Barry Warsaw>And what I love at sort of a high level is this, I think there's a renewed focus on the user experience.

00:26:40.320 --> 00:26:49.080
<v Barry Warsaw>And like uv plus the PEP 723, the inline metadata, you know, you can put uv in the shebang line of your script.

00:26:49.560 --> 00:26:51.760
<v Barry Warsaw>And now you don't have to think about anything.

00:26:52.120 --> 00:26:56.340
<v Barry Warsaw>You get uv from somewhere, and then it takes care of everything.

00:26:57.790 --> 00:27:00.800
<v Barry Warsaw>And Hatch can work the same way, I think, for developers.

00:27:01.100 --> 00:27:08.140
<v Barry Warsaw>But this renewed focus on installing your Python executable,

00:27:08.340 --> 00:27:11.880
<v Barry Warsaw>you don't really have to think about, because those things are very complicated,

00:27:12.030 --> 00:27:14.420
<v Barry Warsaw>and people just want to hit the ground running.

00:27:14.950 --> 00:27:17.600
<v Barry Warsaw>And so if you think about the previous discussion about AI,

00:27:18.260 --> 00:27:19.880
<v Barry Warsaw>I just want things to work.

00:27:20.140 --> 00:27:21.760
<v Barry Warsaw>I know what I want to do.

00:27:22.220 --> 00:27:23.140
<v Barry Warsaw>I can see it.

00:27:23.140 --> 00:27:24.300
<v Barry Warsaw>I can see the vision of it.

00:27:24.300 --> 00:27:25.640
<v Barry Warsaw>And I just don't want to.

00:27:25.960 --> 00:27:28.740
<v Barry Warsaw>An analogy is like when I first learned Python

00:27:28.960 --> 00:27:31.580
<v Barry Warsaw>and I came from C++ and all those languages.

00:27:32.280 --> 00:27:35.140
<v Barry Warsaw>And I thought, oh my gosh, just to get like, hello world,

00:27:35.280 --> 00:27:39.420
<v Barry Warsaw>I have to do a million little things that I shouldn't have to do.

00:27:39.680 --> 00:27:43.120
<v Barry Warsaw>Like create a main and get my braces right

00:27:43.140 --> 00:27:46.760
<v Barry Warsaw>and get all my variables right and get my pound includes correct.

00:27:46.920 --> 00:27:48.980
<v Barry Warsaw>And now I don't have to think about any of that stuff.

00:27:49.260 --> 00:27:59.980
<v Barry Warsaw>And the thing that was eye-opening for me with Python was the distance between vision of what I wanted and working code just really narrowed.

00:28:00.100 --> 00:28:09.320
<v Barry Warsaw>And I think that as we are starting to think about tools and environments and how to bootstrap all this stuff, we're also now taking all that stuff away.

00:28:09.840 --> 00:28:11.580
<v Barry Warsaw>Because people honestly don't care.

00:28:11.650 --> 00:28:13.320
<v Barry Warsaw>I don't care about any of that stuff.

00:28:13.330 --> 00:28:18.020
<v Barry Warsaw>I just want to go from like, I woke up this morning and had a cool idea and I just wanted to get at work.

00:28:18.860 --> 00:28:22.080
<v Michael Kennedy>Or you wanted to share it so you could just share the script and you don't have to say,

00:28:22.460 --> 00:28:24.300
<v Michael Kennedy>here's your steps that you get started with.

00:28:24.980 --> 00:28:25.300
<v Barry Warsaw>Exactly.

00:28:25.800 --> 00:28:26.020
<v Barry Warsaw>Exactly.

00:28:26.320 --> 00:28:28.660
<v Reuven Lerner>I want to thank the two of you for, oh, sorry, sorry, go ahead.

00:28:28.960 --> 00:28:34.220
<v Reuven Lerner>I'm just going to say, like, for years teaching Python that how do we get it installed?

00:28:34.720 --> 00:28:37.580
<v Reuven Lerner>At first, it surprised me how difficult it was for people.

00:28:37.700 --> 00:28:39.260
<v Reuven Lerner>Because like, oh, come on, we just got Python.

00:28:39.460 --> 00:28:40.380
<v Reuven Lerner>Like, what's so hard about this?

00:28:40.620 --> 00:28:44.740
<v Reuven Lerner>But it turns out it's a really big barrier to entry for newcomers.

00:28:45.200 --> 00:28:48.920
<v Reuven Lerner>And I'm very happy that Jupyter Lite now has solved its problems with input.

00:28:49.320 --> 00:28:50.520
<v Reuven Lerner>And it's like huge.

00:28:50.960 --> 00:28:56.820
<v Reuven Lerner>But until now, I hadn't really thought about starting with uv because it's cross-platform.

00:28:57.180 --> 00:29:02.100
<v Reuven Lerner>And if I say to people in the first 10 minutes of class, install uv for your platform and

00:29:02.100 --> 00:29:05.100
<v Reuven Lerner>then say uv in it, your project, bam, you're done.

00:29:05.320 --> 00:29:06.060
<v Reuven Lerner>It just works.

00:29:06.440 --> 00:29:07.200
<v Reuven Lerner>And then it works cross-platform.

00:29:07.580 --> 00:29:08.520
<v Reuven Lerner>This is mind-blowing.

00:29:08.700 --> 00:29:10.140
<v Reuven Lerner>And I'm going to try this at some point.

00:29:10.220 --> 00:29:10.540
<v Reuven Lerner>Thank you.

00:29:10.640 --> 00:29:14.860
<v Gregory Kapfhammer>I can comment on the mind-blowing part because now when I teach undergraduate students, we

00:29:14.880 --> 00:29:20.360
<v Gregory Kapfhammer>start with uv in the very first class. And it is awesome. There were things that would take students,

00:29:20.820 --> 00:29:25.920
<v Gregory Kapfhammer>even very strong students who've had lots of experience, it would still take them a week to

00:29:26.160 --> 00:29:30.160
<v Gregory Kapfhammer>set everything up on their new laptop and get everything ready and to understand all the key

00:29:30.580 --> 00:29:36.640
<v Gregory Kapfhammer>concepts and know where something is in their path. And now we just say, install uv for your

00:29:36.900 --> 00:29:42.820
<v Gregory Kapfhammer>operating system and get running on your computer. And then, hey, you're ready to go. And I don't have

00:29:42.780 --> 00:29:47.040
<v Gregory Kapfhammer>teach them about docker containers and i don't have to tell them how to install python with some

00:29:47.160 --> 00:29:52.900
<v Gregory Kapfhammer>package manager all of those things just work and i think from a learning perspective whether you're

00:29:52.960 --> 00:29:58.540
<v Gregory Kapfhammer>in a class or whether you're in a company or whether you're teaching yourself uv is absolutely

00:29:58.900 --> 00:30:04.960
<v Jodie Burchell>awesome i'm actually wondering whether i am the one who is newest to python here i taught myself

00:30:05.280 --> 00:30:12.740
<v Jodie Burchell>python in 2011 so i was like python 2.7 stage but it was my first programming language i was just

00:30:12.760 --> 00:30:17.920
<v Jodie Burchell>procrastinating during my PhD. And I was like, I should learn to program. So I just taught myself

00:30:18.140 --> 00:30:23.360
<v Jodie Burchell>Python. And I can tell you, you do not come from an engineering background. And you're like,

00:30:23.430 --> 00:30:29.240
<v Jodie Burchell>what is Python? What is Python doing? Why am I typing Python to execute this hello world? And

00:30:29.300 --> 00:30:33.840
<v Jodie Burchell>if you're kind of curious, you get down a rabbit hole before you even get to the point where you're

00:30:33.960 --> 00:30:39.220
<v Jodie Burchell>just focusing on learning the basics. And so it's exactly, I was going to say with Reuven,

00:30:39.240 --> 00:30:43.160
<v Jodie Burchell>And like whether you thought about it for teaching, because we're now debating for Humble Data,

00:30:43.260 --> 00:30:48.040
<v Jodie Burchell>which is a beginner's data science community that I'm part of, whether we switch to uv.

00:30:48.320 --> 00:30:52.180
<v Jodie Burchell>This was Chuck's idea because it does abstract away all these details.

00:30:52.720 --> 00:30:55.320
<v Jodie Burchell>The debate I have is, is it too magic?

00:30:55.820 --> 00:30:59.200
<v Jodie Burchell>This is kind of the problem because I also remember learning about things like virtual

00:30:59.500 --> 00:31:02.540
<v Jodie Burchell>environments, because again, this was my first programming language and being like,

00:31:02.780 --> 00:31:03.740
<v Jodie Burchell>oh, it's a very good idea.

00:31:04.060 --> 00:31:04.980
<v Jodie Burchell>This is best practices.

00:31:05.280 --> 00:31:07.920
<v Jodie Burchell>And it's also a debate we have in PyCharm, right?

00:31:08.220 --> 00:31:14.780
<v Jodie Burchell>Like how much do you magic away the fundamentals versus making people think a little bit, but

00:31:15.140 --> 00:31:15.560
<v Jodie Burchell>I'm not sure.

00:31:15.660 --> 00:31:15.840
<v Michael Kennedy>All right.

00:31:15.920 --> 00:31:18.720
<v Michael Kennedy>Like, would you even let somebody run without a virtual environment?

00:31:19.000 --> 00:31:21.180
<v Michael Kennedy>That's like, that's a take you, that's a stance you could take.

00:31:21.300 --> 00:31:27.620
<v Jodie Burchell>I used to when I first learned Python, because it was too complicated, but then I learned

00:31:27.840 --> 00:31:28.140
<v Jodie Burchell>better.

00:31:28.640 --> 00:31:29.160
<v Jodie Burchell>But yes.

00:31:29.320 --> 00:31:34.380
<v Thomas Wourters>The consideration here is like hiding the magic isn't like hiding the details and having

00:31:34.430 --> 00:31:37.580
<v Thomas Wourters>all this magic just work is great as long as it works.

00:31:38.020 --> 00:31:43.620
<v Thomas Wourters>And the question is, how is it going to break down and how are people going to know how to deal

00:31:43.830 --> 00:31:49.540
<v Thomas Wourters>when it breaks down, if you hide all the magic? And I think virtual envs were, or let's say before

00:31:49.650 --> 00:31:54.740
<v Thomas Wourters>we had virtual envs, installing packages was very much in the, you had to know all the details

00:31:54.910 --> 00:32:00.300
<v Thomas Wourters>because it was very likely going to break down in some way right before we had virtual envs,

00:32:00.560 --> 00:32:04.880
<v Thomas Wourters>because you would end up with weird conflicts or multiple copies of a package installed in

00:32:04.840 --> 00:32:09.820
<v Thomas Wourters>different parts of the system. When we got virtual ends, we sort of didn't have to worry about that

00:32:10.020 --> 00:32:14.380
<v Thomas Wourters>anymore because we were trained in that you can just blow away the virtual one and it just works.

00:32:14.920 --> 00:32:19.900
<v Thomas Wourters>And with uv, we're back into, this looks like a single installation. We don't know what's going

00:32:19.900 --> 00:32:25.360
<v Thomas Wourters>to go on, but we've learned, we as a community and also the people working on uv, we have learned

00:32:25.700 --> 00:32:31.640
<v Thomas Wourters>from those earlier mistakes or not, maybe not mistakes, but consequences of the design.

00:32:32.180 --> 00:32:38.160
<v Thomas Wourters>And they have created something that is, that appears to be very stable where it's unlikely

00:32:38.280 --> 00:32:39.220
<v Thomas Wourters>the magic will break.

00:32:39.460 --> 00:32:43.940
<v Thomas Wourters>And when the magic does break, it's obvious what the problem is or, or it automatically

00:32:44.100 --> 00:32:44.620
<v Thomas Wourters>fixes itself.

00:32:45.100 --> 00:32:50.480
<v Thomas Wourters>So like it's not reusing, broken, installations and that kind of thing.

00:32:50.720 --> 00:32:57.220
<v Thomas Wourters>So the risk now, as it turns out, I think as is proven by the community adopting uv so

00:32:57.860 --> 00:33:00.160
<v Thomas Wourters>fast and so willingly, I think it's acceptable.

00:33:00.180 --> 00:33:01.860
<v Thomas Wourters>Well, I think it's, yeah, I think it's proven itself.

00:33:02.140 --> 00:33:09.380
<v Thomas Wourters>It's clear that this is, it's worth the potential of discovering weird edge cases later, both

00:33:09.520 --> 00:33:16.060
<v Thomas Wourters>because it's probably low likelihood, but also the people behind uv Astral have proven that

00:33:16.200 --> 00:33:18.600
<v Thomas Wourters>they would jump in and fix those issues, right?

00:33:18.600 --> 00:33:22.840
<v Thomas Wourters>They would do anything they need to keep uv workable the same way.

00:33:23.190 --> 00:33:28.920
<v Thomas Wourters>And they have a focus that Python as a whole cannot have because they cater to fewer use

00:33:28.940 --> 00:33:31.200
<v Michael Kennedy>cases than Python as a whole needs to.

00:33:31.320 --> 00:33:36.160
<v Michael Kennedy>On the audience, Galano says, as an enterprise tech director in Python coder, I believe we

00:33:36.300 --> 00:33:40.500
<v Michael Kennedy>should hide the magic which empowers the regular employee to do simple things that make their

00:33:40.620 --> 00:33:40.960
<v Michael Kennedy>job easier.

00:33:41.420 --> 00:33:41.500
<v Michael Kennedy>Yeah.

00:33:41.650 --> 00:33:46.800
<v Barry Warsaw>This notion of abstractions, right, has always been there in computer science.

00:33:47.980 --> 00:33:53.560
<v Barry Warsaw>And, you know, we've used tools or languages or systems where we've tried to bring that

00:33:53.580 --> 00:33:58.600
<v Barry Warsaw>abstraction layer up so that we don't have to think about all these details, as I mentioned

00:33:58.790 --> 00:34:04.080
<v Barry Warsaw>before. The question is, that's always the happy path. And when I'm trying to teach somebody

00:34:04.300 --> 00:34:08.960
<v Barry Warsaw>something like, here's how to use this library or here's how to use this tool, I try to be very

00:34:09.220 --> 00:34:14.659
<v Barry Warsaw>opinionated to keep people on that happy path. Like, assume everything's going to work just right.

00:34:15.020 --> 00:34:19.880
<v Barry Warsaw>Here's how you just make you go down that path to get the thing done that you want. The question

00:34:19.899 --> 00:34:27.200
<v Barry Warsaw>really is when things go wrong, how narrow is that abstraction? And are you able, and even when

00:34:27.200 --> 00:34:31.960
<v Barry Warsaw>you're just curious, like what's really going on underneath the hood? Of course, that's not a really

00:34:31.960 --> 00:34:36.540
<v Barry Warsaw>good analogy today because cars are basically computers on wheels that you can't really

00:34:36.760 --> 00:34:42.540
<v Brett Cannon>understand how they work. But back in your day. But back in my day, we were changing spark plugs,

00:34:42.620 --> 00:34:49.860
<v Brett Cannon>you know, but and crank that window down. Exactly. So I think we always have to leave that

00:34:50.280 --> 00:34:56.620
<v Barry Warsaw>room for the curious and the bad path where when things go wrong or when you're just like,

00:34:56.810 --> 00:35:01.540
<v Barry Warsaw>you know what, I understand how this works, but I'm kind of curious about what's really going on.

00:35:01.780 --> 00:35:06.920
<v Barry Warsaw>How easy is it for me to dive in and get a little bit more of that background, you know,

00:35:07.140 --> 00:35:11.620
<v Barry Warsaw>a little bit more of that understanding of what's going on. I want the magic to decompose,

00:35:12.020 --> 00:35:16.880
<v Brett Cannon>right like you should be able to explain the magic path via a more decomposed steps using the tool

00:35:17.080 --> 00:35:21.760
<v Brett Cannon>all the way down to what the tools like to do behind the scenes just just to admit i the reason

00:35:21.850 --> 00:35:25.900
<v Brett Cannon>i brought this up and i've been thinking about this a lot is i'm thinking of trying to get the python

00:35:26.140 --> 00:35:31.380
<v Brett Cannon>launcher to do a bit more because one interesting thing we haven't really brought up here is we're

00:35:31.390 --> 00:35:36.960
<v Brett Cannon>all seeing uv uv uv uv is a company there's always there's they might disappear and we haven't

00:35:36.980 --> 00:35:41.640
<v Brett Cannon>de-risked ourselves from that. Now we do have Hatch, we do have PDM, but as I said, there's kind

00:35:41.640 --> 00:35:45.440
<v Brett Cannon>of a baseline I think they all share that I think they would be probably okay if the Python launcher

00:35:45.580 --> 00:35:48.800
<v Brett Cannon>just did because that's based on standards, right? Because that's the other thing that there's been

00:35:48.800 --> 00:35:52.600
<v Brett Cannon>a lot of work that has led to this step, right? Like we've gotten way more packaging standards,

00:35:52.900 --> 00:35:58.220
<v Brett Cannon>we've got PEP 723, like we mentioned. There's a lot of work that's come up to lead to this point

00:35:58.460 --> 00:36:03.920
<v Brett Cannon>that all these tools can lean on to have them all have an equivalent outcome because it's expected

00:36:03.940 --> 00:36:04.700
<v Brett Cannon>is how they should be.

00:36:05.199 --> 00:36:07.740
<v Brett Cannon>And so I think it's something we need to consider

00:36:08.210 --> 00:36:09.360
<v Brett Cannon>of how do we make sure,

00:36:09.820 --> 00:36:10.740
<v Brett Cannon>like, by the way, uv,

00:36:11.230 --> 00:36:12.140
<v Brett Cannon>I know the people, they're great.

00:36:12.280 --> 00:36:13.640
<v Brett Cannon>I'm not trying to spares them

00:36:13.760 --> 00:36:14.620
<v Brett Cannon>or think they're going to go away,

00:36:14.780 --> 00:36:16.320
<v Brett Cannon>but it is something we have to consider.

00:36:16.800 --> 00:36:18.100
<v Brett Cannon>And I will also say, Jody,

00:36:18.480 --> 00:36:19.780
<v Brett Cannon>I do think about this for teaching

00:36:20.080 --> 00:36:21.480
<v Brett Cannon>because I'm a dad now

00:36:21.880 --> 00:36:23.460
<v Brett Cannon>and I don't want my kid coming home

00:36:24.180 --> 00:36:25.820
<v Brett Cannon>when they get old enough to learn Python

00:36:25.910 --> 00:36:26.720
<v Brett Cannon>and go, hey, dad,

00:36:26.880 --> 00:36:28.980
<v Brett Cannon>why is getting Python code running so hard?

00:36:29.240 --> 00:36:31.420
<v Brett Cannon>So I want to make sure that that never happens.

00:36:32.160 --> 00:36:34.680
<v Jodie Burchell>But they fall in love with it from the start.

00:36:34.940 --> 00:36:37.600
<v Michael Kennedy>I realized something for the 2026 year interview.

00:36:37.680 --> 00:36:42.960
<v Michael Kennedy>I have to bring a sign that says time for next topic because we got a bunch of topics and we're running low on time.

00:36:43.640 --> 00:36:45.660
<v Michael Kennedy>So, Thomas, let's jump over to yours.

00:36:46.120 --> 00:36:48.240
<v Michael Kennedy>Oh, and I had two topics as well.

00:36:48.400 --> 00:36:52.340
<v Thomas Wourters>So I'm only going to have to pick my favorite child, right?

00:36:52.540 --> 00:36:52.920
<v Thomas Wourters>That's terrible.

00:36:53.900 --> 00:36:57.960
<v Thomas Wourters>My second favorite child is Lazy Imports, which is a relatively new development.

00:36:58.280 --> 00:37:00.000
<v Thomas Wourters>So we'll probably not get to that.

00:37:00.020 --> 00:37:00.120
<v Thomas Wourters>And just accepted.

00:37:00.300 --> 00:37:02.360
<v Thomas Wourters>Yes, it's been accepted and it's going to be awesome.

00:37:03.140 --> 00:37:06.620
<v Thomas Wourters>So I'll just give that a shout out and then move to my favorite child, which is free threaded

00:37:06.850 --> 00:37:06.980
<v Thomas Wourters>Python.

00:37:07.580 --> 00:37:11.640
<v Thomas Wourters>For those who were not aware, the global interpreter lock is going away.

00:37:12.160 --> 00:37:13.700
<v Thomas Wourters>I am stating it as a fact.

00:37:13.840 --> 00:37:17.780
<v Thomas Wourters>It's not actually a fact yet, but it, you know, that's because the steering council hasn't

00:37:18.240 --> 00:37:19.460
<v Thomas Wourters>realized the fact yet.

00:37:20.860 --> 00:37:21.940
<v Brett Cannon>It is trending towards.

00:37:22.320 --> 00:37:28.820
<v Thomas Wourters>Well, I was originally on the steering council that accepted the proposal to add free threading

00:37:28.840 --> 00:37:34.500
<v Thomas Wourters>as a, as an experimental feature, we had this idea of adding it as experimental and then making it

00:37:34.600 --> 00:37:39.300
<v Thomas Wourters>supported, but not the default and then making it the default. And it was all a little vague and,

00:37:39.500 --> 00:37:43.800
<v Thomas Wourters>and up in the air. And then I didn't get reelected for the steering council last year,

00:37:44.060 --> 00:37:49.420
<v Thomas Wourters>which I was not sad about at all. I sort of ran on a, well, if there's nobody better, I'll do it,

00:37:49.520 --> 00:37:54.820
<v Thomas Wourters>but otherwise I have other things to do. And it turns out those other things were making sure that

00:37:54.840 --> 00:37:59.700
<v Thomas Wourters>prefer that Python landed in a supported state. So I lobbied the steering council quite hard,

00:38:00.040 --> 00:38:04.740
<v Thomas Wourters>as Barry might remember at the start of the year, to get some movement on this, like get some

00:38:04.900 --> 00:38:10.500
<v Thomas Wourters>decision going. So for Python 3.14, it is officially supported. The performance is great. It's like

00:38:10.820 --> 00:38:16.360
<v Thomas Wourters>between a couple of percent slower and 10% slower, depending on the hardware and the compiler that

00:38:16.360 --> 00:38:23.240
<v Thomas Wourters>you use. It's basically the same speed on macOS, which is really like it's, that's a combination of

00:38:23.380 --> 00:38:29.240
<v Thomas Wourters>the ARM hardware and Clang specializing things, but it's basically the same speed, which, wow.

00:38:29.580 --> 00:38:35.040
<v Thomas Wourters>And then on recent GCCs on Linux, it's like a couple of percent slower. The main problem is

00:38:35.080 --> 00:38:40.380
<v Thomas Wourters>really community adoption, getting third-party packages to update their extension modules for

00:38:40.780 --> 00:38:48.560
<v Thomas Wourters>the new APIs and the things that by necessity sort of broke, and also supporting free threading in a

00:38:48.420 --> 00:38:54.060
<v Thomas Wourters>in a good way and in packages for Python code, it turns out there's very few changes that

00:38:54.070 --> 00:38:56.840
<v Thomas Wourters>need to be made for things to work well under free threading.

00:38:57.400 --> 00:39:02.680
<v Thomas Wourters>They might not be entirely thread safe, but usually like almost always in cases where it

00:39:02.920 --> 00:39:07.080
<v Thomas Wourters>wasn't thread saved before either, because the guild doesn't actually affect thread safety.

00:39:07.820 --> 00:39:09.300
<v Thomas Wourters>Just the likelihood of things breaking.

00:39:09.600 --> 00:39:14.920
<v Michael Kennedy>I do think there's been a bit of a, the mindset of the Python community hasn't really been

00:39:14.940 --> 00:39:18.380
<v Michael Kennedy>focused on creating thread safe code because the GIL is supposed to protect us.

00:39:18.460 --> 00:39:22.160
<v Michael Kennedy>But soon as it takes multiple steps, then all of a sudden it's just less likely.

00:39:22.340 --> 00:39:23.540
<v Michael Kennedy>It's not that it couldn't happen.

00:39:23.780 --> 00:39:24.760
<v Thomas Wourters>Yeah, that's my point, right?

00:39:24.860 --> 00:39:27.160
<v Thomas Wourters>It's not the GIL never gave you threat safety.

00:39:27.460 --> 00:39:30.720
<v Thomas Wourters>The GIL gave cpythons internals threat safety.

00:39:31.120 --> 00:39:35.980
<v Thomas Wourters>It never really affected Python code and it very rarely affected thread safety in

00:39:36.260 --> 00:39:37.480
<v Thomas Wourters>extension modules as well.

00:39:37.620 --> 00:39:41.780
<v Thomas Wourters>So they already had to take care of, of making sure that the global interpreter

00:39:41.800 --> 00:39:46.560
<v Thomas Wourters>couldn't be released by something that they ended up calling indirectly so it's actually not that

00:39:46.760 --> 00:39:52.980
<v Thomas Wourters>hard to port most things to support free threading and the benefits we've seen some experimental

00:39:53.030 --> 00:39:56.320
<v Thomas Wourters>work because you know it's still it's still new there's still a lot of things that don't

00:39:56.720 --> 00:40:02.060
<v Thomas Wourters>quite support it there's still places where thread contention slows things things down a lot but

00:40:02.180 --> 00:40:10.020
<v Thomas Wourters>we've seen a lot of examples of really promising very parallel problems that now speed up by 10x or

00:40:09.980 --> 00:40:15.560
<v Thomas Wourters>more. And it's going to be really excited in the future. And it's in 2025 that this all started.

00:40:15.820 --> 00:40:21.620
<v Thomas Wourters>I mean, Sam started it earlier, but he's been working on this for years, but it landed in 2025.

00:40:21.880 --> 00:40:26.760
<v Michael Kennedy>It dropped its experimental stage in 314, basically. Yeah. I was going to say, were we all,

00:40:27.040 --> 00:40:30.760
<v Brett Cannon>the three of us on the steering council at the same time when we decided to start the experiment

00:40:30.940 --> 00:40:36.320
<v Barry Warsaw>for free threading? I think Barry wasn't on it. Yeah, I missed a couple of years there, but I'm

00:40:36.340 --> 00:40:36.720
<v Barry Warsaw>Not sure.

00:40:36.920 --> 00:40:37.640
<v Barry Warsaw>No, I totally agree.

00:40:37.640 --> 00:40:48.600
<v Barry Warsaw>I think free threading is one of the most transformative developments for Python, certainly since Python 3, but even maybe more impactful because of the size of the community today.

00:40:49.300 --> 00:40:56.420
<v Barry Warsaw>Personally, you know, not necessarily speaking as a current or potentially former steering council member.

00:40:56.680 --> 00:40:58.480
<v Barry Warsaw>We'll see how that shakes out.

00:40:58.720 --> 00:41:00.080
<v Barry Warsaw>But I think it's inevitable.

00:41:00.460 --> 00:41:08.360
<v Barry Warsaw>I think free threading is absolutely the future of Python, and I think it's going to unlock incredible potential and performance.

00:41:08.930 --> 00:41:10.460
<v Barry Warsaw>I think we just have to do it right.

00:41:10.630 --> 00:41:15.800
<v Barry Warsaw>And so I talked to lots of teams who are building various software all over the community.

00:41:16.640 --> 00:41:23.580
<v Barry Warsaw>And I actually think it's more of an educational and maybe an outreach problem than it is a technological problem.

00:41:23.720 --> 00:41:28.800
<v Barry Warsaw>I mean, yes, there are probably APIs that are missing that will make people's lives easier.

00:41:30.300 --> 00:41:36.040
<v Barry Warsaw>There's probably some libraries that will make other code a little easier to write or whatever or to understand.

00:41:36.900 --> 00:41:37.980
<v Barry Warsaw>But like all that's solvable.

00:41:38.100 --> 00:41:42.620
<v Barry Warsaw>And I think really reaching out to the teams that are, you know, like Thomas said,

00:41:42.640 --> 00:41:46.860
<v Barry Warsaw>that are building the ecosystem, that are moving the ecosystem to a free threading world.

00:41:47.380 --> 00:41:50.040
<v Barry Warsaw>That's where we really need to spend our effort on.

00:41:50.160 --> 00:41:51.100
<v Barry Warsaw>And we'll get there.

00:41:51.360 --> 00:41:52.140
<v Barry Warsaw>It won't be that long.

00:41:52.400 --> 00:41:55.480
<v Barry Warsaw>It certainly won't be as long as it took us to get to Python 3.

00:41:56.920 --> 00:42:04.000
<v Reuven Lerner>I'm sort of curious as someone who's not super experienced with threading or, you know, basic concurrency.

00:42:04.560 --> 00:42:13.820
<v Reuven Lerner>I mean, I've used it, but I feel like now we have threads, especially with free threading and sub interpreters and multiprocessing and asyncio.

00:42:14.360 --> 00:42:19.560
<v Reuven Lerner>And I feel like for many people now it's like, oh, my God, which one am I supposed to use?

00:42:19.920 --> 00:42:24.020
<v Reuven Lerner>And for someone who's experienced, you can sort of say, well, this seems like a better choice.

00:42:24.140 --> 00:42:31.060
<v Reuven Lerner>But are there any plans to sort of try to have a taxonomy of what problems are solved by which of these?

00:42:31.380 --> 00:42:37.360
<v Thomas Wourters>The premise here is that everyone would be using one or more of these low-level techniques that you mentioned.

00:42:37.700 --> 00:42:40.620
<v Thomas Wourters>And I think that's not a good way of looking at it.

00:42:40.860 --> 00:42:46.340
<v Thomas Wourters>Like AsyncIO is a library that you want to use for the things that AsyncIO is good at.

00:42:46.580 --> 00:42:52.220
<v Thomas Wourters>And you can actually very nicely combine it with multiprocessing, with subprocesses, with

00:42:52.510 --> 00:42:57.700
<v Thomas Wourters>so that subprocesses and subinterpreters, just to make it clear that those are two very separate

00:42:57.860 --> 00:43:00.800
<v Thomas Wourters>things and multithreading, both with and without free threading.

00:43:01.100 --> 00:43:06.560
<v Thomas Wourters>And it solves different problems or it gives you different abilities within the AsyncIO

00:43:06.760 --> 00:43:06.900
<v Thomas Wourters>framework.

00:43:06.950 --> 00:43:09.100
<v Thomas Wourters>And the same is true for like GUI frameworks.

00:43:09.730 --> 00:43:14.360
<v Thomas Wourters>I mean, GUI frameworks usually want threads for multiple reasons, but you can use these

00:43:14.490 --> 00:43:15.300
<v Thomas Wourters>other things as well.

00:43:15.720 --> 00:43:21.580
<v Thomas Wourters>I don't think it's down to teaching end users when to use or avoid all these different things.

00:43:22.070 --> 00:43:26.960
<v Thomas Wourters>I think we need higher level abstractions for tasks that people want to solve.

00:43:27.270 --> 00:43:32.980
<v Thomas Wourters>And then those can decide on what for their particular use case is a better approach.

00:43:33.170 --> 00:43:35.840
<v Thomas Wourters>For instance, PyTorch has multiple.

00:43:36.090 --> 00:43:42.180
<v Thomas Wourters>So it's used for people who don't know to train, not just train, but it's used in AI

00:43:42.200 --> 00:43:45.720
<v Thomas Wourters>for generating large matrices and LLMs and what have you.

00:43:46.100 --> 00:43:49.160
<v Thomas Wourters>Part of it is loading data and processing.

00:43:49.680 --> 00:43:52.640
<v Thomas Wourters>And the basic ideas of AsyncIO are,

00:43:52.860 --> 00:43:54.720
<v Thomas Wourters>oh, you can do all these things in parallel

00:43:55.040 --> 00:43:56.500
<v Thomas Wourters>because you're not waiting on the CPU,

00:43:56.720 --> 00:43:57.680
<v Thomas Wourters>you're just waiting on IO.

00:43:58.200 --> 00:44:00.720
<v Thomas Wourters>Turns out it is still a good idea to use threads

00:44:00.960 --> 00:44:02.400
<v Thomas Wourters>for massively parallel IO

00:44:02.600 --> 00:44:05.740
<v Thomas Wourters>because otherwise you end up waiting longer than you need to.

00:44:05.940 --> 00:44:10.120
<v Thomas Wourters>So a problem where we thought AsyncIO would be the solution

00:44:10.140 --> 00:44:15.520
<v Thomas Wourters>and we never needed threads is actually much improved if we tie in threads as well.

00:44:15.730 --> 00:44:19.200
<v Thomas Wourters>And we've seen massive, massive improvements in data loader.

00:44:19.320 --> 00:44:23.660
<v Thomas Wourters>There's even an article, a published article from some people at Meta

00:44:24.200 --> 00:44:28.840
<v Thomas Wourters>showing how much they improve the PyTorch data loader by using multiple threads.

00:44:29.210 --> 00:44:33.240
<v Thomas Wourters>But at a very low level, we don't want end users to need to make that choice, right?

00:44:33.300 --> 00:44:35.380
<v Brett Cannon>I concur to futures is a good point, right?

00:44:35.500 --> 00:44:39.300
<v Brett Cannon>Like all of these approaches are all supported there and it's a unified one.

00:44:39.880 --> 00:44:42.320
<v Brett Cannon>So if you were to teach this, for instance, you could say use concurrent.tot futures.

00:44:42.880 --> 00:44:43.500
<v Brett Cannon>These are all there.

00:44:44.130 --> 00:44:45.460
<v Brett Cannon>This is the potential tradeoff.

00:44:45.550 --> 00:44:46.800
<v Brett Cannon>Like basically use threads.

00:44:46.940 --> 00:44:51.280
<v Brett Cannon>It's going to be the fastest unless there's like some module you have that's not that's

00:44:51.400 --> 00:44:53.040
<v Brett Cannon>screwing up because of threads, then use sub interpreters.

00:44:53.540 --> 00:44:57.540
<v Brett Cannon>And if for some reason sub interpreters don't work, you should move to the processing pool,

00:44:57.710 --> 00:44:58.340
<v Brett Cannon>the process pool.

00:44:58.680 --> 00:45:02.140
<v Brett Cannon>But I mean, basically, you just kind of just like, it's not go sort the fast stuff.

00:45:02.190 --> 00:45:03.300
<v Brett Cannon>And for some reason, it doesn't work.

00:45:03.390 --> 00:45:05.420
<v Brett Cannon>Use the next fastest and just kind of do it that way.

00:45:05.860 --> 00:45:07.820
<v Brett Cannon>After that, then you start to the lower level.

00:45:08.240 --> 00:45:11.240
<v Brett Cannon>Like, okay, why do I want to use subinterpreters instead of threads?

00:45:11.730 --> 00:45:12.260
<v Brett Cannon>Those kinds of threads.

00:45:12.390 --> 00:45:15.600
<v Brett Cannon>But I think that's a different, as I think we're all searching,

00:45:15.830 --> 00:45:18.840
<v Brett Cannon>a different level of abstraction, which is a term we keep bringing up today.

00:45:19.520 --> 00:45:21.520
<v Brett Cannon>It's a level that a lot of people are not going to have to care about.

00:45:21.520 --> 00:45:23.540
<v Brett Cannon>I think the libraries are the ones that are going to have to care about this

00:45:23.570 --> 00:45:25.520
<v Brett Cannon>and who are going to do a lot of this for you.

00:45:25.620 --> 00:45:29.400
<v Michael Kennedy>Let me throw this out on our way out the door to get to Reuven's topic.

00:45:29.920 --> 00:45:32.860
<v Michael Kennedy>I would love to see it solidify around async and await.

00:45:33.150 --> 00:45:36.140
<v Michael Kennedy>And you just await a thing, maybe put a decorator on something.

00:45:36.260 --> 00:45:42.040
<v Michael Kennedy>say this, this one, I want this to be threaded. I want this to be IO. I want this. And you don't,

00:45:42.100 --> 00:45:46.080
<v Michael Kennedy>you just use async and await and don't have to think about it, but that's, that's my dream.

00:45:46.800 --> 00:45:47.800
<v Michael Kennedy>Reuven, what's your dream?

00:45:48.700 --> 00:45:49.740
<v Reuven Lerner>Wow. How long do you have?

00:45:51.000 --> 00:45:51.600
<v Michael Kennedy>No, what's your topic?

00:45:52.640 --> 00:45:58.480
<v Reuven Lerner>So I want to talk about Python ecosystem and funding. When I talk to people with Python

00:45:59.060 --> 00:46:01.820
<v Reuven Lerner>and I talk to them about it, how it's open source, they're like, oh, right, it's open source. That

00:46:01.940 --> 00:46:05.360
<v Reuven Lerner>means I can download it for free. And from their perspective, that's sort of where it starts

00:46:05.640 --> 00:46:10.460
<v Reuven Lerner>and ends. And the notion that people work on it, the notion that needs funding, the notion that

00:46:10.620 --> 00:46:15.060
<v Reuven Lerner>there's a Python software foundation that supports a lot of these activities, the infrastructure

00:46:15.580 --> 00:46:21.400
<v Reuven Lerner>is completely unknown to them and even quite shocking for them to hear. But Python is in many

00:46:21.560 --> 00:46:26.720
<v Reuven Lerner>ways, I think, starting to become a victim of its own success, that we've been dependent on

00:46:27.280 --> 00:46:32.740
<v Reuven Lerner>companies for a number of years to support developers and development. And we've been

00:46:32.700 --> 00:46:38.080
<v Reuven Lerner>assuming that the PSF, which gives money out to lots of organizations to run conferences and

00:46:38.290 --> 00:46:43.380
<v Reuven Lerner>workshops and so forth, can sort of keep scaling up and that they will have enough funding. And

00:46:43.520 --> 00:46:48.500
<v Reuven Lerner>we've seen a few sort of shocks that system in the last year. Most recently, the PSF announced that

00:46:48.500 --> 00:46:52.680
<v Reuven Lerner>it was no longer going to be doing versus sort of pared down about a year ago, what it would give

00:46:52.840 --> 00:46:56.620
<v Reuven Lerner>money for. And then about five months ago, six months ago, I think it was in July or August,

00:46:56.800 --> 00:46:59.700
<v Reuven Lerner>they said, actually, we're not going to be able to fund anything for about a year now.

00:47:00.000 --> 00:47:17.200
<v Reuven Lerner>And then there was the government grant, I think from the NSF that they turned down. And I'm not disputing the reasons for that at all. It basically, it said, well, we'll give you the money if you don't worry about diversity and inclusion. And given that that's like a core part of what the PSF is supposed to do, they could not do that without shutting the doors, which would be kind of counterproductive.

00:47:17.540 --> 00:47:26.480
<v Reuven Lerner>And so I feel like we're not yet there, but we're sort of approaching this, I'm going to term like a problem crisis in funding Python.

00:47:27.040 --> 00:47:32.020
<v Reuven Lerner>The needs of the community keep growing and growing, whether it's workshops, whether it's PyPI, whether it's conferences.

00:47:32.740 --> 00:47:34.640
<v Reuven Lerner>And companies are getting squeezed.

00:47:35.160 --> 00:47:41.760
<v Reuven Lerner>And the number of people, it always shocks me every time there are PSF elections, the incredibly small number of people who vote.

00:47:42.080 --> 00:47:45.680
<v Reuven Lerner>Which means that, let's assume half the people who are members, third of the people.

00:47:46.000 --> 00:47:50.580
<v Reuven Lerner>Like for the millions and millions of people who program Python out there, an infinitesimally

00:47:50.650 --> 00:47:53.240
<v Reuven Lerner>small proportion of them actually join and help to fund it.

00:47:53.430 --> 00:47:56.620
<v Reuven Lerner>So I'm not quite sure what to do with this other than express concern.

00:47:57.110 --> 00:48:01.760
<v Reuven Lerner>But I feel like we've got to figure out ways to fund Python and the PSF in new ways that

00:48:01.760 --> 00:48:04.440
<v Reuven Lerner>will allow it to grow and scale as needed.

00:48:04.620 --> 00:48:05.620
<v Thomas Wourters>I couldn't agree more.

00:48:06.220 --> 00:48:11.760
<v Thomas Wourters>Obviously, the PSF is close to my heart because I was on the board for, I think, a total of

00:48:11.920 --> 00:48:15.520
<v Thomas Wourters>six or nine years or something over, you know, the last 25.

00:48:15.640 --> 00:48:21.520
<v Thomas Wourters>I was also for six months, I was the interim general manager because Eva left and we hadn't

00:48:21.550 --> 00:48:23.480
<v Thomas Wourters>hired Deb yet while I was on the board.

00:48:23.670 --> 00:48:28.940
<v Thomas Wourters>I remember signing the sponsor contracts for the companies that came in wanting to sponsor

00:48:29.170 --> 00:48:29.320
<v Thomas Wourters>Python.

00:48:29.760 --> 00:48:35.260
<v Thomas Wourters>And it is like, it's ridiculous how, and I can say this working for a company that is

00:48:35.310 --> 00:48:38.360
<v Thomas Wourters>one of the biggest sponsors of the PSF and has done so for years.

00:48:38.920 --> 00:48:45.160
<v Thomas Wourters>It's ridiculous how small those sponsorships are and yet how grateful we were that they

00:48:45.080 --> 00:48:47.860
<v Thomas Wourters>came in because every single one has such a big impact.

00:48:48.060 --> 00:48:51.620
<v Thomas Wourters>You can do so much good with the money that comes in.

00:48:52.020 --> 00:48:55.140
<v Thomas Wourters>We need more corporate sponsorships more than we need.

00:48:55.300 --> 00:49:00.580
<v Thomas Wourters>Like, I mean, obviously a million people giving us a couple of bucks, giving the PSF, let's

00:49:00.580 --> 00:49:00.900
<v Thomas Wourters>be clear.

00:49:00.960 --> 00:49:01.780
<v Thomas Wourters>I'm not on the board anymore.

00:49:01.980 --> 00:49:05.160
<v Thomas Wourters>Giving the PSF a couple of bucks would be fantastic.

00:49:05.680 --> 00:49:11.880
<v Thomas Wourters>But I think the big players in the big corporate players where all the AI money is, for instance,

00:49:12.060 --> 00:49:17.380
<v Thomas Wourters>having done basically no sponsorship of the PSF is mind-boggling. It is a textbook

00:49:18.420 --> 00:49:25.220
<v Thomas Wourters>tragedy of the commons right there, right? They rely entirely on PyPI and PyPI is run entirely

00:49:25.220 --> 00:49:30.820
<v Thomas Wourters>with community resources, mostly because of very generous and consistent sponsorship,

00:49:31.180 --> 00:49:38.860
<v Thomas Wourters>basically by Fastly, but also the other sponsors of the PSF. And yet very large players use those

00:49:38.880 --> 00:49:45.640
<v Thomas Wourters>resources more than anyone else and don't actually contribute. Georgie Kerr, she wrote this fantastic

00:49:45.730 --> 00:49:52.000
<v Jodie Burchell>blog post saying pretty much this straight after Europython. So Europython this year was really big

00:49:52.260 --> 00:49:57.240
<v Jodie Burchell>actually. And she was wandering around looking at the sponsor booths and the usual players were there,

00:49:57.620 --> 00:50:03.980
<v Jodie Burchell>but none of these AI companies were there. And the relationship actually between AI, if you want to

00:50:03.800 --> 00:50:09.320
<v Jodie Burchell>call it that. Let's call it ML and neural networks. And like some of the really big companies and

00:50:09.610 --> 00:50:14.700
<v Jodie Burchell>Python actually is really complex. Obviously, a lot of these companies and some of us are here,

00:50:15.160 --> 00:50:20.920
<v Jodie Burchell>employ people to work on Python. Companies like Meta and Google have contributed massively to

00:50:21.140 --> 00:50:27.140
<v Jodie Burchell>frameworks like PyTorch, TensorFlow, Keras. So it's not as simple a picture as saying cough up money

00:50:27.570 --> 00:50:32.620
<v Jodie Burchell>all the time. Like there's a more complex picture here, but definitely there are some notable

00:50:32.900 --> 00:50:39.200
<v Jodie Burchell>absences. And we talked about the volume of money going through. I totally agree with the sentiment.

00:50:39.460 --> 00:50:45.720
<v Jodie Burchell>When the shortfall came and the grants program had to shut down, we were brainstorming at JetBrains,

00:50:45.820 --> 00:50:51.140
<v Jodie Burchell>like maybe we can do some sort of, I don't know, donate some more money and call other companies

00:50:51.260 --> 00:50:55.820
<v Jodie Burchell>to do it. Or we can call on people in the community. And I was like, I don't want to call

00:50:55.820 --> 00:50:59.760
<v Jodie Burchell>on people in the community to do it because they're probably the same people who are also

00:50:59.780 --> 00:51:05.620
<v Jodie Burchell>donating their time for Python. Like it's just squeezing people who give so much of themselves

00:51:05.880 --> 00:51:10.700
<v Jodie Burchell>to this community even more. And it's not sustainable. Like Reuben said, if we keep doing

00:51:10.980 --> 00:51:15.800
<v Jodie Burchell>this, the whole community is going to collapse. Like I'm sure we've all had our own forms of

00:51:16.030 --> 00:51:19.780
<v Brett Cannon>burnout from giving too much. I'm going to pat ourselves on the back here. Everyone on this

00:51:19.940 --> 00:51:25.440
<v Brett Cannon>call who works at a company are all sponsors of the PSF. Thank goodness. But there's obviously a

00:51:25.440 --> 00:51:29.100
<v Brett Cannon>lot of people not on this call who are not sponsors. And I know personally, I wished every

00:51:29.120 --> 00:51:35.220
<v Brett Cannon>company that generated revenue from python usage donated to the psf like and it doesn't see and i

00:51:35.300 --> 00:51:38.440
<v Brett Cannon>think part of the problem is some people think it has to be like a hundred thousand dollars it does

00:51:38.520 --> 00:51:43.380
<v Brett Cannon>not have to be a hundred thousand dollars now if you can afford that amount please do or more there

00:51:43.430 --> 00:51:48.140
<v Brett Cannon>are many ways to donate more than the maximum amount for getting on the website but it's one

00:51:48.140 --> 00:51:51.500
<v Brett Cannon>of these funny things where a lot of people just like oh it's not me right like even startups don't

00:51:51.780 --> 00:51:56.300
<v Brett Cannon>some do to give those ones credit but others don't because like oh we're we're burning through

00:51:56.320 --> 00:52:01.840
<v Brett Cannon>capital level i was like yeah but we're not we're asking for like less so you'd pay a dev right by

00:52:01.840 --> 00:52:07.280
<v Brett Cannon>a lot per year right like the amount we actually asked for to get to the highest tier is still less

00:52:07.340 --> 00:52:12.920
<v Brett Cannon>than a common developer in silicon valley if we're gonna price point to a geograph geogra geographical

00:52:13.080 --> 00:52:18.520
<v Thomas Wourters>location we call kind of comprehend i'm gonna steal a net bachelor's observation here and yeah what

00:52:18.520 --> 00:52:25.740
<v Thomas Wourters>the psf would be happy with is less than a medium company spends on the tips of expensed meals every

00:52:25.760 --> 00:52:31.340
<v Brett Cannon>year. Yeah. Yeah. And it's a long running problem, right? Like, I mean, I've been on the PSF for a

00:52:31.370 --> 00:52:36.380
<v Brett Cannon>long time, too. I've not served as many years as Thomas on the board, but I was like executive

00:52:36.470 --> 00:52:40.780
<v Brett Cannon>vice president because we had to have someone with that title at some point. It's always been a

00:52:40.940 --> 00:52:45.520
<v Brett Cannon>struggle, right? Like I and I also want to be clear, I'm totally appreciative of where we have

00:52:45.630 --> 00:52:50.660
<v Brett Cannon>gotten to, right? Because for the longest time, I was just dying for paid staff on the core team.

00:52:50.830 --> 00:52:55.120
<v Brett Cannon>And now we have three developers as residents. Thank goodness. Still not enough to be clear.

00:52:55.320 --> 00:52:55.920
<v Brett Cannon>I want five.

00:52:56.300 --> 00:52:57.080
<v Brett Cannon>And I've always said that,

00:52:57.340 --> 00:52:58.320
<v Brett Cannon>but I'll happily take three.

00:52:58.740 --> 00:52:59.500
<v Brett Cannon>But it's one of these things

00:52:59.560 --> 00:53:00.480
<v Brett Cannon>where it's a constant struggle.

00:53:00.740 --> 00:53:02.360
<v Brett Cannon>And it got a little bit better

00:53:02.600 --> 00:53:03.240
<v Brett Cannon>before the pandemic

00:53:03.460 --> 00:53:04.480
<v Brett Cannon>just because everyone

00:53:04.520 --> 00:53:05.480
<v Brett Cannon>was spending on conferences

00:53:05.840 --> 00:53:07.240
<v Brett Cannon>and PyCon US is a big driver

00:53:07.320 --> 00:53:08.420
<v Brett Cannon>for the Python Software Foundation.

00:53:08.860 --> 00:53:10.300
<v Brett Cannon>And I know your Python's a driver

00:53:10.340 --> 00:53:11.560
<v Brett Cannon>for the European Society.

00:53:12.140 --> 00:53:12.880
<v Brett Cannon>But then COVID hit

00:53:13.340 --> 00:53:14.980
<v Brett Cannon>and conferences haven't picked back up.

00:53:15.180 --> 00:53:16.480
<v Brett Cannon>And then there's a whole new cohort

00:53:16.880 --> 00:53:19.400
<v Brett Cannon>of companies that have come in post-pandemic

00:53:19.740 --> 00:53:20.720
<v Brett Cannon>that have never had that experience

00:53:21.020 --> 00:53:22.340
<v Brett Cannon>of going to PyCon and sponsoring PyCon.

00:53:22.440 --> 00:53:23.220
<v Brett Cannon>And so they don't think about,

00:53:23.360 --> 00:53:25.280
<v Brett Cannon>I think, sponsoring PyCon

00:53:25.300 --> 00:53:29.140
<v Brett Cannon>the PSF because that's also a big kind of in your face, you should help sponsor this.

00:53:29.570 --> 00:53:33.840
<v Brett Cannon>And I think it's led to this kind of lull where offered spending has gone down, new entrants

00:53:33.890 --> 00:53:37.480
<v Brett Cannon>into the community have not had that experience and thought about it. And it's led to this kind

00:53:37.480 --> 00:53:43.600
<v Brett Cannon>of dearth where, yeah, that PSF had to stop giving out grant money. And it sucks. And I would love

00:53:43.600 --> 00:53:47.600
<v Reuven Lerner>to see it not be that problem. I want to add one interesting data point that I discovered in

00:53:47.690 --> 00:53:53.800
<v Reuven Lerner>short. Keep it short. Yes. NumFocus has about twice the budget of the PSF. I was shocked to

00:53:53.820 --> 00:54:00.360
<v Reuven Lerner>discover this. So basically it is possible to get money from companies to sponsor development of

00:54:00.540 --> 00:54:05.480
<v Reuven Lerner>Python related projects. And I don't know what they're doing that we aren't. And I think it's

00:54:05.540 --> 00:54:10.960
<v Michael Kennedy>worth talking and figuring it out. We need a fundraiser and marketer in residence, maybe. Who

00:54:10.960 --> 00:54:17.920
<v Thomas Wourters>knows? Lauren does a great job, to be clear. The PSF has Lauren and Lauren is that. But it's still

00:54:18.040 --> 00:54:21.980
<v Brett Cannon>hard. We have someone doing it full time at the PSF and it's just hard to get companies to give

00:54:22.020 --> 00:54:22.660
<v Brett Cannon>cash up cash.

00:54:23.500 --> 00:54:24.880
<v Michael Kennedy>Yeah, and what do we get in return?

00:54:25.280 --> 00:54:26.080
<v Michael Kennedy>Well, we already get that.

00:54:26.260 --> 00:54:27.380
<v Michael Kennedy>So, yeah, I know.

00:54:27.840 --> 00:54:28.580
<v Barry Warsaw>All right, Barry.

00:54:28.800 --> 00:54:30.220
<v Barry Warsaw>To just, you know, shift gears

00:54:30.600 --> 00:54:31.620
<v Barry Warsaw>into a different area,

00:54:32.020 --> 00:54:34.560
<v Barry Warsaw>something that I've been thinking a lot

00:54:34.720 --> 00:54:36.580
<v Barry Warsaw>over this past year on the steering council.

00:54:36.860 --> 00:54:38.000
<v Barry Warsaw>Thomas, I'm sure, is going to be,

00:54:38.160 --> 00:54:39.200
<v Barry Warsaw>you know, very well aware,

00:54:39.680 --> 00:54:41.620
<v Barry Warsaw>having been instrumental

00:54:42.040 --> 00:54:45.180
<v Barry Warsaw>in the lazy imports PEP A10.

00:54:45.620 --> 00:54:47.540
<v Barry Warsaw>We have to sort of rethink

00:54:48.260 --> 00:54:50.220
<v Barry Warsaw>how we evolve Python

00:54:50.900 --> 00:54:53.420
<v Barry Warsaw>and how we pose changes to Python

00:54:53.960 --> 00:54:56.440
<v Barry Warsaw>and how we discuss those changes in the community.

00:54:56.590 --> 00:54:59.940
<v Barry Warsaw>Because I think one of the things that I have heard

00:55:00.230 --> 00:55:03.780
<v Barry Warsaw>over and over and over again is that authoring PEPs

00:55:04.260 --> 00:55:08.780
<v Barry Warsaw>is incredibly difficult and emotionally draining

00:55:09.500 --> 00:55:10.940
<v Barry Warsaw>and it's a time sink.

00:55:11.620 --> 00:55:15.860
<v Barry Warsaw>And leading those discussions on discuss.python.org,

00:55:15.990 --> 00:55:17.520
<v Barry Warsaw>which we typically call DPO,

00:55:18.420 --> 00:55:21.400
<v Barry Warsaw>can be toxic at times and very difficult.

00:55:21.800 --> 00:55:24.340
<v Barry Warsaw>So one of the things that I realized

00:55:24.650 --> 00:55:25.960
<v Barry Warsaw>as I was thinking about this

00:55:25.960 --> 00:55:28.760
<v Barry Warsaw>is that peps are 25 years old now, right?

00:55:29.240 --> 00:55:30.820
<v Barry Warsaw>So we've had this,

00:55:31.320 --> 00:55:32.980
<v Barry Warsaw>and not only just peps are old,

00:55:33.110 --> 00:55:35.700
<v Barry Warsaw>but like we've gone through at least two,

00:55:35.890 --> 00:55:38.520
<v Barry Warsaw>if not more sort of complete revolutions

00:55:38.590 --> 00:55:40.040
<v Barry Warsaw>in the way we discuss things.

00:55:40.170 --> 00:55:42.900
<v Barry Warsaw>You know, the community has grown incredibly.

00:55:43.290 --> 00:55:45.720
<v Barry Warsaw>The developer community is somewhat larger,

00:55:46.180 --> 00:55:47.660
<v Barry Warsaw>but just the number of people

00:55:47.680 --> 00:55:54.380
<v Barry Warsaw>who are using Python and who have an interest in it has grown exponentially. So it has become

00:55:54.900 --> 00:56:01.400
<v Barry Warsaw>really difficult to evolve the language in the standard library and the interpreter. And we need

00:56:01.400 --> 00:56:08.760
<v Barry Warsaw>to sort of think about how we can make this easier for people and not lose the voice of the user.

00:56:09.160 --> 00:56:14.500
<v Barry Warsaw>And the number of people who actually engage in topics on DPO is the tip of the iceberg. You know,

00:56:14.600 --> 00:56:24.740
<v Barry Warsaw>We've got millions and millions of users out there in the world who, for example, lazy imports will affect, free threading will affect and don't even know that they have a voice.

00:56:24.890 --> 00:56:31.200
<v Barry Warsaw>And maybe we have to basically represent that, but we have to do it in a much more collaborative and positive way.

00:56:31.740 --> 00:56:33.400
<v Barry Warsaw>That's something that I've been thinking about a lot.

00:56:33.500 --> 00:56:43.580
<v Barry Warsaw>And whether or not I'm on the steering council next year, I think this is something that I'm going to spend some time on trying to think about, you know, talk to people about ways we can make this easier for everyone.

00:56:43.820 --> 00:56:47.340
<v Michael Kennedy>The diversity of use cases for Python in the last couple of years.

00:56:47.390 --> 00:56:48.000
<v Michael Kennedy>So complex.

00:56:48.420 --> 00:56:48.980
<v Michael Kennedy>Yes, exactly.

00:56:49.210 --> 00:56:53.060
<v Brett Cannon>It should also be preface that Barry created the  PEP process. He should have started that one.

00:56:55.780 --> 00:56:57.280
<v Barry Warsaw>It is that old.

00:56:57.610 --> 00:56:57.720
<v Barry Warsaw>Yeah.

00:56:58.540 --> 00:57:02.120
<v Brett Cannon>By the way, just so everyone knows, these are not ages jokes to be mean to Barry.

00:57:02.340 --> 00:57:07.080
<v Brett Cannon>We've always known Barry long enough that we know Barry's okay with us making these jokes.

00:57:07.110 --> 00:57:07.900
<v Brett Cannon>To be very, very clear.

00:57:07.900 --> 00:57:11.920
<v Thomas Wourters>Also, I am almost as old as Barry, although I don't look as old as Barry.

00:57:12.780 --> 00:57:14.300
<v Brett Cannon>Yeah, we're all over from the same age anyways.

00:57:15.300 --> 00:57:18.600
<v Thomas Wourters>Yeah, Barry and I have known each other for 25 years,

00:57:18.960 --> 00:57:21.760
<v Thomas Wourters>and I've always made these jokes of him.

00:57:21.940 --> 00:57:26.220
<v Thomas Wourters>So it is different when you know each other in person.

00:57:26.420 --> 00:57:27.000
<v Thomas Wourters>Let's put it that way.

00:57:28.840 --> 00:57:30.900
<v Thomas Wourters>For the  PEP process, I think for a lot of people,

00:57:31.160 --> 00:57:35.080
<v Thomas Wourters>it's not obvious how difficult the process is.

00:57:35.260 --> 00:57:36.760
<v Thomas Wourters>I mean, it wasn't even obvious to me.

00:57:37.260 --> 00:57:40.720
<v Thomas Wourters>I saw people avoiding writing peps multiple times,

00:57:40.820 --> 00:57:42.940
<v Thomas Wourters>and I was upset, like on the steering council, right?

00:57:43.380 --> 00:57:45.280
<v Thomas Wourters>I saw people making changes where I thought,

00:57:45.440 --> 00:57:46.820
<v Thomas Wourters>this is definitely something

00:57:47.020 --> 00:57:48.420
<v Thomas Wourters>that should have been discussed in a PEP

00:57:48.700 --> 00:57:51.220
<v Thomas Wourters>and the discussion should be recorded in a PEP and all that.

00:57:51.540 --> 00:57:54.600
<v Thomas Wourters>And I didn't understand why they didn't until,

00:57:55.260 --> 00:57:56.800
<v Thomas Wourters>basically until PEP 8.10.

00:57:56.980 --> 00:57:58.920
<v Thomas Wourters>So I did PEP 779,

00:57:58.990 --> 00:58:02.400
<v Thomas Wourters>which was the giving free threading supported status

00:58:02.820 --> 00:58:03.660
<v Thomas Wourters>at the start of the year.

00:58:03.980 --> 00:58:06.200
<v Thomas Wourters>And the discussion there was, you know,

00:58:06.560 --> 00:58:08.540
<v Thomas Wourters>sort of as expected and it's already,

00:58:08.760 --> 00:58:10.280
<v Thomas Wourters>was already an accepted PEP.

00:58:10.600 --> 00:58:12.560
<v Thomas Wourters>It was just the question of how does it become supported?

00:58:12.990 --> 00:58:14.240
<v Thomas Wourters>That one wasn't too exhausting.

00:58:14.770 --> 00:58:20.040
<v Thomas Wourters>And then we got to Lazy Imports, which was Pablo, who is another steering council member,

00:58:20.460 --> 00:58:24.720
<v Thomas Wourters>as well as a bunch of other contributors, including me and two of my co-workers and

00:58:24.820 --> 00:58:28.900
<v Thomas Wourters>one of my former co-workers, who had all had a lot of experience with Lazy Imports, but

00:58:29.040 --> 00:58:31.540
<v Thomas Wourters>not necessarily as much experience with the PEP process.

00:58:32.140 --> 00:58:37.680
<v Thomas Wourters>And Pablo took the front seat because he knew the PEP process and he's done like five PEPs

00:58:37.680 --> 00:58:40.000
<v Thomas Wourters>in the last year or something, some ridiculous number.

00:58:40.360 --> 00:58:48.880
<v Thomas Wourters>And he shared with us the vitriol he got for like offline for the, just the audacity of proposing

00:58:49.120 --> 00:58:54.240
<v Thomas Wourters>something that people disagreed with or something. And that was like, this is a technical suggestion.

00:58:54.300 --> 00:58:59.740
<v Thomas Wourters>This is not a code of conduct issue where I have received my fair share of vitriol around.

00:59:00.160 --> 00:59:06.200
<v Thomas Wourters>This is a technical discussion. And yet he gets this, these ridiculous accusations in his mailbox.

00:59:06.740 --> 00:59:11.980
<v Thomas Wourters>And for some reason, only the primary author gets it as well, which is just weird to me.

00:59:12.140 --> 00:59:13.360
<v Brett Cannon>But people are lazy.

00:59:13.780 --> 00:59:15.420
<v Brett Cannon>Thomas is what I think you just said.

00:59:15.640 --> 00:59:24.500
<v Barry Warsaw>Remember, the steering council exists because Guido was the got the brunt of this for Pet 572, which was the walrus operator.

00:59:24.680 --> 00:59:30.660
<v Barry Warsaw>Right. Which is just like this minor little syntactic thing that is kind of cool when you need it.

00:59:31.020 --> 00:59:42.340
<v Barry Warsaw>But like just the amount of anger and negative energy and vitriol that he got over that was enough to for him to just say, I'm out, you know, and you guys figure it out.

00:59:42.400 --> 00:59:48.280
<v Barry Warsaw>And that cannot be an acceptable way to discuss the evolution of the language.

00:59:48.420 --> 00:59:55.100
<v Thomas Wourters>Especially since apparently now every single  PEP author of any contentious or semi contentious pep.

00:59:55.420 --> 00:59:58.820
<v Thomas Wourters>Although I have to say, Pep 810 had such broad support.

00:59:59.030 --> 01:00:00.940
<v Thomas Wourters>It was hard to call it contentious.

01:00:01.060 --> 01:00:04.240
<v Thomas Wourters>It's just there's a couple of very loud opinions, I guess.

01:00:04.600 --> 01:00:06.720
<v Thomas Wourters>And I'm not saying we shouldn't listen to people.

01:00:06.770 --> 01:00:10.980
<v Thomas Wourters>We should definitely listen to especially contrary opinions.

01:00:11.130 --> 01:00:12.460
<v Thomas Wourters>But there has to be a limit.

01:00:12.750 --> 01:00:15.880
<v Thomas Wourters>There has to be an acceptable way of bringing things up.

01:00:15.890 --> 01:00:20.760
<v Thomas Wourters>There has to be an acceptable way of saying, hey, you didn't actually read the Pep.

01:00:21.120 --> 01:00:26.720
<v Thomas Wourters>please go back and reconsider everything you said after you fully digested the things,

01:00:27.180 --> 01:00:29.020
<v Thomas Wourters>because everything's already been addressed in the pep.

01:00:29.400 --> 01:00:37.480
<v Thomas Wourters>It's just really hard to do this in a way that doesn't destroy the relationship with the person you're telling this, right?

01:00:37.980 --> 01:00:44.020
<v Thomas Wourters>It's hard to tell people, hey, I'm not going to listen to you because you haven't, you know, you've done a bad job.

01:00:44.520 --> 01:00:45.860
<v Brett Cannon>You've chosen not to inform yourself.

01:00:46.220 --> 01:00:54.860
<v Barry Warsaw>I think you make another really strong point, Thomas, which is that there have been changes that have been made to Python that really should have been a pep.

01:00:55.220 --> 01:01:01.480
<v Barry Warsaw>And they aren't because people don't want to go through core developers, don't want to go through this gauntlet.

01:01:01.570 --> 01:01:03.700
<v Barry Warsaw>And so they'll create a PR and then that.

01:01:03.700 --> 01:01:06.880
<v Barry Warsaw>But that's also not good because then, you know, we don't have that.

01:01:06.970 --> 01:01:10.520
<v Barry Warsaw>We don't have the right level of consideration.

01:01:11.160 --> 01:01:19.880
<v Barry Warsaw>And you think about the way that, you know, if you're in your job and you're making a change to something in your job, you have a very close relationship to your teammates.

01:01:20.220 --> 01:01:26.000
<v Barry Warsaw>And so you have that kind of respect and hopefully, right, like compassion and consideration.

01:01:26.720 --> 01:01:35.600
<v Barry Warsaw>And you can have a very productive discussion about a thing and you may win some arguments and you may lose some arguments, but the team moves forward as one.

01:01:35.840 --> 01:01:38.500
<v Barry Warsaw>And I think we've lost a bit of that in Python.

01:01:38.920 --> 01:01:39.940
<v Michael Kennedy>So that's not great.

01:01:40.000 --> 01:01:50.220
<v Michael Kennedy>I think society in general could use a little more civility and kindness, especially to strangers that they haven't met in forums, social media, driving, you name it.

01:01:50.760 --> 01:01:54.160
<v Michael Kennedy>Okay, but we're not going to solve that here, I'm sure.

01:01:54.420 --> 01:01:56.920
<v Michael Kennedy>So instead, let's do Gregory's topic.

01:01:57.260 --> 01:02:04.160
<v Gregory Kapfhammer>Hey, I'm going to change topics quite a bit, but I wanted to call 2025 the year of type checking and language server protocols.

01:02:04.800 --> 01:02:13.780
<v Gregory Kapfhammer>So many of us probably have used tools like mypy to check to see if the types line up in our code or whether or not we happen to be overriding functions correctly.

01:02:14.170 --> 01:02:19.980
<v Gregory Kapfhammer>And so I've used mypy for many years and loved the tool and had a great opportunity to chat with the creator of it.

01:02:20.260 --> 01:02:23.800
<v Gregory Kapfhammer>And I integrate that into my CI and it's really been wonderful.

01:02:24.180 --> 01:02:28.600
<v Gregory Kapfhammer>And I've also been using a lot of LSPs, like, for example, PyRite or PyLands.

01:02:28.900 --> 01:02:33.860
<v Gregory Kapfhammer>But in this year, one of the things that we've seen is, number one, Pyrefly from the team at Meta.

01:02:34.160 --> 01:02:36.600
<v Gregory Kapfhammer>We've also seen ty from the team at Astral.

01:02:36.930 --> 01:02:38.600
<v Gregory Kapfhammer>And there's another one called Zubon.

01:02:38.910 --> 01:02:40.760
<v Gregory Kapfhammer>And Zubon is from David Halter.

01:02:41.120 --> 01:02:43.480
<v Gregory Kapfhammer>David was also the person who created JEDI,

01:02:43.770 --> 01:02:47.620
<v Gregory Kapfhammer>which is another system in Python that helped with a lot of LSP tasks.

01:02:48.040 --> 01:02:51.440
<v Gregory Kapfhammer>What's interesting about all three of the tools that I just mentioned

01:02:51.800 --> 01:02:53.320
<v Gregory Kapfhammer>is that they're implemented in Rust,

01:02:53.800 --> 01:02:58.080
<v Gregory Kapfhammer>and they have taken a lot of the opportunity to make the type checker

01:02:58.260 --> 01:03:01.040
<v Gregory Kapfhammer>and or the LSP significantly faster.

01:03:01.480 --> 01:03:07.640
<v Gregory Kapfhammer>So for me, this has changed how I use the LSP or the type checker and how frequently I use it.

01:03:07.880 --> 01:03:16.580
<v Gregory Kapfhammer>And in my experience, it has helped me to take things that might take tens of seconds or hundreds of seconds and cut them down often to less than a second.

01:03:17.080 --> 01:03:23.860
<v Gregory Kapfhammer>And it's really changed the way in which I'm using a lot of the tools like ty or Pyrefly or Zubon.

01:03:24.180 --> 01:03:31.800
<v Gregory Kapfhammer>So I can have some more details if I'm allowed to share, Michael, but I would say 2025 is the year of type checkers and LSPs.

01:03:31.980 --> 01:03:34.320
<v Michael Kennedy>I think given the timing, let's have people give some feedback.

01:03:34.540 --> 01:03:38.680
<v Michael Kennedy>I personally have been using Pyrefly a ton and am a big fan of it.

01:03:38.740 --> 01:03:42.600
<v Thomas Wourters>I don't know if I'm allowed to have an opinion that isn't Pyrefly is awesome.

01:03:43.380 --> 01:03:48.500
<v Thomas Wourters>I mean, I'm not on the Pyrefly team, but I do regularly chat with people from the Pyrefly team.

01:03:49.040 --> 01:03:50.840
<v Michael Kennedy>Tell people real quick what it is, Thomas.

01:03:51.180 --> 01:03:55.740
<v Thomas Wourters>So Pyrefly is Meta's attempt at a Rust-based type checker.

01:03:56.140 --> 01:03:57.920
<v Thomas Wourters>And so it's very similar to ty.

01:03:58.360 --> 01:04:01.240
<v Thomas Wourters>Started basically at the same time, a little later.

01:04:01.920 --> 01:04:06.100
<v Thomas Wourters>Meta originally had a type checker called Pyre, which was written in OCaml.

01:04:06.480 --> 01:04:09.020
<v Thomas Wourters>They basically decided to start a rewrite in Rust.

01:04:09.300 --> 01:04:11.220
<v Thomas Wourters>And then that really took off.

01:04:11.380 --> 01:04:13.660
<v Thomas Wourters>And that's where we're going now.

01:04:13.900 --> 01:04:14.000
<v Brett Cannon>Yeah.

01:04:14.140 --> 01:04:14.220
<v Brett Cannon>Yeah.

01:04:14.230 --> 01:04:17.960
<v Brett Cannon>I don't know what I can say because I'm actually on the same team as the Pylands team.

01:04:18.460 --> 01:04:20.780
<v Brett Cannon>So, but no, I mean, I think it's good.

01:04:21.060 --> 01:04:22.920
<v Brett Cannon>I think this is one of those interesting scenarios

01:04:23.660 --> 01:04:25.180
<v Brett Cannon>where some people realize like,

01:04:25.340 --> 01:04:27.260
<v Brett Cannon>you know what, we're going to pay the penalty

01:04:28.059 --> 01:04:30.580
<v Brett Cannon>of writing a tool in a way that's faster,

01:04:30.740 --> 01:04:31.640
<v Brett Cannon>but makes us go slower

01:04:31.880 --> 01:04:33.220
<v Brett Cannon>because the overall win for the community

01:04:33.420 --> 01:04:34.840
<v Brett Cannon>is going to be a good win.

01:04:34.900 --> 01:04:36.460
<v Brett Cannon>So it's worth that headache, right?

01:04:36.780 --> 01:04:38.240
<v Brett Cannon>Not to say I don't want to scare people off

01:04:38.360 --> 01:04:39.640
<v Brett Cannon>from writing Rust, but let's be honest,

01:04:39.700 --> 01:04:41.040
<v Brett Cannon>it takes more work to write Rust code

01:04:41.140 --> 01:04:42.360
<v Brett Cannon>than it does take to write Python code.

01:04:42.940 --> 01:04:44.700
<v Brett Cannon>But some people chose to make that trade off

01:04:44.740 --> 01:04:45.960
<v Brett Cannon>and we're all benefiting from it.

01:04:46.260 --> 01:04:47.180
<v Brett Cannon>The one thing I will say

01:04:47.280 --> 01:04:48.280
<v Brett Cannon>that's kind of interesting from this

01:04:48.620 --> 01:04:50.060
<v Brett Cannon>that hasn't gotten a lot of play yet

01:04:50.120 --> 01:04:50.940
<v Brett Cannon>because it's still being developed,

01:04:51.060 --> 01:05:05.580
<v Brett Cannon>But PyLens is actually working with the Pyrefly team to define a type server protocol, TSP, so that a lot of these type servers can just kind of feed the type information to a higher level LSP and let that LSP handle the stuff like symbol renaming and all that stuff.

01:05:05.620 --> 01:05:12.300
<v Brett Cannon>Right. Because the key thing here and the reason there's so many different type checkers is there are there is a spec.

01:05:12.460 --> 01:05:16.500
<v Brett Cannon>Right. And everyone's trying to implement it. But there's differences like in type in terms of type inferencing.

01:05:16.800 --> 01:05:19.100
<v Brett Cannon>And if I actually go listen to Michael's interview,

01:05:19.780 --> 01:05:21.460
<v Brett Cannon>talk Python to me with the Pyrefly team,

01:05:21.560 --> 01:05:23.080
<v Brett Cannon>they actually did a nice little explanation

01:05:23.140 --> 01:05:24.760
<v Brett Cannon>of the difference between Pyrites approach

01:05:25.600 --> 01:05:26.860
<v Brett Cannon>and Pyrefly's approach.

01:05:27.420 --> 01:05:28.360
<v Brett Cannon>And so there's a bit of variance.

01:05:28.640 --> 01:05:31.140
<v Brett Cannon>But for instance, I think there's some talk now

01:05:31.360 --> 01:05:32.440
<v Brett Cannon>of trying to like, how do we make it

01:05:32.440 --> 01:05:33.520
<v Brett Cannon>so everyone doesn't have to reimplement

01:05:33.640 --> 01:05:34.980
<v Brett Cannon>how to rename a symbol, right?

01:05:35.100 --> 01:05:35.680
<v Brett Cannon>That's kind of boring.

01:05:35.840 --> 01:05:37.300
<v Brett Cannon>That's not where the interesting work is.

01:05:37.640 --> 01:05:39.940
<v Brett Cannon>And that's not performant from perspective of

01:05:40.180 --> 01:05:42.920
<v Brett Cannon>you want instantaneously to get that squiggly red line

01:05:43.500 --> 01:05:45.039
<v Brett Cannon>in whether it's VS Code

01:05:45.040 --> 01:05:48.220
<v Brett Cannon>or it's in PyCharm or whatever your editor is, right?

01:05:48.380 --> 01:05:50.340
<v Brett Cannon>You want to get it as fast as possible,

01:05:50.500 --> 01:05:51.340
<v Thomas Wourters>but the rename-

01:05:51.660 --> 01:05:51.860
<v Brett Cannon>Jupyter.

01:05:52.160 --> 01:05:52.280
<v Thomas Wourters>Jupyter.

01:05:52.400 --> 01:05:53.520
<v Thomas Wourters>No, not Emacs.

01:05:53.520 --> 01:05:53.860
<v Thomas Wourters>Everything but Emacs.

01:05:53.900 --> 01:05:56.020
<v Brett Cannon>No, not Emacs.

01:05:56.020 --> 01:05:57.640
<v Barry Warsaw>Just to bring things full circle,

01:05:57.640 --> 01:06:00.500
<v Barry Warsaw>it's that focus on user experience, right?

01:06:00.680 --> 01:06:03.020
<v Barry Warsaw>Which is, yes, you want that squiggly line,

01:06:03.020 --> 01:06:04.740
<v Barry Warsaw>but when things go wrong,

01:06:04.740 --> 01:06:05.640
<v Barry Warsaw>when your type checker says,

01:06:05.640 --> 01:06:07.780
<v Barry Warsaw>oh, you've got a problem,

01:06:07.780 --> 01:06:11.820
<v Barry Warsaw>you know, like I think about as an analogy,

01:06:11.820 --> 01:06:14.600
<v Barry Warsaw>how Pablo has done an amazing amount of work

01:06:14.860 --> 01:06:14.920
<v Barry Warsaw>on the error reporting, right?

01:06:15.020 --> 01:06:26.460
<v Barry Warsaw>When you get an exception and, you know, now you have a lot more clues about what is it that I actually have to change to make the tool, you know, to fix the problem, right?

01:06:26.780 --> 01:06:39.740
<v Barry Warsaw>Like so many times years ago, you know, when people were using mypy, for example, and they'd have some complex failure of their type annotations and have absolutely no idea what to do about it.

01:06:40.140 --> 01:06:44.480
<v Barry Warsaw>And so getting to a place where now we're not just telling people you've done it wrong,

01:06:44.960 --> 01:06:48.560
<v Barry Warsaw>but also here's some ideas about how to fix it.

01:06:49.540 --> 01:06:54.340
<v Michael Kennedy>I think this is a full circle here because honestly, using typing in your Python code

01:06:54.600 --> 01:06:57.020
<v Michael Kennedy>gives a lot of context to the AI when you ask for help.

01:06:57.200 --> 01:06:59.320
<v Michael Kennedy>If you just give it a fragment and it can't work with it.

01:06:59.480 --> 01:07:00.080
<v Gregory Kapfhammer>That's true.

01:07:00.360 --> 01:07:06.320
<v Gregory Kapfhammer>And also, if you can teach your AI agent to use the type checkers and use the LSPs,

01:07:06.640 --> 01:07:08.660
<v Gregory Kapfhammer>it will also generate better code for you.

01:07:09.000 --> 01:07:24.320
<v Gregory Kapfhammer>I think the one challenge I would add to what Barry said a moment ago is that if you're a developer and you're using, say, three or four type checkers at the same time, you also have to be careful about the fact that some of them won't flag an error that the other one will flag.

01:07:24.680 --> 01:07:36.300
<v Gregory Kapfhammer>So I've recently written Python programs and even built a tool with one of my students named Benedek that will automatically generate Python programs that will cause type checkers to disagree with each other.

01:07:39.320 --> 01:07:44.580
<v Gregory Kapfhammer>I will flag it as an error, but none of the other tools will flag it as an error.

01:07:45.020 --> 01:07:50.020
<v Gregory Kapfhammer>And there are also cases where the new tools will all agree with each other, but disagree with mypy.

01:07:50.360 --> 01:07:53.100
<v Gregory Kapfhammer>So there is a type checker conformance test suite.

01:07:53.280 --> 01:07:57.280
<v Gregory Kapfhammer>But I think as developers, even though it might be the year of LSP and type checker,

01:07:57.300 --> 01:08:02.980
<v Gregory Kapfhammer>we also have to be aware of the fact that these tools are maturing and there's still disagreement among them.

01:08:03.400 --> 01:08:07.700
<v Gregory Kapfhammer>and also just different philosophies when it comes to how to type check and how to infer.

01:08:08.240 --> 01:08:12.320
<v Gregory Kapfhammer>And so we have to think about all of those things as these tools mature and become part of our ecosystem.

01:08:12.480 --> 01:08:14.040
<v Michael Kennedy>Yeah, Greg, that last point is important.

01:08:14.240 --> 01:08:17.940
<v Thomas Wourters>Out of curiosity, how did the things where the type checkers disagree

01:08:18.560 --> 01:08:21.380
<v Thomas Wourters>match up with the actual runtime behavior of Python?

01:08:21.980 --> 01:08:24.480
<v Thomas Wourters>Was it like false positives or false negatives?

01:08:24.880 --> 01:08:25.759
<v Gregory Kapfhammer>That's a really good question.

01:08:26.000 --> 01:08:29.900
<v Gregory Kapfhammer>I'll give you more details in the show notes because we actually have it in a GitHub repository

01:08:30.220 --> 01:08:31.339
<v Gregory Kapfhammer>and I can share it with people.

01:08:31.740 --> 01:08:43.200
<v Gregory Kapfhammer>But I think some of it might simply be related to cases where mypy is more conformant to the spec, but the other new tools are not as conformant.

01:08:43.370 --> 01:08:48.180
<v Gregory Kapfhammer>So you can import overload from typing and then have a very overloaded function.

01:08:48.720 --> 01:08:59.960
<v Gregory Kapfhammer>And mypy will actually flag the fact that it's an overloaded function with multiple signatures, whereas PyRite and Pyrefly and Zubon will not actually flag that, even though they should.

01:09:00.160 --> 01:09:02.819
<v Michael Kennedy>Another big area is optional versus not optional.

01:09:03.380 --> 01:09:03.480
<v Michael Kennedy>Yes.

01:09:03.700 --> 01:09:08.960
<v Michael Kennedy>Like, are you allowed to pass a thing that is an optional string when the thing accepts a string?

01:09:09.180 --> 01:09:10.380
<v Michael Kennedy>Some stuff's like, yeah, it's probably fine.

01:09:10.420 --> 01:09:11.359
<v Michael Kennedy>Others are like, no, no, no.

01:09:11.400 --> 01:09:13.540
<v Michael Kennedy>This is an error that you have to do a check.

01:09:13.720 --> 01:09:23.259
<v Michael Kennedy>And if you want to switch type checkers, you might end up with a thousand warnings that you didn't previously had because of an intentional difference of opinion on how strict to be, I think.

01:09:23.400 --> 01:09:23.560
<v Gregory Kapfhammer>Yeah.

01:09:23.680 --> 01:09:29.220
<v Gregory Kapfhammer>So you have to think about false positives and false negatives when you're willing to break the build because of a type error.

01:09:29.299 --> 01:09:31.720
<v Gregory Kapfhammer>All of those things are things you have to factor in.

01:09:31.990 --> 01:09:37.040
<v Gregory Kapfhammer>But to go quickly to this connection to AI, I know it's only recently, but the Pyrefly

01:09:37.130 --> 01:09:41.859
<v Gregory Kapfhammer>team actually announced that they're making Pyrefly work directly with Pydantic AI.

01:09:42.400 --> 01:09:46.640
<v Gregory Kapfhammer>So there's going to be an interoperability between those tools so that when you're building

01:09:46.710 --> 01:09:52.160
<v Gregory Kapfhammer>an AI agent using Pydantic AI, you can also then have better guarantees when you're using

01:09:52.339 --> 01:09:53.580
<v Gregory Kapfhammer>Pyrefly as your type checker.

01:09:53.680 --> 01:09:57.659
<v Jodie Burchell>It makes total sense, though, because then the reasoning LLM that's at the core of the

01:09:57.560 --> 01:10:04.220
<v Jodie Burchell>agent can actually have that information before it tries to execute the code and you don't get in that

01:10:04.220 --> 01:10:09.840
<v Jodie Burchell>loop that they often get in. You can correct it before it runs. Yeah, really good point. I want to

01:10:09.840 --> 01:10:14.660
<v Reuven Lerner>just sort of express my appreciation to all the people working on this typing stuff. As someone

01:10:14.820 --> 01:10:27.520
<v Reuven Lerner>who's come from many, many years in dynamic languages, I was always like, oh, typing. Those

01:10:27.540 --> 01:10:32.740
<v Reuven Lerner>E, I love seeing how easy it is for people to ease into it when they're in Python.

01:10:32.980 --> 01:10:33.900
<v Reuven Lerner>It's not all or nothing.

01:10:34.460 --> 01:10:36.660
<v Reuven Lerner>C, I love the huge number of tools.

01:10:36.760 --> 01:10:39.160
<v Reuven Lerner>The competition in this space is really exciting.

01:10:39.640 --> 01:10:40.620
<v Reuven Lerner>And D, guess what?

01:10:40.840 --> 01:10:41.960
<v Reuven Lerner>It really, really does help.

01:10:42.240 --> 01:10:46.760
<v Reuven Lerner>And I'll even add an E, which is my students who come from Java, C++, C#, and so forth

01:10:47.140 --> 01:10:47.920
<v Reuven Lerner>feel relief.

01:10:48.400 --> 01:10:53.080
<v Reuven Lerner>They find that without type checking, it's like doing a trapeze act without a safety

01:10:53.220 --> 01:10:53.400
<v Reuven Lerner>net.

01:10:53.760 --> 01:10:57.160
<v Reuven Lerner>And so they're very happy to have that typing in there,

01:10:57.380 --> 01:10:57.880
<v Reuven Lerner>typings in there.

01:10:58.200 --> 01:10:59.240
<v Reuven Lerner>So kudos to everyone.

01:10:59.480 --> 01:11:00.620
<v Michael Kennedy>All right, folks, we are out of time.

01:11:00.940 --> 01:11:03.040
<v Michael Kennedy>This could literally go for hours longer.

01:11:04.640 --> 01:11:05.300
<v Michael Kennedy>It was a big year.

01:11:05.760 --> 01:11:06.720
<v Michael Kennedy>It was a big year,

01:11:06.860 --> 01:11:09.940
<v Michael Kennedy>but I think we need to just have a final word.

01:11:10.800 --> 01:11:12.380
<v Michael Kennedy>I'll start and we'll just go around.

01:11:12.720 --> 01:11:14.200
<v Michael Kennedy>So my final thought here is,

01:11:14.660 --> 01:11:16.700
<v Michael Kennedy>we've talked about some things that are negatives

01:11:17.060 --> 01:11:19.100
<v Michael Kennedy>or sort of downers or whatever here and there,

01:11:19.640 --> 01:11:22.860
<v Michael Kennedy>but I still think it's an incredibly exciting time

01:11:22.880 --> 01:11:26.080
<v Michael Kennedy>To be a developer, data scientist, there's so much opportunity out there.

01:11:26.600 --> 01:11:29.480
<v Michael Kennedy>There's so many things to learn and take advantage of and stay on top of.

01:11:29.640 --> 01:11:30.280
<v Michael Kennedy>And amazing.

01:11:30.600 --> 01:11:32.860
<v Michael Kennedy>Every day is slightly more amazing than the previous day.

01:11:33.040 --> 01:11:33.860
<v Michael Kennedy>So I love it.

01:11:34.080 --> 01:11:34.900
<v Michael Kennedy>Gregory, let's go to you next.

01:11:35.000 --> 01:11:35.580
<v Michael Kennedy>Let's go around the circle.

01:11:35.780 --> 01:11:39.400
<v Gregory Kapfhammer>Yeah, I wanted to give a shout out to all of the local Python conferences.

01:11:40.200 --> 01:11:43.660
<v Gregory Kapfhammer>I actually, on a regular basis, have attended the PyOhio conference.

01:11:44.280 --> 01:11:45.320
<v Gregory Kapfhammer>And it is incredible.

01:11:45.620 --> 01:11:48.460
<v Gregory Kapfhammer>The organizers do an absolutely amazing job.

01:11:49.000 --> 01:11:54.120
<v Gregory Kapfhammer>And they have it hosted on a campus, oftentimes at Ohio State or Cleveland State University.

01:11:54.820 --> 01:12:00.740
<v Gregory Kapfhammer>And incredibly, PyOhio is a free conference that anyone can attend with no registration fee.

01:12:01.050 --> 01:12:06.180
<v Gregory Kapfhammer>So Michael, on a comment that I think is really positive, wow, I'm so excited about the regional

01:12:06.430 --> 01:12:08.340
<v Gregory Kapfhammer>Python conferences that I've been able to attend.

01:12:08.500 --> 01:12:08.660
<v Gregory Kapfhammer>Thomas.

01:12:09.020 --> 01:12:10.640
<v Thomas Wourters>Wow, I didn't expect this.

01:12:10.840 --> 01:12:16.520
<v Thomas Wourters>So I think I want to give a shout out to new people joining the community and also joining

01:12:16.540 --> 01:12:22.060
<v Thomas Wourters>just core developer team as triagers or it's just drive by commenters. I know we harped a little bit

01:12:22.160 --> 01:12:27.520
<v Thomas Wourters>about people, you know, giving strong opinions and discussions, but I always look to the far future

01:12:27.720 --> 01:12:33.300
<v Thomas Wourters>as well as the near future. And we always need new people. We need new ideas. We need new opinions. So

01:12:33.840 --> 01:12:38.960
<v Thomas Wourters>yeah, I'm, I'm excited that there's still people joining and signing up and even when it's

01:12:39.240 --> 01:12:44.140
<v Thomas Wourters>thankless work. So I guess I want to say thank you to people doing all the thankless work. Jodi.

01:12:44.380 --> 01:12:51.740
<v Jodie Burchell>Yeah, I want to say this is actually really only my third year or so really in the Python community.

01:12:52.000 --> 01:12:54.220
<v Jodie Burchell>So before that, I was just sort of on the fringes, right?

01:12:54.460 --> 01:12:58.020
<v Jodie Burchell>And after I started advocacy, I started going to the conferences and meeting people.

01:12:58.660 --> 01:13:04.680
<v Jodie Burchell>And I think I didn't kind of get how special the community was until I watched the Python documentary this year.

01:13:04.920 --> 01:13:11.840
<v Jodie Burchell>And I talked to Paul about this, Paul Everett afterwards, also made fun of him for his like early 2000s fashion.

01:13:11.940 --> 01:13:18.400
<v Jodie Burchell>but I think, yeah, like I'm a relative newcomer to this community and you've all made me feel so

01:13:18.600 --> 01:13:24.000
<v Jodie Burchell>welcome. And I guess I want to thank all the incumbents for everything you've done to make

01:13:24.120 --> 01:13:30.100
<v Jodie Burchell>this such a special tech community for minorities and everyone, newbies, you know, Python,

01:13:30.610 --> 01:13:32.860
<v Brett Cannon>Python is love. Oh, geez. How am I supposed to follow that?

01:13:37.230 --> 01:13:41.900
<v Brett Cannon>I think one of the interesting things that we're kind of looping on here is

01:13:41.920 --> 01:13:45.340
<v Brett Cannon>I think the language evolution has slowed down, but it's obviously not stopped, right?

01:13:45.520 --> 01:13:48.640
<v Brett Cannon>Like as Thomas pointed out, there's a lot more stuff happening behind the scenes.

01:13:49.580 --> 01:13:54.660
<v Brett Cannon>Lazy imports are coming, and that was a syntactic change, which apparently brings out the mean side of some people.

01:13:55.100 --> 01:13:57.900
<v Brett Cannon>And we've obviously got our challenges and stuff, but things are still going.

01:13:58.180 --> 01:13:59.380
<v Brett Cannon>We're still looking along.

01:13:59.490 --> 01:14:04.900
<v Brett Cannon>We're still trying to be an open, welcoming place for people like Jody and everyone else who's new coming on over

01:14:05.100 --> 01:14:11.080
<v Brett Cannon>and to continue to be a fun place for all of us slightly grain-beard people who have been here for a long time

01:14:11.100 --> 01:14:12.000
<v Brett Cannon>to make us want to stick around.

01:14:12.300 --> 01:14:15.140
<v Brett Cannon>I think it's just more of the same, honestly.

01:14:15.380 --> 01:14:17.820
<v Brett Cannon>It's all of us just continuing to do what we can

01:14:17.840 --> 01:14:20.320
<v Brett Cannon>to help out to keep this community being a great place.

01:14:20.520 --> 01:14:22.480
<v Brett Cannon>And it all just keeps going forward.

01:14:22.760 --> 01:14:23.860
<v Brett Cannon>And I'll just end with,

01:14:23.900 --> 01:14:25.920
<v Brett Cannon>if you work for a company that's not sponsored the PSF,

01:14:26.000 --> 01:14:26.540
<v Brett Cannon>please do so.

01:14:26.600 --> 01:14:30.680
<v Reuven Lerner>It's rare to have, I mean, a programming language

01:14:30.900 --> 01:14:31.840
<v Reuven Lerner>or any sort of tool

01:14:32.680 --> 01:14:36.040
<v Reuven Lerner>where it is both really, really beneficial to your career

01:14:36.640 --> 01:14:38.860
<v Reuven Lerner>and you get to hang out with really special,

01:14:39.320 --> 01:14:40.420
<v Reuven Lerner>nice, interesting people.

01:14:40.980 --> 01:14:44.680
<v Reuven Lerner>And it's easy to take all that for granted if you've been steeped in the community.

01:14:45.110 --> 01:14:48.520
<v Reuven Lerner>I went to a conference about six months ago, a non-Python conference.

01:14:49.180 --> 01:14:54.760
<v Reuven Lerner>And that was shocking to me to discover that all the speakers were from advertisers and sponsors.

01:14:55.400 --> 01:14:57.240
<v Reuven Lerner>Everything was super commercialized.

01:14:57.580 --> 01:15:00.440
<v Reuven Lerner>People were not interested in just like hanging out and sharing with each other.

01:15:00.880 --> 01:15:04.980
<v Reuven Lerner>And it was a shock to me because I've been to basically only Python conferences for so many years.

01:15:05.050 --> 01:15:08.300
<v Reuven Lerner>I was like, oh, that's not the norm in the industry.

01:15:08.800 --> 01:15:15.640
<v Reuven Lerner>So we've got something really special going that not only is good for the people, but good for everyone's careers and mutually reinforcing and helping each other.

01:15:16.120 --> 01:15:17.580
<v Reuven Lerner>And that's really fantastic.

01:15:17.610 --> 01:15:18.480
<v Reuven Lerner>And we should appreciate that.

01:15:19.140 --> 01:15:20.280
<v Barry Warsaw>Barry, final word.

01:15:20.520 --> 01:15:25.340
<v Barry Warsaw>Thomas stole my thunder just a little bit, but just to tie a couple of these ideas together.

01:15:25.960 --> 01:15:29.360
<v Barry Warsaw>Python, and you know, Brett said this, right?

01:15:29.520 --> 01:15:33.120
<v Barry Warsaw>This is Python is the community or the community is Python.

01:15:33.580 --> 01:15:38.240
<v Barry Warsaw>There's no company that is telling anybody what Python should be.

01:15:38.600 --> 01:15:39.980
<v Barry Warsaw>Python is what we make it.

01:15:40.460 --> 01:15:43.840
<v Barry Warsaw>And, you know, as folks like myself get a little older

01:15:44.140 --> 01:15:47.500
<v Barry Warsaw>and, you know, and we have younger people

01:15:47.700 --> 01:15:48.620
<v Barry Warsaw>coming into the community,

01:15:48.920 --> 01:15:50.760
<v Barry Warsaw>both developers and everything else

01:15:51.280 --> 01:15:54.320
<v Barry Warsaw>who are shaping Python into their vision.

01:15:54.700 --> 01:15:56.120
<v Barry Warsaw>I encourage you,

01:15:56.380 --> 01:15:58.360
<v Barry Warsaw>if you've thought about becoming a core dev,

01:15:58.720 --> 01:15:59.440
<v Barry Warsaw>find a mentor.

01:15:59.660 --> 01:16:01.320
<v Barry Warsaw>There are people out there that will help you.

01:16:01.520 --> 01:16:05.100
<v Barry Warsaw>If you want to be involved in the community, the PSF,

01:16:05.460 --> 01:16:06.260
<v Barry Warsaw>you know, reach out.

01:16:06.320 --> 01:16:08.560
<v Barry Warsaw>There are people who will help guide you

01:16:08.580 --> 01:16:15.680
<v Barry Warsaw>this community. You can be involved. Do not let any self-imposed limitations stop you from

01:16:16.740 --> 01:16:22.440
<v Barry Warsaw>becoming part of the Python community in the way that you want to. And eventually run for the

01:16:22.600 --> 01:16:29.320
<v Thomas Wourters>steering council because we need many, many, many more candidates next year. And you don't need any

01:16:29.580 --> 01:16:33.940
<v Thomas Wourters>qualifications either because I'm a high school dropout and I never went to college or anything.

01:16:34.640 --> 01:16:35.400
<v Thomas Wourters>And look at me.

01:16:35.820 --> 01:16:37.600
<v Brett Cannon>And I have a PhD and I will tell you,

01:16:37.610 --> 01:16:39.600
<v Brett Cannon>I did not need all that to become a Python developer

01:16:39.830 --> 01:16:41.980
<v Brett Cannon>because I was the Python developer before I got the PhD.

01:16:42.540 --> 01:16:43.360
<v Brett Cannon>I'm a bass player.

01:16:43.430 --> 01:16:44.960
<v Barry Warsaw>So if I can do it, anybody can do it.

01:16:47.920 --> 01:16:49.120
<v Michael Kennedy>Thank you everyone for being here.

01:16:49.520 --> 01:16:50.860
<v Michael Kennedy>This awesome look back in the air

01:16:50.940 --> 01:16:52.220
<v Michael Kennedy>and I really appreciate you all taking the time.

01:16:52.420 --> 01:16:52.860
<v Gregory Kapfhammer>Thank you, Michael.

01:16:53.080 --> 01:16:54.440
<v Gregory Kapfhammer>Thanks everybody.

01:16:54.830 --> 01:16:55.140
<v Michael Kennedy>Bye everybody.

01:16:57.320 --> 01:16:59.700
<v Michael Kennedy>This has been another episode of Talk Python To Me.

01:17:00.080 --> 01:17:00.800
<v Michael Kennedy>Thank you to our sponsors.

01:17:01.010 --> 01:17:02.300
<v Michael Kennedy>Be sure to check out what they're offering.

01:17:02.500 --> 01:17:03.860
<v Michael Kennedy>It really helps support the show.

01:17:04.400 --> 01:17:07.200
<v Michael Kennedy>Look into the future and see bugs before they make it to production.

01:17:08.000 --> 01:17:13.280
<v Michael Kennedy>Sentry's Seer AI Code Review uses historical error and performance information at Sentry

01:17:13.660 --> 01:17:17.620
<v Michael Kennedy>to find and flag bugs in your PRs before you even start to review them.

01:17:18.280 --> 01:17:20.100
<v Michael Kennedy>Stop bugs before they enter your code base.

01:17:20.620 --> 01:17:24.500
<v Michael Kennedy>Get started at talkpython.fm/seer-code-review.

01:17:25.020 --> 01:17:26.880
<v Michael Kennedy>If you or your team needs to learn Python,

01:17:27.080 --> 01:17:30.560
<v Michael Kennedy>we have over 270 hours of beginner and advanced courses

01:17:30.560 --> 01:17:37.160
<v Michael Kennedy>on topics ranging from complete beginners to async code, Flask, Django, HTMX, and even LLMs.

01:17:37.480 --> 01:17:39.820
<v Michael Kennedy>Best of all, there's no subscription in sight.

01:17:40.320 --> 01:17:41.980
<v Michael Kennedy>Browse the catalog at talkpython.fm.

01:17:42.680 --> 01:17:46.060
<v Michael Kennedy>And if you're not already subscribed to the show on your favorite podcast player,

01:17:46.700 --> 01:17:47.340
<v Michael Kennedy>what are you waiting for?

01:17:47.980 --> 01:17:49.780
<v Michael Kennedy>Just search for Python in your podcast player.

01:17:49.880 --> 01:17:50.760
<v Michael Kennedy>We should be right at the top.

01:17:51.180 --> 01:17:53.940
<v Michael Kennedy>If you enjoy that geeky rap song, you can download the full track.

01:17:54.160 --> 01:17:56.060
<v Michael Kennedy>The link is actually in your podcast blur show notes.

01:17:56.860 --> 01:17:58.220
<v Michael Kennedy>This is your host, Michael Kennedy.

01:17:58.540 --> 01:17:59.680
<v Michael Kennedy>Thank you so much for listening.

01:17:59.980 --> 01:18:00.620
<v Michael Kennedy>I really appreciate it.

01:18:01.120 --> 01:18:01.800
<v Michael Kennedy>I'll see you next time.

01:18:27.680 --> 01:18:29.420
<v Michael Kennedy>I think is the norm.

