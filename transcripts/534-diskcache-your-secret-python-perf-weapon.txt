00:00:00 <v Michael Kennedy>Your cloud SSD is sitting there, bored, and it would like a job.

00:00:03 <v Michael Kennedy>Today, we're putting into work with DiscCache, a simple, practical cache built on SQLite

00:00:08 <v Michael Kennedy>that can speed things up without spinning up Redis or other extra servers.

00:00:13 <v Michael Kennedy>Once you start to see what it can do, a universe of possibilities opens up.

00:00:17 <v Michael Kennedy>We're joined by Vincent Warmerdom to dive into DiscCache.

00:00:21 <v Michael Kennedy>This is Talk Python To Me, episode 534, recorded December 19th, 2025.

00:00:27 Talk Python To Me, yeah, we ready to roll.

00:00:29 Upgrading the code, no fear of getting old Async in the air, new frameworks in sight

00:00:35 Geeky rap on deck, Quart crew It's time to unite We started in Pyramid, cruising old school lanes

00:00:41 Had that stable base, yeah sir <v Michael Kennedy>Welcome to Talk Python To Me, the number one Python podcast for developers and data scientists.

00:00:48 <v Michael Kennedy>This is your host, Michael Kennedy.

00:00:49 <v Michael Kennedy>I'm a PSF fellow who's been coding for over 25 years.

00:00:54 <v Michael Kennedy>Let's connect on social media.

00:00:55 <v Michael Kennedy>You'll find me and Talk Python on Mastodon, Bluesky, and X.

00:00:58 <v Michael Kennedy>The social links are all in your show notes.

00:01:01 <v Michael Kennedy>You can find over 10 years of past episodes at talkpython.fm.

00:01:05 <v Michael Kennedy>And if you want to be part of the show, you can join our recording live streams.

00:01:08 <v Michael Kennedy>That's right.

00:01:09 <v Michael Kennedy>We live stream the raw uncut version of each episode on YouTube.

00:01:13 <v Michael Kennedy>Just visit talkpython.fm/youtube to see the schedule of upcoming events.

00:01:17 <v Michael Kennedy>Be sure to subscribe there and press the bell so you'll get notified anytime we're recording.

00:01:22 <v Michael Kennedy>Vincent, hello.

00:01:23 <v Michael Kennedy>Michael, Michael, we're back.

00:01:25 <v Michael Kennedy>Awesome.

00:01:26 <v Michael Kennedy>Awesome to be back with you.

00:01:27 <v Michael Kennedy>Yeah, this is almost the sequel to the last time you were on the show.

00:01:32 <v Michael Kennedy>So it's going to be fun.

00:01:34 <v Vincent Warmerdam>Yeah, so sequel in this case, not the query language,

00:01:36 <v Vincent Warmerdam>like an actual sequel of events.

00:01:38 <v Vincent Warmerdam>Yes.

00:01:39 <v Vincent Warmerdam>Yeah, you can correct me if I'm wrong, <v Vincent Warmerdam>but I think what happened is you had me on a podcast a while ago

00:01:45 <v Vincent Warmerdam>to talk about a course that I made, <v Vincent Warmerdam>and a big chunk of the course that we were very enthusiastic about

00:01:49 <v Vincent Warmerdam>was about this tool called DiscCache.

00:01:51 <v Vincent Warmerdam>And then we kind of came to the conclusion, <v Vincent Warmerdam>well, we had to cap it off.

00:01:54 <v Vincent Warmerdam>Maybe it's fun to do an episode on just DiscCache.

00:01:57 <v Vincent Warmerdam>since we're both pretty huge fans of it.

00:01:59 <v Vincent Warmerdam>I think that's how we got here.

00:02:00 <v Michael Kennedy>I think that is how we got here as well.

00:02:02 <v Michael Kennedy>And we're going to dive into this.

00:02:05 <v Michael Kennedy>Honestly, it's a pretty simple library called Disc Cache,

00:02:09 <v Michael Kennedy>but what it unlocks is really, really sweet.

00:02:11 <v Michael Kennedy>And I'm going to talk about a lot of different angles.

00:02:14 <v Michael Kennedy>And now, even though it's just been not that long since you were on the show,

00:02:18 <v Michael Kennedy>maybe just give us a quick intro of who you are.

00:02:20 <v Vincent Warmerdam>Hi, my name is Vincent.

00:02:21 <v Vincent Warmerdam>I've done a bunch of data machine learning stuff, mainly in the past.

00:02:25 <v Vincent Warmerdam>That's sort of what a lot of people know me from.

00:02:27 <v Vincent Warmerdam>These days, though, I work for a company called Marimo.

00:02:29 <v Vincent Warmerdam>You might have heard from us.

00:02:30 <v Vincent Warmerdam>We make very modern Python notebooks.

00:02:32 <v Vincent Warmerdam>We took some lessons from Jupyter, <v Vincent Warmerdam>and we take a new spin of it.

00:02:35 <v Vincent Warmerdam>So that's my day to day.

00:02:37 <v Vincent Warmerdam>But I still like to write notebooks <v Vincent Warmerdam>and do kind of fun little benchmarks and also stuff

00:02:42 <v Vincent Warmerdam>with LLMs.

00:02:42 <v Vincent Warmerdam>And I've just noticed that for a lot of that work, boy,

00:02:45 <v Vincent Warmerdam>disk cache is amazing.

00:02:47 <v Vincent Warmerdam>And I also use it for web stuff.

00:02:48 <v Vincent Warmerdam>And I think that's also what your use case <v Vincent Warmerdam>is a little bit more of.

00:02:51 <v Vincent Warmerdam>But yeah, in notebook land, you also <v Vincent Warmerdam>like to have a very good caching mechanism

00:02:56 <v Vincent Warmerdam>And on the Mremo side of things, we are also working on different caching mechanisms, which I might talk about in a bit.

00:03:01 <v Vincent Warmerdam>But just for me, the bread and butter, the thing I've used for years at this point is disk cache whenever it comes to that territory.

00:03:06 <v Michael Kennedy>Yeah, it's funny.

00:03:07 <v Michael Kennedy>This was recommended to me for Python Bytes as a news item over there quite a while ago, like years ago.

00:03:13 <v Michael Kennedy>And I'm like, oh, that's pretty interesting.

00:03:15 <v Michael Kennedy>And then I saw you using it in the LLM Building Blocks course, and it just unlocked for me.

00:03:20 <v Michael Kennedy>Like, oh, my.

00:03:22 <v Michael Kennedy>Oh, this is something else.

00:03:24 <v Michael Kennedy>And so since then, I've been doing a bunch with it, and I'm a big fan.

00:03:27 <v Michael Kennedy>I've been on this, like trying to avoid complexity, but still getting really cool responses, performance, et cetera, out of your apps.

00:03:35 <v Michael Kennedy>And I think this is a really nice way to add multi-process, super fast caching to your app without involving more servers and more stuff that's got to get connected and keep running and so on.

00:03:47 <v Michael Kennedy>But before we get into the details of that, maybe let's just talk about caching in general.

00:03:53 <v Michael Kennedy>Like what types of caching is there?

00:03:55 <v Michael Kennedy>You know, I sort of give a little precursor there.

00:03:57 <v Michael Kennedy>But yeah, dive into it.

00:03:58 <v Vincent Warmerdam>So like in the course, the main example <v Vincent Warmerdam>I remember talking about was the one--

00:04:03 <v Vincent Warmerdam>you've got this LLM, and you want to do some benchmarks.

00:04:05 <v Vincent Warmerdam>And it might be the case that, I don't know, <v Vincent Warmerdam>using an LLM for, let's say, classification,

00:04:09 <v Vincent Warmerdam>like some text goes in, we got to know whether or not

00:04:12 <v Vincent Warmerdam>it's about a certain topic, yes, no, or something like that.

00:04:14 <v Vincent Warmerdam>Then it would be really great if, suppose, the same text came

00:04:17 <v Vincent Warmerdam>by for whatever reason, that we don't run the query on the LLM

00:04:21 <v Vincent Warmerdam>Again, it's like wasted compute, wasted money.

00:04:23 <v Vincent Warmerdam>So it'd be kind of nice if the same text goes in that we then say,

00:04:27 <v Vincent Warmerdam>oh, we know what the answer to that thing is already.

00:04:29 <v Vincent Warmerdam>We cached it, so here you can go back.

00:04:31 <v Vincent Warmerdam>And that's the case when you're dealing with heavy compute ML systems.

00:04:35 <v Vincent Warmerdam>But there's a similar situation that you might have, I guess,

00:04:37 <v Vincent Warmerdam>with expensive SQL queries, <v Vincent Warmerdam>or you want to reduce the load on a database somewhere.

00:04:41 <v Vincent Warmerdam>Then having some sort of a caching layer that's able to say,

00:04:43 <v Vincent Warmerdam>oh, you're querying for something, but I already know what it is.

00:04:47 <v Vincent Warmerdam>Boom, we can send it back.

00:04:49 <v Vincent Warmerdam>I think the classical thing you would do in Python <v Vincent Warmerdam>is you have this decorator in functools, I think, right?

00:04:53 <v Vincent Warmerdam>The LRU_cache.

00:04:57 <v Michael Kennedy>Yeah, exactly.

00:04:58 <v Michael Kennedy>Yeah.

00:04:58 <v Vincent Warmerdam>That's a hell of a world to that.

00:04:59 <v Vincent Warmerdam>But the downside of that thing is that it's all in memory.

00:05:02 <v Vincent Warmerdam>So if you were to reboot your Python process, <v Vincent Warmerdam>you lose all that caching.

00:05:05 <v Vincent Warmerdam>So that's why people historically, I think, <v Vincent Warmerdam>resorted to--

00:05:08 <v Vincent Warmerdam>I think Redis, I think, is the most well-known caching tool.

00:05:12 <v Vincent Warmerdam>It's the one I've always used.

00:05:13 <v Vincent Warmerdam>There's Memcache, I think.

00:05:14 <v Vincent Warmerdam>There's other tools.

00:05:15 <v Vincent Warmerdam>You could use Postgres for some of this stuff as well.

00:05:18 <v Vincent Warmerdam>But recently, especially because disks are just getting quicker

00:05:21 <v Vincent Warmerdam>and quicker, people have been looking at SQLite <v Vincent Warmerdam>for this sort of a thing as well.

00:05:25 <v Vincent Warmerdam>So that's, I think, the quickest summary <v Vincent Warmerdam>and also sort of the entryway to how I got started with disk cache.

00:05:31 <v Michael Kennedy>Yeah, and so for this example that you highlight in the LLM

00:05:34 <v Michael Kennedy>Building Blocks course, it's not a conversation.

00:05:38 <v Michael Kennedy>It's like a one-shot situation, right?

00:05:41 <v Michael Kennedy>You come up-- you say, I have some code or some documents,

00:05:43 <v Michael Kennedy>and I have almost like an API.

00:05:45 <v Michael Kennedy>I'm going to send that off to the LLM and ask it, tell me X, Y, and Z about it.

00:05:51 <v Michael Kennedy>And sure, it's got some kind of temperature and it won't always give an exactly the same answer,

00:05:56 <v Michael Kennedy>but you're willing to, you know, you're willing to accept an answer.

00:06:00 <v Michael Kennedy>And at that point, like why ask it again and again and again, which it might take seconds,

00:06:05 <v Michael Kennedy>it might cost money.

00:06:06 <v Michael Kennedy>Whereas if you just remember through caching somehow, you remember it, it's like, boom, instant.

00:06:13 <v Vincent Warmerdam>Yeah, and it tends to come up a lot in when you're doing benchmarks, for example.

00:06:16 <v Vincent Warmerdam>So you have this for loop, you want to go over your entire data set, try all these different approaches.

00:06:21 <v Vincent Warmerdam>And if you've got a new approach, then you want that to run, of course.

00:06:23 <v Vincent Warmerdam>But if you accidentally trigger an old approach, then you don't want to incur the cost of like going through all those different LLMs.

00:06:29 <v Vincent Warmerdam>I should say, like, even if you just forget about LLMs, let's just say machine learning in general.

00:06:33 <v Vincent Warmerdam>Let's say there's some sort of image classification thing you're using in the cloud.

00:06:36 <v Vincent Warmerdam>There also, you would say, like, file name goes in.

00:06:39 <v Vincent Warmerdam>that's an image and if the same file name goes in we don't want the expensive compute cost to happen

00:06:43 <v Vincent Warmerdam>either so it's definitely more general than llms but llms do feel like it's the zeitgeisty thing to

00:06:48 <v Michael Kennedy>worry about yeah i think for two reasons one because they're just the topic du jour and two

00:06:54 <v Michael Kennedy>because they're they're i think a part of computing that most people experience that is way slower than

00:06:59 <v Vincent Warmerdam>they're used to yeah well and especially if you're you know if i suppose that you you have a an

00:07:05 <v Vincent Warmerdam>an attic somewhere and you're a dad and you want to do home lab stuff and you're playing with all

00:07:09 <v Vincent Warmerdam>these open source LLM models, then you also learn that, yeah, they're fun to play with, but they also

00:07:14 <v Vincent Warmerdam>take a lot of time to compute things. So then immediately you get the motivation to do it the

00:07:18 <v Michael Kennedy>right way. Yeah, I built a couple of little utilities that talk to a local LLM. I think it's

00:07:25 <v Michael Kennedy>the OpenAI OpenWeights one, that 20 billion parameter one I have running on my Mac Mini,

00:07:31 <v Michael Kennedy>and it's pretty good, a little bit slow, but, you know, it's fine for what it's being used for. And

00:07:35 <v Michael Kennedy>put-- use your disk cache technique on it.

00:07:39 <v Michael Kennedy>And if I ask it the same question again, it's like, boom.

00:07:41 <v Michael Kennedy>You don't need to wait 10 seconds.

00:07:43 <v Michael Kennedy>Here's the answer.

00:07:43 <v Michael Kennedy>Yeah.

00:07:44 <v Vincent Warmerdam>So that-- and I guess like-- but I guess from your perspective,

00:07:46 <v Vincent Warmerdam>I think your main entry point to this domain <v Vincent Warmerdam>was a little bit more from the web dev perspective, right?

00:07:51 <v Vincent Warmerdam>Like that's-- and I suppose you're using it a lot <v Vincent Warmerdam>for preventing expensive queries to go to Postgres,

00:07:57 <v Vincent Warmerdam>or I don't exactly know your backend.

00:07:59 <v Michael Kennedy>You know how-- you won't believe how optimized my website is.

00:08:02 <v Michael Kennedy>There's not a single query that goes to Postgres, <v Michael Kennedy>because they go to MongoDB.

00:08:06 <v Michael Kennedy>I'm just kidding.

00:08:06 <v Vincent Warmerdam>There you go.

00:08:07 <v Michael Kennedy>No, but your point is totally valid.

00:08:10 <v Michael Kennedy>Go into the database, right?

00:08:11 <v Michael Kennedy>Now, I don't actually cache that many requests.

00:08:15 <v Michael Kennedy>I don't avoid that many requests going to the database.

00:08:17 <v Michael Kennedy>They're really quite quick, and so I'm OK with that.

00:08:19 <v Michael Kennedy>But when you think about a feature-rich database, <v Michael Kennedy>feature-rich web app, there's just tons of these little edge

00:08:26 <v Michael Kennedy>cases you're like, oh, got to do that thing.

00:08:28 <v Michael Kennedy>And it's not a big deal, but we've <v Michael Kennedy>got to do it 500 times in a request.

00:08:31 <v Michael Kennedy>Then it is kind of a thing.

00:08:34 <v Michael Kennedy>So let me give you an example.

00:08:35 <v Michael Kennedy>I'll give you some examples.

00:08:36 <v Michael Kennedy>So for example, the good portions of the show notes <v Michael Kennedy>on talkpython.fm are in Markdown.

00:08:43 <v Michael Kennedy>I don't want to show people Markdown.

00:08:44 <v Michael Kennedy>I want to show them HTML, right?

00:08:47 <v Michael Kennedy>So when a request comes in, it'll <v Michael Kennedy>say any fragment of HTML that needs

00:08:53 <v Michael Kennedy>to be turned into Markdown instead of just going, oh,

00:08:56 <v Michael Kennedy>let me process that.

00:08:57 <v Michael Kennedy>It just goes, all right, what is the hash of this <v Michael Kennedy>or some other indicator of the content?

00:09:03 <v Michael Kennedy>And then I've already computed that and stored it in disk cache.

00:09:06 <v Michael Kennedy>So here's the HTML result.

00:09:08 <v Michael Kennedy>Another example is there's a little YouTube icon on each page.

00:09:13 <v Michael Kennedy>And that's actually in the show notes, but then the website parses the YouTube ID out

00:09:17 <v Michael Kennedy>and then embeds it with an, like, there's a bunch of stuff going on there to keep YouTube

00:09:22 <v Michael Kennedy>out of spying on my visitors.

00:09:25 <v Michael Kennedy>But stuff happens, YouTube ID is used.

00:09:27 <v Michael Kennedy>That could be parsed every time.

00:09:29 <v Michael Kennedy>Or I can just say this episode has this YouTube ID.

00:09:33 <v Michael Kennedy>That information goes into a cache, right?

00:09:35 <v Michael Kennedy>And because it's a disk cache sort of scenario, <v Michael Kennedy>like a file-based one, not an LRU cache.

00:09:42 <v Michael Kennedy>It doesn't change the memory footprint <v Michael Kennedy>and it's shared across processes.

00:09:46 <v Michael Kennedy>So in like the web world, <v Michael Kennedy>it's really common to have a web garden

00:09:48 <v Michael Kennedy>where you've got like two or four processes <v Michael Kennedy>all being like round robin to

00:09:53 <v Michael Kennedy>from some web server manager thing, right?

00:09:56 <v Michael Kennedy>If you don't somehow out of process that, <v Michael Kennedy>either Redis or SQLite or database or something,

00:10:03 <v Michael Kennedy>then all of those things are recreating that, right?

00:10:05 <v Michael Kennedy>They can't reuse that, right?

00:10:07 <v Michael Kennedy>So there's a lot of interesting components there.

00:10:09 <v Vincent Warmerdam>And I suppose your web deployment, <v Vincent Warmerdam>you have like a big VM, I suppose,

00:10:11 <v Vincent Warmerdam>and then there's like multiple Docker containers running,

00:10:14 <v Vincent Warmerdam>but they do all have access to the same volume, <v Vincent Warmerdam>and that's how you access SQLite.

00:10:18 <v Michael Kennedy>Bingo, yeah, exactly, exactly.

00:10:21 <v Michael Kennedy>And how am I doing?

00:10:22 <v Michael Kennedy>Yeah, so what I have done is in the Docker Compose file,

00:10:26 <v Michael Kennedy>I have an external, <v Michael Kennedy>This is also important for Docker.

00:10:29 <v Michael Kennedy>So I have an external folder on a big hard drive in the big VM that says, here's where

00:10:34 <v Michael Kennedy>all the caches go.

00:10:36 <v Michael Kennedy>And then depending on which app, it'll pick like a sub directory it can go look at or

00:10:40 <v Michael Kennedy>whatever that it's using.

00:10:41 <v Michael Kennedy>And so that way, even if I do a complete rebuild of the Docker image, it still retains

00:10:48 <v Michael Kennedy>its cache from version to version and all that kind of business.

00:10:51 <v Michael Kennedy>You could do that with a persistent VM as well, volume as well.

00:10:55 <v Michael Kennedy>But I've just decided--

00:10:57 <v Michael Kennedy>you can go and inspect it a little easier <v Michael Kennedy>and see how big the cache is and stuff like that.

00:11:00 <v Vincent Warmerdam>OK, so we're going to get into the weeds of how <v Vincent Warmerdam>disk cache works exactly.

00:11:04 <v Vincent Warmerdam>But I'm triggered here because it sounds like you've done

00:11:06 <v Vincent Warmerdam>something clever there.

00:11:07 <v Vincent Warmerdam>Because what you can do in disk cache <v Vincent Warmerdam>is you can say, look, here's a file that's SQLite.

00:11:11 <v Vincent Warmerdam>And then it behaves like a dictionary, <v Vincent Warmerdam>but it's persisted on disk.

00:11:14 <v Vincent Warmerdam>But what I just heard you say is that you've got multiple caches.

00:11:16 <v Vincent Warmerdam>So am I right to hear that, oh, for some things that

00:11:19 <v Vincent Warmerdam>need to be cached, let's say the YouTube things, <v Vincent Warmerdam>that's a separate file.

00:11:22 <v Vincent Warmerdam>And then all the markdown stuff, that's also <v Vincent Warmerdam>a separate file, and therefore if connections need to be made to either,

00:11:27 <v Vincent Warmerdam>it's also kind of nicely split.

00:11:29 <v Vincent Warmerdam>Is that also the design there?

00:11:30 <v Michael Kennedy>Yeah, that is.

00:11:30 <v Michael Kennedy>And actually, before, like, we're going to dive into all the details of how it works,

00:11:33 <v Michael Kennedy>but I'll just go, I'm just to give people a little glimpse.

00:11:36 <v Michael Kennedy>I'll go ahead and show, I've got this whole admin back in here.

00:11:39 <v Michael Kennedy>And I've got different caches for different purposes.

00:11:42 <v Michael Kennedy>Because they're just SQLite files, you can either say, give me the same one,

00:11:45 <v Michael Kennedy>or you can say, this one is named something else, <v Michael Kennedy>and it has a different file name or different folder or whatever.

00:11:50 <v Michael Kennedy>Right, so I've got one that stores things like that YouTube ID I talked about

00:11:53 <v Michael Kennedy>any markdown, any fragment of markdown anywhere in the web app that it needs to say that needs

00:11:58 <v Michael Kennedy>to go to HTML, like just.

00:12:00 <v Vincent Warmerdam>Yeah, and it's like 8,000 items in that thing.

00:12:03 <v Michael Kennedy>Yeah.

00:12:04 <v Michael Kennedy>In this one, there's 8,970 items, which is nine megs, right?

00:12:08 <v Michael Kennedy>I mean, it's not huge, but it's not too bad.

00:12:10 <v Michael Kennedy>And you can actually even see where it thinks it lives, but that's not really where it lives

00:12:14 <v Michael Kennedy>because there's, you know, the volume redirects and stuff.

00:12:17 <v Michael Kennedy>But I've also got stuff for directly about the episodes that it needs to pull back.

00:12:22 <v Michael Kennedy>And then I do a lot of HTTP caching.

00:12:25 <v Michael Kennedy>And one of the things that I think is really wrong with web development is people say,

00:12:30 <v Michael Kennedy>well, that's like a stale image or that's a stale CSS file or JavaScript, you know,

00:12:33 <v Michael Kennedy>all that kind of stuff.

00:12:34 <v Michael Kennedy>So if you just do like super minor tricks and just put some kind of hash ID on the end

00:12:41 <v Michael Kennedy>of your content, it will, and you teach your CDN or whatever, that that's a different file

00:12:47 <v Michael Kennedy>if it varies by query string, then you never, ever have to worry about stale content ever.

00:12:52 <v Michael Kennedy>right but computing that can be expensive especially for remote stuff like if it's it's on a different

00:12:57 <v Michael Kennedy>it's like a s3 thing but you still want to have it do that so i have a special cache for that and

00:13:01 <v Michael Kennedy>that takes that's like pretty complicated to build up because it's got to do like almost 700 web

00:13:06 <v Michael Kennedy>requests to figure out what those are but once they're done it's blazing fast you don't have to

00:13:10 <v Michael Kennedy>do it again right unless it changes then it doesn't change much and so on so there's that's the way

00:13:14 <v Vincent Warmerdam>that i'm sort of using and appreciating disk cache yeah it works well in your setup because you've

00:13:19 <v Vincent Warmerdam>gone for the VM route. I mean, if you go <v Vincent Warmerdam>for something like Fly.io or maybe even

00:13:24 <v Vincent Warmerdam>DigitalOcean has like a really, I think <v Vincent Warmerdam>it's a nice like app service, but that

00:13:27 <v Vincent Warmerdam>all revolves around Docker containers that like <v Vincent Warmerdam>spin up horizontally. And I

00:13:31 <v Vincent Warmerdam>don't think those containers can <v Vincent Warmerdam>be configured in such a way they share the volume.

00:13:36 <v Vincent Warmerdam>So in that sense, you could still use <v Vincent Warmerdam>disk cache, but then

00:13:40 <v Vincent Warmerdam>each individual instance of the <v Vincent Warmerdam>Docker container would have its own cache, which still could

00:13:43 <v Vincent Warmerdam>work out.

00:13:45 <v Vincent Warmerdam>Not going to be as well <v Vincent Warmerdam>well functional. It's going to be better with your setup, though.

00:13:50 <v Michael Kennedy>Yeah, absolutely. I agree, though. You could still do it. Or you could go, I'll take the

00:13:55 <v Michael Kennedy>zen of what Vincent and Michael are saying today, and I'll apply that to Postgres, or

00:13:59 <v Michael Kennedy>I'll apply that to whatever data. You could pull this off in a database.

00:14:03 <v Vincent Warmerdam>You would just have to do more work. Yeah. I mean, I've had a couple of, I think

00:14:07 <v Vincent Warmerdam>it was like a Django conference talk I saw a while ago. They were also raving about

00:14:11 <v Vincent Warmerdam>disk cache. But the merits of disk cache do depend a little bit on your

00:14:15 <v Vincent Warmerdam>deployment, though.

00:14:15 <v Vincent Warmerdam>That is, I think, one observation.

00:14:17 <v Vincent Warmerdam>Like in your setup, I can definitely imagine it.

00:14:18 <v Vincent Warmerdam>Interesting.

00:14:19 <v Vincent Warmerdam>Yeah.

00:14:19 <v Michael Kennedy>Yeah.

00:14:20 <v Michael Kennedy>Well, I don't even think we properly introduced this thing

00:14:22 <v Michael Kennedy>yet, so.

00:14:23 <v Vincent Warmerdam>But let's maybe go there.

00:14:24 <v Vincent Warmerdam>Yeah.

00:14:24 <v Vincent Warmerdam>Let's start there.

00:14:25 <v Michael Kennedy>Let's start there.

00:14:26 <v Vincent Warmerdam>It's time.

00:14:26 <v Vincent Warmerdam>OK.

00:14:27 <v Vincent Warmerdam>It's time.

00:14:27 <v Vincent Warmerdam>Yeah.

00:14:29 <v Vincent Warmerdam>I guess the simplest way I usually describe it, <v Vincent Warmerdam>it really behaves like a dictionary,

00:14:33 <v Vincent Warmerdam>except you persist a disk and under the hood <v Vincent Warmerdam>is using SQLite.

00:14:36 <v Vincent Warmerdam>I think that's the-- it doesn't cover everything, <v Vincent Warmerdam>but you get quite close, if that's the way it is.

00:14:40 <v Michael Kennedy>I think there might be--

00:14:42 <v Michael Kennedy>you know, I keep harping on this on the show, <v Michael Kennedy>but there are so many people that are new to Python

00:14:45 <v Michael Kennedy>and programming these days.

00:14:47 <v Michael Kennedy>Many, many of them, almost half of them.

00:14:49 <v Michael Kennedy>I think it's worth pointing out, just like, what is SQLite?

00:14:51 <v Michael Kennedy>Like, why is it different than any other database?

00:14:54 <v Michael Kennedy>Like, why have I been using the word database or SQLite

00:14:56 <v Michael Kennedy>when SQLite is a database, right?

00:14:57 <v Michael Kennedy>That's weird.

00:14:58 <v Vincent Warmerdam>- So, I never really took a good database, of course.

00:15:01 <v Vincent Warmerdam>I might be ruining the formalism of it.

00:15:04 <v Vincent Warmerdam>But the main, like, for me at least, <v Vincent Warmerdam>the way I like to think about it is Postgres,

00:15:08 <v Vincent Warmerdam>that's a thing I can run on a VM, <v Vincent Warmerdam>and then other Docker containers can connect to it

00:15:13 <v Vincent Warmerdam>because it's running out of process.

00:15:14 <v Vincent Warmerdam>There's some other process that has the database somewhere,

00:15:17 <v Vincent Warmerdam>and I can connect to it.

00:15:18 <v Vincent Warmerdam>And I think the main thing that makes SQLite different

00:15:20 <v Vincent Warmerdam>is that, no, you got to run it on the same machine,

00:15:23 <v Vincent Warmerdam>on the same process where your program is running.

00:15:25 <v Vincent Warmerdam>And that's, I think, the main--

00:15:26 <v Vincent Warmerdam>and there's all sorts of little details, <v Vincent Warmerdam>like how the data structures are used internally,

00:15:30 <v Vincent Warmerdam>and SQLite doesn't have a lot of types.

00:15:32 <v Vincent Warmerdam>There's lots of other differences.

00:15:33 <v Vincent Warmerdam>I think that's the main one.

00:15:35 <v Vincent Warmerdam>Unless, Michael, I forgot something.

00:15:36 <v Michael Kennedy>MICHAEL LUTH: Yeah, no, I think it's--

00:15:38 <v Michael Kennedy>and it's--

00:15:40 <v Michael Kennedy>operationally, it's a separate thing <v Michael Kennedy>run. It has to have both, it has to be secure because if your data gets exposed, like-

00:15:49 <v Vincent Warmerdam>For Postgres, is it not for SQL? Yes, it's running somewhere. People can SSH in if you're

00:15:54 <v Vincent Warmerdam>not careful. You've got to be mindful of passwords and all that stuff. That's totally true.

00:15:58 <v Michael Kennedy>Right. And it can go down. Like it could just become unavailable because you've screwed up

00:16:02 <v Michael Kennedy>something or whatever, right? It's a thing you have to manage in the complexity of running your app

00:16:07 <v Michael Kennedy>when it's like, well, it used to just be one thing I could run in a Docker container. Well,

00:16:10 <v Michael Kennedy>now I got different servers, they got to coordinate and there's firewalls and there's like, it's just,

00:16:14 <v Michael Kennedy>it just takes it so much higher in terms of complexity that like SQLite is a file.

00:16:19 <v Michael Kennedy>Yes.

00:16:20 <v Vincent Warmerdam>I mean, I do want to maybe defend Postgres a little bit there.

00:16:22 <v Vincent Warmerdam>Cause one thing that's like really nice and convenient in terms of like CICD and deployments

00:16:26 <v Vincent Warmerdam>and all that,  oh, suppose you want to scale horizontally and there's like Docker containers

00:16:31 <v Vincent Warmerdam>running on the left and there's this one Postgres thing running on the right.

00:16:34 <v Vincent Warmerdam>I mean, you can just turn on and off all those Docker containers as you see fit.

00:16:38 <v Vincent Warmerdam>they're just going to connect to the Postgres instance.

00:16:40 <v Vincent Warmerdam>And I've done this trick for Calm Code a bunch of times

00:16:43 <v Vincent Warmerdam>where I just switch cloud providers, <v Vincent Warmerdam>because Postgres is running there,

00:16:46 <v Vincent Warmerdam>and I can just move the Docker containers <v Vincent Warmerdam>to another cloud provider, and it all works fine.

00:16:50 <v Vincent Warmerdam>No migration necessary.

00:16:52 <v Vincent Warmerdam>With SQLite, that aspect is a little bit more tricky.

00:16:54 <v Vincent Warmerdam>You have to be a bit more mindful.

00:16:56 <v Vincent Warmerdam>Although, I should mention, might be worth a Google.

00:16:59 <v Vincent Warmerdam>There's actually this one new cloud provider <v Vincent Warmerdam>that's very much Python-focused.

00:17:02 <v Vincent Warmerdam>It's called Plash, P-L-A dot S-H, I think.

00:17:06 <v Vincent Warmerdam>Oh, this is new to me.

00:17:07 <v Michael Kennedy>Yeah, so I think--

00:17:08 <v Michael Kennedy>Wow, OK.

00:17:09 <v Michael Kennedy>Look at this.

00:17:09 <v Michael Kennedy>From.py to.com in seconds.

00:17:12 <v Vincent Warmerdam>Yeah, it's the Answer AI, Jeremy Howard and friends.

00:17:15 <v Vincent Warmerdam>I don't know to what extent this is super production ready.

00:17:18 <v Vincent Warmerdam>And SQLite, you've got to be mindful of the production aspect

00:17:22 <v Vincent Warmerdam>for some reasons as well.

00:17:23 <v Vincent Warmerdam>But one thing that is kind of cool about them <v Vincent Warmerdam>is they give you a persistent SQLite as a database

00:17:29 <v Vincent Warmerdam>and a pipeline process that can just kind of attach to it.

00:17:32 <v Vincent Warmerdam>And they just-- in their mind, that's <v Vincent Warmerdam>the simplest way that a cloud provider should be.

00:17:36 <v Vincent Warmerdam>take a very opinionated approach.

00:17:38 <v Vincent Warmerdam>So yeah, if you're interested in maybe running this

00:17:40 <v Vincent Warmerdam>as a web service, migrations are a little bit tricky

00:17:43 <v Vincent Warmerdam>in that realm, because you do have <v Vincent Warmerdam>to download the entire data set due to migration

00:17:47 <v Vincent Warmerdam>and upload it again, I think, if I recall correctly.

00:17:50 <v Michael Kennedy>And for some apps, that's no big deal.

00:17:52 <v Michael Kennedy>Others, that's a mega deal.

00:17:53 <v Michael Kennedy>Depends how big that data is.

00:17:55 <v Vincent Warmerdam>So I'm not suggesting this is going <v Vincent Warmerdam>to be for everything and everyone,

00:17:58 <v Vincent Warmerdam>but I do think it's cool, which is why I figured I'd mention it.

00:18:00 <v Michael Kennedy>Oh, it's new to me.

00:18:03 <v Michael Kennedy>I'm going to follow up with a lightstream.io.

00:18:06 <v Michael Kennedy>Have you seen this?

00:18:07 <v Vincent Warmerdam>Yeah, that is also really neat.

00:18:11 <v Vincent Warmerdam>So basically, what if you want to back up your SQLite?

00:18:13 <v Vincent Warmerdam>Like, how could you do that?

00:18:15 <v Vincent Warmerdam>Oh, it might be nice to do that with S3.

00:18:17 <v Vincent Warmerdam>And I think it's like the guy who made the thing works at Fly.io.

00:18:21 <v Vincent Warmerdam>He's doing a bunch of low-level stuff.

00:18:23 <v Vincent Warmerdam>One thing about that open source package <v Vincent Warmerdam>is also really interesting, by the way,

00:18:26 <v Vincent Warmerdam>is I think he refuses PRs from the outside.

00:18:30 <v Vincent Warmerdam>He just wants to have no distractions whatsoever.

00:18:33 <v Vincent Warmerdam>He has a very interesting way of developing software.

00:18:35 <v Vincent Warmerdam>You can submit issues, of course.

00:18:38 <v Vincent Warmerdam>I think if you scroll down, there used to be a notice that

00:18:40 <v Vincent Warmerdam>basically said, hey, this is a--

00:18:42 <v Vincent Warmerdam>I'm not running this--

00:18:43 <v Vincent Warmerdam>Yeah.

00:18:44 <v Vincent Warmerdam>There you go.

00:18:45 <v Vincent Warmerdam>We welcome-- yeah, contribution guide.

00:18:48 <v Vincent Warmerdam>We welcome bug reports.

00:18:51 <v Vincent Warmerdam>Yeah, this is a way where you can basically <v Vincent Warmerdam>stream updates to S3.

00:18:54 <v Vincent Warmerdam>And the main observation there is S3 is actually really cheap

00:18:58 <v Vincent Warmerdam>if all you do is push stuff into it.

00:18:59 <v Vincent Warmerdam>If you never pull it out, usually getting it out <v Vincent Warmerdam>is the expensive bit of S3.

00:19:03 <v Vincent Warmerdam>So this is like pennies on the dollar <v Vincent Warmerdam>for really decent backup.

00:19:08 <v Vincent Warmerdam>And you can also send it to multiple--

00:19:09 <v Vincent Warmerdam>you can send it to Amazon and also to DigitalOcean,

00:19:11 <v Vincent Warmerdam>if you like.

00:19:12 <v Michael Kennedy>Yeah.

00:19:13 <v Michael Kennedy>Yeah, because these days, S3 is really <v Michael Kennedy>a synonym for blob storage on almost any hosting platform.

00:19:20 <v Michael Kennedy>Like, it used to be S3 might go to literally S3 at AWS.

00:19:23 <v Michael Kennedy>But now it's like, or DigitalOcean object spaces, <v Michael Kennedy>or to you name it.

00:19:29 <v Michael Kennedy>They've all adopted the API, kind of like OpenAI's API.

00:19:32 <v Vincent Warmerdam>Yeah, I will say it's a little bit awkward that you have to--

00:19:35 <v Vincent Warmerdam>like, sometimes you go to a cloud provider, <v Vincent Warmerdam>and they say, you have to download a SDK

00:19:40 <v Vincent Warmerdam>from a competing cloud provider, and then you <v Vincent Warmerdam>can connect to our cloud bucket.

00:19:44 <v Michael Kennedy>I know.

00:19:44 <v Michael Kennedy>And it's usually Bodo 3.

00:19:46 <v Michael Kennedy>And Bodo 3 is--

00:19:48 <v Michael Kennedy>if you want to cry because you're using a library, <v Michael Kennedy>like, Bodo 3 has a good chance of being the first one

00:19:53 <v Michael Kennedy>to make you do it.

00:19:53 <v Michael Kennedy>It is so bad for me.

00:19:55 <v Michael Kennedy>It's so not custom--

00:19:57 <v Michael Kennedy>It's not built with craft and love.

00:19:59 <v Michael Kennedy>It's like auto-generated where you pass these--

00:20:02 <v Michael Kennedy>like, you pass this kind of dictionary, <v Michael Kennedy>and then the other argument takes a separate dictionary

00:20:05 <v Michael Kennedy>that relates back-- it's just like, <v Michael Kennedy>could you give me a real API here?

00:20:09 <v Vincent Warmerdam>IAN MCKAYAN: I mean, the one thing <v Vincent Warmerdam>I can appreciate about Bodo that I do think is honest to mention

00:20:12 <v Vincent Warmerdam>is they do try to just maintain it.

00:20:15 <v Vincent Warmerdam>The backward compatibility of that thing <v Vincent Warmerdam>also means it can't move in any direction as well.

00:20:19 <v Vincent Warmerdam>And I can't-- there is this meme where Google kills all

00:20:22 <v Vincent Warmerdam>of its products way too early, and Amazon's meme <v Vincent Warmerdam>that they kill them way too late, sometimes never.

00:20:27 <v Vincent Warmerdam>Right?

00:20:28 <v Vincent Warmerdam>So in that sense, I can appreciate that they just <v Vincent Warmerdam>try to keep Bodo just not necessarily as user friendly,

00:20:33 <v Vincent Warmerdam>but they do keep it super stable.

00:20:34 <v Vincent Warmerdam>Like, I get there's a balance there.

00:20:36 <v Michael Kennedy>Yeah.

00:20:37 <v Michael Kennedy>I feel like we still haven't really introduced this cache.

00:20:39 <v Michael Kennedy>We've kind of set the stage.

00:20:41 <v Vincent Warmerdam>Anyway, but yeah, SQLite, super cool.

00:20:44 <v Vincent Warmerdam>How does it work under the hood?

00:20:45 <v Vincent Warmerdam>Well, it's really just like a Python dictionary.

00:20:47 <v Vincent Warmerdam>So you can say something like, hey, make a new cache.

00:20:49 <v Vincent Warmerdam>And then you can do things like cache, square brackets,

00:20:52 <v Vincent Warmerdam>string name, equals, and then whatever <v Vincent Warmerdam>Python object you like can go in. And Python has this serialization method called a pickle.

00:21:00 <v Vincent Warmerdam>Serialization just means, well, you can persist it to disk in some way, and then you can sort of

00:21:05 <v Vincent Warmerdam>get it back into memory again. And that's what disk cache just uses under the hood. So in theory,

00:21:10 <v Vincent Warmerdam>any Python object that you can think of can go into disk cache. The only sort of thing to be

00:21:16 <v Vincent Warmerdam>mindful of is if you have like Python version, if NumPy version 1 in Python 3.6, and you're going

00:21:21 <v Vincent Warmerdam>to inject a whole lot of that into this cache.

00:21:24 <v Vincent Warmerdam>Don't expect those objects to serialize nicely back

00:21:26 <v Vincent Warmerdam>if you're using Python 3.12 and NumPy version 2 or something.

00:21:29 <v Michael Kennedy>Right, because pickle is almost an in-memory representation

00:21:33 <v Michael Kennedy>of the thing.

00:21:34 <v Michael Kennedy>And that may have evolved over time.

00:21:36 <v Michael Kennedy>That's also a true statement about your own classes, <v Michael Kennedy>potentially.

00:21:39 <v Vincent Warmerdam>Yeah, so if you're dealing with multiple Python versions

00:21:41 <v Vincent Warmerdam>and multiple versions of different packages, <v Vincent Warmerdam>there's a little bit of a danger zone to be aware of there.

00:21:47 <v Vincent Warmerdam>That said, for most of the stuff that I do, <v Vincent Warmerdam>that's basically a non-issue.

00:21:50 <v Vincent Warmerdam>But I do get this nice little object that can just store stuff into SQLite and can get it out.

00:21:56 <v Vincent Warmerdam>And it's very general.

00:21:58 <v Vincent Warmerdam>It's going to try to be clever about it.

00:21:59 <v Vincent Warmerdam>Like if you give it an int, it's going to actually store it as an int and not use the pickle format.

00:22:03 <v Vincent Warmerdam>So there's a couple of clever things that it can do.

00:22:06 <v Vincent Warmerdam>And it's also really like a Python dictionary.

00:22:07 <v Vincent Warmerdam>So you can do the square bracket thing.

00:22:09 <v Vincent Warmerdam>You can also do the delete and then cache square bracket thing to delete a key from the cache.

00:22:15 <v Vincent Warmerdam>Just like a Python dictionary, you have the get method.

00:22:17 <v Vincent Warmerdam>So you can say dot get key.

00:22:19 <v Vincent Warmerdam>And if it's missing, you can pass a default value.

00:22:22 <v Vincent Warmerdam>So it's very much like a dictionary.

00:22:25 <v Vincent Warmerdam>I think Bob's your uncle on that one.

00:22:27 <v Vincent Warmerdam>Unless, Michael, I've forgotten something.

00:22:29 <v Vincent Warmerdam>But I think that's the simplest way to do it.

00:22:30 <v Michael Kennedy>Yeah, pretty much.

00:22:31 <v Michael Kennedy>Yeah, I think so.

00:22:32 <v Michael Kennedy>The difference being it's not in memory.

00:22:34 <v Michael Kennedy>It's stored to a file.

00:22:36 <v Michael Kennedy>It happens-- it's not always a SQLite file.

00:22:39 <v Michael Kennedy>But often, it is a SQLite file as its core foundation

00:22:43 <v Michael Kennedy>that it's stored to.

00:22:43 <v Michael Kennedy>So it gives you process restart ability, <v Michael Kennedy>where it still remembers the stuff you cached.

00:22:49 <v Michael Kennedy>It's not like LRU cache.

00:22:50 <v Michael Kennedy>We got to redo it every single time.

00:22:52 <v Michael Kennedy>And I think, I don't know where it is in the docs here,

00:22:56 <v Michael Kennedy>but the thread safety bit of it and the cross-process safety

00:23:00 <v Michael Kennedy>is really nice about, is it persistent?

00:23:03 <v Michael Kennedy>You've got this whole table here, things like, is it persistent?

00:23:06 <v Michael Kennedy>Yes.

00:23:06 <v Michael Kennedy>Is it thread safe?

00:23:07 <v Michael Kennedy>Yes.

00:23:07 <v Michael Kennedy>Is it process safe?

00:23:08 <v Michael Kennedy>Yes.

00:23:10 <v Michael Kennedy>Compared against other things people might choose.

00:23:13 <v Michael Kennedy>And that, honestly, I think that is the other half of the magic.

00:23:17 <v Vincent Warmerdam>Yeah, so especially for your web stuff, I would say that that's the thing you really want.

00:23:21 <v Vincent Warmerdam>And some of that, of course, is just SQLite itself.

00:23:25 <v Vincent Warmerdam>Historically, one reason why people always used to say, like, use Postgres, not SQLite,

00:23:28 <v Vincent Warmerdam>has to do with precisely this concurrency stuff.

00:23:32 <v Vincent Warmerdam>My impression is that SQLite is really good at reading, but writing can be slow if multiple processes do it.

00:23:37 <v Vincent Warmerdam>Some of that, I think, is related to the disk as well.

00:23:39 <v Vincent Warmerdam>I don't know to what extent that has changed.

00:23:41 <v Vincent Warmerdam>But historically, at least, whenever I was doing Django, hanging out at Django events,

00:23:45 <v Vincent Warmerdam>People are always saying, like, just use Postgres <v Vincent Warmerdam>because it's better for the web thing.

00:23:48 <v Vincent Warmerdam>But it is safe, the SQLite.

00:23:51 <v Vincent Warmerdam>It might become slower, but it is thread safe if it's--

00:23:53 <v Vincent Warmerdam>MARK MANDEL: Right.

00:23:54 <v Michael Kennedy>There's actually-- they've thought a lot about in this thing

00:23:58 <v Michael Kennedy>about transactions, concurrency, and basically dealing with that.

00:24:02 <v Michael Kennedy>But it is ultimately, for the most part, <v Michael Kennedy>still SQLite underneath.

00:24:07 <v Michael Kennedy>But the thing with a cache is if you're writing it more

00:24:10 <v Michael Kennedy>than you're reading it, you probably shouldn't have a cache.

00:24:13 <v Michael Kennedy>Yeah.

00:24:13 <v Michael Kennedy>I mean, like...

00:24:15 <v Vincent Warmerdam>That beats the purpose.

00:24:18 <v Michael Kennedy>Exactly.

00:24:18 <v Michael Kennedy>Like, you get no value if you're recreating it.

00:24:21 <v Michael Kennedy>You're only probably just doing overhead and wasting memory or disk space.

00:24:24 <v Michael Kennedy>So it's inherently a situation where it's going to be pretty read-heavy,

00:24:30 <v Michael Kennedy>and SQLite is good at read-heavy scenarios.

00:24:32 <v Vincent Warmerdam>And maybe it's also fair to say, like, the LRU cache that you get with basic Python,

00:24:36 <v Vincent Warmerdam>so also to maybe explain that one, <v Vincent Warmerdam>so the LRU cache is a little bit different because you decorate a function with it,

00:24:41 <v Vincent Warmerdam>and then given the same inputs, one output goes out,

00:24:44 <v Vincent Warmerdam>you can kind of keep track of a dictionary that's in memory.

00:24:47 <v Vincent Warmerdam>If you don't have a lot of stuff to keep in the back of your mind,

00:24:49 <v Vincent Warmerdam>then maybe you don't have to write to disk, right?

00:24:51 <v Vincent Warmerdam>So there's also maybe a reason to just stick to caching mechanisms

00:24:54 <v Vincent Warmerdam>that use Python memory, because I also think, <v Vincent Warmerdam>I would imagine it to be quicker too.

00:24:59 <v Vincent Warmerdam>But maybe that's also...

00:25:01 <v Vincent Warmerdam>Probably, yes.

00:25:01 <v Vincent Warmerdam>That should be quicker.

00:25:02 <v Vincent Warmerdam>It's just that if you're capped at memory, <v Vincent Warmerdam>then you might want to spill to disk,

00:25:05 <v Vincent Warmerdam>and then disk cache becomes interesting too.

00:25:06 <v Michael Kennedy>Right, for example, you have literally zero serialization, deserialization.

00:25:11 <v Michael Kennedy>What you put in LRU cache is the pointer to the object

00:25:14 <v Michael Kennedy>that you're caching, right?

00:25:15 <v Michael Kennedy>If you've got a class or a list that's part of the LRU cache.

00:25:18 <v Vincent Warmerdam>The one thing that is good to mention <v Vincent Warmerdam>is also a really nice feature of disk cache

00:25:21 <v Vincent Warmerdam>is just like LRU cache has a decorator, <v Vincent Warmerdam>so you can decorate a function, disk cache also has that.

00:25:27 <v Vincent Warmerdam>And it works kind of interestingly, too.

00:25:29 <v Vincent Warmerdam>So when you decorate the function, <v Vincent Warmerdam>you do have to be a little bit careful if you use that.

00:25:34 <v Vincent Warmerdam>But then disk cache will--

00:25:36 <v Vincent Warmerdam>I think it will hash the function name and the inputs

00:25:39 <v Vincent Warmerdam>that you pass.

00:25:40 <v Vincent Warmerdam>I don't know if it also hashes the contents of the function.

00:25:45 <v Vincent Warmerdam>Like if you change the function itself, <v Vincent Warmerdam>I don't know if this cache will actually put that

00:25:49 <v Vincent Warmerdam>in a different slots, if that makes sense.

00:25:51 <v Michael Kennedy>Yeah, you can say @cache_memoize, <v Michael Kennedy>which is the design pattern speak for just remember this.

00:25:57 <v Michael Kennedy>Yeah.

00:25:57 <v Michael Kennedy>It takes the arguments.

00:25:59 <v Vincent Warmerdam>And then it has like the Fibonacci sequence, <v Vincent Warmerdam>which is the classic example, of course.

00:26:02 <v Vincent Warmerdam>And like there are some extra things you can set there as well.

00:26:05 <v Vincent Warmerdam>So you can say things like, hey, I think you're able to--

00:26:08 <v Vincent Warmerdam>yeah, you're able to set the expiry.

00:26:10 <v Vincent Warmerdam>So you can say things like, I want to cache this, <v Vincent Warmerdam>but only for the next five minutes or so,

00:26:14 <v Vincent Warmerdam>which can make a lot of sense if you're doing a front page

00:26:16 <v Vincent Warmerdam>kind of a thing.

00:26:17 <v Vincent Warmerdam>So like the Reddit front page or something <v Vincent Warmerdam>like that that updates, but not every second.

00:26:20 <v Vincent Warmerdam>It probably updates once every five minutes <v Vincent Warmerdam>or something like that.

00:26:23 <v Vincent Warmerdam>And then you do want to have something that's cached,

00:26:25 <v Vincent Warmerdam>but then after that, you want the cache <v Vincent Warmerdam>to maybe basically just reset.

00:26:28 <v Vincent Warmerdam>And that is something you can also <v Vincent Warmerdam>control with a few parameters here.

00:26:31 <v Michael Kennedy>Right, that's interesting.

00:26:32 <v Michael Kennedy>There's a couple good use cases that come to mind for me.

00:26:35 <v Michael Kennedy>Like one, if I put this on the function that <v Michael Kennedy>generated the RSS feed for Talk Python,

00:26:39 <v Michael Kennedy>I could just say every one minute <v Michael Kennedy>and then it might be a little bit expensive to compute

00:26:44 <v Michael Kennedy>because it's got a pars, you know, 535 episodes or whatever.

00:26:48 <v Michael Kennedy>But then for one minute, all the subsequent requests,

00:26:50 <v Michael Kennedy>just here's the answer, here's the answer.

00:26:52 <v Michael Kennedy>And then without me managing anything, <v Michael Kennedy>it will just automatically the next minute refresh itself

00:26:58 <v Michael Kennedy>by the nature of how it works, right?

00:27:00 <v Vincent Warmerdam>How much traffic do you get on that endpoint?

00:27:01 <v Vincent Warmerdam>Just roughly, like you're asking.

00:27:02 <v Michael Kennedy>One terabyte of RSS a month.

00:27:05 <v Michael Kennedy>Okay, gotcha.

00:27:06 <v Vincent Warmerdam>Okay, but there you go.

00:27:08 <v Vincent Warmerdam>Like then just doing that like once a minute instead of like many times a minute will be a huge cookie.

00:27:13 <v Michael Kennedy>I would say it's probably more than one request a second.

00:27:17 <v Michael Kennedy>And the file size, the response size of the RSS feed is over a meg.

00:27:21 <v Michael Kennedy>And so it's a non-trivial amount of asking, you know.

00:27:24 <v Vincent Warmerdam>Yeah.

00:27:24 <v Vincent Warmerdam>And then like, and how do you fix that with a whole bunch of infrastructure?

00:27:27 <v Vincent Warmerdam>No, with a decorator.

00:27:28 <v Vincent Warmerdam>Like that feels...

00:27:29 <v Vincent Warmerdam>Exactly.

00:27:30 <v Michael Kennedy>Exactly.

00:27:31 <v Michael Kennedy>You pretty much summed up all the reasons why I'm so excited about this,

00:27:34 <v Michael Kennedy>because it's like you could do all of this complex stuff

00:27:36 <v Michael Kennedy>or just like you could just literally <v Michael Kennedy>in such a simple way,

00:27:41 <v Michael Kennedy>just not recompute it as often.

00:27:43 <v Michael Kennedy>Yeah.

00:27:43 <v Michael Kennedy>Here's the danger.

00:27:44 <v Michael Kennedy>What if there's a race condition?

00:27:46 <v Michael Kennedy>And oh my goodness, two of them sneak in.

00:27:48 <v Michael Kennedy>You know what I mean?

00:27:49 <v Michael Kennedy>Like, okay, so you've done a little bit extra work <v Michael Kennedy>and you throw it away.

00:27:52 <v Vincent Warmerdam>Who cares?

00:27:52 <v Vincent Warmerdam>I want to use Redis now.

00:27:53 <v Vincent Warmerdam>And Redis is cool, <v Vincent Warmerdam>but I've never used it before.

00:27:56 <v Vincent Warmerdam>Better buy a book.

00:27:57 <v Vincent Warmerdam>Okay, no.

00:27:58 <v Vincent Warmerdam>With this cache, if you, <v Vincent Warmerdam>I mean, I'm sure it won't solve everything,

00:28:02 <v Vincent Warmerdam>but this, I make a bit of a joke by saying, <v Vincent Warmerdam>just use a decorator.

00:28:05 <v Vincent Warmerdam>But it's honestly that feeling that this library really

00:28:07 <v Vincent Warmerdam>does give you.

00:28:08 <v Vincent Warmerdam>You can just use it as a decorator, <v Vincent Warmerdam>which has a lot of great use cases.

00:28:12 <v Vincent Warmerdam>You can just use it as a dictionary.

00:28:13 <v Vincent Warmerdam>So it still feels like you're writing Python.

00:28:16 <v Vincent Warmerdam>It's just Python with one concern less.

00:28:19 <v Vincent Warmerdam>And that is the magic.

00:28:20 <v Michael Kennedy>MARK MANDEL: And it takes on so many of the cool aspects

00:28:22 <v Michael Kennedy>of these high-end servers like Postgres or Redis or Valkey.

00:28:27 <v Michael Kennedy>Valkey is sort of the shiny new Redis, right?

00:28:29 <v Vincent Warmerdam>I would actually love to do a Redis benchmark.

00:28:31 <v Vincent Warmerdam>I haven't done that yet.

00:28:32 <v Vincent Warmerdam>But one thing I do wonder with disks are getting so much faster.

00:28:36 <v Michael Kennedy>Yes.

00:28:36 <v Vincent Warmerdam>Right?

00:28:37 <v Vincent Warmerdam>And so you can actually at some point wonder like how much faster is Redis really going to be

00:28:40 <v Vincent Warmerdam>and how much money are you willing to spend on it?

00:28:43 <v Vincent Warmerdam>Because if your cache is huge and it allows to go in memory in Redis,

00:28:47 <v Vincent Warmerdam>it could be wrong, but Redis is fully in memory, I think, right?

00:28:50 <v Michael Kennedy>I believe so.

00:28:51 <v Michael Kennedy>There is a database aspect.

00:28:53 <v Michael Kennedy>Redis is weird because it could be so many.

00:28:54 <v Michael Kennedy>Redis is cool.

00:28:55 <v Michael Kennedy>It can do a lot.

00:28:57 <v Michael Kennedy>But they do have, they actually have benchmarks here on.

00:29:00 <v Vincent Warmerdam>Ah, there you go.

00:29:01 <v Michael Kennedy>Compared against memcached and Redis.

00:29:06 <v Michael Kennedy>And it has the get speed and the write speed.

00:29:08 <v Michael Kennedy>And this is smaller is better.

00:29:10 <v Michael Kennedy>Yeah, look at this.

00:29:11 <v Michael Kennedy>Disc cache beats Redis.

00:29:13 <v Vincent Warmerdam>And I imagine that's because of the network hop or something.

00:29:17 <v Michael Kennedy>Yeah, exactly.

00:29:17 <v Michael Kennedy>I bet it's the network, the network connection.

00:29:20 <v Michael Kennedy>So if you're running it on the same machine, <v Vincent Warmerdam>you would have a different number there.

00:29:24 <v Vincent Warmerdam>Might be good to maybe caveat that.

00:29:25 <v Michael Kennedy>Yeah, it might be.

00:29:26 <v Vincent Warmerdam>I mean, but also that I think that I don't know when they ran this benchmark,

00:29:29 <v Vincent Warmerdam>but I just checked on PyPI.

00:29:32 <v Vincent Warmerdam>This project started in 2016.

00:29:34 <v Vincent Warmerdam>So it might-

00:29:35 <v Michael Kennedy>I bet this is 2016 data right here.

00:29:38 <v Michael Kennedy>If I know how these docs go.

00:29:40 <v Vincent Warmerdam>Yeah, so it could also be that those are old disks <v Vincent Warmerdam>comparing old memories, right?

00:29:45 <v Michael Kennedy>So then this is one of those weird benchmarks.

00:29:47 <v Vincent Warmerdam>You got to really run them every six months or so <v Vincent Warmerdam>for them to remain relevant.

00:29:51 <v Michael Kennedy>Yeah, yeah.

00:29:51 <v Michael Kennedy>I mean, the new NVM, VVM, whatever, disks, <v Vincent Warmerdam>SSD disks are so fast.

00:29:58 <v Vincent Warmerdam>And also they're not memory.

00:29:59 <v Vincent Warmerdam>Memory is expensive nowadays.

00:30:01 <v Vincent Warmerdam>Yes, it is.

00:30:02 <v Vincent Warmerdam>People want to build data centers with them, I've heard.

00:30:04 <v Vincent Warmerdam>Yeah, yeah.

00:30:05 <v Michael Kennedy>And on the cloud there, this is a totally, <v Michael Kennedy>this is another really interesting aspect to discuss.

00:30:11 <v Michael Kennedy>Probably more of a web dev side of things.

00:30:13 <v Michael Kennedy>But if you do LRU caches or even to a bigger degree, <v Michael Kennedy>I run a whole separate server,

00:30:18 <v Michael Kennedy>even if it is just a Docker container <v Michael Kennedy>that holds a bunch of this stuff in memory,

00:30:22 <v Michael Kennedy>that's going to take more memory on your VM <v Michael Kennedy>or your cloud deployment or whatever.

00:30:26 <v Michael Kennedy>And if you just say, well, <v Michael Kennedy>I have this 160 gig hard drive. That's an NVVM high speed drive. Like maybe I could just put a

00:30:33 <v Michael Kennedy>bunch of stuff there and you could really thin down your deployments, not just because it's not in

00:30:39 <v Michael Kennedy>memory in a cache somewhere, but if you're not having any form of cache, you might be able to

00:30:42 <v Michael Kennedy>dramatically lower how much compute you need and avoid them. Right. Like there's layers of how this

00:30:48 <v Vincent Warmerdam>could like shave off. And again, it's one of those things of like, oh, I just, can I pay for disk

00:30:53 <v Vincent Warmerdam>instead? Oh, that's a whole lot cheaper. What else do I got to do? You just got to write a tech

00:30:56 <v Michael Kennedy>creator yeah i think i pay five dollars for uh i think i remember exactly but i pay something like

00:31:03 <v Michael Kennedy>five dollars for 400 gigs of disc there you go and do you know how much 400 gigs of ram will cost

00:31:09 <v Vincent Warmerdam>on the cloud um well i mean more there goes the college tuition but the exactly sorry kids yeah

00:31:18 <v Vincent Warmerdam>no but like it's um and again like i vividly remember when i started college people were

00:31:23 <v Vincent Warmerdam>always saying oh keep it in memory because it's way faster than disc but i i think we got to let

00:31:26 <v Vincent Warmerdam>a lot of that stuff just go.

00:31:28 <v Michael Kennedy>Interesting idea. Yeah, I agree, though.

00:31:30 <v Michael Kennedy>I think you're right. But anyway, <v Vincent Warmerdam>so far, we've mainly

00:31:34 <v Vincent Warmerdam>been discussing the mechanics of it, but <v Vincent Warmerdam>there's some bills and whistles I think we should maybe also mention.

00:31:38 <v Vincent Warmerdam>The expiry definitely is one of them.

00:31:41 <v Vincent Warmerdam>There's also first in, first out <v Vincent Warmerdam>kinds of things that you can do.

00:31:45 <v Vincent Warmerdam>So maybe if we could go back to that.

00:31:46 <v Michael Kennedy>Yeah, there's a bunch of features, actually, <v Michael Kennedy>there.

00:31:50 <v Michael Kennedy>The expiry is interesting already <v Michael Kennedy>because

00:31:54 <v Michael Kennedy>if you do regular, say, LRU caching <v Michael Kennedy>like that, you have a natural.

00:31:59 <v Michael Kennedy>It's going to go away when the process <v Michael Kennedy>restarts, and that's going to happen eventually.

00:32:03 <v Michael Kennedy>Even in a web app, you ship a new <v Michael Kennedy>version, you've got to restart the thing or something.

00:32:07 <v Michael Kennedy>But when it goes to the disk, <v Michael Kennedy>it starts to pile up, right? That's why I have this little admin

00:32:10 <v Michael Kennedy>page that has, like, how big is this <v Michael Kennedy>and a button to clear it.

00:32:14 <v Vincent Warmerdam>In fairness, that can blow up <v Vincent Warmerdam>to a lot of Palooza as well, if you're not careful.

00:32:18 <v Michael Kennedy>It is a concern. Yeah, it is definitely a concern.

00:32:20 <v Michael Kennedy>And so I think a big way to fix it, <v Michael Kennedy>like the expiry, we already talked about why it's

00:32:24 <v Michael Kennedy>interesting for stale data.

00:32:26 <v Michael Kennedy>You want it to just like auto refresh, <v Michael Kennedy>but it's also just a safeguard of maybe we'll just recompute this once a month.

00:32:32 <v Michael Kennedy>It's really quick and easy.

00:32:34 <v Michael Kennedy>Yeah.

00:32:34 <v Michael Kennedy>Maybe just don't let it linger forever.

00:32:37 <v Vincent Warmerdam>I think what you can also do though, if I'm not mistaken,

00:32:39 <v Vincent Warmerdam>is I think you can also set like a max key size.

00:32:41 <v Vincent Warmerdam>So you can say this cache, this particular disk cache can only have 10,000 keys in it

00:32:46 <v Vincent Warmerdam>and use a first in first out kind of a principle.

00:32:49 <v Michael Kennedy>Right, or last accessed or number of times.

00:32:52 <v Michael Kennedy>There's a bunch of metrics there actually for how that works.

00:32:54 <v Michael Kennedy>Yeah, it's pretty interesting.

00:32:56 <v Vincent Warmerdam>I've never had to fiddle around with them too much,

00:32:59 <v Vincent Warmerdam>but it's one of those things where even if I don't need it right now,

00:33:02 <v Vincent Warmerdam>it is just a relief to see that the feature is there

00:33:04 <v Vincent Warmerdam>in case you might need it later.

00:33:06 <v Michael Kennedy>Yeah, yeah, for sure.

00:33:08 <v Michael Kennedy>Let me see if I can find out where that is.

00:33:09 <v Michael Kennedy>I don't know, keep bouncing around the same spot.

00:33:11 <v Michael Kennedy>I've got it, let's just talk through them.

00:33:12 <v Michael Kennedy>So I think the tags and expiries are pretty interesting,

00:33:15 <v Michael Kennedy>but then there's also, I think, something that surprised me a little bit

00:33:18 <v Michael Kennedy>is these different kinds of caches.

00:33:20 <v Michael Kennedy>So there's like a fan out cache.

00:33:23 <v Michael Kennedy>Have you looked at these?

00:33:24 <v Michael Kennedy>These are interesting.

00:33:25 <v Vincent Warmerdam>I remember reading about, I've never used them, but I do remember reading them.

00:33:29 <v Michael Kennedy>So let me give you the quick rundown and then you'll understand instantly.

00:33:32 <v Michael Kennedy>It's super quick.

00:33:32 <v Michael Kennedy>So it uses sharding, which is a database term, right?

00:33:36 <v Michael Kennedy>So sharding is like, if I've got a billion records and it's a challenge to put them all

00:33:40 <v Michael Kennedy>in the same database entry, database table or server, I could actually have 10 servers

00:33:45 <v Michael Kennedy>and decide, well, okay, what we're going to do is if it's a number of the ID of the user,

00:33:49 <v Michael Kennedy>if the first number is one, then they go into this database.

00:33:52 <v Michael Kennedy>If it's two, then they go in that, right?

00:33:54 <v Michael Kennedy>So 2005 goes into the second database and so on.

00:33:57 <v Michael Kennedy>So it does that as well.

00:33:59 <v Michael Kennedy>This is one of the things it does to try to avoid the issues of multiple writers, I believe.

00:34:04 <v Michael Kennedy>So you're less likely to write to the same database.

00:34:07 <v Michael Kennedy>So it doesn't have to lock as hard.

00:34:08 <v Vincent Warmerdam>It's kind of what you do where you say, oh, I've got this for the YouTube link.

00:34:12 <v Vincent Warmerdam>And I've got this for the HTML markdown.

00:34:14 <v Vincent Warmerdam>Except those are like different chunks because of their use case.

00:34:19 <v Vincent Warmerdam>But you can also imagine, well, I've got this long list of users.

00:34:22 <v Vincent Warmerdam>but I still want to benefit from having multiple SQLite instances.

00:34:25 <v Vincent Warmerdam>And I suppose that's when you use this, right?

00:34:26 <v Michael Kennedy>Yeah, I think that is why.

00:34:28 <v Michael Kennedy>So it says, it's built on top of cache, cache fanout, automatically shards.

00:34:33 <v Michael Kennedy>Automatically, you just said how many you want, it figures out what that means.

00:34:36 <v Michael Kennedy>And it says, while readers and writers don't block each other,

00:34:38 <v Michael Kennedy>writers block other writers.

00:34:39 <v Michael Kennedy>Therefore, a shard for every concurrent writer suggests it.

00:34:44 <v Michael Kennedy>This will depend on your scenario, default is eight.

00:34:46 <v Michael Kennedy>So that's pretty cool.

00:34:48 <v Vincent Warmerdam>Yeah, okay.

00:34:48 <v Vincent Warmerdam>And presumably internally does something like hashing to figure out how to like

00:34:53 <v Michael Kennedy>send it around the shards.

00:34:55 <v Michael Kennedy>Right.

00:34:55 <v Michael Kennedy>The keys themselves have to be hashable anyway, probably.

00:34:57 <v Michael Kennedy>So just hashes the key and then shards on like the first couple letters or whatever.

00:35:02 <v Michael Kennedy>Yeah, this is cool.

00:35:03 <v Michael Kennedy>So it avoids the concurrency crashes.

00:35:06 <v Michael Kennedy>The one difference for me, the reason I didn't choose fanout cache is because I want to be

00:35:10 <v Michael Kennedy>able to say, I want to clear all the YouTube IDs, but I want to keep the really expensive

00:35:13 <v Michael Kennedy>to compute hashes.

00:35:15 <v Michael Kennedy>I want to be able to clear stuff if I really have to by category.

00:35:19 <v Michael Kennedy>And I guess you could also do that with tags, but I'm just not that advanced.

00:35:22 <v Vincent Warmerdam>Well, and also keep it simple, right?

00:35:23 <v Vincent Warmerdam>And again, it's one of those things where it's, oh, it's nice to know that this is in here,

00:35:27 <v Vincent Warmerdam>even if you don't use it directly.

00:35:28 <v Vincent Warmerdam>I do agree.

00:35:29 <v Vincent Warmerdam>This is a really nice feature.

00:35:30 <v Michael Kennedy>It is.

00:35:31 <v Michael Kennedy>And I probably will never in my life use it, but it's really cool that it's like, you know,

00:35:34 <v Michael Kennedy>it's one of those things about a library that when you're thinking about picking it, it's

00:35:38 <v Michael Kennedy>like, okay, the core feature is great, but if I outgrow it, what is my next step?

00:35:42 <v Michael Kennedy>Do I have to completely switch to something really different

00:35:45 <v Michael Kennedy>like Redis or Valkey?

00:35:46 <v Michael Kennedy>Or do I just change the class I'm using?

00:35:49 <v Vincent Warmerdam>I had that with this.

00:35:51 <v Vincent Warmerdam>So I actually had that feeling a while ago.

00:35:53 <v Vincent Warmerdam>We're going to get to my example I think a bit later.

00:35:54 <v Vincent Warmerdam>But I was using the Memoize decorator <v Vincent Warmerdam>to decorate a function to properly cache that.

00:36:00 <v Vincent Warmerdam>But the one issue I had is an input to that function

00:36:04 <v Vincent Warmerdam>was a progress bar.

00:36:05 <v Vincent Warmerdam>It's kind of a remote specific thing.

00:36:06 <v Vincent Warmerdam>I wanted this one progress bar to update <v Vincent Warmerdam>from inside of this one function.

00:36:10 <v Vincent Warmerdam>But the downside was that every time <v Vincent Warmerdam>I rerun the notebook, I make a new progress bar object.

00:36:15 <v Vincent Warmerdam>Oh, and that means that the input <v Vincent Warmerdam>has a different object going in.

00:36:17 <v Vincent Warmerdam>MARK MANDEL: So you never actually hit the cache.

00:36:19 <v Vincent Warmerdam>JOHN MUELLER: So, oh my god, I'm never hitting the cache.

00:36:21 <v Vincent Warmerdam>This is horrible.

00:36:23 <v Vincent Warmerdam>Then it turns out the Memoize decorator <v Vincent Warmerdam>also allows you to ignore a couple of the inputs

00:36:27 <v Vincent Warmerdam>of the function.

00:36:28 <v Vincent Warmerdam>So you can also--

00:36:28 <v Vincent Warmerdam>MARK MANDEL: Oh, interesting.

00:36:28 <v Michael Kennedy>Like ignore by keyword or something, keyword argument.

00:36:31 <v Vincent Warmerdam>JOHN MUELLER: Precisely.

00:36:31 <v Vincent Warmerdam>And there's a bunch of use cases for it, and this was one.

00:36:34 <v Vincent Warmerdam>And you can just imagine my relief <v Vincent Warmerdam>after writing the entire notebook to then look at the docs

00:36:39 <v Vincent Warmerdam>and go, oh, sweet.

00:36:42 <v Michael Kennedy>Yeah, that's super sweet.

00:36:43 <v Michael Kennedy>Yeah.

00:36:44 <v Michael Kennedy>Okay.

00:36:45 <v Michael Kennedy>I think there's right below this.

00:36:46 <v Michael Kennedy>Yeah, there's a couple.

00:36:47 <v Michael Kennedy>We can just go down this list here.

00:36:48 <v Michael Kennedy>There's some cool.

00:36:48 <v Michael Kennedy>Oh, Django.

00:36:49 <v Michael Kennedy>So they have a legit Django cache.

00:36:52 <v Vincent Warmerdam>Yeah, yeah, yeah.

00:36:52 <v Michael Kennedy>Straight in.

00:36:53 <v Vincent Warmerdam>Sweet.

00:36:54 <v Vincent Warmerdam>Yeah, I recall a little bit.

00:36:56 <v Vincent Warmerdam>It was like a huge Django following for this thing.

00:36:58 <v Michael Kennedy>Yeah, and I think this is a part why.

00:36:59 <v Michael Kennedy>And when I first saw it, the reason it got sent to me is somebody's like,

00:37:02 <v Michael Kennedy>oh, this disk cache, Django cache is a really cool thing to just drop into Django.

00:37:07 <v Michael Kennedy>And I'm like, that's cool.

00:37:09 <v Michael Kennedy>I'm not using Django, but I admire it.

00:37:11 <v Michael Kennedy>That's why I didn't really look into it until I saw your use case outside of Django.

00:37:14 <v Michael Kennedy>I'm like, oh, okay, I understand how much this can do.

00:37:17 <v Michael Kennedy>So the Django dish cache says it uses the fanout cache,

00:37:20 <v Michael Kennedy>which we just discussed with the sharding, <v Michael Kennedy>to provide a Django-compatible cache interface.

00:37:25 <v Michael Kennedy>And you just do that in your settings file, <v Michael Kennedy>and you just say the back end is diskcache.django cache,

00:37:29 <v Michael Kennedy>and you give it a location.

00:37:31 <v Michael Kennedy>Boom, off it goes, right?

00:37:32 <v Michael Kennedy>So really, really nice.

00:37:33 <v Michael Kennedy>Cool.

00:37:34 <v Michael Kennedy>Yeah, and it sounds like you've done more Django than me.

00:37:37 <v Michael Kennedy>How's this sit with you?

00:37:37 <v Vincent Warmerdam>I mean, to be very clear, I do think Django is really nice and really mature.

00:37:42 <v Vincent Warmerdam>I do sometimes have a bit of a love-hate relationship with it because Django can go really, really deep.

00:37:47 <v Vincent Warmerdam>And some of that configuration stuff definitely can be a little bit in your face.

00:37:51 <v Vincent Warmerdam>So the main thing I just want to observe is doing everything manually inside of Django can be very time-consuming.

00:37:57 <v Vincent Warmerdam>So it's definitely nice to know that someone took the effort to make a proper Django plugin in the way that Django wants it.

00:38:03 <v Vincent Warmerdam>That's definitely the thing to appreciate here.

00:38:05 <v Vincent Warmerdam>I've never really used this in a Django app, to be honest.

00:38:08 <v Michael Kennedy>Yeah.

00:38:09 <v Michael Kennedy>You know, it has a lot of nice settings here.

00:38:11 <v Michael Kennedy>Like you can set the number of shards, the timeout, so in case there's a write or read

00:38:16 <v Michael Kennedy>contention, it can deal with that or it can at least let you know you're failing.

00:38:19 <v Michael Kennedy>It even has a size limit.

00:38:21 <v Vincent Warmerdam>Does it say how you can configure what to cache and whatnot?

00:38:24 <v Vincent Warmerdam>Or is like the-- I've never really used caches in Django in general.

00:38:27 <v Vincent Warmerdam>So I don't know if there's a general cache feature in Django itself that it will just

00:38:31 <v Vincent Warmerdam>plug into or if--

00:38:32 <v Michael Kennedy>I think there is a general cache feature in Django.

00:38:35 <v Michael Kennedy>The Django people are like screaming silently.

00:38:38 <v Michael Kennedy>Yes.

00:38:38 <v Michael Kennedy>I apologize.

00:38:39 <v Michael Kennedy>I know, I know.

00:38:40 <v Michael Kennedy>But I'm pretty sure it's just like a built-in Django cache functionality.

00:38:44 <v Michael Kennedy>Exactly.

00:38:45 <v Michael Kennedy>Yeah, okay.

00:38:46 <v Michael Kennedy>It just routes into this thing.

00:38:47 <v Vincent Warmerdam>Exactly.

00:38:48 <v Vincent Warmerdam>So instead of configuring Redis, you just feed it this and you're good.

00:38:50 <v Vincent Warmerdam>That's the idea.

00:38:51 <v Michael Kennedy>Yes, exactly.

00:38:53 <v Michael Kennedy>Exactly.

00:38:53 <v Michael Kennedy>So there's more.

00:38:54 <v Michael Kennedy>The next one, I have to rage against the machine.

00:38:57 <v Michael Kennedy>I'm sure it's the way, but DQ, pronounced deck.

00:39:01 <v Vincent Warmerdam>Yeah.

00:39:02 <v Michael Kennedy>So I don't know.

00:39:03 <v Michael Kennedy>For me, I still say DQ.

00:39:04 <v Michael Kennedy>I don't say deck.

00:39:04 <v Michael Kennedy>like it's spelled D-E-Q-U-E.

00:39:06 <v Michael Kennedy>And I know a lot of computer science people just call that deck,

00:39:09 <v Michael Kennedy>but this cache dot DQ or deck, however you want to use it.

00:39:13 <v Michael Kennedy>It provides, there's, <v Michael Kennedy>there's a couple of higher order data structures that like operate on what we

00:39:18 <v Michael Kennedy>talked about so far, but to give you data structure behavior, right?

00:39:21 <v Michael Kennedy>Like what we talked about so far is sort of dictionary,

00:39:24 <v Michael Kennedy>but not list or order or any of that.

00:39:26 <v Michael Kennedy>But this, you can actually do go and add a thing.

00:39:31 <v Michael Kennedy>How do we add one?

00:39:32 <v Michael Kennedy>Anyway, you can say like pop left, pop left.

00:39:34 <v Michael Kennedy>over and over to get, I guess you just add it.

00:39:37 <v Vincent Warmerdam>It's kind of like a queue.

00:39:38 <v Michael Kennedy>Yeah, like a queue, exactly.

00:39:40 <v Michael Kennedy>With the goal of taking stuff out of it instead of into it.

00:39:42 <v Michael Kennedy>But you don't normally think of a cache as doing that.

00:39:44 <v Michael Kennedy>But it'd be a cool way actually to fan out work across processes.

00:39:48 <v Vincent Warmerdam>I was about to say, that's a really good, I think, <v Vincent Warmerdam>I mean, there's people that have made, I forget the name,

00:39:55 <v Vincent Warmerdam>the Python queuing system, salary.

00:39:59 <v Vincent Warmerdam>So that one is also built in such a way that you can say like,

00:40:02 <v Vincent Warmerdam>oh, where do you have the list of jobs that still need doing?

00:40:04 <v Vincent Warmerdam>And I think also Redis is used--

00:40:06 <v Vincent Warmerdam>MARK MANDEL: Yeah, right, Redis and Qum.

00:40:07 <v Michael Kennedy>Yeah, exactly.

00:40:08 <v Michael Kennedy>Or Rabbit and Qum as well.

00:40:10 <v Vincent Warmerdam>FRANCESC CAMPOY: Yeah, exactly.

00:40:11 <v Vincent Warmerdam>But you can configure SQLite if you want to, though,

00:40:14 <v Vincent Warmerdam>if I recall with those.

00:40:15 <v Vincent Warmerdam>It's just that in this particular case, <v Vincent Warmerdam>if you don't want to use salary, you can still kind of roll

00:40:19 <v Vincent Warmerdam>your own by using this cache as well.

00:40:20 <v Vincent Warmerdam>I'm assuming it uses the same pickle tricks, <v Vincent Warmerdam>so you can do general Python things

00:40:24 <v Vincent Warmerdam>and if the process breaks for whatever reason, <v Vincent Warmerdam>you still have the jobs that need doing.

00:40:27 <v Michael Kennedy>MARK MANDEL: Yeah, we're still going <v Michael Kennedy>to have to talk about this serialization thing,

00:40:31 <v Michael Kennedy>These pickles.

00:40:33 <v Michael Kennedy>Yes.

00:40:33 <v Michael Kennedy>Not yet.

00:40:34 <v Michael Kennedy>Let's go through this.

00:40:34 <v Michael Kennedy>Let's go through this first.

00:40:35 <v Michael Kennedy>Let's first.

00:40:36 <v Michael Kennedy>Before we get distracted, because it's a deep.

00:40:40 <v Michael Kennedy>So DEC, I guess we'll go DEC.

00:40:44 <v Michael Kennedy>DEC provides an efficient and safe means for cross-thread, cross-process communication.

00:40:49 <v Michael Kennedy>Like, you would never think you would get that out of a cache, really.

00:40:51 <v Vincent Warmerdam>But it's...

00:40:52 <v Michael Kennedy>You would do that in SQLite.

00:40:54 <v Michael Kennedy>Yeah, exactly.

00:40:55 <v Michael Kennedy>But you would do work to do that, right?

00:40:57 <v Michael Kennedy>You would do like transactions.

00:40:58 <v Michael Kennedy>And you would do sorting.

00:40:59 <v Michael Kennedy>You would figure out, well, what if there's contention?

00:41:01 <v Michael Kennedy>I mean, the fact that it's just kind of a pop, it's pretty nice.

00:41:04 <v Vincent Warmerdam>Yeah, that's definitely nice.

00:41:05 <v Michael Kennedy>No, that's definitely true.

00:41:06 <v Vincent Warmerdam>Although one thing that makes it easy in this case, though, is again, it is all running in like one process.

00:41:11 <v Vincent Warmerdam>So it's not like we've got SQLite running in one place and there's 16 Docker containers that can randomly interact with it.

00:41:16 <v Vincent Warmerdam>No, that can, though.

00:41:17 <v Vincent Warmerdam>Is that the case?

00:41:18 <v Michael Kennedy>Because disk cache itself is already cross-process safe.

00:41:23 <v Michael Kennedy>Like, that's why I was so excited about it.

00:41:25 <v Vincent Warmerdam>But it has to be on the same machine, though.

00:41:27 <v Vincent Warmerdam>Like, that's what I do think.

00:41:28 <v Michael Kennedy>Yes, it's got to at least be accessible.

00:41:30 <v Michael Kennedy>RushRite, that is true.

00:41:31 <v Michael Kennedy>because technically there's nothing that says <v Michael Kennedy>you can't put the file anywhere.

00:41:35 <v Michael Kennedy>I think there's mega performance issues <v Michael Kennedy>and locking issues on,

00:41:38 <v Michael Kennedy>it says basically don't use it on network drives.

00:41:40 <v Vincent Warmerdam>Yeah, so that's the thing.

00:41:42 <v Vincent Warmerdam>Some of this is like, okay, you can do the locking.

00:41:44 <v Vincent Warmerdam>You can do all those things.

00:41:45 <v Vincent Warmerdam>You can do it well, <v Vincent Warmerdam>but the practicality of the network overhead

00:41:47 <v Vincent Warmerdam>is something that usually causes a lot of confuffle,

00:41:50 <v Michael Kennedy>at least in my experience.

00:41:51 <v Michael Kennedy>Yeah.

00:41:52 <v Michael Kennedy>Okay, another one is disk cache index, <v Michael Kennedy>which creates a mutable mapping and ordered dictionary.

00:41:57 <v Michael Kennedy>So if you kind of really want to lay into the dictionary side,

00:42:00 <v Vincent Warmerdam>Yeah, you can do that.

00:42:01 <v Michael Kennedy>That one's transactions as well.

00:42:04 <v Michael Kennedy>So you can actually, it has like sort of in-place updates

00:42:06 <v Michael Kennedy>and other things you can do.

00:42:08 <v Michael Kennedy>So you can say, I want to make sure that I'm going to get

00:42:11 <v Michael Kennedy>two different things out of the cache.

00:42:13 <v Michael Kennedy>And I want to make sure that they're not changed <v Michael Kennedy>while I'm doing that, right?

00:42:17 <v Michael Kennedy>Just like you would with threading or something.

00:42:18 <v Michael Kennedy>Yeah, so nothing can happen in between.

00:42:20 <v Vincent Warmerdam>So they both have to come out at the same time.

00:42:22 <v Vincent Warmerdam>So the two values that I get, they were, they were,

00:42:26 <v Vincent Warmerdam>they both existed at the same time in the cache <v Vincent Warmerdam>at the point in time that I was retrieving it.

00:42:29 <v Michael Kennedy>Yeah, yeah, exactly.

00:42:30 <v Michael Kennedy>So just with cache.transact and you just go to town on it.

00:42:35 <v Michael Kennedy>That's pretty straightforward, right?

00:42:36 <v Michael Kennedy>Yep.

00:42:37 <v Michael Kennedy>Are there any more in here?

00:42:38 <v Michael Kennedy>There's a bunch of recipes for like barriers and throttling and probably semaphore-like stuff,

00:42:44 <v Michael Kennedy>but I don't really want to talk about.

00:42:47 <v Michael Kennedy>But you touched on these eviction policies.

00:42:48 <v Michael Kennedy>Here's where I was looking for.

00:42:49 <v Michael Kennedy>There's these different ones here that are kind of cool.

00:42:52 <v Michael Kennedy>Whoops.

00:42:52 <v Michael Kennedy>I didn't go away.

00:42:53 <v Vincent Warmerdam>Yeah, so you can set a maximum to the cache.

00:42:57 <v Vincent Warmerdam>I think you do that by number of items typically in it.

00:43:00 <v Vincent Warmerdam>It could also be the case.

00:43:01 <v Michael Kennedy>Size or something, yeah.

00:43:02 <v Vincent Warmerdam>Yeah, or like total disk size, <v Vincent Warmerdam>maybe we should double check.

00:43:06 <v Michael Kennedy>The default for the disk size is one gig.

00:43:08 <v Michael Kennedy>Yeah, there you go.

00:43:09 <v Michael Kennedy>So there's already a built-in one, yeah.

00:43:11 <v Michael Kennedy>Which might catch people off guard.

00:43:14 <v Michael Kennedy>Much of the stuff is cash, but not always.

00:43:15 <v Michael Kennedy>I don't understand.

00:43:17 <v Vincent Warmerdam>Yeah, you've got to be a little bit mindful of that,

00:43:18 <v Vincent Warmerdam>I suppose.

00:43:19 <v Vincent Warmerdam>But it's the same default, <v Vincent Warmerdam>not to have it go to infinity.

00:43:24 <v Vincent Warmerdam>Agreed.

00:43:26 <v Vincent Warmerdam>Yeah, I guess small screen on my side, but like, yeah, last recently.

00:43:30 <v Michael Kennedy>I'll read them out.

00:43:31 <v Michael Kennedy>I'll read them out for you.

00:43:31 <v Michael Kennedy>Yeah.

00:43:31 <v Michael Kennedy>So we got recent last recently stored as a default, every cache item

00:43:35 <v Michael Kennedy>records the time it was stored in the cache and that adds an index to that

00:43:40 <v Michael Kennedy>field.

00:43:40 <v Michael Kennedy>So it's nice and fast, which is cool.

00:43:41 <v Michael Kennedy>We have, this is, there's some other ones that are more nuanced, like least

00:43:46 <v Michael Kennedy>recently used, not in terms of time, but we've got one that was accessed a hundred

00:43:51 <v Michael Kennedy>times and one that was accessed two times.

00:43:53 <v Michael Kennedy>Even if the one is accessed two times was just accessed,

00:43:55 <v Michael Kennedy>that one's getting kicked out because it's not as useful.

00:43:57 <v Michael Kennedy>I don't know.

00:43:58 <v Michael Kennedy>That's a pretty neat feature.

00:43:59 <v Michael Kennedy>And then the one people would expect is, I don't know,

00:44:02 <v Michael Kennedy>maybe at least recently used.

00:44:04 <v Michael Kennedy>How are you?

00:44:04 <v Vincent Warmerdam>Yeah.

00:44:06 <v Vincent Warmerdam>Yeah, exactly.

00:44:07 <v Vincent Warmerdam>And there's also pruning mechanisms, if I'm not mistaken.

00:44:10 <v Vincent Warmerdam>So there's all sorts of fun.

00:44:11 <v Vincent Warmerdam>You can argue there are bells and whistles until you need them.

00:44:15 <v Vincent Warmerdam>And one thing I have always found is every item that I see here,

00:44:19 <v Vincent Warmerdam>you might not need it right now, <v Vincent Warmerdam>but for every item you see, you do plausibly go,

00:44:23 <v Vincent Warmerdam>oh, but that might be useful later down the line somewhere.

00:44:25 <v Vincent Warmerdam>Like the transaction thing where you retrieve two things at the same time.

00:44:29 <v Vincent Warmerdam>I don't really have a use case for it, but I can imagine it one might,

00:44:33 <v Vincent Warmerdam>where the consistency really matters.

00:44:35 <v Michael Kennedy>Yeah, I can.

00:44:36 <v Michael Kennedy>I could see using the fan out cache.

00:44:38 <v Vincent Warmerdam>Yeah, definitely.

00:44:39 <v Michael Kennedy>But probably not the transaction.

00:44:41 <v Michael Kennedy>But I'm already talking to MongoDB, which doesn't have transactions effectively.

00:44:45 <v Michael Kennedy>So not really.

00:44:47 <v Michael Kennedy>What about performance?

00:44:48 <v Michael Kennedy>Should we talk about your graphs?

00:44:50 <v Michael Kennedy>You brought pictures.

00:44:51 <v Vincent Warmerdam>Yes.

00:44:51 <v Vincent Warmerdam>So that might be, so when you told me like, hey, let's do an episode on disk cache,

00:44:55 <v Vincent Warmerdam>and I kind of told myself, okay, then I need to do some homework.

00:44:58 <v Vincent Warmerdam>Like, I actually have to use it for something real.

00:44:59 <v Vincent Warmerdam>It's a bit complex.

00:45:01 <v Vincent Warmerdam>So what we're going to try and do is we're looking at a chart right now,

00:45:04 <v Vincent Warmerdam>and I'm going to explain to Michael what it does, <v Vincent Warmerdam>and I'm going to try to explain it in such a way such that if you're not watching

00:45:09 <v Vincent Warmerdam>but listening, that you're also going to be fairly interested in what you're seeing.

00:45:12 <v Michael Kennedy>And I'll link to the chart, of course, people can.

00:45:15 <v Vincent Warmerdam>Yeah, so this is all running on GitHub pages, <v Vincent Warmerdam>and the charts that you see here definitely needed a bit of disk cache

00:45:20 <v Vincent Warmerdam>to make it less painful.

00:45:23 <v Vincent Warmerdam>So what I've done is I've downloaded a Git repository.

00:45:26 <v Vincent Warmerdam>What you're looking at right now <v Vincent Warmerdam>is the Git repository for Marimo.

00:45:29 <v Vincent Warmerdam>And then I just take a point in time <v Vincent Warmerdam>and I say, okay, let's just see all the lines of code.

00:45:34 <v Vincent Warmerdam>And then I take another point in time.

00:45:36 <v Vincent Warmerdam>And then I basically just do kind of a Git blame <v Vincent Warmerdam>to see if the line got changed in between.

00:45:41 <v Vincent Warmerdam>So what you're looking at here <v Vincent Warmerdam>is kind of a chart over time

00:45:44 <v Vincent Warmerdam>where it's basically like a bar chart, <v Vincent Warmerdam>but it changes colors as time moves forward.

00:45:49 <v Vincent Warmerdam>and the shape that you see is that things that happened early on,

00:45:53 <v Vincent Warmerdam>well, there's a nice thick slab, <v Vincent Warmerdam>but it gets a little bit thinner and thinner as time moves forward

00:45:57 <v Vincent Warmerdam>because some of those lines of code got replaced.

00:45:59 <v Vincent Warmerdam>But in the case of Marimo, you can see that, you know,

00:46:02 <v Vincent Warmerdam>most of the lines of code actually stay around for a long time

00:46:05 <v Michael Kennedy>and it's kind of like a smooth sedimentary layer every time we move forward.

00:46:10 <v Michael Kennedy>It's compressing a little over time.

00:46:12 <v Michael Kennedy>Like there's the weight of the project has sort of compressed it.

00:46:15 <v Michael Kennedy>So, yeah, it's pretty interesting.

00:46:17 <v Michael Kennedy>So, okay, so that's pretty cool.

00:46:18 <v Vincent Warmerdam>But you can also go to Django.

00:46:21 <v Michael Kennedy>So there's a director on top.

00:46:22 <v Michael Kennedy>MARK MANDEL: So if I go to Django.

00:46:24 <v Michael Kennedy>Oh, you can put this cache in here.

00:46:26 <v Michael Kennedy>This is really different.

00:46:27 <v Michael Kennedy>FRANCESC CAMPOY: Yes.

00:46:28 <v Vincent Warmerdam>MARK MANDEL: What is this telling us?

00:46:29 <v Vincent Warmerdam>FRANCESC CAMPOY: So what you can see here <v Vincent Warmerdam>is that at some point in time, there's

00:46:33 <v Vincent Warmerdam>a huge shift in the sediment.

00:46:35 <v Vincent Warmerdam>There's a lot of light sand and a lot of the dark sand goes away.

00:46:38 <v Vincent Warmerdam>There's also a button that allows you to show the version number.

00:46:41 <v Vincent Warmerdam>So I've--

00:46:42 <v Vincent Warmerdam>yep, there you go.

00:46:43 <v Michael Kennedy>MARK MANDEL: There we go, yeah.

00:46:44 <v Vincent Warmerdam>FRANCESC CAMPOY: So you can see that right before a new version,

00:46:46 <v Vincent Warmerdam>a bunch of changes got introduced or right after.

00:46:49 <v Vincent Warmerdam>It's usually around the version number <v Vincent Warmerdam>that you can see that shift.

00:46:51 <v Michael Kennedy>Right, once the feature freeze is lifted, <v Michael Kennedy>some stuff comes in, PRs come in maybe or something.

00:46:58 <v Michael Kennedy>Yes.

00:46:59 <v Vincent Warmerdam>And one other thing that's actually kind of fun, <v Vincent Warmerdam>if you go--

00:47:02 <v Vincent Warmerdam>there's this project called Psychot LEGO <v Vincent Warmerdam>that you can also go ahead and select.

00:47:05 <v Vincent Warmerdam>And folks--

00:47:06 <v Michael Kennedy>I've heard a pretty cool guy maintains that, yeah.

00:47:09 <v Vincent Warmerdam>Well, so the funny thing is you can see that there's

00:47:11 <v Vincent Warmerdam>a massive shift there at some point.

00:47:12 <v Michael Kennedy>OK.

00:47:13 <v Vincent Warmerdam>That's when we got the new maintainer.

00:47:16 <v Michael Kennedy>Are you on the purple or the green side?

00:47:18 <v Vincent Warmerdam>So there's this dark blue sediment that sort of goes down massively at that point.

00:47:22 <v Vincent Warmerdam>But yeah, no, so but in this case, like the first thing he did is redid all the docs. So we went

00:47:27 <v Vincent Warmerdam>from Sphinx to make docs. And that's like a huge, if you look at the lines of code that changed as

00:47:31 <v Vincent Warmerdam>a result that, you know, that's quite a lot. But if we now start talking about how you make a chart

00:47:36 <v Vincent Warmerdam>like this, you got to imagine like, I take the start of the GitHub history, I take the end of the

00:47:40 <v Vincent Warmerdam>GitHub history, I sample like 100 points in between, and then for every line in every file,

00:47:46 <v Vincent Warmerdam>I do a git blame.

00:47:49 <v Michael Kennedy>MARK MANDEL: I think Django is something like 300,000 lines

00:47:52 <v Michael Kennedy>of code.

00:47:52 <v Michael Kennedy>I mean, that's a lot of--

00:47:54 <v Michael Kennedy>A lot of--

00:47:54 <v Vincent Warmerdam>MARK MANDEL: So that thing took two hours and 15 minutes

00:47:57 <v Vincent Warmerdam>on my M4 Mac.

00:47:58 <v Vincent Warmerdam>And if you go there, you can actually select it.

00:48:02 <v Vincent Warmerdam>That one-- that was a chunky boy, is what I'll say.

00:48:06 <v Vincent Warmerdam>MARK MANDEL: Yeah, 550,000 lines.

00:48:08 <v Vincent Warmerdam>Yeah.

00:48:09 <v Vincent Warmerdam>MARK MANDEL: There you go.

00:48:09 <v Vincent Warmerdam>But you can see that there's one version change, I think,

00:48:12 <v Vincent Warmerdam>where they made a bunch of changes.

00:48:13 <v Vincent Warmerdam>And it could be that--

00:48:14 <v Vincent Warmerdam>MARK MANDEL: Yeah.

00:48:15 <v Vincent Warmerdam>That might have been, again, because I checked the docs

00:48:17 <v Vincent Warmerdam>as well on Markdown files, it might have been a big docs

00:48:20 <v Vincent Warmerdam>change.

00:48:20 <v Vincent Warmerdam>But hopefully by just looking at this, <v Vincent Warmerdam>you can go like, oh yeah, this is probably a notebook somewhere.

00:48:25 <v Vincent Warmerdam>And there's a huge for loop that does threading <v Vincent Warmerdam>and tries to do as much in parallel as possible.

00:48:31 <v Vincent Warmerdam>And there's a progress bar.

00:48:33 <v Vincent Warmerdam>Right?

00:48:34 <v Vincent Warmerdam>Yeah.

00:48:35 <v Vincent Warmerdam>And we don't--

00:48:37 <v Michael Kennedy>Now I see why you had this problem with the caching.

00:48:39 <v Vincent Warmerdam>That's right.

00:48:41 <v Vincent Warmerdam>But yeah, but here's also where the threading came in.

00:48:43 <v Vincent Warmerdam>Because the moment you say this point in time, now do all the files, do the git blame, that's definitely something that can happen in parallel.

00:48:49 <v Vincent Warmerdam>But then for every file, for every point in time, you do want to have something in the cache that says, okay, if I have to restart this notebook for whatever reason, that number is just known.

00:48:58 <v Vincent Warmerdam>Don't check it again.

00:48:59 <v Michael Kennedy>Yeah.

00:48:59 <v Michael Kennedy>Yeah, super interesting.

00:49:00 <v Michael Kennedy>Okay.

00:49:01 <v Michael Kennedy>I wonder if this 4.0 in 2022, is that might be when they switched to async?

00:49:08 <v Michael Kennedy>They started supporting async.

00:49:10 <v Michael Kennedy>It could be docs as well.

00:49:11 <v Michael Kennedy>I'm not sure.

00:49:12 <v Vincent Warmerdam>Well, yeah, so that's kind of the hard thing of some of these charts.

00:49:15 <v Vincent Warmerdam>Like, I could expand these charts by saying things like,

00:49:18 <v Vincent Warmerdam>okay, only the Python files, et cetera.

00:49:22 <v Vincent Warmerdam>But, like, the way that this is hosted, <v Vincent Warmerdam>this is, like, really using the disk as a cache

00:49:27 <v Vincent Warmerdam>because all these charts are Altair charts, <v Vincent Warmerdam>and you can save them to disk,

00:49:29 <v Vincent Warmerdam>and then you can easily upload them to GitHub pages.

00:49:32 <v Vincent Warmerdam>So I do everything in disk cache to make sure that if I,

00:49:35 <v Vincent Warmerdam>for whatever reason, the notebook fails, <v Vincent Warmerdam>I don't have to sort of do anything fancy to get it back up.

00:49:41 <v Vincent Warmerdam>But then once it's time to actually put it on the site,

00:49:44 <v Vincent Warmerdam>I could use disk cache to show the charts, <v Vincent Warmerdam>but then I would need a server.

00:49:47 <v Vincent Warmerdam>So actually using disk to actually just serve some files

00:49:51 <v Vincent Warmerdam>is also just a pretty fine and good idea.

00:49:54 <v Vincent Warmerdam>There are some things on the Marimo side <v Vincent Warmerdam>where we are also hoping to maybe give better caching tools

00:50:00 <v Vincent Warmerdam>to the library itself.

00:50:02 <v Vincent Warmerdam>It's just that when I was doing this, <v Vincent Warmerdam>I actually found a bug in our caching layer,

00:50:05 <v Vincent Warmerdam>so then I switched back to disk cache.

00:50:07 <v Michael Kennedy>You know what?

00:50:07 <v Michael Kennedy>Look, that's valuable.

00:50:08 <v Michael Kennedy>That's maybe not the way you will find, but it's valuable.

00:50:11 <v Vincent Warmerdam>It's-- oh, so one thing you learn is that caching is actually

00:50:15 <v Vincent Warmerdam>hard to get right.

00:50:16 <v Michael Kennedy>Oh, it is.

00:50:17 <v Vincent Warmerdam>It is.

00:50:18 <v Michael Kennedy>Very hard.

00:50:18 <v Vincent Warmerdam>It's on par with naming things.

00:50:22 <v Michael Kennedy>It is one of the two things that goes wrong--

00:50:25 <v Michael Kennedy>naming things, cache invalidation, and off by one errors.

00:50:28 <v Vincent Warmerdam>Yes, exactly.

00:50:29 <v Michael Kennedy>It's the middle one.

00:50:30 <v Vincent Warmerdam>Yeah.

00:50:32 <v Vincent Warmerdam>Dad jokes are amazing.

00:50:33 <v Vincent Warmerdam>Anyway, so one thing about this repo, by the way, <v Vincent Warmerdam>this is all my--

00:50:38 <v Vincent Warmerdam>we're going to add a link to the show notes.

00:50:40 <v Vincent Warmerdam>There is a notebook, so if you feel like adding your own project

00:50:43 <v Vincent Warmerdam>that you want to just add, feel free to spend your compute

00:50:46 <v Vincent Warmerdam>resources two and a half hours to add a popular project.

00:50:49 <v Vincent Warmerdam>I would love to have that.

00:50:50 <v Vincent Warmerdam>One thing I think will be cool with these sorts of charts

00:50:52 <v Vincent Warmerdam>is to see what will change when LLMs kind of get into the mix.

00:50:55 <v Vincent Warmerdam>Do we see more code shifts happen if more LLMs get used

00:50:59 <v Vincent Warmerdam>for these libraries?

00:50:59 <v Michael Kennedy>MARK MANDEL: Very interesting.

00:51:01 <v Vincent Warmerdam>I don't know if more code--

00:51:02 <v Michael Kennedy>old code will get changed, but they are verbose code writers,

00:51:06 <v Michael Kennedy>those things.

00:51:06 <v Vincent Warmerdam>Yes.

00:51:07 <v Vincent Warmerdam>So this, assuming we can do this over time <v Vincent Warmerdam>and we're going to start tracking this,

00:51:13 <v Vincent Warmerdam>I'm calling this code archaeology.

00:51:15 <v Vincent Warmerdam>I do think it will be an interesting chart.

00:51:18 <v Vincent Warmerdam>As is, I think it's already quite interesting to see differences

00:51:20 <v Vincent Warmerdam>between different projects.

00:51:21 <v Vincent Warmerdam>I think if you go to sentence transformers, <v Vincent Warmerdam>you can also see when the project got moved from an academic lab

00:51:25 <v Vincent Warmerdam>to hugging face.

00:51:26 <v Vincent Warmerdam>So there are interesting things you can see with these charts.

00:51:30 <v Vincent Warmerdam>But you are going through every file, every line, <v Michael Kennedy>get blame 100 times.

00:51:35 <v Vincent Warmerdam>Yeah, a lot.

00:51:36 <v Michael Kennedy>You got to do 100 times per line as well.

00:51:39 <v Vincent Warmerdam>Well, so the start of the project with a Git repository,

00:51:42 <v Vincent Warmerdam>and then to make a chart like this, <v Vincent Warmerdam>you got a sample over the entire timeline.

00:51:46 <v Vincent Warmerdam>And it is a bit cheeky because sometimes you can go like,

00:51:48 <v Vincent Warmerdam>OK, but there's a character that changed because of a linter.

00:51:51 <v Vincent Warmerdam>And then is that really a change?

00:51:53 <v Vincent Warmerdam>Does it really matter?

00:51:55 <v Michael Kennedy>It's whoever decided to run the format on the thing or whatever.

00:52:00 <v Vincent Warmerdam>We're looking at the Django chart.

00:52:01 <v Vincent Warmerdam>It could also just be that black just got an update

00:52:03 <v Vincent Warmerdam>or something like that, right?

00:52:03 <v Vincent Warmerdam>Yeah, exactly.

00:52:04 <v Vincent Warmerdam>It's also possible.

00:52:06 <v Michael Kennedy>It's very possible.

00:52:07 <v Vincent Warmerdam>It's unlikely, but it's not impossible, let me say.

00:52:09 <v Vincent Warmerdam>But yeah, anyway.

00:52:11 <v Vincent Warmerdam>Yeah, this was one of the benchmarks <v Vincent Warmerdam>that I did with disk cache that I thought was pretty amusing

00:52:16 <v Vincent Warmerdam>and pretty interesting.

00:52:18 <v Vincent Warmerdam>But there's this one other feature <v Vincent Warmerdam>that I think we should also talk about, which

00:52:21 <v Vincent Warmerdam>is that if you want to, disk cache actually lets you

00:52:24 <v Vincent Warmerdam>do the serialization yourself.

00:52:26 <v Vincent Warmerdam>So normally, what it would do is it would say, <v Vincent Warmerdam>like, OK, let's do the pickle thing.

00:52:31 <v Vincent Warmerdam>And it's a bit clever, right?

00:52:32 <v Vincent Warmerdam>So if the thing you're storing is like an integer, <v Vincent Warmerdam>doesn't go through the whole pickle thing and just stores it as an integer there's these native types

00:52:38 <v Michael Kennedy>that sqlite has and then you know it's able to do something clever but right as soon as it becomes

00:52:42 <v Michael Kennedy>like a custom class or a list of weird things then yeah then then it's i personally don't like it

00:52:49 <v Michael Kennedy>pickling i would i would prefer that it makes me do something it's i think it's weird well so the

00:52:53 <v Vincent Warmerdam>thing is you can write your own disk class and then what you can do is you can pass set disk class

00:52:58 <v Vincent Warmerdam>onto uh the disk cache itself and i'm just kind of wondering like when might it make sense to do

00:53:03 <v Vincent Warmerdam>this sort of a thing and if you go to the docs there's actually like a really good example just

00:53:07 <v Michael Kennedy>right there which is jason yeah i i lost your example if i'll get it back if you type disk

00:53:13 <v Vincent Warmerdam>you'll find it so jason has this interesting thing the it is text if you think about it but

00:53:18 <v Vincent Warmerdam>it's text that has a bit of structure and that means that there are these compression libraries

00:53:23 <v Vincent Warmerdam>you can actually run on them and especially if you have like a pattern that repeats itself let's say

00:53:28 <v Vincent Warmerdam>a list of users or something like that and there's always the user key and there's always maybe the

00:53:32 <v Vincent Warmerdam>the email key and those things just repeat themselves all over the place,

00:53:36 <v Vincent Warmerdam>then there is an opportunity to, <v Vincent Warmerdam>there's this library called zlib where you can just take that string,

00:53:41 <v Vincent Warmerdam>you can compress it and then that compressed representation can go into disk cache instead.

00:53:46 <v Vincent Warmerdam>Yeah, I figured that sounds like a lot of fun.

00:53:49 <v Vincent Warmerdam>You can just grab the implementation there.

00:53:51 <v Vincent Warmerdam>I have this notebooks repository where I have LLMs just write fun little notebooks.

00:53:55 <v Vincent Warmerdam>I always check the results obviously just to be clear on that.

00:53:58 <v Vincent Warmerdam>But one thing that was I think pretty cool to see, <v Vincent Warmerdam>if you just do the normal data type and you pickle it, then you get a certain size. And if you just

00:54:08 <v Vincent Warmerdam>have a very short, normal Python dictionary basic thing, then it's negligible. You shouldn't use this

00:54:14 <v Vincent Warmerdam>JSON trick. But the moment you get text heavy, there's just a lot of text that you're inputting

00:54:19 <v Vincent Warmerdam>there and there's some repetition of characters. Or if you really do something that's highly

00:54:23 <v Vincent Warmerdam>compressible, it is not unheard of to get like 80%, 90% savings

00:54:30 <v Vincent Warmerdam>on your disk space, basically.

00:54:32 <v Vincent Warmerdam>Now, there is a little bit of overhead <v Vincent Warmerdam>because you were doing the compression and decompression.

00:54:36 <v Vincent Warmerdam>But if you're doing text-heavy stuff, <v Vincent Warmerdam>this is something that can actually save you a whole bunch.

00:54:40 <v Vincent Warmerdam>And I can imagine for LLMs, this would also be a win.

00:54:43 <v Michael Kennedy>OK.

00:54:43 <v Michael Kennedy>So this JSON disk, not only does it serialize to and from JSON,

00:54:47 <v Michael Kennedy>which I think is safer.

00:54:49 <v Michael Kennedy>It can be a pain if you had date times.

00:54:51 <v Vincent Warmerdam>You've got to do something about that.

00:54:52 <v Vincent Warmerdam>or JSON or something like that.

00:54:53 <v Vincent Warmerdam>You can.

00:54:54 <v Michael Kennedy>Yeah, yeah, I think.

00:54:55 <v Michael Kennedy>But then it's using Zlib here.

00:54:57 <v Michael Kennedy>You know, I just actually did something like this <v Michael Kennedy>for just something in my database.

00:55:00 <v Michael Kennedy>It had nothing to do with caching.

00:55:02 <v Michael Kennedy>But these records are holding tons of text <v Michael Kennedy>for something sort of tangential to the podcast.

00:55:10 <v Michael Kennedy>And I'm like, I don't really want to put 100K of text

00:55:13 <v Michael Kennedy>that I'm not going to query against or search <v Michael Kennedy>into the database.

00:55:17 <v Michael Kennedy>So I used Python's XZ implementation.

00:55:20 <v Michael Kennedy>And like you said.

00:55:21 <v Vincent Warmerdam>There's a bunch of compression algorithms you could use.

00:55:22 <v Michael Kennedy>It was way fast.

00:55:23 <v Michael Kennedy>So I just store it as bytes now, and it's like a tenth the size.

00:55:26 <v Michael Kennedy>It's great.

00:55:26 <v Michael Kennedy>So I guess this is the same, but for the cache back end, right?

00:55:29 <v Vincent Warmerdam>Yeah.

00:55:30 <v Vincent Warmerdam>And I think-- well, you can see, I think Zlib <v Vincent Warmerdam>is being used internally.

00:55:33 <v Michael Kennedy>Yeah.

00:55:33 <v Michael Kennedy>I mean, it's not XZ, but it's the same idea.

00:55:36 <v Vincent Warmerdam>Yeah, exactly.

00:55:38 <v Vincent Warmerdam>And there's always new compression algorithms.

00:55:40 <v Vincent Warmerdam>Like, feel free to check whatever makes sense.

00:55:42 <v Vincent Warmerdam>But the fact that you have one very cool example <v Vincent Warmerdam>to add on the docs, because you can just copy and paste it.

00:55:47 <v Vincent Warmerdam>A lot of people benefit from it.

00:55:48 <v Vincent Warmerdam>But why stop here?

00:55:50 <v Michael Kennedy>Because this is the company you can do for JSON.

00:55:52 <v Vincent Warmerdam>What else can you do?

00:55:53 <v Michael Kennedy>Before we move on, though, if I were writing this, <v Michael Kennedy>I would recommend using microJSON or ORJSON

00:56:00 <v Michael Kennedy>or whatever, some of the more high performance versions

00:56:03 <v Michael Kennedy>right there.

00:56:03 <v Vincent Warmerdam>Yeah, and I think ORJSON--

00:56:05 <v Vincent Warmerdam>I mean, performance is cool.

00:56:07 <v Vincent Warmerdam>The reason I use ORJSON a lot more <v Vincent Warmerdam>has to do with the types that it supports.

00:56:10 <v Vincent Warmerdam>So it can accept the NumPy arrays, for example, <v Vincent Warmerdam>and just listifies it.

00:56:14 <v Vincent Warmerdam>And I think it has a few things with dates as well.

00:56:17 <v Vincent Warmerdam>It just has a slightly better support for a few things.

00:56:19 <v Michael Kennedy>OK, good to know.

00:56:20 <v Michael Kennedy>All right, where are we going?

00:56:21 <v Michael Kennedy>What's next?

00:56:23 <v Vincent Warmerdam>Numpy arrays.

00:56:24 <v Vincent Warmerdam>OK.

00:56:25 <v Vincent Warmerdam>So a lot of people like to do things with embeddings nowadays.

00:56:29 <v Vincent Warmerdam>So like text thing goes in, some sort of array thing comes out.

00:56:31 <v Vincent Warmerdam>And then hopefully, if two texts are similar, <v Vincent Warmerdam>then the arrays are also similar.

00:56:35 <v Vincent Warmerdam>So you can do all sorts of fun little lookups.

00:56:37 <v Vincent Warmerdam>And I do a fair share of doing things with embeddings.

00:56:40 <v Vincent Warmerdam>And embeddings are also not notoriously expensive <v Vincent Warmerdam>to calculate, but still pretty expensive to calculate.

00:56:46 <v Vincent Warmerdam>OK, but you can write your full Python thing in there.

00:56:48 <v Vincent Warmerdam>So if you compare storing NumPy as bytes compared to that

00:56:54 <v Vincent Warmerdam>to a pickle, it's actually even.

00:56:55 <v Vincent Warmerdam>There's very little to gain there.

00:56:57 <v Vincent Warmerdam>But one thing you could do is you could say, well, <v Vincent Warmerdam>let's maybe bring it down to float 16.

00:57:03 <v Vincent Warmerdam>That's a thing you can do.

00:57:04 <v Vincent Warmerdam>You can sort of say, before we save it, <v Vincent Warmerdam>we actually make it just a little bit less accurate

00:57:09 <v Vincent Warmerdam>on the numeric part of it.

00:57:10 <v Vincent Warmerdam>But that'll save us a whole bunch of disk space.

00:57:11 <v Michael Kennedy>So that's already kind of old.

00:57:13 <v Michael Kennedy>Well, you need it to be super precise <v Michael Kennedy>when it's involved in calculations.

00:57:17 <v Michael Kennedy>But then in the end, if you're not going to report the numbers

00:57:20 <v Michael Kennedy>to great decimal places, maybe going down is good, yeah.

00:57:23 <v Vincent Warmerdam>Yeah, it depends on the use case.

00:57:25 <v Vincent Warmerdam>But typically, you could argue maybe a 1% difference

00:57:28 <v Vincent Warmerdam>in similarity if we have 100x savings on disk.

00:57:32 <v Vincent Warmerdam>That'll be kind of a win.

00:57:34 <v Vincent Warmerdam>So one thing I was sort of focusing on is just this--

00:57:37 <v Vincent Warmerdam>you can do things like, OK, come up <v Vincent Warmerdam>with your own little weird data structure where you say,

00:57:42 <v Vincent Warmerdam>OK, let's pretend we're going to quantize the whole thing.

00:57:45 <v Vincent Warmerdam>So we're going to calculate the quantiles of the float values that it can take.

00:57:50 <v Vincent Warmerdam>And we're going to take basically 256 buckets.

00:57:55 <v Vincent Warmerdam>We're going to store the scale.

00:57:57 <v Vincent Warmerdam>We're going to store the mean.

00:57:58 <v Vincent Warmerdam>And then we're going to store in what bucket the number was in.

00:58:01 <v Vincent Warmerdam>And you can turn that into a string representation.

00:58:03 <v Vincent Warmerdam>These things are pretty fun to write.

00:58:05 <v Vincent Warmerdam>Nice.

00:58:06 <v Vincent Warmerdam>And yeah, and then you scroll down into your big notebook and then you find this.

00:58:12 <v Vincent Warmerdam>There you go.

00:58:13 <v Vincent Warmerdam>That's a retrieval time.

00:58:14 <v Vincent Warmerdam>I think I got like a 4x improvement in terms of like disk space being saved.

00:58:20 <v Vincent Warmerdam>It was like a 1% similarity score that I had to give up for doing things like this.

00:58:24 <v Vincent Warmerdam>Mileage can vary, of course, but like, again, these are fun things to sort of start playing with

00:58:29 <v Vincent Warmerdam>because you have access to the way that you write that down.

00:58:32 <v Vincent Warmerdam>So that was also like a fun little exercise to do.

00:58:36 <v Michael Kennedy>Yeah.

00:58:36 <v Michael Kennedy>Could you save NumPy arrays by just putting up, just converting it to bytes?

00:58:41 <v Michael Kennedy>There's probably some efficient.

00:58:42 <v Michael Kennedy>You know what?

00:58:43 <v Michael Kennedy>What about a parquet file?

00:58:45 <v Michael Kennedy>Like in an in-memory Parquet file, then you just say,

00:58:47 <v Michael Kennedy>here's the value in bytes.

00:58:50 <v Vincent Warmerdam>So I tried the bytes thing and compared it to the pickle thing,

00:58:53 <v Vincent Warmerdam>and that was basically the same size.

00:58:55 <v Michael Kennedy>OK.

00:58:55 <v Vincent Warmerdam>That barely led to anything.

00:58:57 <v Vincent Warmerdam>About the Parquet one, I mean--

00:59:00 <v Vincent Warmerdam>You do get compression.

00:59:01 <v Vincent Warmerdam>Well, yeah, but I could be wrong on this one.

00:59:03 <v Vincent Warmerdam>But I think Parquet is optimized to be a disk representation.

00:59:07 <v Vincent Warmerdam>And then once you want to have it in memory, <v Vincent Warmerdam>it becomes an arrow representation.

00:59:11 <v Vincent Warmerdam>I see.

00:59:11 <v Vincent Warmerdam>Yeah, probably.

00:59:12 <v Vincent Warmerdam>So in that sense, what I would do is, OK, <v Vincent Warmerdam>if you have something in Arrow, you use this cache

00:59:16 <v Vincent Warmerdam>to make sure it's written as parquet.

00:59:18 <v Vincent Warmerdam>But then you have to be-- you kind of have <v Michael Kennedy>to know what you're doing if you're going to make parquet

00:59:23 <v Vincent Warmerdam>files.

00:59:24 <v Vincent Warmerdam>And also, the benefit of a parquet file <v Vincent Warmerdam>is that you have one huge table.

00:59:27 <v Vincent Warmerdam>Because then--

00:59:27 <v Vincent Warmerdam>Right, you can scan it, yeah.

00:59:28 <v Vincent Warmerdam>Yeah, it's a columnar format.

00:59:30 <v Vincent Warmerdam>So then if I were a column, boy, would I <v Vincent Warmerdam>want to have all the rows in me.

00:59:35 <v Vincent Warmerdam>So in that sense, what you--

00:59:38 <v Vincent Warmerdam>yeah, so in that sense, what I would do instead <v Vincent Warmerdam>is if you, for whatever reason, you just have a lot of data,

00:59:43 <v Vincent Warmerdam>It's still kind of a cache, but it makes more sense to store all of it in like a huge parquet file.

00:59:47 <v Vincent Warmerdam>In parquet, you can store a partition.

00:59:49 <v Vincent Warmerdam>So you can say this one column that's partitioned, a date would be like a very typical thing to partition on.

00:59:54 <v Vincent Warmerdam>And then if you point polars to like parquet, but you say, I only want to have this date,

00:59:58 <v Vincent Warmerdam>it can sort of do the forward scan and only pick the rows that you're interested in.

01:00:03 <v Vincent Warmerdam>And I would imagine that that would beat anything we might do with this cache, especially if the table is big.

01:00:09 <v Michael Kennedy>So you don't always want to cache stuff.

01:00:11 <v Michael Kennedy>Like I said, I actually don't avoid hitting the Mongo database

01:00:15 <v Michael Kennedy>a lot for my projects because it's like the response time

01:00:18 <v Michael Kennedy>is quick enough and might as well.

01:00:20 <v Michael Kennedy>I want to take two little avenues here.

01:00:22 <v Michael Kennedy>But the first one is, what about DuckDB?

01:00:25 <v Michael Kennedy>I know at least on the data science side and the analytics

01:00:28 <v Michael Kennedy>side, DuckDB is really popular, really well respected,

01:00:31 <v Michael Kennedy>really fast.

01:00:32 <v Michael Kennedy>Maybe you don't even cache it.

01:00:33 <v Michael Kennedy>Maybe you just use DuckDB as a thing.

01:00:36 <v Vincent Warmerdam>How do you feel about that?

01:00:37 <v Vincent Warmerdam>I mean, DuckDB does solve a very different problem <v Vincent Warmerdam>than SQLite or Postgres in a way.

01:00:42 <v Vincent Warmerdam>So I don't believe-- to name one thing, <v Vincent Warmerdam>I believe DuckDB does assume that everything under the hood

01:00:47 <v Vincent Warmerdam>is immutable.

01:00:49 <v Vincent Warmerdam>So it will never be ASCID compliant, <v Vincent Warmerdam>because it doesn't necessarily have to be.

01:00:52 <v Vincent Warmerdam>You can still insert rows, if I'm not mistaken.

01:00:54 <v Vincent Warmerdam>But the use case is just assumed <v Vincent Warmerdam>to be analytical in general.

01:00:58 <v Vincent Warmerdam>That like--

01:00:58 <v Vincent Warmerdam>I see.

01:00:59 <v Vincent Warmerdam>--it's really designed to sort of fit that use case.

01:01:03 <v Vincent Warmerdam>You can insert rows, though.

01:01:04 <v Michael Kennedy>So like--

01:01:05 <v Michael Kennedy>I mean, you might be caching data science things <v Michael Kennedy>that you're only computing once.

01:01:08 <v Michael Kennedy>Like, for example, your charts.

01:01:11 <v Michael Kennedy>Once you've computed that, it's not going to change because it's historical.

01:01:14 <v Vincent Warmerdam>I mean, I might want to rerun it a month later or something like that.

01:01:16 <v Vincent Warmerdam>That's something I might want to do.

01:01:18 <v Vincent Warmerdam>And in that particular case, it would be cool if the sampling is the same

01:01:21 <v Vincent Warmerdam>and I just want to add one sample at the end that all those samples I had before,

01:01:25 <v Vincent Warmerdam>that those are in a cache somewhere.

01:01:26 <v Michael Kennedy>Or maybe you want faster, better resolution.

01:01:29 <v Michael Kennedy>Instead of going 100, you're going to go to 1,000 points,

01:01:31 <v Michael Kennedy>but you could do 10% less because those are done, right?

01:01:34 <v Vincent Warmerdam>So stuff like that.

01:01:35 <v Vincent Warmerdam>But then what you would never do with a cache is do a group buy

01:01:37 <v Vincent Warmerdam>and then a mean, for example.

01:01:39 <v Vincent Warmerdam>It's like--

01:01:41 <v Michael Kennedy>It's not-- it's outgrown its use at that point.

01:01:43 <v Michael Kennedy>That's for sure.

01:01:45 <v Vincent Warmerdam>Yeah.

01:01:45 <v Vincent Warmerdam>And if it were a part of it, then the docs would say so.

01:01:47 <v Vincent Warmerdam>But like-- no, so in my mind, DuckDB really just <v Vincent Warmerdam>solves a different problem, similar to like general SQLite

01:01:54 <v Vincent Warmerdam>also solves a different problem than disk cache.

01:01:56 <v Vincent Warmerdam>And also Postgres is also solving a slightly different problem.

01:01:59 <v Michael Kennedy>Sure.

01:01:59 <v Vincent Warmerdam>All right, fair.

01:02:00 <v Michael Kennedy>Like the other angle--

01:02:01 <v Michael Kennedy>Yeah?

01:02:02 <v Michael Kennedy>No, go ahead.

01:02:02 <v Michael Kennedy>Finish your thoughts.

01:02:03 <v Vincent Warmerdam>Well, I also really love Postgres, I got to say.

01:02:06 <v Vincent Warmerdam>Like the thing I really like about it <v Vincent Warmerdam>is that it is like boring, but in a good way, software

01:02:09 <v Vincent Warmerdam>where like I have a Postgres thing running there <v Vincent Warmerdam>and whatever SSH thing I need, I can just swap the cloud

01:02:17 <v Vincent Warmerdam>provider and it'll just go ahead and still <v Vincent Warmerdam>run without me having to move the data

01:02:20 <v Vincent Warmerdam>or do any migration or anything like that.

01:02:22 <v Vincent Warmerdam>That is also just like a nice feeling, <v Vincent Warmerdam>but it solves a different problem.

01:02:25 <v Michael Kennedy>Yeah.

01:02:25 <v Michael Kennedy>Yeah.

01:02:26 <v Michael Kennedy>These would very likely be used together, not instead of--

01:02:29 <v Michael Kennedy>I mean, Postgres can be used instead of disk cache, <v Michael Kennedy>but disk cache, definitely not instead of Postgres.

01:02:34 <v Michael Kennedy>So the other one, the other angle I wanted to riff on, have you riff on just a little bit is

01:02:38 <v Michael Kennedy>think people, especially people who are maybe new to this idea of caching, they can end up thinking,

01:02:43 <v Michael Kennedy>okay, I'm going to store stuff. We talked a lot about like, I get something back from the database.

01:02:47 <v Michael Kennedy>I could store that in a cache. So I don't have to query it again or whatever. And those are

01:02:51 <v Michael Kennedy>certainly good use cases. But I think a lot of times an even better use case is if you're going

01:02:55 <v Michael Kennedy>to get 20 rows back from a database, do some Python and construct them along with a little

01:03:00 <v Michael Kennedy>other information into some object.

01:03:03 <v Michael Kennedy>And then that's really what you want to work with.

01:03:04 <v Michael Kennedy>Store that constructed thing in the cache.

01:03:07 <v Michael Kennedy>You know what I mean?

01:03:08 <v Michael Kennedy>Like, as far as you can go down the compute layer, like, don't just stop like, well, it

01:03:12 <v Michael Kennedy>comes back from the database, so we cache it.

01:03:14 <v Michael Kennedy>Like, if there's a way to say it, like, there's a bunch of work after that, think about how

01:03:16 <v Michael Kennedy>you might cache at that level.

01:03:18 <v Vincent Warmerdam>Okay, I'm going to pitch you a dream then.

01:03:21 <v Vincent Warmerdam>Imagine you have a Python notebook and, oh, you're running a cell, you're running a cell,

01:03:26 <v Vincent Warmerdam>you're running a cell, and halfway the kernel dies for whatever weird reason.

01:03:29 <v Michael Kennedy>Right.

01:03:30 <v Vincent Warmerdam>it'd be nice if I could just reboot the notebook and it would just pick it up again and move further.

01:03:33 <v Vincent Warmerdam>Because again, I'm picking something out of a database and I'm doing something little with it

01:03:37 <v Vincent Warmerdam>and processing, processing, processing. But wouldn't it be nice if maybe every cell had a caching mechanism?

01:03:43 <v Vincent Warmerdam>If only you had some influence. If only we're a company that did this kind of stuff.

01:03:51 <v Vincent Warmerdam>You can imagine these are things that we are thinking about. And again, what I'm about to

01:03:55 <v Vincent Warmerdam>suggest is definitely a dream. This is not something that works right now. Don't pin me on this.

01:03:59 <v Vincent Warmerdam>like we're thinking out loud here.

01:04:01 <v Vincent Warmerdam>You can also imagine this being super useful <v Vincent Warmerdam>where an entire team can share the cache.

01:04:05 <v Vincent Warmerdam>Yeah.

01:04:05 <v Vincent Warmerdam>Right?

01:04:06 <v Vincent Warmerdam>So if your colleague already calculated something, <v Vincent Warmerdam>you don't have to recalculate it again.

01:04:10 <v Vincent Warmerdam>There's all sorts of use cases like that as well.

01:04:13 <v Vincent Warmerdam>But there may be, there are these moments <v Vincent Warmerdam>when you want to have very tight manual control

01:04:17 <v Vincent Warmerdam>over what goes into the cache.

01:04:19 <v Vincent Warmerdam>That makes a lot of sense and it's great.

01:04:21 <v Vincent Warmerdam>But there are also moments <v Vincent Warmerdam>when you just really don't want to think about it at all.

01:04:24 <v Vincent Warmerdam>And you just want everything to be cached.

01:04:25 <v Michael Kennedy>Could I just use this thing as a checkpoint?

01:04:28 <v Michael Kennedy>I can autosave as my code runs.

01:04:30 <v Michael Kennedy>Yeah, that's cool.

01:04:31 <v Vincent Warmerdam>Yeah.

01:04:31 <v Vincent Warmerdam>And again, doing this right is hard, <v Vincent Warmerdam>because there's all sorts of weird Python types.

01:04:36 <v Vincent Warmerdam>And I mentioned the progress bar thing.

01:04:38 <v Michael Kennedy>And there's all sorts of things that we've <v Vincent Warmerdam>got to be mindful of here.

01:04:42 <v Vincent Warmerdam>But if you're thinking about really, <v Vincent Warmerdam>how would you use this in data science

01:04:46 <v Vincent Warmerdam>when you fetch a little bit of data and deal with it,

01:04:48 <v Vincent Warmerdam>to me, it is starting to feel more natural <v Vincent Warmerdam>than thinking about cells in a notebook,

01:04:52 <v Vincent Warmerdam>maybe cache on that level.

01:04:53 <v Michael Kennedy>Yeah, that's pretty interesting.

01:04:55 <v Michael Kennedy>just sort of cascade them along as a hash of the hashes

01:05:00 <v Michael Kennedy>of the prior cells or--

01:05:01 <v Vincent Warmerdam>Well, and this is where things become tricky, of course,

01:05:04 <v Vincent Warmerdam>because then, OK, I've got this one cell, <v Vincent Warmerdam>and I change one function in it.

01:05:07 <v Vincent Warmerdam>Oh, if you're going to cache on the entire cell, <v Vincent Warmerdam>oh, everything has to rerun.

01:05:10 <v Vincent Warmerdam>And then, oh, if you're not careful, <v Vincent Warmerdam>your cache is going to be huge.

01:05:13 <v Vincent Warmerdam>So like, OK, how do you do this in a user-friendly way?

01:05:16 <v Vincent Warmerdam>There's all sorts of--

01:05:17 <v Vincent Warmerdam>it sounds easier than it is the one thing I want to say.

01:05:19 <v Michael Kennedy>Yeah, well, I think you've got a better chance <v Michael Kennedy>with Marima than with Jupyter, at least,

01:05:23 <v Michael Kennedy>because you have a dependency graph.

01:05:25 <v Michael Kennedy>So you can at least say, if this one is invalid, <v Michael Kennedy>that means the following three are also invalid,

01:05:32 <v Michael Kennedy>being sort of propagated there.

01:05:33 <v Vincent Warmerdam>Totally.

01:05:34 <v Vincent Warmerdam>But I try to focus a little bit more on the user experience

01:05:38 <v Vincent Warmerdam>side of things.

01:05:38 <v Vincent Warmerdam>And one thing I've really learned from the notebook

01:05:40 <v Vincent Warmerdam>with the progress bar is just there <v Vincent Warmerdam>were moments when I felt like, oh, I just

01:05:44 <v Vincent Warmerdam>want this entire thing to be automated.

01:05:46 <v Vincent Warmerdam>Don't make me think about this.

01:05:47 <v Vincent Warmerdam>And then there were moments where I thought, oh, it's really

01:05:49 <v Vincent Warmerdam>nice to have tight manual control.

01:05:51 <v Vincent Warmerdam>How do I provide you with both?

01:05:53 <v Vincent Warmerdam>Yeah.

01:05:54 <v Vincent Warmerdam>That's quite tricky.

01:05:55 <v Vincent Warmerdam>But it is a dream, so that's something to keep in mind.

01:05:57 <v Michael Kennedy>Yeah, maybe someday there'll be a turn on cash flow checkbox

01:06:01 <v Michael Kennedy>something.

01:06:01 <v Vincent Warmerdam>Yeah, or well, at least till then, <v Vincent Warmerdam>I do think having something that works on disk instead of memory

01:06:07 <v Vincent Warmerdam>these days is also just a boon.

01:06:10 <v Michael Kennedy>Right.

01:06:10 <v Michael Kennedy>So this works in data science notebooks.

01:06:12 <v Michael Kennedy>It works in web apps.

01:06:13 <v Michael Kennedy>It works in little TUIs.

01:06:15 <v Michael Kennedy>It doesn't care.

01:06:16 <v Vincent Warmerdam>It works with LLMs.

01:06:19 <v Vincent Warmerdam>And if you have a kind of--

01:06:20 <v Vincent Warmerdam>actually, similar to your set of, <v Vincent Warmerdam>If you have multiple processes with your web app running on one VM,

01:06:25 <v Vincent Warmerdam>if you have one big VM that you share with your colleagues,

01:06:27 <v Vincent Warmerdam>you can also just share the cache, actually.

01:06:29 <v Michael Kennedy>Yeah, that's true.

01:06:30 <v Michael Kennedy>So that's the reason you can't just point the same file, yeah.

01:06:32 <v Vincent Warmerdam>Yeah, and especially if you're doing like big experiments

01:06:34 <v Vincent Warmerdam>like grid search results or stuff like that, <v Vincent Warmerdam>that you really don't want to recalculate the big compute thing.

01:06:39 <v Vincent Warmerdam>That's actually not too unreasonable.

01:06:41 <v Michael Kennedy>Yeah, that's cool.

01:06:42 <v Michael Kennedy>Yeah, if you have a shared Jupyter server.

01:06:44 <v Vincent Warmerdam>Yeah, and a bunch of universities have that, right?

01:06:47 <v Michael Kennedy>Yeah, exactly.

01:06:48 <v Michael Kennedy>I don't want to go down this path because we're basically out of time.

01:06:51 <v Michael Kennedy>I respect your time.

01:06:52 <v Michael Kennedy>However, I do think there's a whole interesting conversation to be had about like, how do you

01:06:57 <v Michael Kennedy>choose the right key for your, what goes into the cache?

01:07:01 <v Michael Kennedy>Because you can end up with staleness really easy if something changes.

01:07:05 <v Michael Kennedy>But if you incorporate the right stuff, you might never run into stale data problems because,

01:07:11 <v Michael Kennedy>you know, like for example, I talked about the YouTube ID.

01:07:15 <v Michael Kennedy>Basically the cache key is something like episode, episode data, episode YouTube thing,

01:07:20 <v Michael Kennedy>colon YouTube, colon the hash of the show notes, right?

01:07:25 <v Michael Kennedy>Something like that, where there's no way <v Michael Kennedy>that the show notes are gonna change

01:07:28 <v Michael Kennedy>and I'll get the old data because guess what?

01:07:32 <v Michael Kennedy>It's constructed out of the source, right?

01:07:34 <v Michael Kennedy>Things like that.

01:07:35 <v Michael Kennedy>There's probably a lot, especially like in your notebook side.

01:07:39 <v Michael Kennedy>There's a lot to consider there, I think.

01:07:41 <v Vincent Warmerdam>- Yeah, I mean, so I remember this one thing <v Vincent Warmerdam>with the course where I still wanted it to be cached,

01:07:46 <v Vincent Warmerdam>but I wanted to have like text goes in <v Vincent Warmerdam>And then five responses from the LLM go out.

01:07:51 <v Vincent Warmerdam>And the way you solve that is you just add another key.

01:07:53 <v Vincent Warmerdam>But you have to be mindful of the cache key.

01:07:55 <v Vincent Warmerdam>And you can-- oh, and you can use tuples, by the way.

01:07:57 <v Vincent Warmerdam>That's also something you can totally use as a cache key.

01:07:58 <v Michael Kennedy>Right, right.

01:07:59 <v Vincent Warmerdam>So that was easy to fix.

01:08:01 <v Vincent Warmerdam>It's just that you have to be mindful.

01:08:02 <v Michael Kennedy>Yeah, that's kind of-- I want to give a quick shout out to that.

01:08:05 <v Michael Kennedy>I want to leave--

01:08:06 <v Michael Kennedy>I don't want to leave on a sour note.

01:08:08 <v Michael Kennedy>But I think it's necessary to give this shout out, <v Michael Kennedy>or this like call this out, rather, is the way I should say it,

01:08:14 <v Michael Kennedy>is I think this project is awesome.

01:08:15 <v Michael Kennedy>You think it's awesome.

01:08:17 <v Michael Kennedy>Honestly, I think it doesn't need really very much.

01:08:19 <v Michael Kennedy>But if you look at last updated, <v Michael Kennedy>if you look at the last updated date,

01:08:24 <v Michael Kennedy>it's really, it hasn't got a lot of attention <v Michael Kennedy>in the last six months or something like that.

01:08:29 <v Vincent Warmerdam>Yeah, and if I look at PyPI, <v Vincent Warmerdam>the last release was 2023,

01:08:34 <v Vincent Warmerdam>which, yeah, a year and a half ago.

01:08:36 <v Michael Kennedy>Yeah, and it's okay to, <v Michael Kennedy>I would like to say that it's okay for things to be done.

01:08:40 <v Michael Kennedy>It doesn't have to, things don't have to change, <v Michael Kennedy>but there's also a decent amount of,

01:08:45 <v Michael Kennedy>like conversations on the issues and they haven't, you know,

01:08:48 <v Michael Kennedy>like a couple of days ago, actually someone asked about this, but you know,

01:08:52 <v Michael Kennedy>the last change, I believe the guy Grant who works on it,

01:08:57 <v Michael Kennedy>started working at open AI about the time changes stopped going on.

01:09:02 <v Michael Kennedy>I'm not entirely sure. I feel like I could be confused with another project.

01:09:06 <v Michael Kennedy>So Grant, if that's not true, I apologize, but I think that it is.

01:09:11 <v Michael Kennedy>Pretty sure that is. Do we have LinkedIn?

01:09:13 <v Vincent Warmerdam>I mean, I am comfortable stating is--

01:09:16 <v Vincent Warmerdam>let me put it this way.

01:09:18 <v Vincent Warmerdam>Yes, my colleague might make a different caching mechanism.

01:09:21 <v Vincent Warmerdam>And yes, I might use that at some point.

01:09:22 <v Vincent Warmerdam>But at least for where I'm at right now, <v Vincent Warmerdam>this cache needs to break vividly in front of my face

01:09:28 <v Vincent Warmerdam>for me to consider not using it.

01:09:30 <v Vincent Warmerdam>Because it does feel like it's done in a really good way.

01:09:33 <v Vincent Warmerdam>The main thing that needs to happen, I think, <v Vincent Warmerdam>functionally to make sure this doesn't get deprecated too

01:09:38 <v Vincent Warmerdam>badly is just you got to update the Python version.

01:09:40 <v Vincent Warmerdam>When a new Python version comes out, <v Vincent Warmerdam>you got to update PyPI to confirm,

01:09:43 <v Vincent Warmerdam>like, OK, we do support this Python version.

01:09:45 <v Vincent Warmerdam>But I mean, most of the--

01:09:48 <v Vincent Warmerdam>if you look at the area that needs to be covered, <v Vincent Warmerdam>a lot of that has been covered by SQLite.

01:09:51 <v Vincent Warmerdam>And that thing is definitely still being maintained.

01:09:54 <v Michael Kennedy>It's getting mega maintained.

01:09:56 <v Michael Kennedy>That's right.

01:09:57 <v Michael Kennedy>So I also don't see the problem.

01:09:59 <v Michael Kennedy>I'm not going to not use it.

01:10:01 <v Michael Kennedy>I just want to put it out there on the radar for people

01:10:04 <v Michael Kennedy>for whom my co-look is to go, oh, Michael and Vincent

01:10:06 <v Michael Kennedy>were so psyched, and I started to use this.

01:10:08 <v Michael Kennedy>And now I'm really disappointed because of whatever.

01:10:10 <v Michael Kennedy>I saw this.

01:10:11 <v Vincent Warmerdam>I mean, the only real doom scenario I can come up with

01:10:14 <v Vincent Warmerdam>is if SQLite made like a breaking change.

01:10:16 <v Vincent Warmerdam>That's the only thing I can kind of come up with.

01:10:18 <v Michael Kennedy>But the odds of that seem very low.

01:10:20 <v Michael Kennedy>Yeah, and it's on GitHub.

01:10:21 <v Michael Kennedy>You can fork it.

01:10:22 <v Michael Kennedy>I fork it.

01:10:22 <v Michael Kennedy>Exactly, exactly.

01:10:23 <v Michael Kennedy>So, no, I definitely am still super excited about it.

01:10:27 <v Michael Kennedy>I just want to make sure that we put that out there.

01:10:29 <v Michael Kennedy>I'd intended to talk about it sooner in the conversation,

01:10:32 <v Michael Kennedy>but you know what?

01:10:33 <v Michael Kennedy>We were just so excited.

01:10:34 <v Vincent Warmerdam>Yeah, no.

01:10:36 <v Vincent Warmerdam>This is definitely in my top five favorite Python libraries

01:10:38 <v Vincent Warmerdam>outside of the standard lib.

01:10:40 <v Vincent Warmerdam>Awesome.

01:10:40 <v Michael Kennedy>Yeah, I've really, really have gotten awesome results out of it as well.

01:10:43 <v Michael Kennedy>So remember the way we opened the show and you talked about this,

01:10:45 <v Michael Kennedy>like when we talked about the LLM building block stuff

01:10:48 <v Michael Kennedy>on the previous time you were on the show, <v Michael Kennedy>it was like, oh, we better not go too deep on this,

01:10:53 <v Michael Kennedy>even though we're both so excited because it's going to derail the show.

01:10:56 <v Michael Kennedy>We're now one hour and 15 minutes into it.

01:10:58 <v Michael Kennedy>We kind of cut ourselves off.

01:11:00 <v Michael Kennedy>I think that was accurate.

01:11:02 <v Vincent Warmerdam>Yeah, I mean, you get two dads making dad jokes <v Vincent Warmerdam>and riffing on tools they both like.

01:11:06 <v Vincent Warmerdam>It's bound to exceed a barbecue.

01:11:10 <v Michael Kennedy>Yes, I know.

01:11:11 <v Michael Kennedy>I wonder what would happen if sometime we just removed the time limit,

01:11:15 <v Michael Kennedy>just got real comfortable and just riffed on something.

01:11:17 <v Michael Kennedy>It could be hours.

01:11:18 <v Michael Kennedy>It would be fun.

01:11:18 <v Michael Kennedy>But maybe not today.

01:11:20 <v Michael Kennedy>Two-hour live streams exist, Michael.

01:11:22 <v Michael Kennedy>I know.

01:11:24 <v Michael Kennedy>I've listened to some podcasts at over three hours.

01:11:26 <v Michael Kennedy>I'm like, how is this still going?

01:11:27 <v Michael Kennedy>But you know what?

01:11:28 <v Michael Kennedy>Yeah.

01:11:28 <v Michael Kennedy>It's all good.

01:11:29 <v Vincent Warmerdam>But yeah, this is a good point in time.

01:11:32 <v Michael Kennedy>We're both excited.

01:11:33 <v Michael Kennedy>That's the summary.

01:11:34 <v Michael Kennedy>That is the summary.

01:11:35 <v Michael Kennedy>And I think I'm going to let you have the final word on this topic here.

01:11:39 <v Michael Kennedy>like maybe speak to people just about caching in general

01:11:42 <v Michael Kennedy>and disk cache in particular as we close it out?

01:11:45 <v Vincent Warmerdam>I mean, I guess the main thing that I learned <v Vincent Warmerdam>with the whole caching thing in the last couple of years,

01:11:49 <v Vincent Warmerdam>I always thought it was kind of like a web thing.

01:11:52 <v Vincent Warmerdam>Like, oh, you know, front page of Reddit, <v Vincent Warmerdam>that thing has to be cached.

01:11:55 <v Vincent Warmerdam>That's the way you think about it.

01:11:55 <v Vincent Warmerdam>Yeah, of course.

01:11:56 <v Vincent Warmerdam>And thinking about it too much that way <v Vincent Warmerdam>totally blocked me from considering, like, oh,

01:12:00 <v Vincent Warmerdam>but if you do stuff in notebooks and data science land,

01:12:02 <v Vincent Warmerdam>then you need this as well.

01:12:03 <v Vincent Warmerdam>And I think there's actually a little emerging discovery

01:12:07 <v Vincent Warmerdam>phenomenon happening where people that do things <v Vincent Warmerdam>LLM's at some point go like, oh, I need a cache.

01:12:11 <v Vincent Warmerdam>And then, oh.

01:12:15 <v Vincent Warmerdam>So that's the main thing I suppose I want to say.

01:12:16 <v Vincent Warmerdam>Like, even if you're doing more data stuff, <v Vincent Warmerdam>like give this disk cache thing a try.

01:12:19 <v Vincent Warmerdam>It's just good.

01:12:20 <v Michael Kennedy>Yeah, it's so easy to adopt and try out.

01:12:23 <v Michael Kennedy>Like, you can throw it in there.

01:12:24 <v Michael Kennedy>Just add a decorator.

01:12:26 <v Michael Kennedy>Exactly, see what you get.

01:12:27 <v Michael Kennedy>See what you get.

01:12:28 <v Michael Kennedy>All right, Vincent, welcome.

01:12:30 <v Michael Kennedy>Oh, thank you for coming back.

01:12:31 <v Michael Kennedy>I really appreciate it.

01:12:32 <v Michael Kennedy>Thanks for having me.

01:12:33 <v Michael Kennedy>Always good to talk to you.

01:12:34 <v Michael Kennedy>Yeah.

01:12:34 <v Vincent Warmerdam>And yeah, see you next time when we, again, <v Vincent Warmerdam>find out there's a cool Python library.

01:12:38 <v Michael Kennedy>Yeah, that's going to be the three-hour episode.

01:12:41 <v Michael Kennedy>Watch out, y'all.

01:12:43 <v Michael Kennedy>Have a good one.

01:12:44 <v Michael Kennedy>Later.

01:12:45 <v Michael Kennedy>This has been another episode of Talk Python To Me.

01:12:48 <v Michael Kennedy>Thank you to our sponsors.

01:12:49 <v Michael Kennedy>Be sure to check out what they're offering.

01:12:50 <v Michael Kennedy>It really helps support the show.

01:12:52 <v Michael Kennedy>If you or your team needs to learn Python, <v Michael Kennedy>we have over 270 hours of beginner and advanced courses

01:12:58 <v Michael Kennedy>on topics ranging from complete beginners to async code,

01:13:02 <v Michael Kennedy>Flask, Django, HTMX, and even LLMs.

01:13:05 <v Michael Kennedy>Best of all, there's no subscription in sight.

01:13:08 <v Michael Kennedy>browse the catalog at talkpython.fm.

01:13:10 <v Michael Kennedy>And if you're not already subscribed to the show <v Michael Kennedy>on your favorite podcast player,

01:13:14 <v Michael Kennedy>what are you waiting for?

01:13:15 <v Michael Kennedy>Just search for Python in your podcast player.

01:13:17 <v Michael Kennedy>We should be right at the top.

01:13:19 <v Michael Kennedy>If you enjoyed that geeky rap song, <v Michael Kennedy>you can download the full track.

01:13:22 <v Michael Kennedy>The link is actually in your podcast blur show notes.

01:13:24 <v Michael Kennedy>This is your host, Michael Kennedy.

01:13:26 <v Michael Kennedy>Thank you so much for listening.

01:13:27 <v Michael Kennedy>I really appreciate it.

01:13:28 <v Michael Kennedy>I'll see you next time.

01:13:41 I'm out.

